{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Import Packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "################################################################################\n",
    "# NUMPY\n",
    "# conda install numpy\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "################################################################################\n",
    "# MATPLOTLIB\n",
    "# conda install matplotlib\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "################################################################################\n",
    "# SEABORN\n",
    "# conda install seaborn\n",
    "\n",
    "import seaborn as sns\n",
    "\n",
    "################################################################################\n",
    "# PYLTTB - Time Series Downsampling Using Largest-Triangle-Three-Buckets\n",
    "# pip install pylttb\n",
    "\n",
    "from pylttb import lttb\n",
    "\n",
    "################################################################################\n",
    "# NEO\n",
    "# pip install git+https://github.com/NeuralEnsemble/python-neo.git\n",
    "# - AxoGraph support requires axographio to be installed: pip install axographio\n",
    "\n",
    "# import neo\n",
    "\n",
    "################################################################################\n",
    "# QUANTITIES\n",
    "# conda install quantities\n",
    "\n",
    "import quantities as pq\n",
    "pq.markup.config.use_unicode = True  # allow symbols like mu for micro in output\n",
    "pq.mN = pq.UnitQuantity('millinewton', pq.N/1e3, symbol = 'mN');  # define millinewton\n",
    "\n",
    "################################################################################\n",
    "# ELEPHANT\n",
    "# pip install elephant\n",
    "\n",
    "import elephant\n",
    "\n",
    "################################################################################\n",
    "# PANDAS\n",
    "# conda install pandas\n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "################################################################################\n",
    "# STATSMODELS\n",
    "# conda install statsmodels\n",
    "\n",
    "import statsmodels.api as sm\n",
    "\n",
    "################################################################################\n",
    "# SPM1D - One-Dimensional Statistical Parametric Mapping\n",
    "# pip install spm1d\n",
    "\n",
    "# import spm1d\n",
    "\n",
    "################################################################################\n",
    "# EPHYVIEWER\n",
    "# pip install git+https://github.com/jpgill86/ephyviewer.git@experimental\n",
    "# - requires PyAV: conda install -c conda-forge av\n",
    "\n",
    "# import ephyviewer\n",
    "\n",
    "################################################################################\n",
    "# ParseMetadata\n",
    "# - requires ipywidgets: conda install ipywidgets\n",
    "# - requires yaml:       conda install pyyaml\n",
    "\n",
    "from ParseMetadata import LoadMetadata\n",
    "\n",
    "################################################################################\n",
    "# ImportData\n",
    "\n",
    "from ImportData import LoadAndPrepareData\n",
    "\n",
    "################################################################################\n",
    "# NeoUtilities\n",
    "\n",
    "from NeoUtilities import NeoAnalogSignalDerivative, NeoAnalogSignalRAUC, CausalAlphaKernel\n",
    "\n",
    "################################################################################\n",
    "# NeoToEphyviewerBridge\n",
    "\n",
    "# from NeoToEphyviewerBridge import NeoSegmentToEphyviewerSources#, PlotExampleWithEphyviewer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# IPython Magics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# make figures interactive and open in a separate window\n",
    "# %matplotlib qt\n",
    "\n",
    "# make figures interactive and inline\n",
    "%matplotlib notebook\n",
    "\n",
    "# make figures non-interactive and inline\n",
    "# %matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# specify the data sets to analyze\n",
    "data_sets = [\n",
    "    '2018-06-21_IN-VIVO_JG-08 002',\n",
    "#     '2018-06-24_IN-VIVO_JG-08 001',\n",
    "]\n",
    "\n",
    "# load the metadata containing file paths\n",
    "all_metadata = LoadMetadata()\n",
    "\n",
    "# store metadata in a dictionary that we will add to later\n",
    "data = {}\n",
    "for data_set_name in data_sets:\n",
    "    data[data_set_name] = {}\n",
    "    data[data_set_name]['metadata'] = all_metadata[data_set_name]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# select which swallow sequences to use\n",
    "\n",
    "data['2018-06-21_IN-VIVO_JG-08 002']['time_windows_to_keep'] = [\n",
    "    [-np.inf, np.inf], # keep everything\n",
    "#     [659, 726.1], # tension maximized and no perturbation\n",
    "#     [666.95, 726.1], # tension maximized and no perturbation, and extra long large hump excluded\n",
    "]\n",
    "\n",
    "# data['2018-06-24_IN-VIVO_JG-08 001']['time_windows_to_keep'] = [\n",
    "# #     [-np.inf, np.inf], # keep everything\n",
    "#     [2244.7, 2259.9], [2269.5, 2355.95], # tension maximized and no perturbation\n",
    "# #     [2244.7, 2259.9], [2269.5, 2290.2], [2307, 2355.95], # tension maximized and no perturbation, and extra long large hump excluded\n",
    "# ]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Import the Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for data_set_name, d in data.items():\n",
    "\n",
    "    # read in the data\n",
    "    blk = LoadAndPrepareData(d['metadata'])\n",
    "\n",
    "    # grab the force vs time data and rescale to mN\n",
    "    signalNameToAxoGraphIndex = {sig.name:i for i, sig in enumerate(blk.segments[0].analogsignals)}\n",
    "    force_idx = signalNameToAxoGraphIndex.get('Force', None)\n",
    "    assert(force_idx is not None)\n",
    "    d['force_sig'] = blk.segments[0].analogsignals[force_idx].rescale('mN')\n",
    "\n",
    "    # grab the spike trains\n",
    "    spike_trains = {}\n",
    "    for st in blk.segments[0].spiketrains:\n",
    "        spike_trains[st.name] = st\n",
    "    d['spike_trains'] = spike_trains\n",
    "\n",
    "    # grab the sampling period\n",
    "    d['sampling_period'] = blk.segments[0].analogsignals[0].sampling_period\n",
    "\n",
    "#     display(blk)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for data_set_name, d in data.items():\n",
    "    \n",
    "    # grab the output force timing data\n",
    "    epochs_df = pd.read_csv(d['metadata']['epoch_encoder_file'])\n",
    "    \n",
    "    # compute end times\n",
    "    epochs_df = epochs_df.assign(**{\n",
    "        'end': lambda e: e['time'] + e['duration'],\n",
    "    })\n",
    "    \n",
    "    # copy middle times (end of large hump and start of small hump) into 'force' epochs\n",
    "    for i, epoch in epochs_df[epochs_df['label'] == 'force'].iterrows():\n",
    "        for j, subepoch in epochs_df[epochs_df['label'] == 'large hump'].iterrows():\n",
    "            if subepoch['time'] >= epoch['time']-1e-7 and subepoch['end'] <= epoch['end']+1e-7:\n",
    "                epochs_df.loc[i, 'middle'] = subepoch['end']\n",
    "    \n",
    "    # find max forces in each epoch\n",
    "    for i, epoch in epochs_df[epochs_df['label'] == 'force'].iterrows():\n",
    "        epochs_df.loc[i, 'large max'] = max(d['force_sig'].time_slice(epoch['time']  *pq.s, epoch['middle']*pq.s).magnitude)[0]\n",
    "        epochs_df.loc[i, 'small max'] = max(d['force_sig'].time_slice(epoch['middle']*pq.s, epoch['end']   *pq.s).magnitude)[0]\n",
    "    \n",
    "    # drop all but 'force' rows\n",
    "    epochs_df = epochs_df[epochs_df['label'] == 'force']\n",
    "    \n",
    "    # keep only epochs that are entirely inside the time windows\n",
    "    epochs_df = epochs_df[np.any(list(map(lambda t: (t[0] <= epochs_df['time']) & (epochs_df['end'] <= t[1]), d['time_windows_to_keep'])), axis=0)]\n",
    "    \n",
    "    # colors\n",
    "    epochs_df = epochs_df.assign(colormap_arg = np.linspace(0, 1, len(epochs_df)))\n",
    "    \n",
    "    d['epochs_df'] = epochs_df\n",
    "    \n",
    "#     print(data_set_name)\n",
    "#     display(epochs_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Plots"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# color map\n",
    "cm = plt.cm.cool\n",
    "# cm = plt.cm.brg\n",
    "# cm = plt.cm.RdBu"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Figure 1: Plot forces across real time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plt.figure(1, figsize=(9,4))\n",
    "# for i, data_set_name in enumerate(data_sets):\n",
    "#     d = data[data_set_name]\n",
    "#     plt.subplot(1, len(data), i+1)\n",
    "#     plt.title(data_set_name)\n",
    "#     plt.ylabel('Force (mN)')\n",
    "#     plt.xlabel('Original chart time (s)')\n",
    "#     for j, epoch in d['epochs_df'].iterrows():\n",
    "#         epoch_force_sig = d['force_sig'].time_slice(epoch['time']*pq.s, epoch['end']*pq.s)\n",
    "#         plt.plot(epoch_force_sig.times, epoch_force_sig.as_array(), color=cm(epoch['colormap_arg']))\n",
    "# plt.tight_layout()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Figure 2: Plot forces, spike trains, and firing rate models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# spike_labels = d['spike_trains'].keys()\n",
    "spike_labels = [\n",
    "#     'I2',\n",
    "#     'B8a/b',\n",
    "#     'B3 (50-100 uV)',\n",
    "#     '? (45-50 uV)',\n",
    "#     'B6/B9 ? (26-45 uV)',\n",
    "    'B38 ? (17-26 uV)',\n",
    "#     '? (15-17 uV)',\n",
    "#     'B4/B5',\n",
    "]\n",
    "\n",
    "plt.figure(2, figsize=(9,2+2*len(spike_labels)))\n",
    "for i, data_set_name in enumerate(data_sets):\n",
    "    d = data[data_set_name]\n",
    "\n",
    "    # === FORCE ===\n",
    "    ax = plt.subplot(len(spike_labels)+1, len(data), 2*i+1)\n",
    "    plt.title(data_set_name)\n",
    "    plt.ylabel('Force (mN)')\n",
    "    plt.xlabel('Time (s)')\n",
    "    plt.xlim(min(d['epochs_df']['time']), max(d['epochs_df']['end']))\n",
    "\n",
    "    for j, epoch in d['epochs_df'].iterrows():\n",
    "        epoch_force_sig = d['force_sig'].time_slice(epoch['time']*pq.s, epoch['end']*pq.s)\n",
    "        plt.plot(epoch_force_sig.times, epoch_force_sig.as_array(), color=cm(epoch['colormap_arg']))\n",
    "\n",
    "    # === RASTER PLOTS + RATE MODELS ===\n",
    "    for j, spike_label in enumerate(spike_labels):\n",
    "        st = d['spike_trains'][spike_label]\n",
    "        st = st.time_slice(\n",
    "            min(d['epochs_df']['time'])*pq.s - 5*pq.s,\n",
    "            max(d['epochs_df']['end'])*pq.s  + 5*pq.s\n",
    "        ) # drop spikes outside plot range except for a few sec margin so beginning and final firing rates are accurate\n",
    "\n",
    "        plt.subplot(len(spike_labels)+1, len(data), 2*i+2+j, sharex=ax)\n",
    "        plt.ylabel(spike_label + '\\n(rate model)')\n",
    "        plt.xlabel('Time (s)')\n",
    "        plt.xlim(min(d['epochs_df']['time']), max(d['epochs_df']['end']))\n",
    "        plt.ylim([-2, 40])\n",
    "\n",
    "        # raster plot\n",
    "        plt.eventplot(positions=st, lineoffsets=-1, colors='red')\n",
    "\n",
    "        # spike train convolution\n",
    "        kernels = [\n",
    "            CausalAlphaKernel(0.03*np.sqrt(2)*pq.s), # match my old poster's synapse model\n",
    "#             CausalAlphaKernel(0.2*pq.s),\n",
    "#             elephant.kernels.AlphaKernel(0.03*np.sqrt(2)*pq.s),\n",
    "#             elephant.kernels.AlphaKernel(0.2*pq.s),\n",
    "#             elephant.kernels.EpanechnikovLikeKernel(0.2*pq.s),\n",
    "#             elephant.kernels.ExponentialKernel(0.2*pq.s),\n",
    "            elephant.kernels.GaussianKernel(0.2*pq.s),\n",
    "#             elephant.kernels.LaplacianKernel(0.2*pq.s),\n",
    "#             elephant.kernels.RectangularKernel(0.2*pq.s),\n",
    "#             elephant.kernels.TriangularKernel(0.2*pq.s)\n",
    "        ]\n",
    "        for kernel in kernels:\n",
    "            rate = elephant.statistics.instantaneous_rate(\n",
    "                spiketrain=st, sampling_period=d['sampling_period'], kernel=kernel)\n",
    "            plt.plot(rate.times.rescale('s'), rate)\n",
    "\n",
    "        # instantaneous firing frequency step plot\n",
    "#         plt.plot(st[:-1], 1/elephant.statistics.isi(st), drawstyle='steps-post')\n",
    "\n",
    "plt.tight_layout()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
