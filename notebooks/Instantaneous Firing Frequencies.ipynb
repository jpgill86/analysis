{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Import Packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import quantities as pq\n",
    "import elephant\n",
    "import statsmodels.api as sm\n",
    "import neurotic\n",
    "from neurotic.gui.config import _neo_epoch_to_dataframe\n",
    "from utils import CausalAlphaKernel\n",
    "\n",
    "pq.markup.config.use_unicode = True  # allow symbols like mu for micro in output\n",
    "pq.mN = pq.UnitQuantity('millinewton', pq.N/1e3, symbol = 'mN');  # define millinewton"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# IPython Magics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# make figures interactive and open in a separate window\n",
    "# %matplotlib qt\n",
    "\n",
    "# make figures interactive and inline\n",
    "%matplotlib notebook\n",
    "\n",
    "# make figures non-interactive and inline\n",
    "# %matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# specify the data sets to analyze\n",
    "data_sets = [\n",
    "    'IN VIVO / JG08 / 2018-06-21 / 002',\n",
    "    'IN VIVO / JG08 / 2018-06-24 / 001',\n",
    "    'IN VIVO / JG12 / 2019-05-10 / 002',\n",
    "]\n",
    "\n",
    "# load the metadata containing file paths\n",
    "metadata = neurotic.MetadataSelector(file='../../data/metadata.yml')\n",
    "\n",
    "# store metadata in a dictionary that we will add to later\n",
    "data = {}\n",
    "for data_set_name in data_sets:\n",
    "    metadata.select(data_set_name)\n",
    "    data[data_set_name] = {}\n",
    "    data[data_set_name]['metadata'] = metadata.selected_metadata"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# select which swallow sequences to use\n",
    "\n",
    "data['IN VIVO / JG08 / 2018-06-21 / 002']['time_windows_to_keep'] = [\n",
    "#     [-np.inf, np.inf], # keep everything\n",
    "    [659, 726.1], # tension maximized and no perturbation\n",
    "#     [666.95, 726.1], # tension maximized and no perturbation, and extra long large hump excluded\n",
    "#     [666.95, 705], # sequence of 5 very stereotyped swallows\n",
    "]\n",
    "\n",
    "data['IN VIVO / JG08 / 2018-06-24 / 001']['time_windows_to_keep'] = [\n",
    "#     [-np.inf, np.inf], # keep everything\n",
    "    [2244.7, 2259.9], [2269.5, 2355.95], # tension maximized and no perturbation\n",
    "#     [2244.7, 2259.9], [2269.5, 2290.2], [2307, 2355.95], # tension maximized and no perturbation, and extra long large hump excluded\n",
    "    \n",
    "#     [3932, 3990],\n",
    "#     [2232, 2356], [2743, 2940], [3095, 3140], [3385, 3425], [3570, 3594], [3923, 3990]\n",
    "]\n",
    "\n",
    "data['IN VIVO / JG12 / 2019-05-10 / 002']['time_windows_to_keep'] = [\n",
    "#     [-np.inf, np.inf], # keep everything\n",
    "#     [430, 525],\n",
    "    [430, 580],\n",
    "#     [2890, 2946],#[2890, 3085],\n",
    "]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Import and Process the Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for data_set_name, d in data.items():\n",
    "\n",
    "    # read in the data\n",
    "    blk = neurotic.load_dataset(d['metadata'])\n",
    "#     signalNameToIndex = {sig.name:i for i, sig in enumerate(blk.segments[0].analogsignals)}\n",
    "    signalNameToIndex = {sig.name.replace('-L','').replace('-PROX',''):i for i, sig in enumerate(blk.segments[0].analogsignals)}\n",
    "\n",
    "    # grab the force vs time data and rescale to mN\n",
    "    d['force_sig'] = blk.segments[0].analogsignals[signalNameToIndex['Force']].rescale('mN')\n",
    "\n",
    "    # apply a super-low-pass filter to force signal\n",
    "    d['smoothed_force_sig'] = elephant.signal_processing.butter(  # may raise a FutureWarning\n",
    "        signal = d['force_sig'],\n",
    "        lowpass_freq = 0.5*pq.Hz,\n",
    "    )\n",
    "\n",
    "    # calculate the derivative of the force vs time data and smooth it\n",
    "    d['dforce/dt'] = elephant.signal_processing.butter(  # may raise a FutureWarning\n",
    "        signal = elephant.signal_processing.derivative(d['force_sig']),\n",
    "        lowpass_freq = 2*pq.Hz,\n",
    "    ).rescale('mN/s')\n",
    "\n",
    "    # grab the voltage vs time data and rescale to uV\n",
    "    d['i2_sig']  = blk.segments[0].analogsignals[signalNameToIndex['I2']].rescale('uV')\n",
    "    d['rn_sig']  = blk.segments[0].analogsignals[signalNameToIndex['RN']].rescale('uV')\n",
    "    d['bn2_sig'] = blk.segments[0].analogsignals[signalNameToIndex['BN2']].rescale('uV')\n",
    "    d['bn3_sig'] = blk.segments[0].analogsignals[signalNameToIndex['BN3']].rescale('uV')\n",
    "\n",
    "    # grab the spike trains\n",
    "    spike_trains = {}\n",
    "    for st in blk.segments[0].spiketrains:\n",
    "        spike_trains[st.name] = st\n",
    "    d['spike_trains'] = spike_trains\n",
    "\n",
    "    # grab the sampling period\n",
    "    d['sampling_period'] = blk.segments[0].analogsignals[0].sampling_period\n",
    "\n",
    "    # keep only epochs that are entirely inside the time windows\n",
    "    epochs_df = _neo_epoch_to_dataframe(blk.segments[0].epochs)\n",
    "    epochs_df = epochs_df[np.any(list(map(lambda t: (t[0] <= epochs_df['Start (s)']) & (epochs_df['End (s)'] <= t[1]), d['time_windows_to_keep'])), axis=0)]\n",
    "\n",
    "    # copy middle times (end of large hump and start of small hump) into 'force' epochs\n",
    "    for i, epoch in epochs_df[epochs_df['Type'] == 'force'].iterrows():\n",
    "        for j, subepoch in epochs_df[epochs_df['Type'] == 'large hump'].iterrows():\n",
    "            if subepoch['Start (s)'] >= epoch['Start (s)']-1e-7 and subepoch['End (s)'] <= epoch['End (s)']+1e-7:\n",
    "                epochs_df.loc[i, 'Middle (s)'] = subepoch['End (s)']\n",
    "\n",
    "    # drop all but 'force' rows\n",
    "    epochs_df = epochs_df[epochs_df['Type'] == 'force']\n",
    "\n",
    "    # find max forces in each epoch\n",
    "    for i, epoch in epochs_df.iterrows():\n",
    "        epochs_df.loc[i,                'max'] = max(         d['force_sig'].time_slice(epoch['Start (s)'] *pq.s, epoch['End (s)']   *pq.s).magnitude)[0]\n",
    "        epochs_df.loc[i,          'large max'] = max(         d['force_sig'].time_slice(epoch['Start (s)'] *pq.s, epoch['Middle (s)']*pq.s).magnitude)[0] if not np.isnan(epoch.get('Middle (s)', np.nan)) else np.nan\n",
    "        epochs_df.loc[i,          'small max'] = max(         d['force_sig'].time_slice(epoch['Middle (s)']*pq.s, epoch['End (s)']   *pq.s).magnitude)[0] if not np.isnan(epoch.get('Middle (s)', np.nan)) else np.nan\n",
    "        epochs_df.loc[i, 'smoothed large max'] = max(d['smoothed_force_sig'].time_slice(epoch['Start (s)'] *pq.s, epoch['Middle (s)']*pq.s).magnitude)[0] if not np.isnan(epoch.get('Middle (s)', np.nan)) else np.nan\n",
    "        epochs_df.loc[i, 'smoothed small max'] = max(d['smoothed_force_sig'].time_slice(epoch['Middle (s)']*pq.s, epoch['End (s)']   *pq.s).magnitude)[0] if not np.isnan(epoch.get('Middle (s)', np.nan)) else np.nan\n",
    "\n",
    "    # find rectified area under the curve (RAUC) in each epoch\n",
    "    for i, epoch in epochs_df.iterrows():\n",
    "        epochs_df.loc[i,            'force RAUC'] = elephant.signal_processing.rauc(d['force_sig'].time_slice(epoch['Start (s)'] *pq.s, epoch['End (s)']   *pq.s))                   .rescale('mN*s')\n",
    "        epochs_df.loc[i, 'large hump force RAUC'] = elephant.signal_processing.rauc(d['force_sig'].time_slice(epoch['Start (s)'] *pq.s, epoch['Middle (s)']*pq.s))                   .rescale('mN*s') if not np.isnan(epoch.get('Middle (s)', np.nan)) else np.nan\n",
    "        epochs_df.loc[i, 'small hump force RAUC'] = elephant.signal_processing.rauc(d['force_sig'].time_slice(epoch['Middle (s)']*pq.s, epoch['End (s)']   *pq.s))                   .rescale('mN*s') if not np.isnan(epoch.get('Middle (s)', np.nan)) else np.nan\n",
    "        epochs_df.loc[i,               'I2 RAUC'] = elephant.signal_processing.rauc(d['i2_sig']   .time_slice(epoch['Start (s)'] *pq.s, epoch['End (s)']   *pq.s), baseline = 'mean').rescale('uV*s')\n",
    "        epochs_df.loc[i,               'RN RAUC'] = elephant.signal_processing.rauc(d['rn_sig']   .time_slice(epoch['Start (s)'] *pq.s, epoch['End (s)']   *pq.s), baseline = 'mean').rescale('uV*s')\n",
    "        epochs_df.loc[i,              'BN2 RAUC'] = elephant.signal_processing.rauc(d['bn2_sig']  .time_slice(epoch['Start (s)'] *pq.s, epoch['End (s)']   *pq.s), baseline = 'mean').rescale('uV*s')\n",
    "        epochs_df.loc[i,              'BN3 RAUC'] = elephant.signal_processing.rauc(d['bn3_sig']  .time_slice(epoch['Start (s)'] *pq.s, epoch['End (s)']   *pq.s), baseline = 'mean').rescale('uV*s')\n",
    "\n",
    "    # colors\n",
    "    epochs_df = epochs_df.assign(colormap_arg = np.linspace(0, 1, len(epochs_df)))\n",
    "\n",
    "    d['epochs_df'] = epochs_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Plots"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# color map\n",
    "cm = plt.cm.cool\n",
    "# cm = plt.cm.brg\n",
    "# cm = plt.cm.RdBu\n",
    "\n",
    "sns.set(\n",
    "#     context = 'poster',\n",
    "    style = 'ticks',\n",
    "    font_scale = 1,\n",
    "    font = 'Palatino Linotype',\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Figure 1: Plot forces across real time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plt.figure(1, figsize=(9,3))\n",
    "# for i, data_set_name in enumerate(data_sets):\n",
    "#     d = data[data_set_name]\n",
    "#     plt.subplot(1, len(data), i+1)\n",
    "#     plt.title('{}\\nt = {}'.format(data_set_name, d['time_windows_to_keep']))\n",
    "#     plt.ylabel('Force (mN)')\n",
    "#     plt.xlabel('Original chart time (s)')\n",
    "#     for j, epoch in d['epochs_df'].iterrows():\n",
    "#         epoch_force_sig = d['force_sig'].time_slice(epoch['Start (s)']*pq.s, epoch['End (s)']*pq.s)\n",
    "#         plt.plot(epoch_force_sig.times, epoch_force_sig.as_array(), color=cm(epoch['colormap_arg']))\n",
    "#     sns.despine(ax=plt.gca(), offset=10, trim=True) # offset axes from plot\n",
    "# plt.tight_layout()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Figure 2: Plot forces, spike trains, and firing rate models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_plot_cols = len(data)\n",
    "n_plot_rows = 2 + max(len(d['spike_trains']) for k,d in data.items())\n",
    "plt.figure(2, figsize=(9,2*n_plot_rows))\n",
    "\n",
    "for i, data_set_name in enumerate(data_sets):\n",
    "    d = data[data_set_name]\n",
    "    t_min = min(d['epochs_df']['Start (s)'])\n",
    "    t_max = max(d['epochs_df']['End (s)'])\n",
    "\n",
    "    # === FORCE ===\n",
    "    ax = plt.subplot(n_plot_rows, n_plot_cols, i+1)\n",
    "    plt.title('{}\\nt = {}'.format(data_set_name, d['time_windows_to_keep']))\n",
    "    plt.ylabel('Force (mN)')\n",
    "    plt.xlim(t_min, t_max)\n",
    "    plt.ylim([-10, 400])\n",
    "    \n",
    "#     sns.despine(ax=plt.gca(), offset=10, trim=True, bottom=True)\n",
    "#     plt.gca().xaxis.set_visible(False)\n",
    "\n",
    "    for j, epoch in d['epochs_df'].iterrows():\n",
    "        epoch_force_sig = d['force_sig'].time_slice(epoch['Start (s)']*pq.s, epoch['End (s)']*pq.s)\n",
    "        plt.plot(epoch_force_sig.times, epoch_force_sig.as_array(), color=cm(epoch['colormap_arg']))\n",
    "        plt.text(np.mean([epoch['Start (s)'], epoch['End (s)']]), epoch['max'], '{:.0f}'.format(epoch['force RAUC']), fontsize=8, ha='center')\n",
    "        if not np.isnan(epoch.get('Middle (s)', np.nan)):\n",
    "            plt.text(np.mean([epoch['Start (s)'],  epoch['Middle (s)']]), epoch['smoothed small max'], '{:.0f}'.format(epoch['large hump force RAUC']), fontsize=8, ha='center')\n",
    "            plt.text(np.mean([epoch['Middle (s)'], epoch['End (s)']]),    epoch['smoothed small max'], '{:.0f}'.format(epoch['small hump force RAUC']), fontsize=8, ha='center')\n",
    "\n",
    "    # === D(FORCE)/DT ===\n",
    "    plt.subplot(n_plot_rows, n_plot_cols, (1)*n_plot_cols+i+1, sharex=ax)\n",
    "    plt.axhline(0, color='gray', linewidth=0.5)\n",
    "    dfdt = d['dforce/dt'].time_slice(t_min*pq.s, t_max*pq.s)\n",
    "    plt.plot(dfdt.times, dfdt.as_array())\n",
    "    plt.ylabel('d(Force)/dt (mN/s)')\n",
    "    plt.ylim([-400, 400])\n",
    "    \n",
    "#     sns.despine(ax=plt.gca(), offset=10, trim=True, bottom=True)\n",
    "#     plt.gca().xaxis.set_visible(False)\n",
    "\n",
    "    # === RASTER PLOTS + RATE MODELS ===\n",
    "    spike_labels = d['spike_trains'].keys()\n",
    "\n",
    "    for j, spike_label in enumerate(spike_labels):\n",
    "        st = d['spike_trains'][spike_label]\n",
    "        st = st.time_slice(\n",
    "            t_min*pq.s - 5*pq.s,\n",
    "            t_max*pq.s + 5*pq.s\n",
    "        ) # drop spikes outside plot range except for a few sec margin so beginning and final firing rates are accurate\n",
    "\n",
    "        plt.subplot(n_plot_rows, n_plot_cols, (2+j)*n_plot_cols+i+1, sharex=ax)\n",
    "        plt.ylabel(spike_label + '\\n(rate model)')\n",
    "        plt.xlim(t_min, t_max)\n",
    "        plt.ylim([-2, 40])\n",
    "        \n",
    "        if j == len(spike_labels)-1:\n",
    "#             sns.despine(ax=plt.gca(), offset=10, trim=True)\n",
    "            plt.xlabel('Time (s)')\n",
    "#         else:\n",
    "#             sns.despine(ax=plt.gca(), offset=10, trim=True, bottom=True)\n",
    "#             plt.gca().xaxis.set_visible(False)\n",
    "\n",
    "        # raster plot\n",
    "        plt.eventplot(positions=st, lineoffsets=-1, colors='red')\n",
    "\n",
    "        # spike train convolution\n",
    "        kernels = [\n",
    "#             CausalAlphaKernel(0.03*np.sqrt(2)*pq.s), # match my old poster's synapse model\n",
    "            CausalAlphaKernel(0.2*pq.s),\n",
    "#             elephant.kernels.AlphaKernel(0.03*np.sqrt(2)*pq.s),\n",
    "#             elephant.kernels.AlphaKernel(0.2*pq.s),\n",
    "#             elephant.kernels.EpanechnikovLikeKernel(0.2*pq.s),\n",
    "#             elephant.kernels.ExponentialKernel(0.2*pq.s),\n",
    "#             elephant.kernels.GaussianKernel(0.2*pq.s),\n",
    "#             elephant.kernels.LaplacianKernel(0.2*pq.s),\n",
    "#             elephant.kernels.RectangularKernel(0.2*pq.s),\n",
    "#             elephant.kernels.TriangularKernel(0.2*pq.s)\n",
    "        ]\n",
    "        for kernel in kernels:\n",
    "            rate = elephant.statistics.instantaneous_rate(\n",
    "                spiketrain=st, sampling_period=d['sampling_period'], kernel=kernel)\n",
    "            plt.plot(rate.times.rescale('s'), rate)\n",
    "\n",
    "        # instantaneous firing frequency step plot\n",
    "#         if st.size > 0:\n",
    "# #             plt.plot(st[:-1], 1/elephant.statistics.isi(st), drawstyle='steps-post')\n",
    "#             times = st.times.rescale('s')\n",
    "#             times = np.concatenate([[t_min], times, [t_max]])*pq.s\n",
    "#             iff = 1/elephant.statistics.isi(st)\n",
    "#             iff = np.concatenate([[0], iff.rescale('1/s'), [0, 0]])/pq.s\n",
    "#             plt.plot(times, iff, drawstyle='steps-post')\n",
    "\n",
    "        for k, epoch in d['epochs_df'].iterrows():\n",
    "            plt.text(np.mean([epoch['Start (s)'], epoch['End (s)']]), 20, st.time_slice(epoch['Start (s)'], epoch['End (s)']).size, fontsize=8, ha='center')\n",
    "\n",
    "plt.tight_layout()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### MODEL FIT WORK IN PROGRESS -------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_set_name = 'IN VIVO / JG08 / 2018-06-21 / 002'\n",
    "# data_set_name = 'IN VIVO / JG08 / 2018-06-24 / 001'\n",
    "# data_set_name = 'IN VIVO / JG12 / 2019-05-10 / 002'\n",
    "d = data[data_set_name]\n",
    "\n",
    "t_min = min(d['epochs_df']['Start (s)'])\n",
    "t_max = max(d['epochs_df']['End (s)'])\n",
    "\n",
    "force_sig = d['force_sig'].time_slice(t_min*pq.s, t_max*pq.s)\n",
    "\n",
    "# need to make sure t_min, t_max are aligned with the sample times\n",
    "# of force_sig, since they will determine the rate models' times\n",
    "t_min = force_sig.t_start.rescale('s').magnitude\n",
    "t_max = force_sig.t_stop.rescale('s').magnitude\n",
    "\n",
    "\n",
    "baseline = 0\n",
    "spike_rate_models = {\n",
    "#     'I2':    {'weight': -0.002,    'rate_constant': 1},\n",
    "#     'B8a/b': {'weight': 0.05,    'rate_constant': 1},\n",
    "    'B3':    {'weight': 0.05, 'rate_constant': 1},\n",
    "    'B6/B9': {'weight': 0.05, 'rate_constant': 0.5},\n",
    "    'B38':   {'weight': 0.025, 'rate_constant': 1},\n",
    "}\n",
    "params = [baseline]\n",
    "for unit, p in spike_rate_models.items():\n",
    "    params += [p['weight'], p['rate_constant']]\n",
    "params = np.array(params)\n",
    "\n",
    "unit_names = list(spike_rate_models.keys())\n",
    "# unit_names = ['B3', 'B6/B9', 'B38']\n",
    "\n",
    "# 0 iters, error = 5438.537110230563\n",
    "# params = np.array([0, 0.05, 1, 0.05, 0.5, 0.025, 1])\n",
    "\n",
    "# 1 iters, error = 5436.993468396257\n",
    "# params = np.array([3.80738436e-08, 5.00000362e-02, 1.00000377e+00, 5.00000362e-02, 5.00003788e-01, 2.49999990e-02, 9.99999962e-01])\n",
    "\n",
    "# 2 iters, error = 5282.6250908482625\n",
    "# params = np.array([2.46302317e-04, 5.00897420e-02, 9.99644748e-01, 5.12355946e-02, 4.99630339e-01, 2.48409028e-02, 1.00002662e+00])\n",
    "\n",
    "# 10 iters, error = 2999.8449262352165\n",
    "# params = np.array([0.18306482, 0.00436199, 0.99686335, 0.04440692, 0.45378227, 0.        , 1.01851402])\n",
    "\n",
    "# 33 iters (terminated), error = 2802.0291040955985\n",
    "# params = np.array([0.18100302, 0.05385427, 0.97966784, 0.03796378, 0.39556   , 0.        , 1.01637518])\n",
    "\n",
    "baseline, params = params[0], params[1:]\n",
    "spike_rate_models = {}\n",
    "for n, (w, r) in zip(unit_names, params.reshape(-1, 2)):\n",
    "    spike_rate_models[n] = {'weight': w, 'rate_constant': r}\n",
    "\n",
    "# # 1 iter without mean shift\n",
    "# spike_rate_models = {\n",
    "#     'B3':    {'weight': 0.39999997, 'rate_constant': 0.99999993},\n",
    "#     'B6/B9': {'weight': 0.40000004, 'rate_constant': 0.50000684},\n",
    "#     'B38':   {'weight': 0.19999999, 'rate_constant': 0.99999993},\n",
    "# }\n",
    "\n",
    "# # 3 iters without mean shift\n",
    "# spike_rate_models = {\n",
    "#     'B3':    {'weight': 0.39905256, 'rate_constant': 1.23447876},\n",
    "#     'B6/B9': {'weight': 0.40142116, 'rate_constant': 0.49882414},\n",
    "#     'B38':   {'weight': 0.19952626, 'rate_constant': 0.99763389},\n",
    "# }\n",
    "\n",
    "# # 5 iters without mean shift\n",
    "# spike_rate_models = {\n",
    "#     'B3':    {'weight': 0.39850763, 'rate_constant': 1.4001333},\n",
    "#     'B6/B9': {'weight': 0.40437206, 'rate_constant': 0.43688527},\n",
    "#     'B38':   {'weight': 0.19504436, 'rate_constant': 1.00480115},\n",
    "# }\n",
    "\n",
    "# 7 iters without mean shift\n",
    "# spike_rate_models = {\n",
    "#     'B3':    {'weight': 0.39850765, 'rate_constant': 1.40015991},\n",
    "#     'B6/B9': {'weight': 0.40437244, 'rate_constant': 0.43688048},\n",
    "#     'B38':   {'weight': 0.19504362, 'rate_constant': 1.00480165},\n",
    "# }\n",
    "\n",
    "# 10 iters without mean shift\n",
    "# spike_rate_models = {\n",
    "#     'B3':    {'weight': 0.44591693, 'rate_constant': 7.14593357},\n",
    "#     'B6/B9': {'weight': 0.33406253, 'rate_constant': 0.46480023},\n",
    "#     'B38':   {'weight': 0.24457259, 'rate_constant': 6.77407843},\n",
    "# }\n",
    "\n",
    "for name, params in spike_rate_models.items():\n",
    "    \n",
    "    # get the spike train\n",
    "    st = d['spike_trains'][name]\n",
    "    st = st.time_slice(\n",
    "        t_min*pq.s - 5*pq.s,\n",
    "        t_max*pq.s,\n",
    "    ) # drop spikes outside plot range except for a few sec before so beginning firing rate is accurate\n",
    "    params['spike_train'] = st\n",
    "    \n",
    "    # convolve the spike train with the kernel\n",
    "    params['rate'] = elephant.statistics.instantaneous_rate(\n",
    "        spiketrain=st,\n",
    "        sampling_period=d['sampling_period'],\n",
    "#         t_start=st.t_start, # default\n",
    "        kernel=CausalAlphaKernel(params['rate_constant']*pq.s),\n",
    "    )\n",
    "\n",
    "\n",
    "force_ylim = [-10, 500]\n",
    "rate_ylim = [-2, 2]\n",
    "\n",
    "n_plot_rows = len(spike_rate_models) + 2\n",
    "plt.figure(99, figsize=(9,2*n_plot_rows))\n",
    "\n",
    "# === FORCE ===\n",
    "ax = plt.subplot(n_plot_rows, 1, 1)\n",
    "plt.title('{}\\nt = {}'.format(data_set_name, d['time_windows_to_keep']))\n",
    "plt.ylabel('Force (mN)')\n",
    "plt.xlim(t_min, t_max)\n",
    "plt.ylim(force_ylim)\n",
    "\n",
    "plt.plot(force_sig.times, force_sig.as_array(), color='C1')\n",
    "\n",
    "# === RASTER PLOTS + RATE MODELS ===\n",
    "for j, (name, params) in enumerate(spike_rate_models.items()):\n",
    "\n",
    "    plt.subplot(n_plot_rows, 1, j+2, sharex=ax)\n",
    "    plt.ylabel(f\"{name}\\nweight: {np.round(params['weight'],3)}\\nrate const: {np.round(params['rate_constant'],3)} sec\")\n",
    "    plt.xlim(t_min, t_max)\n",
    "    plt.ylim(rate_ylim)\n",
    "\n",
    "    # raster plot\n",
    "    plt.eventplot(positions=params['spike_train'], lineoffsets=-1, colors='red')\n",
    "\n",
    "    # spike train convolution\n",
    "    plt.plot(params['rate'].times.rescale('s'), params['rate'] * params['weight'])\n",
    "\n",
    "    for k, epoch in d['epochs_df'].iterrows():\n",
    "        label = params['spike_train'].time_slice(epoch['Start (s)'], epoch['End (s)']).size\n",
    "        plt.text(np.mean([epoch['Start (s)'], epoch['End (s)']]), 1, label, fontsize=8, ha='center')\n",
    "\n",
    "# === COMBINED MODEL ===\n",
    "\n",
    "plt.subplot(n_plot_rows, 1, len(spike_rate_models)+2, sharex=ax)\n",
    "plt.ylabel(f'Sum of rates\\nvs norm force\\nbaseline: {np.round(baseline,3)}')\n",
    "plt.xlabel('Time (s)')\n",
    "plt.xlim(t_min, t_max)\n",
    "plt.ylim([-0.1, 1.1])\n",
    "\n",
    "# assert all times are the same so that simple addition of rates can be done\n",
    "for j, (name, params) in enumerate(spike_rate_models.items()):\n",
    "    assert np.all(params['rate'].times == spike_rate_models[list(spike_rate_models.keys())[0]]['rate'].times)\n",
    "\n",
    "rate_sum = None\n",
    "for name, params in spike_rate_models.items():\n",
    "    if rate_sum is None:\n",
    "        rate_sum = params['rate'] * params['weight']\n",
    "    else:\n",
    "        rate_sum += params['rate'] * params['weight']\n",
    "\n",
    "plt.plot(rate_sum.times.rescale('s'), rate_sum.as_array()+baseline)#/rate_sum.max())\n",
    "# plt.plot(rate_sum.times.rescale('s'), rate_sum.as_array()/rate_sum.max().magnitude+baseline)\n",
    "\n",
    "force_sig = d['force_sig'].time_slice(t_min*pq.s, t_max*pq.s)\n",
    "plt.plot(force_sig.times, force_sig.as_array()/force_sig.max(), color='C1')\n",
    "\n",
    "plt.tight_layout()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for key in spike_rate_models:\n",
    "#     for t in spike_rate_models[key]['spike_train'].times:\n",
    "#         print(f'\"{key}\",{np.round(t.magnitude,4)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_time_range(data_set_name):\n",
    "    d = data[data_set_name]\n",
    "    t_min = min(d['epochs_df']['Start (s)'])\n",
    "    t_max = max(d['epochs_df']['End (s)'])\n",
    "\n",
    "    force_sig = d['force_sig'].time_slice(t_min*pq.s, t_max*pq.s)\n",
    "\n",
    "    # need to make sure t_min, t_max are aligned with the sample times\n",
    "    # of force_sig, since they will determine the rate models' times\n",
    "    t_min = force_sig.t_start.rescale('s').magnitude\n",
    "    t_max = force_sig.t_stop.rescale('s').magnitude\n",
    "    \n",
    "    return t_min, t_max\n",
    "\n",
    "\n",
    "def get_spike_trains(data_set_name, t_min, t_max, unit_names):\n",
    "    \n",
    "    spike_trains = []\n",
    "    for name in unit_names:\n",
    "        # get the spike train\n",
    "        st = d['spike_trains'][name]\n",
    "        st = st.time_slice(\n",
    "            t_min*pq.s - 5*pq.s,\n",
    "            t_max*pq.s + 5*pq.s\n",
    "        ) # drop spikes outside plot range except for a few sec margin so beginning and final firing rates are accurate\n",
    "        spike_trains.append(st)\n",
    "    \n",
    "    return spike_trains\n",
    "\n",
    "def get_model_time_series(t_min, t_max, sampling_period, spike_trains, params):\n",
    "    \n",
    "    # assume params is a flattened array of ordered pairs (weight, rate_constant) with baseline appended\n",
    "    baseline, params = params[0], params[1:]\n",
    "    params = params.reshape(-1, 2)\n",
    "    \n",
    "    rate_sum = None\n",
    "    for st, p in zip(spike_trains, params):\n",
    "        weight, rate_constant = p\n",
    "        rate_model = elephant.statistics.instantaneous_rate(\n",
    "            spiketrain=st,\n",
    "            sampling_period=sampling_period,\n",
    "            t_start=st.t_start, # default\n",
    "            kernel=CausalAlphaKernel(rate_constant*pq.s),\n",
    "        )\n",
    "        if rate_sum is None:\n",
    "            rate_sum = rate_model * weight\n",
    "        else:\n",
    "            rate_sum += rate_model * weight\n",
    "    \n",
    "    rate_sum = rate_sum.time_slice(t_min*pq.s, t_max*pq.s)\n",
    "    rate_sum = rate_sum.as_array() + baseline\n",
    "    \n",
    "    return rate_sum\n",
    "\n",
    "def get_sum_of_square_residuals(data_set_name, rate_sum):\n",
    "    d = data[data_set_name]\n",
    "    t_min, t_max = get_time_range(data_set_name)\n",
    "    \n",
    "    force_sig = d['force_sig'].time_slice(t_min*pq.s, t_max*pq.s)\n",
    "    \n",
    "    force_sig = force_sig.as_array()\n",
    "    force_sig = force_sig/force_sig.max()\n",
    "    \n",
    "    return float(((rate_sum-force_sig)**2).sum())\n",
    "\n",
    "def do_it_efficiently(params, t_min, t_max, sampling_period, spike_trains, force_sig_normalized):\n",
    "    \n",
    "    # assume params is a flattened array of ordered pairs (weight, rate_constant) with baseline appended\n",
    "    baseline, params = params[0], params[1:]\n",
    "    params = params.reshape(-1, 2)\n",
    "    \n",
    "    rate_sum = None\n",
    "    for st, p in zip(spike_trains, params):\n",
    "        weight, rate_constant = p\n",
    "        rate_model = elephant.statistics.instantaneous_rate(\n",
    "            spiketrain=st,\n",
    "            sampling_period=sampling_period,\n",
    "            kernel=CausalAlphaKernel(rate_constant*pq.s),\n",
    "        )\n",
    "        if rate_sum is None:\n",
    "            rate_sum = rate_model * weight\n",
    "        else:\n",
    "            rate_sum += rate_model * weight\n",
    "    \n",
    "    rate_sum = rate_sum.time_slice(t_min*pq.s, t_max*pq.s)\n",
    "    \n",
    "    rate_sum = rate_sum.as_array() + baseline\n",
    "    \n",
    "    return float(((rate_sum-force_sig_normalized)**2).sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_set_name = 'IN VIVO / JG08 / 2018-06-21 / 002'\n",
    "unit_names = ['B3', 'B6/B9', 'B38']\n",
    "params = np.array([0, 0.05, 1, 0.05, 0.5, 0.025, 1])\n",
    "\n",
    "d = data[data_set_name]\n",
    "t_min, t_max = get_time_range(data_set_name)\n",
    "spike_trains = get_spike_trains(data_set_name, t_min, t_max, unit_names)\n",
    "rate_sum = get_model_time_series(t_min, t_max, d['sampling_period'], spike_trains, params)\n",
    "error = get_sum_of_square_residuals(data_set_name, rate_sum)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_set_name = 'IN VIVO / JG08 / 2018-06-21 / 002'\n",
    "unit_names = ['B3', 'B6/B9', 'B38']\n",
    "params = np.array([0, 0.05, 1, 0.05, 0.5, 0.025, 1])\n",
    "\n",
    "d = data[data_set_name]\n",
    "t_min, t_max = get_time_range(data_set_name)\n",
    "force_sig = d['force_sig'].time_slice(t_min*pq.s, t_max*pq.s)\n",
    "spike_trains = get_spike_trains(data_set_name, t_min, t_max, unit_names)\n",
    "\n",
    "# # THIS IS DIFFERENT FROM WHAT I PLOTTED ABOVE WITH TRUE ZERO\n",
    "# force_sig = (force_sig-force_sig.mean())/force_sig.std()\n",
    "\n",
    "force_sig = force_sig.as_array()\n",
    "force_sig = force_sig/force_sig.max()\n",
    "\n",
    "error = do_it_efficiently(params, t_min, t_max, d['sampling_period'], spike_trains, force_sig)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import scipy\n",
    "\n",
    "data_set_name = 'IN VIVO / JG08 / 2018-06-21 / 002'\n",
    "unit_names = ['B3', 'B6/B9', 'B38']\n",
    "\n",
    "# params = np.array([0.4, 1, 0.4, 0.5, 0.2, 1])\n",
    "params = np.array([0, 0.05, 1, 0.05, 0.5, 0.025, 1])\n",
    "lb = np.array([\n",
    "    0,    # baseline\n",
    "    0,    # weight 1\n",
    "    1e-3, # rate constant 1\n",
    "    0,    # weight 2\n",
    "    1e-3, # rate constant 2\n",
    "    0,    # weight 3\n",
    "    1e-3, # rate constant 3\n",
    "])\n",
    "ub = np.array([\n",
    "    1,   # baseline\n",
    "    1,   # weight 1\n",
    "    100, # rate constant 1\n",
    "    1,   # weight 2\n",
    "    100, # rate constant 2\n",
    "    1,   # weight 3\n",
    "    100, # rate constant 3\n",
    "])\n",
    "\n",
    "d = data[data_set_name]\n",
    "t_min, t_max = get_time_range(data_set_name)\n",
    "force_sig = d['force_sig'].time_slice(t_min*pq.s, t_max*pq.s)\n",
    "spike_trains = get_spike_trains(data_set_name, t_min, t_max, unit_names)\n",
    "\n",
    "# # THIS IS DIFFERENT FROM WHAT I PLOTTED ABOVE WITH TRUE ZERO\n",
    "# force_sig = (force_sig-force_sig.mean())/force_sig.std()\n",
    "\n",
    "force_sig = force_sig.as_array()\n",
    "force_sig = force_sig/force_sig.max()\n",
    "\n",
    "result = scipy.optimize.minimize(\n",
    "    do_it_efficiently,\n",
    "    params,\n",
    "    (t_min, t_max, d['sampling_period'], spike_trains, force_sig),\n",
    "    bounds=scipy.optimize.Bounds(lb, ub),\n",
    "    options={'maxiter': 100},\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(np.array([params, result.x])) # 100 iters with baseline, err: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(np.array([params, result.x])) # 10 iters with baseline, err: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(np.array([params, result.x])) # 2 iters with baseline, err: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(np.array([params, result.x])) # 1 iter with baseline, err: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(np.array([params, result.x])) # 10 iters without mean shift, err: 3572"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(np.array([params, result.x])) # 7 iters without mean shift, err: 5385"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(np.array([params, result.x])) # 5 iters without mean shift, err: 5385"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(np.array([params, result.x])) # 3 iters without mean shift, err: 5430"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(np.array([params, result.x])) # 1 iter without mean shift"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(np.array([params, result.x])) # 10 iters with mean shift"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(np.array([params, result.x])) # 5 iters with mean shift"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure()\n",
    "plt.plot(rate_sum.times.rescale('s'), rate_sum)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### ------- END MODEL FIT WORK IN PROGRESS "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Figure 3: Plot number of spikes vs force RAUC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(3, figsize=(9,6))\n",
    "for i, data_set_name in enumerate(data_sets):\n",
    "    d = data[data_set_name]\n",
    "    plt.subplot(1, len(data), i+1)\n",
    "    \n",
    "#     rauc_label = 'small hump force RAUC'\n",
    "    rauc_label = 'large hump force RAUC'\n",
    "#     rauc_label = 'force RAUC'\n",
    "    y = d['epochs_df'][rauc_label]\n",
    "\n",
    "    spike_labels = d['spike_trains'].keys()\n",
    "#     spike_labels = [\n",
    "#     #     'I2',\n",
    "#         'B8a/b',\n",
    "#         'B3 (50-100 uV)',\n",
    "#     #     '? (45-50 uV)',\n",
    "#         'B6/B9 ? (26-45 uV)',\n",
    "#         'B38 ? (17-26 uV)',\n",
    "#     #     '? (15-17 uV)',\n",
    "#         'B4/B5',\n",
    "#     ]\n",
    "\n",
    "    legend_text = []\n",
    "    for j, spike_label in enumerate(spike_labels):\n",
    "        x = []\n",
    "        for k, epoch in d['epochs_df'].iterrows():\n",
    "            st = d['spike_trains'][spike_label].time_slice(epoch['Start (s)'], epoch['End (s)'])\n",
    "            x.append(st.size)\n",
    "        \n",
    "        model = sm.OLS(y, sm.add_constant(x)).fit()\n",
    "        legend_text.append('{}, R$^2$ = {:.2f}, p = {:.3f}'.format(spike_label, model.rsquared, model.pvalues[1]))\n",
    "        \n",
    "#         plt.scatter(x, y)\n",
    "#         line_plot_x = np.linspace(min(x),max(x),100)\n",
    "#         plt.plot(line_plot_x, line_plot_x*model.params[1] + model.params[0])\n",
    "        sns.regplot(x=x, y=y, ci=None, truncate=True)\n",
    "\n",
    "    plt.title('{}\\nt = {}'.format(data_set_name, d['time_windows_to_keep']))\n",
    "    plt.xlabel('Number of spikes in swallow motor pattern')\n",
    "#     plt.ylabel('Integrated force (mN·s)')\n",
    "    plt.ylabel(rauc_label + ' (mN·s)')\n",
    "    plt.legend(legend_text, fontsize = 9)\n",
    "    sns.despine(ax=plt.gca(), offset=10, trim=True) # offset axes from plot\n",
    "plt.tight_layout()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Figure 4: Plot BN2 RAUC vs force RAUC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(4, figsize=(9,6))\n",
    "for i, data_set_name in enumerate(data_sets):\n",
    "    d = data[data_set_name]\n",
    "    plt.subplot(1, len(data), i+1)\n",
    "    \n",
    "    x = d['epochs_df']['BN2 RAUC']\n",
    "    y = d['epochs_df']['force RAUC']\n",
    "    \n",
    "    plt.xlim([0, 25])\n",
    "    plt.ylim([0, 1200])\n",
    "    \n",
    "    model = sm.OLS(y, sm.add_constant(x)).fit()\n",
    "    legend_text = ['R$^2$ = {:.2f}, p = {:.3f}, n = {}'.format(model.rsquared, model.pvalues[1], len(x))]\n",
    "    \n",
    "#     plt.scatter(x, y)\n",
    "#     line_plot_x = np.linspace(plt.gca().get_xlim()[0],plt.gca().get_xlim()[1],100)\n",
    "#     plt.plot(line_plot_x, line_plot_x*model.params[1] + model.params[0])\n",
    "    sns.regplot(x=x, y=y, ci=False)\n",
    "    \n",
    "    plt.title('{}\\nt = {}'.format(data_set_name, d['time_windows_to_keep']))\n",
    "    plt.xlabel('BN2 RAUC (integrated rectified voltage on buccal nerve 2) (μV·s)')\n",
    "    plt.ylabel('Force RAUC (integrated force) (mN·s)')\n",
    "    plt.legend(legend_text)#, fontsize = 9)\n",
    "    sns.despine(ax=plt.gca(), offset=10, trim=True) # offset axes from plot\n",
    "plt.tight_layout()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Figure 5: Plot BN3 RAUC vs force RAUC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(5, figsize=(9,6))\n",
    "for i, data_set_name in enumerate(data_sets):\n",
    "    d = data[data_set_name]\n",
    "    plt.subplot(1, len(data), i+1)\n",
    "    \n",
    "    x = d['epochs_df']['BN3 RAUC']\n",
    "    y = d['epochs_df']['force RAUC']\n",
    "    \n",
    "    plt.xlim([0, 50])\n",
    "    plt.ylim([0, 1200])\n",
    "    \n",
    "    model = sm.OLS(y, sm.add_constant(x)).fit()\n",
    "    legend_text = ['R$^2$ = {:.2f}, p = {:.3f}, n = {}'.format(model.rsquared, model.pvalues[1], len(x))]\n",
    "    \n",
    "#     plt.scatter(x, y)\n",
    "#     line_plot_x = np.linspace(plt.gca().get_xlim()[0],plt.gca().get_xlim()[1],100)\n",
    "#     plt.plot(line_plot_x, line_plot_x*model.params[1] + model.params[0])\n",
    "    sns.regplot(x=x, y=y, ci=False)\n",
    "    \n",
    "    plt.title('{}\\nt = {}'.format(data_set_name, d['time_windows_to_keep']))\n",
    "    plt.xlabel('BN3 RAUC (integrated rectified voltage on buccal nerve 3) (μV·s)')\n",
    "    plt.ylabel('Force RAUC (integrated force) (mN·s)')\n",
    "    plt.legend(legend_text)#, fontsize = 9)\n",
    "    sns.despine(ax=plt.gca(), offset=10, trim=True) # offset axes from plot\n",
    "plt.tight_layout()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Figure 6: Plot RN RAUC vs force RAUC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(6, figsize=(9,6))\n",
    "for i, data_set_name in enumerate(data_sets):\n",
    "    d = data[data_set_name]\n",
    "    plt.subplot(1, len(data), i+1)\n",
    "    \n",
    "    x = d['epochs_df']['RN RAUC']\n",
    "    y = d['epochs_df']['force RAUC']\n",
    "    \n",
    "    plt.xlim([0, 25])\n",
    "    plt.ylim([0, 1200])\n",
    "    \n",
    "    model = sm.OLS(y, sm.add_constant(x)).fit()\n",
    "    legend_text = ['R$^2$ = {:.2f}, p = {:.3f}, n = {}'.format(model.rsquared, model.pvalues[1], len(x))]\n",
    "    \n",
    "#     plt.scatter(x, y)\n",
    "#     line_plot_x = np.linspace(plt.gca().get_xlim()[0],plt.gca().get_xlim()[1],100)\n",
    "#     plt.plot(line_plot_x, line_plot_x*model.params[1] + model.params[0])\n",
    "    sns.regplot(x=x, y=y, ci=False)\n",
    "    \n",
    "    plt.title('{}\\nt = {}'.format(data_set_name, d['time_windows_to_keep']))\n",
    "    plt.xlabel('RN RAUC (integrated rectified voltage on radular nerve) (μV·s)')\n",
    "    plt.ylabel('Force RAUC (integrated force) (mN·s)')\n",
    "    plt.legend(legend_text)#, fontsize = 9)\n",
    "    sns.despine(ax=plt.gca(), offset=10, trim=True) # offset axes from plot\n",
    "plt.tight_layout()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Figure 7: Plot BN2 RAUC vs RN RAUC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(7, figsize=(9,6))\n",
    "for i, data_set_name in enumerate(data_sets):\n",
    "    d = data[data_set_name]\n",
    "    plt.subplot(1, len(data), i+1)\n",
    "    \n",
    "    x = d['epochs_df']['BN2 RAUC']\n",
    "    y = d['epochs_df']['RN RAUC']\n",
    "    \n",
    "    plt.xlim([0, 25])\n",
    "    plt.ylim([0, 25])\n",
    "    \n",
    "    model = sm.OLS(y, sm.add_constant(x)).fit()\n",
    "    legend_text = ['R$^2$ = {:.2f}, p = {:.3f}, n = {}'.format(model.rsquared, model.pvalues[1], len(x))]\n",
    "    \n",
    "#     plt.scatter(x, y)\n",
    "#     line_plot_x = np.linspace(plt.gca().get_xlim()[0],plt.gca().get_xlim()[1],100)\n",
    "#     plt.plot(line_plot_x, line_plot_x*model.params[1] + model.params[0])\n",
    "    sns.regplot(x=x, y=y, ci=False)\n",
    "    \n",
    "    plt.title('{}\\nt = {}'.format(data_set_name, d['time_windows_to_keep']))\n",
    "    plt.xlabel('BN2 RAUC (integrated rectified voltage on buccal nerve 2) (μV·s)')\n",
    "    plt.ylabel('RN RAUC (integrated rectified voltage on radular nerve) (μV·s)')\n",
    "    plt.legend(legend_text)#, fontsize = 9)\n",
    "    sns.despine(ax=plt.gca(), offset=10, trim=True) # offset axes from plot\n",
    "plt.tight_layout()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Figure 8: Plot BN2 RAUC vs BN3 RAUC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(8, figsize=(9,6))\n",
    "for i, data_set_name in enumerate(data_sets):\n",
    "    d = data[data_set_name]\n",
    "    plt.subplot(1, len(data), i+1)\n",
    "    \n",
    "    x = d['epochs_df']['BN2 RAUC']\n",
    "    y = d['epochs_df']['BN3 RAUC']\n",
    "    \n",
    "    plt.xlim([0, 25])\n",
    "    plt.ylim([0, 50])\n",
    "    \n",
    "    model = sm.OLS(y, sm.add_constant(x)).fit()\n",
    "    legend_text = ['R$^2$ = {:.2f}, p = {:.3f}, n = {}'.format(model.rsquared, model.pvalues[1], len(x))]\n",
    "    \n",
    "#     plt.scatter(x, y)\n",
    "#     line_plot_x = np.linspace(plt.gca().get_xlim()[0],plt.gca().get_xlim()[1],100)\n",
    "#     plt.plot(line_plot_x, line_plot_x*model.params[1] + model.params[0])\n",
    "    sns.regplot(x=x, y=y, ci=False)\n",
    "    \n",
    "    plt.title('{}\\nt = {}'.format(data_set_name, d['time_windows_to_keep']))\n",
    "    plt.xlabel('BN2 RAUC (integrated rectified voltage on buccal nerve 2) (μV·s)')\n",
    "    plt.ylabel('BN3 RAUC (integrated rectified voltage on buccal nerve 3) (μV·s)')\n",
    "    plt.legend(legend_text)#, fontsize = 9)\n",
    "    sns.despine(ax=plt.gca(), offset=10, trim=True) # offset axes from plot\n",
    "plt.tight_layout()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Figure 9: Plot RN RAUC vs BN3 RAUC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(9, figsize=(9,6))\n",
    "for i, data_set_name in enumerate(data_sets):\n",
    "    d = data[data_set_name]\n",
    "    plt.subplot(1, len(data), i+1)\n",
    "    \n",
    "    x = d['epochs_df']['RN RAUC']\n",
    "    y = d['epochs_df']['BN3 RAUC']\n",
    "    \n",
    "    plt.xlim([0, 25])\n",
    "    plt.ylim([0, 50])\n",
    "    \n",
    "    model = sm.OLS(y, sm.add_constant(x)).fit()\n",
    "    legend_text = ['R$^2$ = {:.2f}, p = {:.3f}, n = {}'.format(model.rsquared, model.pvalues[1], len(x))]\n",
    "    \n",
    "#     plt.scatter(x, y)\n",
    "#     line_plot_x = np.linspace(plt.gca().get_xlim()[0],plt.gca().get_xlim()[1],100)\n",
    "#     plt.plot(line_plot_x, line_plot_x*model.params[1] + model.params[0])\n",
    "    sns.regplot(x=x, y=y, ci=False)\n",
    "    \n",
    "    plt.title('{}\\nt = {}'.format(data_set_name, d['time_windows_to_keep']))\n",
    "    plt.xlabel('RN RAUC (integrated rectified voltage on radular nerve) (μV·s)')\n",
    "    plt.ylabel('BN3 RAUC (integrated rectified voltage on buccal nerve 3) (μV·s)')\n",
    "    plt.legend(legend_text)#, fontsize = 9)\n",
    "    sns.despine(ax=plt.gca(), offset=10, trim=True) # offset axes from plot\n",
    "plt.tight_layout()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
