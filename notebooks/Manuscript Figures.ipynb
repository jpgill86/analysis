{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\\>\\>\\> CLICK [HERE](#Figures) TO JUMP DOWN TO MANUSCRIPT FIGURES <<<"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Preamble"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "source": [
    "## Import Packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "outputs": [],
   "source": [
    "import datetime\n",
    "import numpy as np\n",
    "import quantities as pq\n",
    "import elephant\n",
    "import pandas as pd\n",
    "import statsmodels.api as sm\n",
    "import neurotic\n",
    "from neurotic.datasets.data import _detect_spikes\n",
    "from utils import BehaviorsDataFrame, DownsampleNeoSignal\n",
    "\n",
    "pq.markup.config.use_unicode = True  # allow symbols like mu for micro in output\n",
    "pq.mN = pq.UnitQuantity('millinewton', pq.N/1e3, symbol = 'mN');  # define millinewton\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.patches as patches\n",
    "from matplotlib.ticker import MultipleLocator\n",
    "import seaborn as sns\n",
    "\n",
    "plt.rcParams.update({'figure.max_open_warning': 0})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "source": [
    "## IPython Magics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "outputs": [],
   "source": [
    "# make figures interactive and open in a separate window\n",
    "# %matplotlib qt\n",
    "\n",
    "# make figures interactive and inline\n",
    "%matplotlib notebook\n",
    "\n",
    "# make figures non-interactive and inline\n",
    "# %matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "source": [
    "## Plot Settings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "outputs": [],
   "source": [
    "# general plot settings\n",
    "sns.set(\n",
    "#     context = 'poster',\n",
    "    style = 'ticks',\n",
    "    font_scale = 1,\n",
    "    font = 'Palatino Linotype',\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "outputs": [],
   "source": [
    "markers = ['.', '+', 'x', '1', '4', 'o', 'D']\n",
    "colors = ['C0', 'C1', 'C2', 'C3', 'C4', 'C5', 'C6']\n",
    "\n",
    "unit_colors = {\n",
    "    'I2 spikes': 'C9', # cyan\n",
    "    'B8a/b':     'C6', # pink  #'C4', # purple\n",
    "    'B3':        'C3', # red\n",
    "    'B6/B9':     'C2', # green\n",
    "    'B38':       'C1', # orange\n",
    "}\n",
    "force_colors = {\n",
    "    'dip': unit_colors['I2 spikes'],\n",
    "    'initial rise': unit_colors['B8a/b'],\n",
    "    'rise': unit_colors['B6/B9'],\n",
    "    'plateau': unit_colors['B3'],\n",
    "    'shoulder': unit_colors['B38'],\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "source": [
    "## Data Parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "outputs": [],
   "source": [
    "feeding_bouts = {\n",
    "    # (animal, food, bout_index): (\n",
    "    #     data_set_name,\n",
    "    #     channels_to_keep,\n",
    "    #     time_window,\n",
    "    #     epoch_types_to_keep,\n",
    "    #     burst_thresholds,\n",
    "    # )\n",
    "\n",
    "    ('JG07', 'Tape nori', 0): (\n",
    "        'IN VIVO / JG07 / 2018-05-20 / 002',\n",
    "        ['I2-L', 'RN-L', 'BN2-L', 'BN3-L', 'Force'],\n",
    "        [2718, 2755], # 5 swallows\n",
    "        ['Swallow (tape nori)'],\n",
    "        {\n",
    "            'I2 spikes': (10,  5)*pq.Hz, # same as Cullins et al. 2015a (based on Hurwitz et al. 1996)\n",
    "            'B8a/b':     ( 3,  3)*pq.Hz, # same as Cullins et al. 2015a (based on Morton and Chiel 1993a)\n",
    "            'B3':        ( 8,  2)*pq.Hz, # based on Lu et al. 2015\n",
    "            'B6/B9':     (10,  5)*pq.Hz, # based on Lu et al. 2015\n",
    "            'B38':       ( 8,  5)*pq.Hz, # based on McManus et al. 2014\n",
    "        },\n",
    "    ),\n",
    "    \n",
    "    ('JG08', 'Tape nori', 0): (\n",
    "        'IN VIVO / JG08 / 2018-06-21 / 002',\n",
    "        ['I2', 'RN', 'BN2', 'BN3', 'Force'],\n",
    "        [148, 208], # 7 swallows, some bucket and head movement\n",
    "        ['Swallow (tape nori)'],\n",
    "        {\n",
    "            'I2 spikes': (10,  5)*pq.Hz, # same as Cullins et al. 2015a (based on Hurwitz et al. 1996)\n",
    "            'B8a/b':     ( 3,  3)*pq.Hz, # same as Cullins et al. 2015a (based on Morton and Chiel 1993a)\n",
    "            'B3':        ( 8,  2)*pq.Hz, # based on Lu et al. 2015\n",
    "#             'B6/B9':     (10,  5)*pq.Hz, # based on Lu et al. 2015\n",
    "            'B6/B9':     (10,  3)*pq.Hz, # based on Lu et al. 2015 (end threshold reduced for this animal)\n",
    "            'B38':       ( 8,  5)*pq.Hz, # based on McManus et al. 2014\n",
    "        },\n",
    "    ),\n",
    "\n",
    "    ('JG08', 'Tape nori', 1): (\n",
    "        'IN VIVO / JG08 / 2018-06-21 / 002',\n",
    "        ['I2', 'RN', 'BN2', 'BN3', 'Force'],\n",
    "        [664, 701], # 5 swallows, large bucket movement\n",
    "        ['Swallow (tape nori)'],\n",
    "        {\n",
    "            'I2 spikes': (10,  5)*pq.Hz, # same as Cullins et al. 2015a (based on Hurwitz et al. 1996)\n",
    "            'B8a/b':     ( 3,  3)*pq.Hz, # same as Cullins et al. 2015a (based on Morton and Chiel 1993a)\n",
    "            'B3':        ( 8,  2)*pq.Hz, # based on Lu et al. 2015\n",
    "#             'B6/B9':     (10,  5)*pq.Hz, # based on Lu et al. 2015\n",
    "            'B6/B9':     (10,  3)*pq.Hz, # based on Lu et al. 2015 (end threshold reduced for this animal)\n",
    "            'B38':       ( 8,  5)*pq.Hz, # based on McManus et al. 2014\n",
    "        },\n",
    "    ),\n",
    "\n",
    "    ('JG08', 'Tape nori', 2): (\n",
    "        'IN VIVO / JG08 / 2018-06-21 / 002',\n",
    "        ['I2', 'RN', 'BN2', 'BN3', 'Force'],\n",
    "        [1452, 1477], # 3 swallows, some bucket movement\n",
    "        ['Swallow (tape nori)'],\n",
    "        {\n",
    "            'I2 spikes': (10,  5)*pq.Hz, # same as Cullins et al. 2015a (based on Hurwitz et al. 1996)\n",
    "            'B8a/b':     ( 3,  3)*pq.Hz, # same as Cullins et al. 2015a (based on Morton and Chiel 1993a)\n",
    "            'B3':        ( 8,  2)*pq.Hz, # based on Lu et al. 2015\n",
    "#             'B6/B9':     (10,  5)*pq.Hz, # based on Lu et al. 2015\n",
    "            'B6/B9':     (10,  3)*pq.Hz, # based on Lu et al. 2015 (end threshold reduced for this animal)\n",
    "            'B38':       ( 8,  5)*pq.Hz, # based on McManus et al. 2014\n",
    "        },\n",
    "    ),\n",
    "\n",
    "    ('JG11', 'Tape nori', 0): (\n",
    "        'IN VIVO / JG11 / 2019-04-03 / 004',\n",
    "        ['I2', 'RN', 'BN2', 'BN3-PROX', 'Force'],\n",
    "        [1233, 1280], # 5 swallows\n",
    "        ['Swallow (tape nori)'],\n",
    "        {\n",
    "            'I2 spikes': (10,  5)*pq.Hz, # same as Cullins et al. 2015a (based on Hurwitz et al. 1996)\n",
    "            'B8a/b':     ( 3,  3)*pq.Hz, # same as Cullins et al. 2015a (based on Morton and Chiel 1993a)\n",
    "            'B3':        ( 8,  2)*pq.Hz, # based on Lu et al. 2015\n",
    "            'B6/B9':     (10,  5)*pq.Hz, # based on Lu et al. 2015\n",
    "            'B38':       ( 8,  5)*pq.Hz, # based on McManus et al. 2014\n",
    "        },\n",
    "    ),\n",
    "\n",
    "    ('JG12', 'Tape nori', 0): (\n",
    "        'IN VIVO / JG12 / 2019-05-10 / 002',\n",
    "        ['I2', 'RN', 'BN2', 'BN3-DIST', 'Force'],\n",
    "        [437, 465], # 4 swallows\n",
    "        ['Swallow (tape nori)'],\n",
    "        {\n",
    "            'I2 spikes': (10,  5)*pq.Hz, # same as Cullins et al. 2015a (based on Hurwitz et al. 1996)\n",
    "            'B8a/b':     ( 3,  3)*pq.Hz, # same as Cullins et al. 2015a (based on Morton and Chiel 1993a)\n",
    "            'B3':        ( 8,  2)*pq.Hz, # based on Lu et al. 2015\n",
    "            'B6/B9':     (10,  5)*pq.Hz, # based on Lu et al. 2015\n",
    "            'B38':       ( 8,  5)*pq.Hz, # based on McManus et al. 2014\n",
    "        },\n",
    "    ),\n",
    "    \n",
    "    ('JG12', 'Tape nori', 1): (\n",
    "        'IN VIVO / JG12 / 2019-05-10 / 002',\n",
    "        ['I2', 'RN', 'BN2', 'BN3-DIST', 'Force'],\n",
    "        [2901, 2937], # 5 swallows\n",
    "        ['Swallow (tape nori)'],\n",
    "        {\n",
    "            'I2 spikes': (10,  5)*pq.Hz, # same as Cullins et al. 2015a (based on Hurwitz et al. 1996)\n",
    "            'B8a/b':     ( 3,  3)*pq.Hz, # same as Cullins et al. 2015a (based on Morton and Chiel 1993a)\n",
    "            'B3':        ( 8,  2)*pq.Hz, # based on Lu et al. 2015\n",
    "            'B6/B9':     (10,  5)*pq.Hz, # based on Lu et al. 2015\n",
    "            'B38':       ( 8,  5)*pq.Hz, # based on McManus et al. 2014\n",
    "        },\n",
    "    ),\n",
    "\n",
    "    ('JG14', 'Tape nori', 0): (\n",
    "        'IN VIVO / JG14 / 2019-07-29 / 004',\n",
    "        ['I2', 'RN', 'BN2', 'BN3-PROX', 'Force'],\n",
    "        [831, 870], # 5 swallows\n",
    "        ['Swallow (tape nori)'],\n",
    "        {\n",
    "            'I2 spikes': (10,  5)*pq.Hz, # same as Cullins et al. 2015a (based on Hurwitz et al. 1996)\n",
    "            'B8a/b':     ( 3,  3)*pq.Hz, # same as Cullins et al. 2015a (based on Morton and Chiel 1993a)\n",
    "            'B3':        ( 8,  2)*pq.Hz, # based on Lu et al. 2015\n",
    "            'B6/B9':     (10,  5)*pq.Hz, # based on Lu et al. 2015\n",
    "            'B38':       ( 8,  5)*pq.Hz, # based on McManus et al. 2014\n",
    "        },\n",
    "    ),\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "source": [
    "## Helper Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "outputs": [],
   "source": [
    "def query_union(queries):\n",
    "    return '|'.join([f'({q})' for q in queries if q is not None])\n",
    "\n",
    "def label2query(label):\n",
    "    animal, food = label[:4], label[5:]\n",
    "    query = f'(Animal == \"{animal}\") & (Food == \"{food}\")'\n",
    "    return query\n",
    "\n",
    "def contains(series, string):\n",
    "#     return np.array([string in x for x in series])\n",
    "    return series.map(lambda x: string in x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def update_filter(metadata, new_filter):\n",
    "    i = next((i for i, f in enumerate(metadata['filters']) if f['channel'] == new_filter['channel']), None)\n",
    "    if i is not None:\n",
    "        metadata['filters'][i] = new_filter\n",
    "    else:\n",
    "        metadata['filters'].append(new_filter)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "outputs": [],
   "source": [
    "def get_sig(blk, channel):\n",
    "    sig = next((sig for sig in blk.segments[0].analogsignals if sig.name == channel), None)\n",
    "    if sig is None:\n",
    "        raise Exception(f'Channel \"{channel}\" could not be found')\n",
    "    else:\n",
    "        return sig"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "outputs": [],
   "source": [
    "def finite_min(x, y):\n",
    "    '''Workaround for Quantities warning about comparison to NaN'''\n",
    "    if np.isfinite(x) and np.isfinite(y):\n",
    "        return min(x, y)\n",
    "    elif np.isfinite(x):\n",
    "        return x\n",
    "    elif np.isfinite(y):\n",
    "        return y\n",
    "    else:\n",
    "        return np.nan\n",
    "\n",
    "def finite_max(x, y):\n",
    "    '''Workaround for Quantities warning about comparison to NaN'''\n",
    "    if np.isfinite(x) and np.isfinite(y):\n",
    "        return max(x, y)\n",
    "    elif np.isfinite(x):\n",
    "        return x\n",
    "    elif np.isfinite(y):\n",
    "        return y\n",
    "    else:\n",
    "        return np.nan"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "outputs": [],
   "source": [
    "def find_bursts(st, burst_thresholds):\n",
    "    '''Find every sequence of spikes that qualifies as a burst'''\n",
    "    \n",
    "    isi = elephant.statistics.isi(st).rescale('s')\n",
    "    iff = 1/isi\n",
    "\n",
    "    start_freq, end_freq = burst_thresholds\n",
    "    start_mask = iff > start_freq\n",
    "    end_mask = iff < end_freq\n",
    "\n",
    "    bursts = []\n",
    "    scan_index = -1\n",
    "    while scan_index < iff.size:\n",
    "        start_index = None\n",
    "        end_index = None\n",
    "\n",
    "        start_mask_indexes = np.where(start_mask)[0]\n",
    "        start_mask_indexes = start_mask_indexes[start_mask_indexes > scan_index]\n",
    "        if start_mask_indexes.size == 0:\n",
    "            break\n",
    "\n",
    "        start_index = start_mask_indexes[0] # first time that iff rises above start threshold\n",
    "\n",
    "        end_mask_indexes = np.where(end_mask)[0]\n",
    "        end_mask_indexes = end_mask_indexes[end_mask_indexes > start_index]\n",
    "        if end_mask_indexes.size > 0:\n",
    "            end_index = end_mask_indexes[0] # first time after start that iff drops below end theshold\n",
    "        else:\n",
    "            end_index = -1 # end of spike train (include all spikes after start)\n",
    "\n",
    "        burst = {\n",
    "            'Start (s)': st[start_index].rescale('s'),\n",
    "            'End (s)': st[end_index].rescale('s'),\n",
    "            'Duration (s)': (st[end_index] - st[start_index]).rescale('s'),\n",
    "            'Number of spikes': end_index-start_index+1 if end_index > 0 else st.size-start_index\n",
    "        }\n",
    "        bursts.append(burst)\n",
    "        if end_index == -1:\n",
    "            break\n",
    "        else:\n",
    "            scan_index = end_index\n",
    "    \n",
    "    return bursts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "outputs": [],
   "source": [
    "def is_good_burst(burst):\n",
    "    return burst['Duration (s)'] >= 0.5*pq.s and burst['Number of spikes'] > 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def print_column_analysis(column):\n",
    "    unit = column.split('(')[-1].split(')')[0]\n",
    "    mean = df_all[column].mean()\n",
    "    std = df_all[column].std()\n",
    "    cv = std/abs(mean)\n",
    "    print(f'Overall mean +/- std: {mean:.2f} +/- {std:.2f} {unit}')\n",
    "    print(f'Overall coefficient of variation CV: {cv:.2f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_vertical_lines_with_delay(axes, t, delay, force_y, color):\n",
    "\n",
    "    # plot vertical line in force plot at time t\n",
    "    axes[-1].add_artist(patches.ConnectionPatch(\n",
    "        xyA=(t, force_y), xyB=(t, 1),\n",
    "        coordsA='data', coordsB=axes[-1].get_xaxis_transform(),\n",
    "        axesA=axes[-1], axesB=axes[-1],\n",
    "        color=color, lw=1, ls=':'))\n",
    "    \n",
    "    # plot vertical line through all neural plots at time t-delay\n",
    "    axes[-1].add_artist(patches.ConnectionPatch(\n",
    "        xyA=(t-delay, 0), xyB=(t-delay, 1),\n",
    "        coordsA=axes[-2].get_xaxis_transform(), coordsB=axes[0].get_xaxis_transform(),\n",
    "        axesA=axes[-2], axesB=axes[0],\n",
    "        color=color, lw=1, ls=':'))\n",
    "    \n",
    "    # connect the two lines\n",
    "    axes[-1].add_artist(patches.ConnectionPatch(\n",
    "        xyA=(t-delay, 0), xyB=(t, 1),\n",
    "        coordsA=axes[-2].get_xaxis_transform(), coordsB=axes[-1].get_xaxis_transform(),\n",
    "        axesA=axes[-2], axesB=axes[-1],\n",
    "        color=color, lw=1, ls=':'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def lighten_color(color, amount=0.5):\n",
    "    '''\n",
    "    Lightens the given color by multiplying (1-luminosity) by the given amount.\n",
    "    Input can be matplotlib color string, hex string, or RGB tuple.\n",
    "\n",
    "    Examples:\n",
    "    >> lighten_color('g', 0.3)\n",
    "    >> lighten_color('#F034A3', 0.6)\n",
    "    >> lighten_color((.3,.55,.1), 0.5)\n",
    "    \n",
    "    https://stackoverflow.com/a/49601444/3314376\n",
    "    '''\n",
    "    import matplotlib.colors as mc\n",
    "    import colorsys\n",
    "    try:\n",
    "        c = mc.cnames[color]\n",
    "    except:\n",
    "        c = color\n",
    "    c = colorsys.rgb_to_hls(*mc.to_rgb(c))\n",
    "    return colorsys.hls_to_rgb(c[0], 1 - amount * (1 - c[1]), c[2])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import and Process the Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Main dataframe used for most figures"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "outputs": [],
   "source": [
    "start = datetime.datetime.now()\n",
    "\n",
    "# use Neo RawIO lazy loading to load much faster and using less memory\n",
    "# - with lazy=True, filtering parameters specified in metadata are ignored\n",
    "# - with lazy=True, loading via time_slice requires neo>=0.8.0.dev\n",
    "# - IMPORTANT: force and I2 filters affect smoothness and possibly threshold crossings and spike detection\n",
    "lazy = False\n",
    "\n",
    "# load the metadata containing file paths\n",
    "metadata = neurotic.MetadataSelector(file='../../data/metadata.yml')\n",
    "\n",
    "# filter epochs for each bout and perform calculations\n",
    "df_list = []\n",
    "last_data_set_name = None\n",
    "for (animal, food, bout_index), (data_set_name, channels_to_keep, time_window, epoch_types_to_keep, burst_thresholds) in feeding_bouts.items():\n",
    "    \n",
    "    ###\n",
    "    ### LOCATE BEHAVIOR EPOCHS AND SUBEPOCHS\n",
    "    ###\n",
    "    \n",
    "    metadata.select(data_set_name)\n",
    "    if data_set_name is last_data_set_name:\n",
    "        # skip reloading the data if it's already in memory\n",
    "        pass\n",
    "    else:\n",
    "        blk = neurotic.load_dataset(metadata, lazy=lazy)\n",
    "    last_data_set_name = data_set_name\n",
    "    \n",
    "    # construct a query for locating behaviors\n",
    "    behavior_query = f'(Type in {epoch_types_to_keep}) & ({time_window[0]} <= Start) & (End <= {time_window[1]})'\n",
    "    \n",
    "    # construct queries for locating epochs associated with each behavior\n",
    "    # - each query should match at most one epoch\n",
    "    # - dictionary keys are used as prefixes for the names of new columns\n",
    "    subepoch_queries = {}\n",
    "    \n",
    "    subepoch_queries['I2 protraction activity'] = f'(Type == \"I2 protraction activity\") & ' \\\n",
    "                                                  f'(@behavior_start-1 <= Start) & (End <= @behavior_end)' # must start no earlier than 1 second before behavior and end within it\n",
    "    \n",
    "    subepoch_queries['B8 activity']             = f'(Type == \"B8 activity\") & ' \\\n",
    "                                                  f'(@behavior_start <= Start) & (End <= @behavior_end)' # must be fully contained within behavior\n",
    "    \n",
    "    subepoch_queries['B3/6/9/10 activity']      = f'(Type == \"B3/6/9/10 activity\") & ' \\\n",
    "                                                  f'(@behavior_start <= Start) & (End <= @behavior_end)' # must be fully contained within behavior\n",
    "\n",
    "    subepoch_queries['B38 activity']            = f'(Type == \"B38 activity\") & ' \\\n",
    "                                                  f'(@behavior_end-2 <= Start) & (Start <= @behavior_end+2)' # must start within 2 seconds of behavior end\n",
    "\n",
    "    subepoch_queries['Force dip']               = f'(Type == \"Force dip\") & ' \\\n",
    "                                                  f'(@behavior_start <= Start) & (End <= @behavior_end)' # must be fully contained within behavior\n",
    "    \n",
    "    subepoch_queries['Force shoulder']          = f'(Type == \"Force shoulder\") & ' \\\n",
    "                                                  f'(@behavior_end-2 <= Start) & (Start <= @behavior_end+2)' # must start within 2 seconds of behavior end\n",
    "    \n",
    "    # construct a table in which each row is a behavior and subepoch data\n",
    "    # is added as columns, e.g. df['Force start (s)']\n",
    "    df = BehaviorsDataFrame(blk.segments[0].epochs, behavior_query, subepoch_queries)\n",
    "\n",
    "    \n",
    "    \n",
    "    ###\n",
    "    ### PERFORM CALCULATIONS\n",
    "    ###\n",
    "\n",
    "    # spike train columns must have type 'object', which\n",
    "    # can be accomplished by initializing with None\n",
    "    units = [\n",
    "        'I2 spikes',\n",
    "        'B8a/b',\n",
    "        'B3',\n",
    "        'B6/B9',\n",
    "        'B38',\n",
    "    ]\n",
    "    for unit in units:\n",
    "        df[unit+' spike train'] = None\n",
    "        df[unit+' inter-spike intervals (s)'] = None\n",
    "        df[unit+' all bursts (s)'] = None\n",
    "\n",
    "        # while we're at it, initialize some other things that might otherwise never be given values\n",
    "        df[unit+' first burst start (s)'] = np.nan\n",
    "        df[unit+' first burst end (s)'] = np.nan\n",
    "        df[unit+' first burst duration (s)'] = 0\n",
    "        df[unit+' first burst spike count'] = 0\n",
    "        df[unit+' first burst mean frequency (Hz)'] = np.nan\n",
    "        df[unit+' last burst start (s)'] = np.nan\n",
    "        df[unit+' last burst end (s)'] = np.nan\n",
    "        df[unit+' last burst duration (s)'] = 0\n",
    "        df[unit+' last burst spike count'] = 0\n",
    "        df[unit+' last burst mean frequency (Hz)'] = np.nan\n",
    "\n",
    "\n",
    "    # sanity check: plot all channels for entire time window\n",
    "    fig, axes = plt.subplots(len(channels_to_keep), 1, sharex=True, figsize=(9.5, 10)) # dimensions for notebook\n",
    "#     fig, axes = plt.subplots(len(channels_to_keep), 1, sharex=True, figsize=(11, 8.5)) # dimensions for printing\n",
    "    channel_units = ['uV', 'uV', 'uV', 'uV', 'mN']\n",
    "    for i, channel in enumerate(channels_to_keep):\n",
    "        plt.sca(axes[i])\n",
    "        sig = get_sig(blk, channel)\n",
    "        sig = sig.time_slice(time_window[0]*pq.s, time_window[1]*pq.s)\n",
    "        sig = sig.rescale(channel_units[i])\n",
    "        plt.plot(sig.times, sig.magnitude, c='0.8', lw=1, zorder=-1)\n",
    "        \n",
    "        if i == 0:\n",
    "            plt.title(f'({animal}, {food}, {bout_index}): {data_set_name}')\n",
    "            \n",
    "        plt.ylabel(sig.name + ' (' + sig.units.dimensionality.string + ')')\n",
    "        axes[i].yaxis.set_label_coords(-0.06, 0.5)\n",
    "        \n",
    "        if i < len(channels_to_keep)-1:\n",
    "            # remove right, top, and bottom plot borders, and remove x-axis\n",
    "            sns.despine(ax=plt.gca(), bottom=True)\n",
    "            plt.gca().xaxis.set_visible(False)\n",
    "        else:\n",
    "            # remove right and top plot borders, and set x-label\n",
    "            sns.despine(ax=plt.gca())\n",
    "            plt.xlabel('Time (s)')\n",
    "                \n",
    "\n",
    "    \n",
    "    # sanity check: plot smoothed force for entire time window\n",
    "    channel = 'Force'\n",
    "    sig = get_sig(blk, channel)\n",
    "    if lazy:\n",
    "        sig = sig.time_slice(None, None)\n",
    "    sig = elephant.signal_processing.butter(sig, lowpass_freq = 5*pq.Hz)\n",
    "    sig = sig.time_slice(time_window[0]*pq.s, time_window[1]*pq.s)\n",
    "    sig = sig.rescale('mN')\n",
    "    plt.plot(sig.times, sig.magnitude, c='k', lw=1, zorder=0)\n",
    "    force_smoothed_sig = sig\n",
    "    \n",
    "    \n",
    "    \n",
    "    # iterate over all swallows\n",
    "    for j, i in enumerate(df.index):\n",
    "        \n",
    "        behavior_start = df.loc[i, 'Start (s)']*pq.s\n",
    "        behavior_end = df.loc[i, 'End (s)']*pq.s\n",
    "        \n",
    "        ###\n",
    "        ### FORCE\n",
    "        ###\n",
    "        \n",
    "        # quantify force in each behavior\n",
    "        \n",
    "        force_dip_start = df.loc[i, 'Force dip start (s)']*pq.s\n",
    "        force_rise_start = df.loc[i, 'Force rise start (s)'] = df.loc[i, 'Force dip end (s)']*pq.s\n",
    "        force_shoulder_start = df.loc[i, 'Force shoulder start (s)']*pq.s\n",
    "        force_shoulder_end = df.loc[i, 'Force shoulder end (s)']*pq.s\n",
    "        \n",
    "        # get dip min using smoothed force\n",
    "        sig = force_smoothed_sig\n",
    "        sig = sig.time_slice(force_dip_start, force_rise_start + 0.5*pq.s)\n",
    "        force_min_time = df.loc[i, 'Force min time (s)'] = elephant.spike_train_generation.peak_detection(sig, 1000*pq.mN, sign='below')[0]\n",
    "        force_min = df.loc[i, 'Force min (mN)'] = sig[sig.time_index(force_min_time)][0]\n",
    "\n",
    "        # get smoothed force for whole behavior for remaining force calculations\n",
    "        sig = force_smoothed_sig\n",
    "        if np.isfinite(force_shoulder_end):\n",
    "            sig = sig.time_slice(force_dip_start - 0.01*pq.s, force_shoulder_end + 0.01*pq.s)\n",
    "        else:\n",
    "            sig = sig.time_slice(force_dip_start - 0.01*pq.s, behavior_end + 0.01*pq.s)\n",
    "        sig = sig.rescale('mN')\n",
    "\n",
    "        # find force peak, force baseline, and the force at 50% and 80% of peak height relative to baseline\n",
    "        force_peak_time = elephant.spike_train_generation.peak_detection(sig, 0*pq.mN)[0]\n",
    "        force_peak = df.loc[i, 'Force peak (mN)'] = sig[sig.time_index(force_peak_time)][0]\n",
    "        force_baseline = df.loc[i, 'Force baseline (mN)'] = sig[sig.time_index(force_rise_start)][0]\n",
    "        force_increase = df.loc[i, 'Force increase (mN)'] = force_peak-force_baseline\n",
    "        force_50percent = df.loc[i, 'Force 50%-height (mN)'] = force_baseline + 0.5*force_increase\n",
    "        force_80percent = df.loc[i, 'Force 80%-height (mN)'] = force_baseline + 0.8*force_increase\n",
    "\n",
    "        # find time when force first rises above the 50%-height threshold\n",
    "        crossings = elephant.spike_train_generation.threshold_detection(sig, force_50percent, 'above')\n",
    "        force_50percent_start = df.loc[i, 'Force 50%-height start (s)'] = crossings[np.where(crossings > force_rise_start)[0][0]].rescale('s')\n",
    "        \n",
    "        # find time when force first rises above the 80%-height threshold\n",
    "        crossings = elephant.spike_train_generation.threshold_detection(sig, force_80percent, 'above')\n",
    "        force_80percent_start = df.loc[i, 'Force 80%-height start (s)'] = crossings[np.where(crossings > force_rise_start)[0][0]].rescale('s')\n",
    "        \n",
    "        # find time when force drops below the 80%-height threshold after peaking\n",
    "        crossings = elephant.spike_train_generation.threshold_detection(sig, force_80percent, 'below')\n",
    "        force_80percent_end = df.loc[i, 'Force 80%-height end (s)'] = crossings[np.where(crossings > force_peak_time)[0][0]].rescale('s')\n",
    "        \n",
    "        # find time when force drops below the 50%-height threshold after peaking\n",
    "        crossings = elephant.spike_train_generation.threshold_detection(sig, force_50percent, 'below')\n",
    "        force_50percent_end = df.loc[i, 'Force 50%-height end (s)'] = crossings[np.where(crossings > force_peak_time)[0][0]].rescale('s')\n",
    "        \n",
    "        # find force rise and plateau durations\n",
    "        force_rise_plateau_duration = df.loc[i, 'Force rise and plateau duration (s)'] = force_80percent_end - force_rise_start\n",
    "        force_80percent_duration = df.loc[i, 'Force 80%-height duration (s)'] = force_80percent_end - force_80percent_start\n",
    "        \n",
    "        # find average slope during rising phase\n",
    "        force_slope = df.loc[i, 'Force slope (mN/s)'] = ((force_80percent-force_baseline)/(force_80percent_start-force_rise_start)).rescale('mN/s')\n",
    "\n",
    "        \n",
    "        # sanity check: plot 50%-height and 80%-height force thresholds\n",
    "        plt.sca(axes[channels_to_keep.index('Force')])\n",
    "        plt.plot([force_50percent_start, force_50percent_end], [force_50percent, force_50percent], c='gray', lw=1, ls=':')\n",
    "        plt.plot([force_80percent_start, force_80percent_end], [force_80percent, force_80percent], c='gray', lw=1, ls=':')\n",
    "        \n",
    "        # sanity check: plot force dip\n",
    "        sig2 = sig.time_slice(force_dip_start, force_rise_start)\n",
    "        plt.plot(sig2.times, sig2.magnitude, c=force_colors['dip'], lw=2, zorder=1)\n",
    "        \n",
    "        # sanity check: plot force rise\n",
    "        sig2 = sig.time_slice(force_rise_start, force_80percent_start)\n",
    "        plt.plot(sig2.times, sig2.magnitude, c=force_colors['rise'], lw=2, zorder=1)\n",
    "        \n",
    "        # sanity check: plot force plateau\n",
    "        sig2 = sig.time_slice(force_80percent_start, force_80percent_end)\n",
    "        plt.plot(sig2.times, sig2.magnitude, c=force_colors['plateau'], lw=2, zorder=1)\n",
    "        \n",
    "        # sanity check: plot force shoulder\n",
    "        if np.isfinite(force_shoulder_start):\n",
    "            sig2 = sig.time_slice(force_shoulder_start, force_shoulder_end)\n",
    "            plt.plot(sig2.times, sig2.magnitude, c=force_colors['shoulder'], lw=2, zorder=1)\n",
    "\n",
    "        # sanity check: plot force min, baseline, peak, and threshold crossings\n",
    "        plt.plot([force_min_time],        [force_min],       marker=6, markersize=5, color='k')\n",
    "        plt.plot([force_peak_time],       [force_peak],      marker=7, markersize=5, color='k')\n",
    "#         plt.plot([force_rise_start],      [force_baseline],  marker=6, markersize=5, color='k')\n",
    "#         plt.plot([force_50percent_start], [force_50percent], marker=5, markersize=5, color='k')\n",
    "#         plt.plot([force_50percent_end],   [force_50percent], marker=4, markersize=5, color='k')\n",
    "#         plt.plot([force_80percent_start], [force_80percent], marker=5, markersize=5, color='k')\n",
    "#         plt.plot([force_80percent_end],   [force_80percent], marker=4, markersize=5, color='k')\n",
    "\n",
    "        \n",
    "        \n",
    "        ###\n",
    "        ### FIND SPIKE TRAINS\n",
    "        ###\n",
    "        \n",
    "        if lazy:\n",
    "            if metadata['amplitude_discriminators'] is not None:\n",
    "                for discriminator in metadata['amplitude_discriminators']:\n",
    "                    sig = get_sig(blk, discriminator['channel'])\n",
    "                    if sig is not None:\n",
    "                        sig = sig.time_slice(behavior_start - 5*pq.s, behavior_end + 5*pq.s)\n",
    "                        st = _detect_spikes(sig, discriminator, blk.segments[0].epochs)\n",
    "                        st_epoch_start = df.loc[i, discriminator['epoch']+' start (s)']*pq.s\n",
    "                        st_epoch_end = df.loc[i, discriminator['epoch']+' end (s)']*pq.s\n",
    "                        st = st.time_slice(st_epoch_start, st_epoch_end)\n",
    "                        df.at[i, st.name+' spike train'] = st # 'at', not 'loc', is important for inserting list into cell\n",
    "        else:\n",
    "            for spiketrain in blk.segments[0].spiketrains:\n",
    "                discriminator = next((d for d in metadata['amplitude_discriminators'] if d['name'] == spiketrain.name), None)\n",
    "                if discriminator is None:\n",
    "                    raise Exception(f'For data set \"{data_set_name}\", discriminator \"{spiketrain.name}\" could not be found')\n",
    "                st_epoch_start = df.loc[i, discriminator['epoch']+' start (s)']*pq.s\n",
    "                st_epoch_end = df.loc[i, discriminator['epoch']+' end (s)']*pq.s\n",
    "                st = spiketrain.time_slice(st_epoch_start, st_epoch_end)\n",
    "                df.at[i, st.name+' spike train'] = st # 'at', not 'loc', is important for inserting list into cell\n",
    "    \n",
    "    \n",
    "            \n",
    "        ###\n",
    "        ### QUANTIFY SPIKE TRAINS AND BURSTS\n",
    "        ###\n",
    "        \n",
    "        for k, unit in enumerate(units):\n",
    "            st = df.loc[i, unit+' spike train']\n",
    "            if st is not None:\n",
    "                df.loc[i, unit+' spike count'] = st.size\n",
    "                if st.size > 0:\n",
    "                    \n",
    "                    # get the neural channel\n",
    "                    channel = st.annotations['channels'][0]\n",
    "                    sig = get_sig(blk, channel)\n",
    "\n",
    "                    # get the signal for the behavior with 10 seconds cushion before and after (for better baseline estimation)\n",
    "                    sig = sig.time_slice(behavior_start - 10*pq.s, behavior_end + 10*pq.s)\n",
    "                    sig = sig.rescale(channel_units[channels_to_keep.index(channel)])\n",
    "                    \n",
    "                    # find every sequence of spikes that qualifies as a burst\n",
    "                    bursts = df.at[i, unit+' all bursts (s)'] = find_bursts(st, burst_thresholds[unit]) # 'at', not 'loc', is important for inserting list into cell\n",
    "                    \n",
    "                    first_burst_start = np.nan\n",
    "                    first_burst_end = np.nan\n",
    "                    first_burst_spike_count = 0\n",
    "                    first_burst_mean_freq = 0*pq.Hz\n",
    "                    last_burst_start = np.nan\n",
    "                    last_burst_end = np.nan\n",
    "                    last_burst_spike_count = 0\n",
    "                    last_burst_mean_freq = 0*pq.Hz\n",
    "                    if len(bursts) > 0:\n",
    "\n",
    "                        for burst in bursts:\n",
    "                            if is_good_burst(burst):\n",
    "                                first_burst_start, first_burst_end = burst['Start (s)'], burst['End (s)']\n",
    "                                first_burst_duration = first_burst_end-first_burst_start\n",
    "                                df.loc[i, unit+' first burst start (s)'] = first_burst_start.rescale('s')\n",
    "                                df.loc[i, unit+' first burst end (s)'] = first_burst_end.rescale('s')\n",
    "                                first_burst_duration = df.loc[i, unit+' first burst duration (s)'] = first_burst_duration.rescale('s')\n",
    "                                first_burst_spike_count = df.loc[i, unit+' first burst spike count'] = st.time_slice(first_burst_start, first_burst_end).size\n",
    "                                first_burst_mean_freq = df.loc[i, unit+' first burst mean frequency (Hz)'] = ((first_burst_spike_count-1)/first_burst_duration).rescale('Hz')\n",
    "                                \n",
    "                                # find burst RAUC and mean voltage\n",
    "                                first_burst_rauc = df.loc[i, unit+' first burst RAUC (μV·s)'] = elephant.signal_processing.rauc(sig, baseline='mean', t_start=first_burst_start, t_stop=first_burst_end).rescale('uV*s')\n",
    "                                first_burst_mean_rect_voltage = df.loc[i, unit+' first burst mean rectified voltage (μV)'] = first_burst_rauc/first_burst_duration\n",
    "\n",
    "                                break # quit after finding first good burst\n",
    "\n",
    "                        for burst in reversed(bursts):\n",
    "                            if is_good_burst(burst):\n",
    "                                last_burst_start, last_burst_end = burst['Start (s)'], burst['End (s)']\n",
    "                                last_burst_duration = last_burst_end-last_burst_start\n",
    "                                df.loc[i, unit+' last burst start (s)'] = last_burst_start.rescale('s')\n",
    "                                df.loc[i, unit+' last burst end (s)'] = last_burst_end.rescale('s')\n",
    "                                last_burst_duration = df.loc[i, unit+' last burst duration (s)'] = last_burst_duration.rescale('s')\n",
    "                                last_burst_spike_count = df.loc[i, unit+' last burst spike count'] = st.time_slice(last_burst_start, last_burst_end).size\n",
    "                                last_burst_mean_freq = df.loc[i, unit+' last burst mean frequency (Hz)'] = ((last_burst_spike_count-1)/last_burst_duration).rescale('Hz')\n",
    "\n",
    "                                # find burst RAUC and mean voltage\n",
    "                                last_burst_rauc = df.loc[i, unit+' last burst RAUC (μV·s)'] = elephant.signal_processing.rauc(sig, baseline='mean', t_start=last_burst_start, t_stop=last_burst_end).rescale('uV*s')\n",
    "                                last_burst_mean_rect_voltage = df.loc[i, unit+' last burst mean rectified voltage (μV)'] = last_burst_rauc/last_burst_duration\n",
    "    \n",
    "                                break # quit after finding first (actually, last) good burst\n",
    "\n",
    "                                    \n",
    "                    # sanity check: plot spikes\n",
    "                    plt.sca(axes[channels_to_keep.index(channel)])\n",
    "                    marker = ['.', 'x'][j%2] # alternate markers between behaviors\n",
    "                    \n",
    "                    spike_amplitudes = np.array([sig[sig.time_index(t)] for t in st]) * pq.Quantity(sig.units)\n",
    "                    plt.scatter(st.times.rescale('s'), spike_amplitudes, marker=marker, c=unit_colors[unit])\n",
    "\n",
    "                    # sanity check: plot burst windows\n",
    "                    discriminator = next((d for d in metadata['amplitude_discriminators'] if d['name'] == st.name), None)\n",
    "                    if discriminator is None:\n",
    "                        raise Exception(f'For data set \"{data_set_name}\", discriminator \"{st.name}\" could not be found')\n",
    "                    bottom = pq.Quantity(discriminator['amplitude'][0], discriminator['units']).rescale(sig.units)\n",
    "                    top = pq.Quantity(discriminator['amplitude'][1], discriminator['units']).rescale(sig.units)\n",
    "                    height = top-bottom\n",
    "                    for burst in bursts:\n",
    "                        left = burst['Start (s)']\n",
    "                        right = burst['End (s)']\n",
    "                        width = right-left\n",
    "                        linestyle = '-' if is_good_burst(burst) else '--'\n",
    "                        rect = patches.Rectangle((left, bottom), width, height, ls=linestyle, edgecolor=unit_colors[unit], fill=False)\n",
    "                        plt.gca().add_patch(rect)\n",
    "\n",
    "                    # sanity check: plot markers for edges of bursts\n",
    "                    if top > 0:\n",
    "                        plt.plot([first_burst_start], [top], marker=7, markersize=5, color='k')#unit_colors[unit])\n",
    "                        plt.plot([last_burst_end], [top], marker=7, markersize=5, color='k')#unit_colors[unit])\n",
    "                    else:\n",
    "                        plt.plot([first_burst_start], [bottom], marker=6, markersize=5, color='k')#unit_colors[unit])\n",
    "                        plt.plot([last_burst_end], [bottom], marker=6, markersize=5, color='k')#unit_colors[unit])\n",
    "\n",
    "\n",
    "\n",
    "        ###\n",
    "        ### INSTANTANEOUS FIRING FREQUENCIES\n",
    "        ###\n",
    "        \n",
    "        for unit in ['B6/B9']:\n",
    "            st = df.loc[i, unit+' spike train']\n",
    "            if st is not None:\n",
    "                if st.size > 0:\n",
    "                    channel = st.annotations['channels'][0]\n",
    "                    plt.sca(axes[channels_to_keep.index(channel)])\n",
    "                    \n",
    "                    times = st.times.rescale('s')\n",
    "                    times = np.concatenate([[behavior_start], times, [behavior_end]])*pq.s\n",
    "                    iff = 1/elephant.statistics.isi(st)\n",
    "                    iff = np.concatenate([[0], iff.rescale('1/s'), [0, 0]])/pq.s\n",
    "                    \n",
    "                    # arbitrary rescaling to fit in plot\n",
    "                    shift = -6 * np.abs(discriminator['amplitude']).max()\n",
    "                    iff = iff.magnitude/5+shift\n",
    "                    \n",
    "                    plt.plot(times, iff, drawstyle='steps-post', c=lighten_color(unit_colors[unit], amount=0.7), zorder=0)\n",
    "        \n",
    "        \n",
    "        \n",
    "        ###\n",
    "        ### TIMING DELAYS\n",
    "        ###\n",
    "        \n",
    "        i2_burst_start   = df.loc[i, 'I2 spikes first burst start (s)']*pq.s\n",
    "        i2_burst_end     = df.loc[i, 'I2 spikes last burst end (s)']*pq.s\n",
    "        b8_burst_start   = df.loc[i, 'B8a/b first burst start (s)']*pq.s\n",
    "        b8_burst_end     = df.loc[i, 'B8a/b last burst end (s)']*pq.s\n",
    "        b6b9_burst_start = df.loc[i, 'B6/B9 first burst start (s)']*pq.s\n",
    "        b6b9_burst_end   = df.loc[i, 'B6/B9 last burst end (s)']*pq.s\n",
    "        b3_burst_start   = df.loc[i, 'B3 first burst start (s)']*pq.s\n",
    "        b3_burst_end     = df.loc[i, 'B3 last burst end (s)']*pq.s\n",
    "        b38_burst_start  = df.loc[i, 'B38 first burst start (s)']*pq.s\n",
    "        b38_burst_end    = df.loc[i, 'B38 last burst end (s)']*pq.s\n",
    "        \n",
    "        # consider B3/B6/B9 bursting if either B3 or B6/B9 is bursting\n",
    "        b3b6b9_burst_start    = df.loc[i, 'B3/B6/B9 burst start (s)']    = finite_min(b6b9_burst_start, b3_burst_start)\n",
    "        b3b6b9_burst_end      = df.loc[i, 'B3/B6/B9 burst end (s)']      = finite_max(b6b9_burst_end,   b3_burst_end)\n",
    "        b3b6b9_burst_duration = df.loc[i, 'B3/B6/B9 burst duration (s)'] = b3b6b9_burst_end - b3b6b9_burst_start\n",
    "        \n",
    "        # consider bursting only if B8a/b and B3/B6/B9 are both bursting\n",
    "        b8_or_b3b6b9_burst_end = df.loc[i, 'B8a/b and B3/B6/B9 conjunction end (s)'] = \\\n",
    "                                           finite_min(b8_burst_end, b3b6b9_burst_end)\n",
    "        \n",
    "        # delays from neural to force\n",
    "        i2_force_min_delay             = df.loc[i, 'Delay from I2 end to force min (s)'] = \\\n",
    "                                                   force_min_time - i2_burst_end\n",
    "\n",
    "        b8_force_start_delay           = df.loc[i, 'Delay from B8a/b start to force start (s)'] = \\\n",
    "                                                   force_rise_start - b8_burst_start\n",
    "        b8_force_end_delay             = df.loc[i, 'Delay from B8a/b end to force end (s)'] = \\\n",
    "                                                   force_80percent_end - b8_burst_end\n",
    "        \n",
    "        b6b9_force_start_delay         = df.loc[i, 'Delay from B6/B9 start to force start (s)'] = \\\n",
    "                                                   force_rise_start - b6b9_burst_start\n",
    "        b6b9_force_end_delay           = df.loc[i, 'Delay from B6/B9 end to force end (s)'] = \\\n",
    "                                                   force_80percent_end - b6b9_burst_end\n",
    "\n",
    "        b3b6b9_force_start_delay       = df.loc[i, 'Delay from B3/B6/B9 start to force start (s)'] = \\\n",
    "                                                   force_rise_start - b3b6b9_burst_start\n",
    "        b3b6b9_force_end_delay         = df.loc[i, 'Delay from B3/B6/B9 end to force end (s)'] = \\\n",
    "                                                   force_80percent_end - b3b6b9_burst_end\n",
    "        b3b6b9_force_50percent_delay   = df.loc[i, 'Delay from B3/B6/B9 start to force 50%-height (s)'] = \\\n",
    "                                                   force_50percent_start - b3b6b9_burst_start\n",
    "        b3b6b9_force_80percent_delay   = df.loc[i, 'Delay from B3/B6/B9 start to force 80%-height (s)'] = \\\n",
    "                                                   force_80percent_start - b3b6b9_burst_start\n",
    "        \n",
    "        b3_force_80percent_start_delay = df.loc[i, 'Delay from B3 start to force 80%-height start (s)'] = \\\n",
    "                                                   force_80percent_start - b3_burst_start\n",
    "        b3_force_80percent_end_delay   = df.loc[i, 'Delay from B3 end to force 80%-height end (s)'] = \\\n",
    "                                                   force_80percent_end - b3_burst_end\n",
    "        b8_or_b3b6b9_force_80percent_end_delay = \\\n",
    "                                         df.loc[i, 'Delay from either B8a/b or B3/B6/B9 end to force 80%-height end (s)'] = \\\n",
    "                                                   force_80percent_end - b8_or_b3b6b9_burst_end\n",
    "        \n",
    "        b38_shoulder_start_delay       = df.loc[i, 'Delay from B38 start to shoulder start (s)'] = \\\n",
    "                                                   force_shoulder_start - b38_burst_start\n",
    "        b38_shoulder_end_delay         = df.loc[i, 'Delay from B38 end to shoulder end (s)'] = \\\n",
    "                                                   force_shoulder_end - b38_burst_end\n",
    "\n",
    "    \n",
    "\n",
    "        ###\n",
    "        ### MISC\n",
    "        ###\n",
    "        \n",
    "        st = df.loc[i, 'B8a/b spike train']\n",
    "        b8_preb3b6b9_burst_duration    = df.loc[i, 'B8a/b pre-B3/B6/B9 burst duration (s)'] = \\\n",
    "                                                   b3b6b9_burst_start - b8_burst_start\n",
    "        b8_preb3b6b9_burst_spike_count = df.loc[i, 'B8a/b pre-B3/B6/B9 burst spike count'] = \\\n",
    "                                                   st.time_slice(b8_burst_start, b3b6b9_burst_start).size\n",
    "        b8_preb3b6b9_burst_mean_freq   = df.loc[i, 'B8a/b pre-B3/B6/B9 burst mean frequency (Hz)'] = \\\n",
    "                                                   ((b8_preb3b6b9_burst_spike_count-1)/b8_preb3b6b9_burst_duration).rescale('Hz')\n",
    "        \n",
    "        # get the neural channel\n",
    "        channel = st.annotations['channels'][0]\n",
    "        sig = get_sig(blk, channel)\n",
    "        \n",
    "        # get the signal for the behavior with 5 seconds cushion before and after (for better baseline estimation)\n",
    "        sig = sig.time_slice(behavior_start - 5*pq.s, behavior_end + 5*pq.s)\n",
    "        sig = sig.rescale('uV')\n",
    "\n",
    "        # find RAUC and mean voltage for B8a/b before B3/B6/B9 start in each behavior\n",
    "        if np.isfinite(b8_burst_start) and np.isfinite(b3b6b9_burst_start):\n",
    "            b8_preb3b6b9_rauc = df.loc[i, 'B8a/b pre-B3/B6/B9 burst RAUC (μV·s)'] = elephant.signal_processing.rauc(sig, baseline='mean', t_start=b8_burst_start, t_stop=b3b6b9_burst_start).rescale('uV*s')\n",
    "            b8_preb3b6b9_mean_rect_voltage = df.loc[i, 'B8a/b pre-B3/B6/B9 burst mean rectified voltage (μV)'] = b8_preb3b6b9_rauc/b8_preb3b6b9_burst_duration\n",
    "        else:\n",
    "            print(f'Missing either B8a/b burst and/or B3/B6/B9 burst in data set \"{data_set_name}\" for swallow spanning times ({behavior_start}, {behavior_end})')\n",
    "\n",
    "            \n",
    "        # get force during rise and plateau\n",
    "        sig = get_sig(blk, 'Force')\n",
    "        sig = sig.time_slice(force_rise_start, force_80percent_end)\n",
    "        sig = sig.rescale('mN')\n",
    "        \n",
    "        # get force at end of B8-only burst, offset by delay\n",
    "        force_b8_only_rise_end = df.loc[i, 'Force delayed B8-only rise end (s)'] = force_rise_start + b8_preb3b6b9_burst_duration\n",
    "        force_b8_only_rise_height = df.loc[i, 'Force at delayed B8-only rise end (mN)'] = sig[sig.time_index(force_b8_only_rise_end)][0]\n",
    "\n",
    "        # find average slope during initial rising phase (before B3/B6/B9 begin, offset by delay)\n",
    "        force_initial_increase = df.loc[i, 'Force initial increase (mN)'] = (force_b8_only_rise_height-force_baseline).rescale('mN')\n",
    "        force_initial_slope = df.loc[i, 'Force initial slope (mN/s)'] = (force_initial_increase/b8_preb3b6b9_burst_duration).rescale('mN/s')\n",
    "\n",
    "        \n",
    "        \n",
    "        # sanity check: plot force initial rise\n",
    "#         sig = force_smoothed_sig\n",
    "#         sig = sig.time_slice(force_rise_start, force_b8_only_rise_end)\n",
    "#         sig = sig.rescale('mN')\n",
    "#         plt.sca(axes[channels_to_keep.index('Force')])\n",
    "#         plt.plot(sig.times, sig.magnitude, c=force_colors['initial rise'], lw=2, zorder=1)\n",
    "        \n",
    "        \n",
    "        \n",
    "        # sanity check: plot important times across all subplots, with delays set by I2 end and force min\n",
    "        if j == 0:\n",
    "            muscle_delay = i2_force_min_delay\n",
    "            axes[-1].text(\n",
    "                force_min_time, 1.05, f\"{muscle_delay.rescale('ms'):.0f} ms delay\",\n",
    "                horizontalalignment='left', verticalalignment='center', transform=axes[-1].get_xaxis_transform(),\n",
    "                fontsize=8)\n",
    "        plot_vertical_lines_with_delay(axes, force_min_time, muscle_delay, force_min, force_colors['dip'])\n",
    "        plot_vertical_lines_with_delay(axes, force_80percent_start, muscle_delay, force_80percent, force_colors['plateau'])\n",
    "        plot_vertical_lines_with_delay(axes, force_80percent_end, muscle_delay, force_80percent, force_colors['plateau'])\n",
    "        if np.isfinite(force_shoulder_end):\n",
    "            sig = force_smoothed_sig\n",
    "            plot_vertical_lines_with_delay(axes, force_shoulder_end, muscle_delay, sig[sig.time_index(force_shoulder_end)][0], force_colors['shoulder'])\n",
    "\n",
    "\n",
    "        \n",
    "    # optimize plot margins\n",
    "    plt.subplots_adjust(\n",
    "        left   = 0.1,\n",
    "        right  = 0.99,\n",
    "        top    = 0.96,\n",
    "        bottom = 0.06,\n",
    "        hspace = 0.15,\n",
    "    )\n",
    "    \n",
    "    # export figure\n",
    "    plt.gcf().savefig(f'sanity-checks/{animal} {food} {bout_index}.png', dpi=300)\n",
    "\n",
    "    # renumber behaviors assuming all behaviors are from a single contiguous sequence\n",
    "    df = df.sort_values('Start (s)').reset_index(drop=True).rename_axis('Behavior_index')\n",
    "    \n",
    "    # index the table on 4 variables\n",
    "    df['Animal'] = animal\n",
    "    df['Food'] = food\n",
    "    df['Bout_index'] = bout_index\n",
    "    df = df.reset_index().set_index(['Animal', 'Food', 'Bout_index', 'Behavior_index'])\n",
    "    \n",
    "    df_list += [df]\n",
    "    \n",
    "df_all = pd.concat(df_list, sort=False).sort_index()\n",
    "\n",
    "end = datetime.datetime.now()\n",
    "print('elapsed time:', end-start)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Plots with \"keeper\" markers only"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "start = datetime.datetime.now()\n",
    "\n",
    "# use Neo RawIO lazy loading to load much faster and using less memory\n",
    "# - with lazy=True, filtering parameters specified in metadata are ignored\n",
    "# - with lazy=True, loading via time_slice requires neo>=0.8.0.dev\n",
    "# - IMPORTANT: force and I2 filters affect smoothness and possibly threshold crossings and spike detection\n",
    "lazy = False\n",
    "\n",
    "# load the metadata containing file paths\n",
    "metadata = neurotic.MetadataSelector(file='../../data/metadata.yml')\n",
    "\n",
    "# filter epochs for each bout and perform calculations\n",
    "df_list = []\n",
    "last_data_set_name = None\n",
    "for (animal, food, bout_index), (data_set_name, channels_to_keep, time_window, epoch_types_to_keep, burst_thresholds) in feeding_bouts.items():\n",
    "    \n",
    "    ###\n",
    "    ### LOCATE BEHAVIOR EPOCHS AND SUBEPOCHS\n",
    "    ###\n",
    "    \n",
    "    metadata.select(data_set_name)\n",
    "    if data_set_name is last_data_set_name:\n",
    "        # skip reloading the data if it's already in memory\n",
    "        pass\n",
    "    else:\n",
    "        blk = neurotic.load_dataset(metadata, lazy=lazy)\n",
    "    last_data_set_name = data_set_name\n",
    "    \n",
    "    # construct a query for locating behaviors\n",
    "    behavior_query = f'(Type in {epoch_types_to_keep}) & ({time_window[0]} <= Start) & (End <= {time_window[1]})'\n",
    "    \n",
    "    # construct queries for locating epochs associated with each behavior\n",
    "    # - each query should match at most one epoch\n",
    "    # - dictionary keys are used as prefixes for the names of new columns\n",
    "    subepoch_queries = {}\n",
    "    \n",
    "    subepoch_queries['I2 protraction activity'] = f'(Type == \"I2 protraction activity\") & ' \\\n",
    "                                                  f'(@behavior_start-1 <= Start) & (End <= @behavior_end)' # must start no earlier than 1 second before behavior and end within it\n",
    "    \n",
    "    subepoch_queries['B8 activity']             = f'(Type == \"B8 activity\") & ' \\\n",
    "                                                  f'(@behavior_start <= Start) & (End <= @behavior_end)' # must be fully contained within behavior\n",
    "    \n",
    "    subepoch_queries['B3/6/9/10 activity']      = f'(Type == \"B3/6/9/10 activity\") & ' \\\n",
    "                                                  f'(@behavior_start <= Start) & (End <= @behavior_end)' # must be fully contained within behavior\n",
    "\n",
    "    subepoch_queries['B38 activity']            = f'(Type == \"B38 activity\") & ' \\\n",
    "                                                  f'(@behavior_end-2 <= Start) & (Start <= @behavior_end+2)' # must start within 2 seconds of behavior end\n",
    "\n",
    "    subepoch_queries['Force dip']               = f'(Type == \"Force dip\") & ' \\\n",
    "                                                  f'(@behavior_start <= Start) & (End <= @behavior_end)' # must be fully contained within behavior\n",
    "    \n",
    "    subepoch_queries['Force shoulder']          = f'(Type == \"Force shoulder\") & ' \\\n",
    "                                                  f'(@behavior_end-2 <= Start) & (Start <= @behavior_end+2)' # must start within 2 seconds of behavior end\n",
    "    \n",
    "    # construct a table in which each row is a behavior and subepoch data\n",
    "    # is added as columns, e.g. df['Force start (s)']\n",
    "    df = BehaviorsDataFrame(blk.segments[0].epochs, behavior_query, subepoch_queries)\n",
    "\n",
    "    \n",
    "    \n",
    "    ###\n",
    "    ### PERFORM CALCULATIONS\n",
    "    ###\n",
    "\n",
    "    # spike train columns must have type 'object', which\n",
    "    # can be accomplished by initializing with None\n",
    "    units = [\n",
    "        'I2 spikes',\n",
    "        'B8a/b',\n",
    "        'B3',\n",
    "        'B6/B9',\n",
    "        'B38',\n",
    "    ]\n",
    "    for unit in units:\n",
    "        df[unit+' spike train'] = None\n",
    "        df[unit+' inter-spike intervals (s)'] = None\n",
    "        df[unit+' all bursts (s)'] = None\n",
    "\n",
    "        # while we're at it, initialize some other things that might otherwise never be given values\n",
    "        df[unit+' first burst start (s)'] = np.nan\n",
    "        df[unit+' first burst end (s)'] = np.nan\n",
    "        df[unit+' first burst duration (s)'] = 0\n",
    "        df[unit+' first burst spike count'] = 0\n",
    "        df[unit+' first burst mean frequency (Hz)'] = np.nan\n",
    "        df[unit+' last burst start (s)'] = np.nan\n",
    "        df[unit+' last burst end (s)'] = np.nan\n",
    "        df[unit+' last burst duration (s)'] = 0\n",
    "        df[unit+' last burst spike count'] = 0\n",
    "        df[unit+' last burst mean frequency (Hz)'] = np.nan\n",
    "\n",
    "\n",
    "    # sanity check: plot all channels for entire time window\n",
    "    fig, axes = plt.subplots(len(channels_to_keep), 1, sharex=True, figsize=(9.5, 10)) # dimensions for notebook\n",
    "#     fig, axes = plt.subplots(len(channels_to_keep), 1, sharex=True, figsize=(11, 8.5)) # dimensions for printing\n",
    "    channel_units = ['uV', 'uV', 'uV', 'uV', 'mN']\n",
    "    for i, channel in enumerate(channels_to_keep):\n",
    "        plt.sca(axes[i])\n",
    "        sig = get_sig(blk, channel)\n",
    "        sig = sig.time_slice(time_window[0]*pq.s, time_window[1]*pq.s)\n",
    "        sig = sig.rescale(channel_units[i])\n",
    "        plt.plot(sig.times, sig.magnitude, c='0.8', lw=1, zorder=-1)\n",
    "        \n",
    "        if i == 0:\n",
    "            plt.title(f'({animal}, {food}, {bout_index}): {data_set_name}')\n",
    "            \n",
    "        plt.ylabel(sig.name + ' (' + sig.units.dimensionality.string + ')')\n",
    "        axes[i].yaxis.set_label_coords(-0.06, 0.5)\n",
    "        \n",
    "        if i < len(channels_to_keep)-1:\n",
    "            # remove right, top, and bottom plot borders, and remove x-axis\n",
    "            sns.despine(ax=plt.gca(), bottom=True)\n",
    "            plt.gca().xaxis.set_visible(False)\n",
    "        else:\n",
    "            # remove right and top plot borders, and set x-label\n",
    "            sns.despine(ax=plt.gca())\n",
    "            plt.xlabel('Time (s)')\n",
    "                \n",
    "\n",
    "    \n",
    "    # sanity check: plot smoothed force for entire time window\n",
    "    channel = 'Force'\n",
    "    sig = get_sig(blk, channel)\n",
    "    if lazy:\n",
    "        sig = sig.time_slice(None, None)\n",
    "    sig = elephant.signal_processing.butter(sig, lowpass_freq = 5*pq.Hz)\n",
    "    sig = sig.time_slice(time_window[0]*pq.s, time_window[1]*pq.s)\n",
    "    sig = sig.rescale('mN')\n",
    "    plt.plot(sig.times, sig.magnitude, c='k', lw=1, zorder=0)\n",
    "    force_smoothed_sig = sig\n",
    "    \n",
    "    \n",
    "    \n",
    "    # iterate over all swallows\n",
    "    for j, i in enumerate(df.index):\n",
    "        \n",
    "        behavior_start = df.loc[i, 'Start (s)']*pq.s\n",
    "        behavior_end = df.loc[i, 'End (s)']*pq.s\n",
    "        \n",
    "        ###\n",
    "        ### FORCE\n",
    "        ###\n",
    "        \n",
    "        # quantify force in each behavior\n",
    "        \n",
    "        force_dip_start = df.loc[i, 'Force dip start (s)']*pq.s\n",
    "        force_rise_start = df.loc[i, 'Force rise start (s)'] = df.loc[i, 'Force dip end (s)']*pq.s\n",
    "        force_shoulder_start = df.loc[i, 'Force shoulder start (s)']*pq.s\n",
    "        force_shoulder_end = df.loc[i, 'Force shoulder end (s)']*pq.s\n",
    "        \n",
    "        # get dip min using smoothed force\n",
    "        sig = force_smoothed_sig\n",
    "        sig = sig.time_slice(force_dip_start, force_rise_start + 0.5*pq.s)\n",
    "        force_min_time = df.loc[i, 'Force min time (s)'] = elephant.spike_train_generation.peak_detection(sig, 1000*pq.mN, sign='below')[0]\n",
    "        force_min = df.loc[i, 'Force min (mN)'] = sig[sig.time_index(force_min_time)][0]\n",
    "\n",
    "        # get smoothed force for whole behavior for remaining force calculations\n",
    "        sig = force_smoothed_sig\n",
    "        if np.isfinite(force_shoulder_end):\n",
    "            sig = sig.time_slice(force_dip_start - 0.01*pq.s, force_shoulder_end + 0.01*pq.s)\n",
    "        else:\n",
    "            sig = sig.time_slice(force_dip_start - 0.01*pq.s, behavior_end + 0.01*pq.s)\n",
    "        sig = sig.rescale('mN')\n",
    "\n",
    "        # find force peak, force baseline, and the force at 50% and 80% of peak height relative to baseline\n",
    "        force_peak_time = elephant.spike_train_generation.peak_detection(sig, 0*pq.mN)[0]\n",
    "        force_peak = df.loc[i, 'Force peak (mN)'] = sig[sig.time_index(force_peak_time)][0]\n",
    "        force_baseline = df.loc[i, 'Force baseline (mN)'] = sig[sig.time_index(force_rise_start)][0]\n",
    "        force_increase = df.loc[i, 'Force increase (mN)'] = force_peak-force_baseline\n",
    "        force_50percent = df.loc[i, 'Force 50%-height (mN)'] = force_baseline + 0.5*force_increase\n",
    "        force_80percent = df.loc[i, 'Force 80%-height (mN)'] = force_baseline + 0.8*force_increase\n",
    "\n",
    "        # find time when force first rises above the 50%-height threshold\n",
    "        crossings = elephant.spike_train_generation.threshold_detection(sig, force_50percent, 'above')\n",
    "        force_50percent_start = df.loc[i, 'Force 50%-height start (s)'] = crossings[np.where(crossings > force_rise_start)[0][0]].rescale('s')\n",
    "        \n",
    "        # find time when force first rises above the 80%-height threshold\n",
    "        crossings = elephant.spike_train_generation.threshold_detection(sig, force_80percent, 'above')\n",
    "        force_80percent_start = df.loc[i, 'Force 80%-height start (s)'] = crossings[np.where(crossings > force_rise_start)[0][0]].rescale('s')\n",
    "        \n",
    "        # find time when force drops below the 80%-height threshold after peaking\n",
    "        crossings = elephant.spike_train_generation.threshold_detection(sig, force_80percent, 'below')\n",
    "        force_80percent_end = df.loc[i, 'Force 80%-height end (s)'] = crossings[np.where(crossings > force_peak_time)[0][0]].rescale('s')\n",
    "        \n",
    "        # find time when force drops below the 50%-height threshold after peaking\n",
    "        crossings = elephant.spike_train_generation.threshold_detection(sig, force_50percent, 'below')\n",
    "        force_50percent_end = df.loc[i, 'Force 50%-height end (s)'] = crossings[np.where(crossings > force_peak_time)[0][0]].rescale('s')\n",
    "        \n",
    "        # find force rise and plateau durations\n",
    "        force_rise_plateau_duration = df.loc[i, 'Force rise and plateau duration (s)'] = force_80percent_end - force_rise_start\n",
    "        force_80percent_duration = df.loc[i, 'Force 80%-height duration (s)'] = force_80percent_end - force_80percent_start\n",
    "        \n",
    "        # find average slope during rising phase\n",
    "        force_slope = df.loc[i, 'Force slope (mN/s)'] = ((force_80percent-force_baseline)/(force_80percent_start-force_rise_start)).rescale('mN/s')\n",
    "\n",
    "        \n",
    "        # sanity check: plot 50%-height and 80%-height force thresholds\n",
    "        plt.sca(axes[channels_to_keep.index('Force')])\n",
    "#         plt.plot([force_50percent_start, force_50percent_end], [force_50percent, force_50percent], c='gray', lw=1, ls=':')\n",
    "#         plt.plot([force_80percent_start, force_80percent_end], [force_80percent, force_80percent], c='gray', lw=1, ls=':')\n",
    "        \n",
    "        # sanity check: plot force dip\n",
    "#         sig2 = sig.time_slice(force_dip_start, force_rise_start)\n",
    "#         plt.plot(sig2.times, sig2.magnitude, c=force_colors['dip'], lw=2, zorder=1)\n",
    "        \n",
    "        # sanity check: plot force rise\n",
    "#         sig2 = sig.time_slice(force_rise_start, force_80percent_start)\n",
    "#         plt.plot(sig2.times, sig2.magnitude, c=force_colors['rise'], lw=2, zorder=1)\n",
    "        \n",
    "        # sanity check: plot force plateau\n",
    "#         sig2 = sig.time_slice(force_80percent_start, force_80percent_end)\n",
    "#         plt.plot(sig2.times, sig2.magnitude, c=force_colors['plateau'], lw=2, zorder=1)\n",
    "        \n",
    "        # sanity check: plot force shoulder\n",
    "#         if np.isfinite(force_shoulder_start):\n",
    "#             sig2 = sig.time_slice(force_shoulder_start, force_shoulder_end)\n",
    "#             plt.plot(sig2.times, sig2.magnitude, c=force_colors['shoulder'], lw=2, zorder=1)\n",
    "\n",
    "        # sanity check: plot force min, baseline, peak, and threshold crossings\n",
    "#         plt.plot([force_min_time],        [force_min],       marker=6, markersize=5, color='k')\n",
    "#         plt.plot([force_peak_time],       [force_peak],      marker=7, markersize=5, color='k')\n",
    "#         plt.plot([force_rise_start],      [force_baseline],  marker=6, markersize=5, color='k')\n",
    "#         plt.plot([force_50percent_start], [force_50percent], marker=5, markersize=5, color='k')\n",
    "#         plt.plot([force_50percent_end],   [force_50percent], marker=4, markersize=5, color='k')\n",
    "#         plt.plot([force_80percent_start], [force_80percent], marker=5, markersize=5, color='k')\n",
    "#         plt.plot([force_80percent_end],   [force_80percent], marker=4, markersize=5, color='k')\n",
    "\n",
    "        \n",
    "        \n",
    "        ###\n",
    "        ### FIND SPIKE TRAINS\n",
    "        ###\n",
    "        \n",
    "        if lazy:\n",
    "            if metadata['amplitude_discriminators'] is not None:\n",
    "                for discriminator in metadata['amplitude_discriminators']:\n",
    "                    sig = get_sig(blk, discriminator['channel'])\n",
    "                    if sig is not None:\n",
    "                        sig = sig.time_slice(behavior_start - 5*pq.s, behavior_end + 5*pq.s)\n",
    "                        st = _detect_spikes(sig, discriminator, blk.segments[0].epochs)\n",
    "                        st_epoch_start = df.loc[i, discriminator['epoch']+' start (s)']*pq.s\n",
    "                        st_epoch_end = df.loc[i, discriminator['epoch']+' end (s)']*pq.s\n",
    "                        st = st.time_slice(st_epoch_start, st_epoch_end)\n",
    "                        df.at[i, st.name+' spike train'] = st # 'at', not 'loc', is important for inserting list into cell\n",
    "        else:\n",
    "            for spiketrain in blk.segments[0].spiketrains:\n",
    "                discriminator = next((d for d in metadata['amplitude_discriminators'] if d['name'] == spiketrain.name), None)\n",
    "                if discriminator is None:\n",
    "                    raise Exception(f'For data set \"{data_set_name}\", discriminator \"{spiketrain.name}\" could not be found')\n",
    "                st_epoch_start = df.loc[i, discriminator['epoch']+' start (s)']*pq.s\n",
    "                st_epoch_end = df.loc[i, discriminator['epoch']+' end (s)']*pq.s\n",
    "                st = spiketrain.time_slice(st_epoch_start, st_epoch_end)\n",
    "                df.at[i, st.name+' spike train'] = st # 'at', not 'loc', is important for inserting list into cell\n",
    "    \n",
    "    \n",
    "            \n",
    "        ###\n",
    "        ### QUANTIFY SPIKE TRAINS AND BURSTS\n",
    "        ###\n",
    "        \n",
    "        for k, unit in enumerate(units):\n",
    "            st = df.loc[i, unit+' spike train']\n",
    "            if st is not None:\n",
    "                df.loc[i, unit+' spike count'] = st.size\n",
    "                if st.size > 0:\n",
    "                    \n",
    "                    # get the neural channel\n",
    "                    channel = st.annotations['channels'][0]\n",
    "                    sig = get_sig(blk, channel)\n",
    "\n",
    "                    # get the signal for the behavior with 10 seconds cushion before and after (for better baseline estimation)\n",
    "                    sig = sig.time_slice(behavior_start - 10*pq.s, behavior_end + 10*pq.s)\n",
    "                    sig = sig.rescale(channel_units[channels_to_keep.index(channel)])\n",
    "                    \n",
    "                    # find every sequence of spikes that qualifies as a burst\n",
    "                    bursts = df.at[i, unit+' all bursts (s)'] = find_bursts(st, burst_thresholds[unit]) # 'at', not 'loc', is important for inserting list into cell\n",
    "                    \n",
    "                    first_burst_start = np.nan\n",
    "                    first_burst_end = np.nan\n",
    "                    first_burst_spike_count = 0\n",
    "                    first_burst_mean_freq = 0*pq.Hz\n",
    "                    last_burst_start = np.nan\n",
    "                    last_burst_end = np.nan\n",
    "                    last_burst_spike_count = 0\n",
    "                    last_burst_mean_freq = 0*pq.Hz\n",
    "                    if len(bursts) > 0:\n",
    "\n",
    "                        for burst in bursts:\n",
    "                            if is_good_burst(burst):\n",
    "                                first_burst_start, first_burst_end = burst['Start (s)'], burst['End (s)']\n",
    "                                first_burst_duration = first_burst_end-first_burst_start\n",
    "                                df.loc[i, unit+' first burst start (s)'] = first_burst_start.rescale('s')\n",
    "                                df.loc[i, unit+' first burst end (s)'] = first_burst_end.rescale('s')\n",
    "                                first_burst_duration = df.loc[i, unit+' first burst duration (s)'] = first_burst_duration.rescale('s')\n",
    "                                first_burst_spike_count = df.loc[i, unit+' first burst spike count'] = st.time_slice(first_burst_start, first_burst_end).size\n",
    "                                first_burst_mean_freq = df.loc[i, unit+' first burst mean frequency (Hz)'] = ((first_burst_spike_count-1)/first_burst_duration).rescale('Hz')\n",
    "                                \n",
    "                                # find burst RAUC and mean voltage\n",
    "                                first_burst_rauc = df.loc[i, unit+' first burst RAUC (μV·s)'] = elephant.signal_processing.rauc(sig, baseline='mean', t_start=first_burst_start, t_stop=first_burst_end).rescale('uV*s')\n",
    "                                first_burst_mean_rect_voltage = df.loc[i, unit+' first burst mean rectified voltage (μV)'] = first_burst_rauc/first_burst_duration\n",
    "\n",
    "                                break # quit after finding first good burst\n",
    "\n",
    "                        for burst in reversed(bursts):\n",
    "                            if is_good_burst(burst):\n",
    "                                last_burst_start, last_burst_end = burst['Start (s)'], burst['End (s)']\n",
    "                                last_burst_duration = last_burst_end-last_burst_start\n",
    "                                df.loc[i, unit+' last burst start (s)'] = last_burst_start.rescale('s')\n",
    "                                df.loc[i, unit+' last burst end (s)'] = last_burst_end.rescale('s')\n",
    "                                last_burst_duration = df.loc[i, unit+' last burst duration (s)'] = last_burst_duration.rescale('s')\n",
    "                                last_burst_spike_count = df.loc[i, unit+' last burst spike count'] = st.time_slice(last_burst_start, last_burst_end).size\n",
    "                                last_burst_mean_freq = df.loc[i, unit+' last burst mean frequency (Hz)'] = ((last_burst_spike_count-1)/last_burst_duration).rescale('Hz')\n",
    "\n",
    "                                # find burst RAUC and mean voltage\n",
    "                                last_burst_rauc = df.loc[i, unit+' last burst RAUC (μV·s)'] = elephant.signal_processing.rauc(sig, baseline='mean', t_start=last_burst_start, t_stop=last_burst_end).rescale('uV*s')\n",
    "                                last_burst_mean_rect_voltage = df.loc[i, unit+' last burst mean rectified voltage (μV)'] = last_burst_rauc/last_burst_duration\n",
    "    \n",
    "                                break # quit after finding first (actually, last) good burst\n",
    "\n",
    "                                    \n",
    "                    # sanity check: plot spikes\n",
    "                    plt.sca(axes[channels_to_keep.index(channel)])\n",
    "                    marker = ['.', 'x'][j%2] # alternate markers between behaviors\n",
    "                    \n",
    "                    spike_amplitudes = np.array([sig[sig.time_index(t)] for t in st]) * pq.Quantity(sig.units)\n",
    "                    plt.scatter(st.times.rescale('s'), spike_amplitudes, marker=marker, c=unit_colors[unit])\n",
    "\n",
    "                    # sanity check: plot burst windows\n",
    "                    discriminator = next((d for d in metadata['amplitude_discriminators'] if d['name'] == st.name), None)\n",
    "                    if discriminator is None:\n",
    "                        raise Exception(f'For data set \"{data_set_name}\", discriminator \"{st.name}\" could not be found')\n",
    "                    bottom = pq.Quantity(discriminator['amplitude'][0], discriminator['units']).rescale(sig.units)\n",
    "                    top = pq.Quantity(discriminator['amplitude'][1], discriminator['units']).rescale(sig.units)\n",
    "                    height = top-bottom\n",
    "                    for burst in bursts:\n",
    "                        left = burst['Start (s)']\n",
    "                        right = burst['End (s)']\n",
    "                        width = right-left\n",
    "                        linestyle = '-' if is_good_burst(burst) else '--'\n",
    "                        rect = patches.Rectangle((left, bottom), width, height, ls=linestyle, edgecolor=unit_colors[unit], fill=False)\n",
    "                        plt.gca().add_patch(rect)\n",
    "\n",
    "                    # sanity check: plot markers for edges of bursts\n",
    "                    if top > 0:\n",
    "                        plt.plot([first_burst_start], [top], marker=7, markersize=5, color='k')#unit_colors[unit])\n",
    "                        plt.plot([last_burst_end], [top], marker=7, markersize=5, color='k')#unit_colors[unit])\n",
    "                    else:\n",
    "                        plt.plot([first_burst_start], [bottom], marker=6, markersize=5, color='k')#unit_colors[unit])\n",
    "                        plt.plot([last_burst_end], [bottom], marker=6, markersize=5, color='k')#unit_colors[unit])\n",
    "\n",
    "\n",
    "\n",
    "        ###\n",
    "        ### INSTANTANEOUS FIRING FREQUENCIES\n",
    "        ###\n",
    "        \n",
    "        for unit in ['B6/B9']:\n",
    "            st = df.loc[i, unit+' spike train']\n",
    "            if st is not None:\n",
    "                if st.size > 0:\n",
    "                    channel = st.annotations['channels'][0]\n",
    "                    plt.sca(axes[channels_to_keep.index(channel)])\n",
    "                    \n",
    "                    times = st.times.rescale('s')\n",
    "                    times = np.concatenate([[behavior_start], times, [behavior_end]])*pq.s\n",
    "                    iff = 1/elephant.statistics.isi(st)\n",
    "                    iff = np.concatenate([[0], iff.rescale('1/s'), [0, 0]])/pq.s\n",
    "                    \n",
    "                    # arbitrary rescaling to fit in plot\n",
    "                    shift = -6 * np.abs(discriminator['amplitude']).max()\n",
    "                    iff = iff.magnitude/5+shift\n",
    "                    \n",
    "                    plt.plot(times, iff, drawstyle='steps-post', c=lighten_color(unit_colors[unit], amount=0.7), zorder=0)\n",
    "        \n",
    "        \n",
    "        \n",
    "        ###\n",
    "        ### TIMING DELAYS\n",
    "        ###\n",
    "        \n",
    "        i2_burst_start   = df.loc[i, 'I2 spikes first burst start (s)']*pq.s\n",
    "        i2_burst_end     = df.loc[i, 'I2 spikes last burst end (s)']*pq.s\n",
    "        b8_burst_start   = df.loc[i, 'B8a/b first burst start (s)']*pq.s\n",
    "        b8_burst_end     = df.loc[i, 'B8a/b last burst end (s)']*pq.s\n",
    "        b6b9_burst_start = df.loc[i, 'B6/B9 first burst start (s)']*pq.s\n",
    "        b6b9_burst_end   = df.loc[i, 'B6/B9 last burst end (s)']*pq.s\n",
    "        b3_burst_start   = df.loc[i, 'B3 first burst start (s)']*pq.s\n",
    "        b3_burst_end     = df.loc[i, 'B3 last burst end (s)']*pq.s\n",
    "        b38_burst_start  = df.loc[i, 'B38 first burst start (s)']*pq.s\n",
    "        b38_burst_end    = df.loc[i, 'B38 last burst end (s)']*pq.s\n",
    "        \n",
    "        # consider B3/B6/B9 bursting if either B3 or B6/B9 is bursting\n",
    "        b3b6b9_burst_start    = df.loc[i, 'B3/B6/B9 burst start (s)']    = finite_min(b6b9_burst_start, b3_burst_start)\n",
    "        b3b6b9_burst_end      = df.loc[i, 'B3/B6/B9 burst end (s)']      = finite_max(b6b9_burst_end,   b3_burst_end)\n",
    "        b3b6b9_burst_duration = df.loc[i, 'B3/B6/B9 burst duration (s)'] = b3b6b9_burst_end - b3b6b9_burst_start\n",
    "        \n",
    "        # consider bursting only if B8a/b and B3/B6/B9 are both bursting\n",
    "        b8_or_b3b6b9_burst_end = df.loc[i, 'B8a/b and B3/B6/B9 conjunction end (s)'] = \\\n",
    "                                           finite_min(b8_burst_end, b3b6b9_burst_end)\n",
    "        \n",
    "        # delays from neural to force\n",
    "        i2_force_min_delay             = df.loc[i, 'Delay from I2 end to force min (s)'] = \\\n",
    "                                                   force_min_time - i2_burst_end\n",
    "\n",
    "        b8_force_start_delay           = df.loc[i, 'Delay from B8a/b start to force start (s)'] = \\\n",
    "                                                   force_rise_start - b8_burst_start\n",
    "        b8_force_end_delay             = df.loc[i, 'Delay from B8a/b end to force end (s)'] = \\\n",
    "                                                   force_80percent_end - b8_burst_end\n",
    "        \n",
    "        b6b9_force_start_delay         = df.loc[i, 'Delay from B6/B9 start to force start (s)'] = \\\n",
    "                                                   force_rise_start - b6b9_burst_start\n",
    "        b6b9_force_end_delay           = df.loc[i, 'Delay from B6/B9 end to force end (s)'] = \\\n",
    "                                                   force_80percent_end - b6b9_burst_end\n",
    "\n",
    "        b3b6b9_force_start_delay       = df.loc[i, 'Delay from B3/B6/B9 start to force start (s)'] = \\\n",
    "                                                   force_rise_start - b3b6b9_burst_start\n",
    "        b3b6b9_force_end_delay         = df.loc[i, 'Delay from B3/B6/B9 end to force end (s)'] = \\\n",
    "                                                   force_80percent_end - b3b6b9_burst_end\n",
    "        b3b6b9_force_50percent_delay   = df.loc[i, 'Delay from B3/B6/B9 start to force 50%-height (s)'] = \\\n",
    "                                                   force_50percent_start - b3b6b9_burst_start\n",
    "        b3b6b9_force_80percent_delay   = df.loc[i, 'Delay from B3/B6/B9 start to force 80%-height (s)'] = \\\n",
    "                                                   force_80percent_start - b3b6b9_burst_start\n",
    "        \n",
    "        b3_force_80percent_start_delay = df.loc[i, 'Delay from B3 start to force 80%-height start (s)'] = \\\n",
    "                                                   force_80percent_start - b3_burst_start\n",
    "        b3_force_80percent_end_delay   = df.loc[i, 'Delay from B3 end to force 80%-height end (s)'] = \\\n",
    "                                                   force_80percent_end - b3_burst_end\n",
    "        b8_or_b3b6b9_force_80percent_end_delay = \\\n",
    "                                         df.loc[i, 'Delay from either B8a/b or B3/B6/B9 end to force 80%-height end (s)'] = \\\n",
    "                                                   force_80percent_end - b8_or_b3b6b9_burst_end\n",
    "        \n",
    "        b38_shoulder_start_delay       = df.loc[i, 'Delay from B38 start to shoulder start (s)'] = \\\n",
    "                                                   force_shoulder_start - b38_burst_start\n",
    "        b38_shoulder_end_delay         = df.loc[i, 'Delay from B38 end to shoulder end (s)'] = \\\n",
    "                                                   force_shoulder_end - b38_burst_end\n",
    "\n",
    "    \n",
    "\n",
    "        ###\n",
    "        ### MISC\n",
    "        ###\n",
    "        \n",
    "        st = df.loc[i, 'B8a/b spike train']\n",
    "        b8_preb3b6b9_burst_duration    = df.loc[i, 'B8a/b pre-B3/B6/B9 burst duration (s)'] = \\\n",
    "                                                   b3b6b9_burst_start - b8_burst_start\n",
    "        b8_preb3b6b9_burst_spike_count = df.loc[i, 'B8a/b pre-B3/B6/B9 burst spike count'] = \\\n",
    "                                                   st.time_slice(b8_burst_start, b3b6b9_burst_start).size\n",
    "        b8_preb3b6b9_burst_mean_freq   = df.loc[i, 'B8a/b pre-B3/B6/B9 burst mean frequency (Hz)'] = \\\n",
    "                                                   ((b8_preb3b6b9_burst_spike_count-1)/b8_preb3b6b9_burst_duration).rescale('Hz')\n",
    "        \n",
    "        # get the neural channel\n",
    "        channel = st.annotations['channels'][0]\n",
    "        sig = get_sig(blk, channel)\n",
    "        \n",
    "        # get the signal for the behavior with 5 seconds cushion before and after (for better baseline estimation)\n",
    "        sig = sig.time_slice(behavior_start - 5*pq.s, behavior_end + 5*pq.s)\n",
    "        sig = sig.rescale('uV')\n",
    "\n",
    "        # find RAUC and mean voltage for B8a/b before B3/B6/B9 start in each behavior\n",
    "        if np.isfinite(b8_burst_start) and np.isfinite(b3b6b9_burst_start):\n",
    "            b8_preb3b6b9_rauc = df.loc[i, 'B8a/b pre-B3/B6/B9 burst RAUC (μV·s)'] = elephant.signal_processing.rauc(sig, baseline='mean', t_start=b8_burst_start, t_stop=b3b6b9_burst_start).rescale('uV*s')\n",
    "            b8_preb3b6b9_mean_rect_voltage = df.loc[i, 'B8a/b pre-B3/B6/B9 burst mean rectified voltage (μV)'] = b8_preb3b6b9_rauc/b8_preb3b6b9_burst_duration\n",
    "        else:\n",
    "            print(f'Missing either B8a/b burst and/or B3/B6/B9 burst in data set \"{data_set_name}\" for swallow spanning times ({behavior_start}, {behavior_end})')\n",
    "\n",
    "            \n",
    "        # get force during rise and plateau\n",
    "        sig = get_sig(blk, 'Force')\n",
    "        sig = sig.time_slice(force_rise_start, force_80percent_end)\n",
    "        sig = sig.rescale('mN')\n",
    "        \n",
    "        # get force at end of B8-only burst, offset by delay\n",
    "        force_b8_only_rise_end = df.loc[i, 'Force delayed B8-only rise end (s)'] = force_rise_start + b8_preb3b6b9_burst_duration\n",
    "        force_b8_only_rise_height = df.loc[i, 'Force at delayed B8-only rise end (mN)'] = sig[sig.time_index(force_b8_only_rise_end)][0]\n",
    "\n",
    "        # find average slope during initial rising phase (before B3/B6/B9 begin, offset by delay)\n",
    "        force_initial_increase = df.loc[i, 'Force initial increase (mN)'] = (force_b8_only_rise_height-force_baseline).rescale('mN')\n",
    "        force_initial_slope = df.loc[i, 'Force initial slope (mN/s)'] = (force_initial_increase/b8_preb3b6b9_burst_duration).rescale('mN/s')\n",
    "\n",
    "        \n",
    "        \n",
    "        # sanity check: plot force initial rise\n",
    "#         sig = force_smoothed_sig\n",
    "#         sig = sig.time_slice(force_rise_start, force_b8_only_rise_end)\n",
    "#         sig = sig.rescale('mN')\n",
    "#         plt.sca(axes[channels_to_keep.index('Force')])\n",
    "#         plt.plot(sig.times, sig.magnitude, c=force_colors['initial rise'], lw=2, zorder=1)\n",
    "        \n",
    "        \n",
    "        \n",
    "#         # sanity check: plot important times across all subplots, with delays set by I2 end and force min\n",
    "#         if j == 0:\n",
    "#             muscle_delay = i2_force_min_delay\n",
    "#             axes[-1].text(\n",
    "#                 force_min_time, 1.05, f\"{muscle_delay.rescale('ms'):.0f} ms delay\",\n",
    "#                 horizontalalignment='left', verticalalignment='center', transform=axes[-1].get_xaxis_transform(),\n",
    "#                 fontsize=8)\n",
    "#         plot_vertical_lines_with_delay(axes, force_min_time, muscle_delay, force_min, force_colors['dip'])\n",
    "#         plot_vertical_lines_with_delay(axes, force_80percent_start, muscle_delay, force_80percent, force_colors['plateau'])\n",
    "#         plot_vertical_lines_with_delay(axes, force_80percent_end, muscle_delay, force_80percent, force_colors['plateau'])\n",
    "#         if np.isfinite(force_shoulder_end):\n",
    "#             sig = force_smoothed_sig\n",
    "#             plot_vertical_lines_with_delay(axes, force_shoulder_end, muscle_delay, sig[sig.time_index(force_shoulder_end)][0], force_colors['shoulder'])\n",
    "    \n",
    "    \n",
    "    \n",
    "    # sanity check: plot vertical lines at \"keepers\"\n",
    "    sig = force_smoothed_sig\n",
    "    ep_poi = next((ep for ep in blk.segments[0].epochs if ep.name == 'Keeper'), None)\n",
    "    if ep_poi is not None:\n",
    "        ep_poi = ep_poi.time_slice(time_window[0]*pq.s, time_window[1]*pq.s)\n",
    "        if ep_poi.size > 0:\n",
    "            first_force_min_time = ep_poi.times[0]\n",
    "            first_i2_burst_end = df.loc[df.index[0], 'I2 spikes first burst end (s)']*pq.s\n",
    "            muscle_delay = first_force_min_time - first_i2_burst_end\n",
    "\n",
    "            axes[-1].text(\n",
    "                first_force_min_time, 1.05, f\"{muscle_delay.rescale('ms'):.0f} ms delay\",\n",
    "                horizontalalignment='right', verticalalignment='center', transform=axes[-1].get_xaxis_transform(),\n",
    "                fontsize=8)\n",
    "            for t in ep_poi.times:\n",
    "                plot_vertical_lines_with_delay(axes, t, muscle_delay, sig[sig.time_index(t)][0], 'gray')\n",
    "\n",
    "\n",
    "        \n",
    "    # optimize plot margins\n",
    "    plt.subplots_adjust(\n",
    "        left   = 0.1,\n",
    "        right  = 0.99,\n",
    "        top    = 0.96,\n",
    "        bottom = 0.06,\n",
    "        hspace = 0.15,\n",
    "    )\n",
    "    \n",
    "    # export figure\n",
    "    plt.gcf().savefig(f'sanity-checks/{animal} {food} {bout_index}.png', dpi=300)\n",
    "\n",
    "    # renumber behaviors assuming all behaviors are from a single contiguous sequence\n",
    "    df = df.sort_values('Start (s)').reset_index(drop=True).rename_axis('Behavior_index')\n",
    "    \n",
    "    # index the table on 4 variables\n",
    "    df['Animal'] = animal\n",
    "    df['Food'] = food\n",
    "    df['Bout_index'] = bout_index\n",
    "    df = df.reset_index().set_index(['Animal', 'Food', 'Bout_index', 'Behavior_index'])\n",
    "    \n",
    "    df_list += [df]\n",
    "    \n",
    "# df_all = pd.concat(df_list, sort=False).sort_index()\n",
    "\n",
    "end = datetime.datetime.now()\n",
    "print('elapsed time:', end-start)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Special dataframe used for Fig 2C only"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "feeding_bouts = {\n",
    "    # (animal, food, bout_index): (data_set_name, time_window, epoch_types_to_keep)\n",
    "        \n",
    "    ('JG12', 'Regular nori', 0): ('IN VIVO / JG12 / 2019-05-10 / 002', [ 147,  165], ['Swallow (regular 5-cm nori strip)']),\n",
    "    ('JG12', 'Regular nori', 1): ('IN VIVO / JG12 / 2019-05-10 / 002', [ 229,  245], ['Swallow (regular 5-cm nori strip)']),\n",
    "    ('JG12', 'Regular nori', 2): ('IN VIVO / JG12 / 2019-05-10 / 002', [ 277,  291], ['Swallow (regular 5-cm nori strip)']),\n",
    "\n",
    "    ('JG12', 'Tape nori',   99): ('IN VIVO / JG12 / 2019-05-10 / 002', [2890, 3080], ['Swallow (tape nori)']),\n",
    "}\n",
    "\n",
    "# filter epochs for each feeding condition and perform calculations\n",
    "df_list = []\n",
    "last_data_set_name = None\n",
    "for (animal, food, bout_index), (data_set_name, time_window, epoch_types_to_keep) in feeding_bouts.items():\n",
    "    \n",
    "    metadata.select(data_set_name)\n",
    "    if data_set_name is last_data_set_name:\n",
    "        # skip reloading the data if it's already in memory\n",
    "        pass\n",
    "    else:\n",
    "        blk = neurotic.load_dataset(metadata, lazy=True)\n",
    "    last_data_set_name = data_set_name\n",
    "    \n",
    "    # construct a query for locating behaviors\n",
    "    behavior_query = f'(Type in {epoch_types_to_keep}) & ({time_window[0]} <= Start) & (End <= {time_window[1]})'\n",
    "    \n",
    "    # construct queries for locating epochs associated with each behavior\n",
    "    # - each query should match at most one epoch\n",
    "    # - dictionary keys are used as prefixes for the names of new columns\n",
    "    subepoch_queries = {}\n",
    "    \n",
    "    # construct a table in which each row is a behavior and subepoch data\n",
    "    # is added as columns, e.g. df['Force start (s)']\n",
    "    df = BehaviorsDataFrame(blk.segments[0].epochs, behavior_query, subepoch_queries)\n",
    "\n",
    "    # calculate interbehavior interval assuming all behaviors are from a single contiguous sequence\n",
    "    df['Interval after (s)'] = np.nan\n",
    "    previous_i = None\n",
    "    for i in df.index:\n",
    "        if previous_i is not None:\n",
    "            df.loc[previous_i, 'Interval after (s)']  = df.loc[i, 'Start (s)'] - df.loc[previous_i, 'End (s)']\n",
    "        previous_i = i\n",
    "\n",
    "    # renumber behaviors assuming all behaviors are from a single contiguous sequence\n",
    "    df = df.sort_values('Start (s)').reset_index(drop=True).rename_axis('Behavior_index')\n",
    "    \n",
    "    # index the table on 4 variables\n",
    "    df['Animal'] = animal\n",
    "    df['Food'] = food\n",
    "    df['Bout_index'] = bout_index\n",
    "    df = df.reset_index().set_index(['Animal', 'Food', 'Bout_index', 'Behavior_index'])\n",
    "    \n",
    "    df_list += [df]\n",
    "    \n",
    "df_durations_intervals = pd.concat(df_list, sort=False).sort_index()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "source": [
    "## Plotting Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "outputs": [],
   "source": [
    "def scatter2d(ax, data_subsets, xlabel, xlim, ylabel, ylim, trend=False, trend_separately=False, tooltips=False, padding=0.05):\n",
    "    \n",
    "    for j, (label, query) in enumerate(data_subsets.items()):\n",
    "        if query is not None:\n",
    "            df = df_all.query(query)\n",
    "            ax.scatter(df[xlabel], df[ylabel],\n",
    "                       label=label, marker=markers[j], c=colors[j], clip_on=False)\n",
    "            \n",
    "    all_points = df_all.query(query_union(data_subsets.values()))[[xlabel, ylabel]].dropna()\n",
    "    \n",
    "    if len(all_points) > 0:\n",
    "\n",
    "        xrange = np.ptp(all_points.iloc[:, 0])\n",
    "        xmin = min(all_points.iloc[:, 0]) - xrange * padding\n",
    "        xmax = max(all_points.iloc[:, 0]) + xrange * padding\n",
    "        if xlim is None:\n",
    "            xlim = [xmin, xmax]\n",
    "        if xlim[0] is None:\n",
    "            xlim[0] = xmin\n",
    "        if xlim[1] is None:\n",
    "            xlim[1] = xmax\n",
    "\n",
    "        yrange = np.ptp(all_points.iloc[:, 1])\n",
    "        ymin = min(all_points.iloc[:, 1]) - yrange * padding\n",
    "        ymax = max(all_points.iloc[:, 1]) + yrange * padding\n",
    "        if ylim is None:\n",
    "            ylim = [ymin, ymax]\n",
    "        if ylim[0] is None:\n",
    "            ylim[0] = ymin\n",
    "        if ylim[1] is None:\n",
    "            ylim[1] = ymax\n",
    "    \n",
    "    if trend_separately:\n",
    "        for j, (label, query) in enumerate(data_subsets.items()):\n",
    "            if query is not None:\n",
    "                df = df_all.query(query)[[xlabel, ylabel]].dropna()\n",
    "                model = sm.OLS(df.iloc[:,1], sm.add_constant(df.iloc[:,0])).fit()\n",
    "                model_stats = 'R$^2$ = {:.2f}, p = {:.3f}, n = {}'.format(model.rsquared, model.pvalues[1], len(df))\n",
    "                print(label+':', model_stats)\n",
    "                model_x = np.linspace(xlim[0], xlim[1], 100)\n",
    "                model_y = model.params[0] + model.params[1] * model_x\n",
    "                ax.plot(model_x, model_y, color=colors[j])#, label=model_stats)\n",
    "                \n",
    "    if trend:\n",
    "        model = sm.OLS(all_points.iloc[:,1], sm.add_constant(all_points.iloc[:,0])).fit()\n",
    "        model_stats = 'R$^2$ = {:.2f}, p = {:.3f}, n = {}'.format(model.rsquared, model.pvalues[1], len(all_points))\n",
    "        print('All points:', model_stats)\n",
    "        model_x = np.linspace(xlim[0], xlim[1], 100)\n",
    "        model_y = model.params[0] + model.params[1] * model_x\n",
    "        ax.plot(model_x, model_y, color='gray')#, label=model_stats)\n",
    "    \n",
    "    if tooltips:\n",
    "        # create a transparent layer containing all points for detecting mouse events\n",
    "        sc = ax.scatter(all_points.iloc[:, 0], all_points.iloc[:, 1], label=None,\n",
    "                        alpha=0, # transparent points\n",
    "                        s=0.001, # small radius of tooltip activation\n",
    "                       )\n",
    "        \n",
    "        # initialize a hidden empty tooltip\n",
    "        annot = ax.annotate(\n",
    "            '', xy=(0, 0),                              # initialize empty at origin\n",
    "            xytext=(0, 15), textcoords='offset points', # position text above point\n",
    "            color='k', size=10, ha='center',            # small black centered text\n",
    "            bbox=dict(fc='w', lw=0, alpha=0.6),         # transparent white background\n",
    "            arrowprops=dict(shrink=0, headlength=7, headwidth=7, width=0, lw=0, color='k'), # small black arrow\n",
    "        )\n",
    "        annot.set_visible(False)\n",
    "        \n",
    "        # prepare tooltip contents\n",
    "        tooltip_text = [' '.join([str(x) for x in index]) for index in list(all_points.index)]\n",
    "        \n",
    "        # bind the animation of tooltips to a hover event\n",
    "        def hover(event):\n",
    "            if event.inaxes == ax:\n",
    "                cont, ind = sc.contains(event)\n",
    "                if cont:\n",
    "                    point_index = ind['ind'][0]\n",
    "                    pos = sc.get_offsets()[point_index]\n",
    "                    annot.xy = pos\n",
    "                    annot.set_text(tooltip_text[point_index])\n",
    "                    annot.set_visible(True)\n",
    "                    ax.figure.canvas.draw_idle()\n",
    "                else:\n",
    "                    if annot.get_visible():\n",
    "                        annot.set_visible(False)\n",
    "                        ax.figure.canvas.draw_idle()\n",
    "        ax.figure.canvas.mpl_connect('motion_notify_event', hover)\n",
    "        \n",
    "    ax.set_xlabel(xlabel)\n",
    "    ax.set_xlim(xlim)\n",
    "    ax.set_ylabel(ylabel)#.replace('rectified ',''))\n",
    "    ax.set_ylim(ylim)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def prettyplot(\n",
    "    blk,\n",
    "    t_start,\n",
    "    t_stop,\n",
    "    plots,\n",
    "    outfile_basename=None, # base name of output files\n",
    "    export_only=False,     # if True, will not render in notebook\n",
    "    formats=['pdf', 'svg', 'png'], # extensions of output files\n",
    "    dpi=300,               # resolution (applicable only for PNG)\n",
    "    figsize=(14, 7),       # figure size in inches\n",
    "    linewidth=1,           # thickness of lines in points\n",
    "    majorticks=5,          # spacing of labeled x-axis ticks in seconds\n",
    "    minorticks=1,          # spacing of unlabeled x-axis ticks in seconds\n",
    "    ylabel_offset=-0.06,   # horizontal positioning of y-axis labels\n",
    "    layout_settings=None,  # positioning of plot edges and the space between plots\n",
    "):\n",
    "    \n",
    "    if export_only:\n",
    "        plt.ioff()\n",
    "        \n",
    "    plt.figure(figsize=figsize)\n",
    "\n",
    "    num_subplots = len(plots)\n",
    "    for i, p in enumerate(plots):\n",
    "\n",
    "        # switch to the appropriate subplot in the figure\n",
    "        if i==0:\n",
    "            ax = plt.subplot(num_subplots, 1, i+1)\n",
    "        else:\n",
    "            plt.subplot(num_subplots, 1, i+1, sharex=ax)\n",
    "\n",
    "        # select and rescale a channel for the subplot\n",
    "        sig = next((sig for sig in blk.segments[0].analogsignals if sig.name == p['channel']), None)\n",
    "        assert sig is not None, f\"Signal with name {p['channel']} not found\"\n",
    "        sig = sig.time_slice(t_start, t_stop)\n",
    "        sig = sig.rescale(p['units'])\n",
    "\n",
    "        # downsample the data\n",
    "        sig_downsampled = DownsampleNeoSignal(sig, p.get('decimation_factor', 1))\n",
    "\n",
    "        # specify the x- and y-data for the subplot\n",
    "        plt.plot(\n",
    "            sig_downsampled.times,\n",
    "            sig_downsampled.as_quantity(),\n",
    "            linewidth=linewidth,\n",
    "            color=p.get('color', 'k'),\n",
    "        )\n",
    "\n",
    "        # specify the y-axis label\n",
    "        plt.ylabel(p.get('ylabel', sig.name+' ('+sig.units.dimensionality.string+')'))\n",
    "\n",
    "        # position the y-axis label so that all subplot y-axis labels are aligned\n",
    "        plt.gca().yaxis.set_label_coords(ylabel_offset, 0.5)\n",
    "\n",
    "        # specify the plot range\n",
    "        plt.xlim([t_start, t_stop])\n",
    "        plt.ylim(p['ylim'])\n",
    "\n",
    "        if i == num_subplots-1:\n",
    "            # turn on minor (frequent and unlabeled) ticks for the bottom x-axis\n",
    "            plt.gca().xaxis.set_minor_locator(MultipleLocator(minorticks))\n",
    "\n",
    "            # turn on major (infrequent and labeled) ticks for the bottom x-axis\n",
    "            plt.gca().xaxis.set_major_locator(MultipleLocator(majorticks))\n",
    "\n",
    "            # disable scientific notation for major tick labels\n",
    "            # plt.gca().xaxis.get_major_formatter().set_useOffset(False) # not necessary?\n",
    "\n",
    "            # specify the bottom x-axis label\n",
    "            plt.xlabel('Time ('+sig.times.units.dimensionality.string+')')\n",
    "\n",
    "            # offset axes from plot\n",
    "            sns.despine(ax=plt.gca(), offset=10)#, trim=True)\n",
    "        else:\n",
    "            # offset axes and remove x-axis\n",
    "            sns.despine(ax=plt.gca(), offset=10, trim=True, bottom=True)\n",
    "            plt.gca().xaxis.set_visible(False)\n",
    "\n",
    "    # adjust the white space around and between the subplots\n",
    "    if layout_settings is None:\n",
    "        plt.gcf().tight_layout()\n",
    "    else:\n",
    "        plt.subplots_adjust(**layout_settings)\n",
    "\n",
    "    if outfile_basename is not None:\n",
    "        # specify file metadata (applicable only for PDF)\n",
    "        metadata = dict(\n",
    "            Subject = 'Data file: '  + blk.file_origin + '\\n' +\n",
    "                      'Start time: ' + str(t_start)    + '\\n' +\n",
    "                      'End time: '   + str(t_stop),\n",
    "        )\n",
    "\n",
    "        # write the figure to files\n",
    "        for ext in formats:\n",
    "            plt.gcf().savefig(outfile_basename+'.'+ext, metadata=metadata, dpi=dpi)\n",
    "\n",
    "    if export_only:\n",
    "        plt.ion()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Figures"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## [FIGURE 1] Biomechanics schematic ❌"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "-"
    }
   },
   "source": [
    "Schematic illustration of biomechanics of _Aplysia_ swallowing\n",
    "- Synthesis of Cullins et al. 2015a, Fig. 6, and McManus et al. 2014, Fig. 10.\n",
    "- Show grasper protraction/retraction, grasper closing/opening, anterior jaws closing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "-"
    }
   },
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## [FIGURE 2] Motor pattern and force examples"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "### Fig 2A ✅"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "-"
    }
   },
   "source": [
    "Short sequence of swallows on regular nori, 4 channels\n",
    "\n",
    "- TODO: Annotations? (e.g., \"Bite/swallow\", \"Swallow\", \"Swallow\", \"Bite\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The plot output by this code is much longer than it will be in the final figure and must be cropped manually. It is rendered with the same amount of time showing as Fig 2B so that time scales are identical."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Labels are intentionally overlapping since they will be manually replaced in Inkscape for a different style after rendering."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "start = datetime.datetime.now()\n",
    "\n",
    "outfile_basename = 'figure-2A-export'\n",
    "data_set_name = 'IN VIVO / JG12 / 2019-05-10 / 002'\n",
    "t_start, t_stop = [228.8, 392.8] * pq.s # t=278, twidth=164, first few are regular nori strip swallows\n",
    "plots = [\n",
    "    {'channel': 'I2',       'units': 'uV', 'ylim': [ -60,  60]}, #, 'decimation_factor': 400},\n",
    "    {'channel': 'RN',       'units': 'uV', 'ylim': [ -25,  25]}, #, 'decimation_factor': 400},\n",
    "    {'channel': 'BN2',      'units': 'uV', 'ylim': [ -45,  45]}, #, 'decimation_factor': 400},\n",
    "    {'channel': 'BN3-DIST', 'units': 'uV', 'ylim': [ -60,  60], 'ylabel': 'BN3 (μV)'}, #, 'decimation_factor': 400},\n",
    "    {'channel': 'Force',    'units': 'mN', 'ylim': [ -50, 450], 'decimation_factor': 100},\n",
    "]\n",
    "\n",
    "kwargs = dict(\n",
    "    formats = ['png'],\n",
    "    dpi = 600,\n",
    "    figsize = (14, 5),\n",
    "    majorticks = 10,\n",
    "    minorticks = 5,\n",
    "    linewidth = 0.5,\n",
    "    ylabel_offset = -0.01,\n",
    "    layout_settings = dict(\n",
    "        left   = 0.04,\n",
    "        right  = 0.99,\n",
    "        top    = 0.97,\n",
    "        bottom = 0.08,\n",
    "        hspace = -0.1,\n",
    "    ),\n",
    ")\n",
    "\n",
    "# load the data\n",
    "metadata = neurotic.MetadataSelector('../../data/metadata.yml')\n",
    "metadata.select(data_set_name)\n",
    "blk = neurotic.load_dataset(metadata)\n",
    "\n",
    "# plot the data\n",
    "# with sns.plotting_context('poster', font_scale=0.5):\n",
    "with sns.plotting_context('notebook', font_scale=1):\n",
    "    prettyplot(blk, t_start, t_stop, plots, outfile_basename, **kwargs)\n",
    "\n",
    "end = datetime.datetime.now()\n",
    "print('render time:', end-start)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "-"
    }
   },
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "### Fig 2B ✅"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "-"
    }
   },
   "source": [
    "Long sequence of swallows on tape nori exemplar\n",
    "\n",
    "- TODO: Mark which swallows are used in later analysis?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Labels are intentionally overlapping since they will be manually replaced in Inkscape for a different style after rendering."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "start = datetime.datetime.now()\n",
    "\n",
    "outfile_basename = 'figure-2B-export'\n",
    "data_set_name = 'IN VIVO / JG12 / 2019-05-10 / 002'\n",
    "t_start, t_stop = [2879, 3043] * pq.s # t=2928.2, twidth=164, 19 tape nori swallows\n",
    "plots = [\n",
    "    {'channel': 'I2',       'units': 'uV', 'ylim': [ -60,  60]}, #, 'decimation_factor': 400},\n",
    "    {'channel': 'RN',       'units': 'uV', 'ylim': [ -25,  25]}, #, 'decimation_factor': 400},\n",
    "    {'channel': 'BN2',      'units': 'uV', 'ylim': [ -45,  45]}, #, 'decimation_factor': 400},\n",
    "    {'channel': 'BN3-DIST', 'units': 'uV', 'ylim': [ -60,  60], 'ylabel': 'BN3 (μV)'}, #, 'decimation_factor': 400},\n",
    "    {'channel': 'Force',    'units': 'mN', 'ylim': [ -50, 450], 'decimation_factor': 100},\n",
    "]\n",
    "\n",
    "kwargs = dict(\n",
    "    formats = ['png'],\n",
    "    dpi = 600,\n",
    "    figsize = (14, 5),\n",
    "    majorticks = 10,\n",
    "    minorticks = 5,\n",
    "    linewidth = 0.5,\n",
    "    ylabel_offset = -0.01,\n",
    "    layout_settings = dict(\n",
    "        left   = 0.04,\n",
    "        right  = 0.99,\n",
    "        top    = 0.97,\n",
    "        bottom = 0.08,\n",
    "        hspace = -0.1,\n",
    "    ),\n",
    ")\n",
    "\n",
    "# load the data\n",
    "metadata = neurotic.MetadataSelector('../../data/metadata.yml')\n",
    "metadata.select(data_set_name)\n",
    "blk = neurotic.load_dataset(metadata)\n",
    "\n",
    "# plot the data\n",
    "# with sns.plotting_context('poster', font_scale=0.5):\n",
    "with sns.plotting_context('notebook', font_scale=1):\n",
    "    prettyplot(blk, t_start, t_stop, plots, outfile_basename, **kwargs)\n",
    "\n",
    "end = datetime.datetime.now()\n",
    "print('render time:', end-start)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "-"
    }
   },
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "### Fig 2C ✅"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "-"
    }
   },
   "source": [
    "Plot swallow duration and inter-swallow interval differences between tape nori and reg nori"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(5, 5))\n",
    "ax = plt.gca()\n",
    "\n",
    "df = df_durations_intervals.reset_index()\n",
    "df = df.rename(columns={\n",
    "    'Duration (s)':       'Swallow duration',\n",
    "    'Interval after (s)': 'Inter-swallow interval'})\n",
    "df = pd.melt(df,\n",
    "             id_vars=['Animal', 'Food', 'Bout_index', 'Behavior_index'],\n",
    "             value_vars=['Swallow duration', 'Inter-swallow interval'],\n",
    "             var_name='',\n",
    "             value_name='Duration/interval (s)')\n",
    "sns.boxplot(hue='Food', y='Duration/interval (s)', x='', data=df, fliersize=0, whis=999) # whis=999 ensures whiskers go to min and max\n",
    "# sns.swarmplot(hue='Food', y='Duration/interval (s)', x='', data=df)\n",
    "\n",
    "plt.tight_layout()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "-"
    }
   },
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "### Fig 2D ✅"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "-"
    }
   },
   "source": [
    "Exemplar force plot for one swallow with labeled features (rise, plateau, shoulder, etc.)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Labels are intentionally overlapping since they will be manually replaced in Inkscape for a different style after rendering."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "start = datetime.datetime.now()\n",
    "\n",
    "outfile_basename = 'figure-2D-export'\n",
    "data_set_name = 'IN VIVO / JG12 / 2019-05-10 / 002'\n",
    "t_start, t_stop = [3001.3, 3009.75] * pq.s # t=3003.835, twidth=8.45\n",
    "plots = [\n",
    "    {'channel': 'Force',    'units': 'mN', 'ylim': [   0, 250], 'decimation_factor': 100},\n",
    "]\n",
    "\n",
    "kwargs = dict(\n",
    "    formats = ['png'],\n",
    "    dpi = 600,\n",
    "    figsize = (7, 5),\n",
    "    majorticks = 1,\n",
    "    minorticks = 1,\n",
    "    linewidth = 2,\n",
    "    ylabel_offset = -0.04,\n",
    "    layout_settings = dict(\n",
    "        left   = 0.1,\n",
    "        right  = 0.99,\n",
    "        top    = 0.97,\n",
    "        bottom = 0.08,\n",
    "        hspace = -0.1,\n",
    "    ),\n",
    ")\n",
    "\n",
    "# load the metadata\n",
    "metadata = neurotic.MetadataSelector('../../data/metadata.yml')\n",
    "metadata.select(data_set_name)\n",
    "\n",
    "# add/update the force filter\n",
    "new_force_filter = {'channel': 'Force', 'lowpass': 10}\n",
    "update_filter(metadata, new_force_filter)\n",
    "\n",
    "# load the data\n",
    "blk = neurotic.load_dataset(metadata)\n",
    "\n",
    "# plot the data\n",
    "# with sns.plotting_context('poster', font_scale=0.5):\n",
    "with sns.plotting_context('notebook', font_scale=1):\n",
    "    prettyplot(blk, t_start, t_stop, plots, outfile_basename, **kwargs)\n",
    "    \n",
    "end = datetime.datetime.now()\n",
    "print('render time:', end-start)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "-"
    }
   },
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## [FIGURE 3] First phase of swallowing: peak of protraction and min force"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "### Fig 3A ✅"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "-"
    }
   },
   "source": [
    "Example motor patterns, lines connecting I2 muscle activity ending and force minimum\n",
    "\n",
    "* TODO: Place event markers programattically so they are completely accurate"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Labels are intentionally overlapping since they will be manually replaced in Inkscape for a different style after rendering."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "start = datetime.datetime.now()\n",
    "\n",
    "outfile_basename = 'figure-3A-export'\n",
    "data_set_name = 'IN VIVO / JG12 / 2019-05-10 / 002'\n",
    "t_start, t_stop = [2944.5, 3002.5] * pq.s # t=2961.9, twidth=58, 6 tape nori swallows\n",
    "plots = [\n",
    "    {'channel': 'I2',       'units': 'uV', 'ylim': [ -35,  35]}, #, 'decimation_factor': 400},\n",
    "#     {'channel': 'RN',       'units': 'uV', 'ylim': [ -25,  25]}, #, 'decimation_factor': 400},\n",
    "#     {'channel': 'BN2',      'units': 'uV', 'ylim': [ -45,  45]}, #, 'decimation_factor': 400},\n",
    "#     {'channel': 'BN3-DIST', 'units': 'uV', 'ylim': [ -60,  60], 'ylabel': 'BN3 (μV)'}, #, 'decimation_factor': 400},\n",
    "    {'channel': 'Force',    'units': 'mN', 'ylim': [ -50, 450], 'decimation_factor': 100},\n",
    "]\n",
    "\n",
    "kwargs = dict(\n",
    "    formats = ['png'],\n",
    "    dpi = 600,\n",
    "    figsize = (12, 4),\n",
    "    majorticks = 10,\n",
    "    minorticks = 5,\n",
    "    linewidth = 0.5,\n",
    "    ylabel_offset = -0.01,\n",
    "    layout_settings = dict(\n",
    "        left   = 0.04,\n",
    "        right  = 0.99,\n",
    "        top    = 0.97,\n",
    "        bottom = 0.08,\n",
    "        hspace = 0,\n",
    "    ),\n",
    ")\n",
    "\n",
    "# load the data\n",
    "metadata = neurotic.MetadataSelector('../../data/metadata.yml')\n",
    "metadata.select(data_set_name)\n",
    "blk = neurotic.load_dataset(metadata)\n",
    "\n",
    "# plot the data\n",
    "# with sns.plotting_context('poster', font_scale=0.5):\n",
    "with sns.plotting_context('notebook', font_scale=1):\n",
    "    prettyplot(blk, t_start, t_stop, plots, outfile_basename, **kwargs)\n",
    "\n",
    "end = datetime.datetime.now()\n",
    "print('render time:', end-start)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "-"
    }
   },
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "### Fig 3B ✅"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "-"
    }
   },
   "source": [
    "Plot delay between I2 muscle activity ending and force drop"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- **The Good**: Almost all points are to the right, consistent with peak protraction causing force drop\n",
    "\n",
    "- **The Bad**: Within-animal variability is high, and some extreme delays are too long\n",
    "\n",
    "- **Verdict**: Very good for showing I2 protraction idea is plausible. Data from different animals can probably be lumped together without issue."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(5, 5))\n",
    "ax = plt.gca()\n",
    "\n",
    "df = df_all.reset_index()\n",
    "column = 'Delay from I2 end to force min (s)'\n",
    "\n",
    "sns.boxplot(y='Animal', x=column, data=df, fliersize=0, whis=999) # whis=999 ensures whiskers go to min and max\n",
    "# sns.swarmplot(y='Animal', x=column, data=df, color='0.25')\n",
    "\n",
    "# sns.boxplot(x=column, data=df, fliersize=0, whis=999) # whis=999 ensures whiskers go to min and max\n",
    "# sns.swarmplot(x=column, data=df, color='0.25')\n",
    "\n",
    "plt.axvline(x=0, ls=':', c='gray', zorder=-1)\n",
    "\n",
    "plt.tight_layout()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "column = 'Delay from I2 end to force min (s)'\n",
    "print_column_analysis(column)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [],
   "source": [
    "# points that aren't where we expected\n",
    "column = 'Delay from I2 end to force min (s)'\n",
    "df_all[df_all[column] < 0][[column]]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "-"
    }
   },
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## [FIGURE 4] Second phase of swallowing: grasper closing and initial force rise"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "### Fig 4A ❌"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "-"
    }
   },
   "source": [
    "Example motor patterns, lines connecting B8a/b motor neuron activity starting and force beginning to rise"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "-"
    }
   },
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "### Fig 4B ❗"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "-"
    }
   },
   "source": [
    "Plot delay between B3/B6/B9 motor neuron activity starting and force beginning to rise. Takeaway: Force occurs first, evidence that these motor neurons don't start the rise"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- **The Good**: In most swallows, force starts before B3/B6/B9\n",
    "\n",
    "- **The Bad**: However, this is not true in about 1/3 of swallows. Variability is high, so this timing relationship is not reliable.\n",
    "\n",
    "- This suggests that although there are swallows where B3/B6/B9 might have initialiated force rise, there are even more swallows where it couldn't have because force rose first.\n",
    "\n",
    "- **Verdict**: Because the plot isn't compelling, instead of showing it we could just cite the statistic (\"In X% of swallows, B3/B6/B9 bursts started after force generation had already begun\") to motivate the B8a/b analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(5, 5))\n",
    "ax = plt.gca()\n",
    "\n",
    "df = df_all.reset_index()\n",
    "column = 'Delay from B3/B6/B9 start to force start (s)'\n",
    "\n",
    "sns.boxplot(y='Animal', x=column, data=df, fliersize=0, whis=999) # whis=999 ensures whiskers go to min and max\n",
    "sns.swarmplot(y='Animal', x=column, data=df, color='0.25')\n",
    "\n",
    "# sns.boxplot(x=column, data=df, fliersize=0, whis=999) # whis=999 ensures whiskers go to min and max\n",
    "# sns.swarmplot(x=column, data=df, color='0.25')\n",
    "\n",
    "plt.axvline(x=0, ls=':', c='gray', zorder=-1)\n",
    "\n",
    "plt.tight_layout()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "column = 'Delay from B3/B6/B9 start to force start (s)'\n",
    "print_column_analysis(column)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [],
   "source": [
    "# points that aren't where we expected\n",
    "column = 'Delay from B3/B6/B9 start to force start (s)'\n",
    "df_all[df_all[column] > 0][[column]]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "-"
    }
   },
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "### Fig 4C ✅"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "-"
    }
   },
   "source": [
    "Plot delay between B8a/b motor neuron activity starting and force beginning to rise. Takeaway: B8a/b have the right timing for being the cause of initial force rise (by closing the grasper)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- **The Good**: B8a/b always precedes force start. With the exception of JG11, variability is low. Means are similar enough that we might be able to propose a \"typical\" delay.\n",
    "\n",
    "- **The Bad**: JG11's variability\n",
    "\n",
    "- **Verdict**: Very supportive of the argument. Check JG11's outliers for errors. This figure is clean enough that swallows from multiple animals could probably be lumped together without issue."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(5, 5))\n",
    "ax = plt.gca()\n",
    "\n",
    "df = df_all.reset_index()\n",
    "column = 'Delay from B8a/b start to force start (s)'\n",
    "\n",
    "sns.boxplot(y='Animal', x=column, data=df, fliersize=0, whis=999) # whis=999 ensures whiskers go to min and max\n",
    "sns.swarmplot(y='Animal', x=column, data=df, color='0.25')\n",
    "\n",
    "# sns.boxplot(x=column, data=df, fliersize=0, whis=999) # whis=999 ensures whiskers go to min and max\n",
    "# sns.swarmplot(x=column, data=df, color='0.25')\n",
    "\n",
    "plt.axvline(x=0, ls=':', c='gray', zorder=-1)\n",
    "\n",
    "plt.tight_layout()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "column = 'Delay from B8a/b start to force start (s)'\n",
    "print_column_analysis(column)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [],
   "source": [
    "# points that aren't where we expected\n",
    "column = 'Delay from B8a/b start to force start (s)'\n",
    "df_all[df_all[column] < 0][[column]]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "-"
    }
   },
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "### Fig 4D ❌"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "-"
    }
   },
   "source": [
    "Plot mean rectified voltage on radula nerve (B8a/b burst) preceding the start of B3/B6/B9 activity against initial force slope or delta force. Takeaway: Show that intensity of B8a/b activity correlates with intensity of force rise"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- **The Good**: 4 of 5 animals have positive slopes\n",
    "\n",
    "- **The Bad**: Highly variable. No significant correlations.\n",
    "\n",
    "- The boundaries of the \"B8a/b pre-B3/B6/B9\" period are hightly sensitive to several threshold parameters, so it may not be possible to locate it reliably.\n",
    "\n",
    "- Measurements based on mean rectified voltage probably should not be lumped together from different animals without normalization.\n",
    "\n",
    "- **Verdict**: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(5, 5))\n",
    "ax = plt.gca()\n",
    "\n",
    "data_subsets = [\n",
    "    'JG07 Tape nori',\n",
    "    'JG08 Tape nori',\n",
    "    'JG11 Tape nori',\n",
    "    'JG12 Tape nori',\n",
    "    'JG14 Tape nori',\n",
    "]\n",
    "data_subsets = {label:label2query(label) for label in data_subsets}\n",
    "\n",
    "# xlabel, xlim = 'B8 activity mean rectified voltage (μV)', [0, None]\n",
    "# xlabel, xlim = 'B8a/b first burst mean rectified voltage (μV)', [0, None]\n",
    "xlabel, xlim = 'B8a/b pre-B3/B6/B9 burst mean rectified voltage (μV)', [0, None]\n",
    "# xlabel, xlim = 'B8a/b pre-B3/B6/B9 burst mean frequency (Hz)', [0, None]\n",
    "# ylabel, ylim = 'Force slope (mN/s)', [0, None]\n",
    "ylabel, ylim = 'Force initial slope (mN/s)', [0, None]\n",
    "# ylabel, ylim = 'Force initial increase (mN)', [0, None]\n",
    "\n",
    "scatter2d(ax, data_subsets, xlabel, xlim, ylabel, ylim, trend=True, trend_separately=True, tooltips=True)\n",
    "ax.legend()\n",
    "sns.despine(ax=ax, offset=20, trim=True)\n",
    "plt.tight_layout()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "-"
    }
   },
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "### Fig 4 Alternatives ❓"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [],
   "source": [
    "plt.figure(figsize=(5, 5))\n",
    "ax = plt.gca()\n",
    "\n",
    "data_subsets = [\n",
    "    'JG07 Tape nori',\n",
    "    'JG08 Tape nori',\n",
    "    'JG11 Tape nori',\n",
    "    'JG12 Tape nori',\n",
    "    'JG14 Tape nori',\n",
    "]\n",
    "data_subsets = {label:label2query(label) for label in data_subsets}\n",
    "\n",
    "# xlabel, xlim = 'B8 activity mean rectified voltage (μV)', [0, None]\n",
    "# xlabel, xlim = 'B8a/b first burst mean rectified voltage (μV)', [0, None]\n",
    "# xlabel, xlim = 'B8a/b pre-B3/B6/B9 burst mean rectified voltage (μV)', [0, None]\n",
    "xlabel, xlim = 'B8a/b pre-B3/B6/B9 burst mean frequency (Hz)', [0, None]\n",
    "# ylabel, ylim = 'Force slope (mN/s)', [0, None]\n",
    "ylabel, ylim = 'Force initial slope (mN/s)', [0, None]\n",
    "# ylabel, ylim = 'Force initial increase (mN)', [0, None]\n",
    "\n",
    "scatter2d(ax, data_subsets, xlabel, xlim, ylabel, ylim, trend=True, trend_separately=True, tooltips=True)\n",
    "ax.legend()\n",
    "sns.despine(ax=ax, offset=20, trim=True)\n",
    "plt.tight_layout()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(5, 5))\n",
    "ax = plt.gca()\n",
    "\n",
    "data_subsets = [\n",
    "    'JG07 Tape nori',\n",
    "    'JG08 Tape nori',\n",
    "    'JG11 Tape nori',\n",
    "    'JG12 Tape nori',\n",
    "    'JG14 Tape nori',\n",
    "]\n",
    "data_subsets = {label:label2query(label) for label in data_subsets}\n",
    "\n",
    "# xlabel, xlim = 'B8 activity mean rectified voltage (μV)', [0, None]\n",
    "# xlabel, xlim = 'B8a/b first burst mean rectified voltage (μV)', [0, None]\n",
    "xlabel, xlim = 'B8a/b pre-B3/B6/B9 burst mean rectified voltage (μV)', [0, None]\n",
    "# xlabel, xlim = 'B8a/b pre-B3/B6/B9 burst mean frequency (Hz)', [0, None]\n",
    "# ylabel, ylim = 'Force slope (mN/s)', [0, None]\n",
    "# ylabel, ylim = 'Force initial slope (mN/s)', [0, None]\n",
    "ylabel, ylim = 'Force initial increase (mN)', [0, None]\n",
    "\n",
    "scatter2d(ax, data_subsets, xlabel, xlim, ylabel, ylim, trend=True, trend_separately=True, tooltips=True)\n",
    "ax.legend()\n",
    "sns.despine(ax=ax, offset=20, trim=True)\n",
    "plt.tight_layout()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(5, 5))\n",
    "ax = plt.gca()\n",
    "\n",
    "data_subsets = [\n",
    "    'JG07 Tape nori',\n",
    "    'JG08 Tape nori',\n",
    "    'JG11 Tape nori',\n",
    "    'JG12 Tape nori',\n",
    "    'JG14 Tape nori',\n",
    "]\n",
    "data_subsets = {label:label2query(label) for label in data_subsets}\n",
    "\n",
    "# xlabel, xlim = 'B8 activity mean rectified voltage (μV)', [0, None]\n",
    "# xlabel, xlim = 'B8a/b first burst mean rectified voltage (μV)', [0, None]\n",
    "# xlabel, xlim = 'B8a/b pre-B3/B6/B9 burst mean rectified voltage (μV)', [0, None]\n",
    "xlabel, xlim = 'B8a/b pre-B3/B6/B9 burst mean frequency (Hz)', [0, None]\n",
    "# ylabel, ylim = 'Force slope (mN/s)', [0, None]\n",
    "# ylabel, ylim = 'Force initial slope (mN/s)', [0, None]\n",
    "ylabel, ylim = 'Force initial increase (mN)', [0, None]\n",
    "\n",
    "scatter2d(ax, data_subsets, xlabel, xlim, ylabel, ylim, trend=True, trend_separately=True, tooltips=True)\n",
    "ax.legend()\n",
    "sns.despine(ax=ax, offset=20, trim=True)\n",
    "plt.tight_layout()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [],
   "source": [
    "plt.figure(figsize=(5, 5))\n",
    "ax = plt.gca()\n",
    "\n",
    "data_subsets = [\n",
    "    'JG07 Tape nori',\n",
    "    'JG08 Tape nori',\n",
    "    'JG11 Tape nori',\n",
    "    'JG12 Tape nori',\n",
    "    'JG14 Tape nori',\n",
    "]\n",
    "data_subsets = {label:label2query(label) for label in data_subsets}\n",
    "\n",
    "# xlabel, xlim = 'B8 activity duration (s)', [0, 8]\n",
    "xlabel, xlim = 'B8a/b first burst duration (s)', [0, 8]\n",
    "ylabel, ylim = 'Force rise and plateau duration (s)', [0, 8]\n",
    "\n",
    "scatter2d(ax, data_subsets, xlabel, xlim, ylabel, ylim, trend=True, trend_separately=True, tooltips=False)\n",
    "plt.plot([0, 999], [0, 999], ls=':', c='gray', zorder=0)\n",
    "ax.legend()\n",
    "sns.despine(ax=ax, offset=20, trim=True)\n",
    "plt.tight_layout()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "-"
    }
   },
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## [FIGURE 5] Third phase of swallowing: maintaining high force"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "### Fig 5A ✅"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Example motor patterns, lines connecting B3/B6/B9 motor neuron activity to force plateau\n",
    "\n",
    "* TODO: Place event markers programmatically"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Labels are intentionally overlapping since they will be manually replaced in Inkscape for a different style after rendering."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "start = datetime.datetime.now()\n",
    "\n",
    "outfile_basename = 'figure-5A-export'\n",
    "data_set_name = 'IN VIVO / JG12 / 2019-05-10 / 002'\n",
    "t_start, t_stop = [2944.5, 3002.5] * pq.s # t=2961.9, twidth=58, 6 tape nori swallows\n",
    "plots = [\n",
    "#     {'channel': 'I2',       'units': 'uV', 'ylim': [ -35,  35]}, #, 'decimation_factor': 400},\n",
    "#     {'channel': 'RN',       'units': 'uV', 'ylim': [ -25,  25]}, #, 'decimation_factor': 400},\n",
    "    {'channel': 'BN2',      'units': 'uV', 'ylim': [ -45,  45]}, #, 'decimation_factor': 400},\n",
    "#     {'channel': 'BN3-DIST', 'units': 'uV', 'ylim': [ -60,  60], 'ylabel': 'BN3 (μV)'}, #, 'decimation_factor': 400},\n",
    "    {'channel': 'Force',    'units': 'mN', 'ylim': [ -50, 450], 'decimation_factor': 100},\n",
    "]\n",
    "\n",
    "kwargs = dict(\n",
    "    formats = ['png'],\n",
    "    dpi = 600,\n",
    "    figsize = (12, 4),\n",
    "    majorticks = 10,\n",
    "    minorticks = 5,\n",
    "    linewidth = 0.5,\n",
    "    ylabel_offset = -0.01,\n",
    "    layout_settings = dict(\n",
    "        left   = 0.04,\n",
    "        right  = 0.99,\n",
    "        top    = 0.97,\n",
    "        bottom = 0.08,\n",
    "        hspace = 0,\n",
    "    ),\n",
    ")\n",
    "\n",
    "# load the data\n",
    "metadata = neurotic.MetadataSelector('../../data/metadata.yml')\n",
    "metadata.select(data_set_name)\n",
    "blk = neurotic.load_dataset(metadata)\n",
    "\n",
    "# plot the data\n",
    "# with sns.plotting_context('poster', font_scale=0.5):\n",
    "with sns.plotting_context('notebook', font_scale=1):\n",
    "    prettyplot(blk, t_start, t_stop, plots, outfile_basename, **kwargs)\n",
    "\n",
    "end = datetime.datetime.now()\n",
    "print('render time:', end-start)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "### Fig 5B ✅"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Plot delay between B3/B6/B9 motor neuron activity starting and force reaching 50% max height. Takeaway: B3/B6/B9 have the right timing for keeping force high"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- **The Good**: All delays are positive.\n",
    "\n",
    "- **The Bad**: Delays are highly variable.\n",
    "\n",
    "- Perhaps 50%-height isn't the right comparison point. Maybe B3/B6/B9 have effects earlier at 20%-height, or maybe later.\n",
    "\n",
    "- **Verdict**: Not bad, but perhaps could be better. Delay might be more consistent with a better comparison point."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(5, 5))\n",
    "ax = plt.gca()\n",
    "\n",
    "df = df_all.reset_index()\n",
    "column = 'Delay from B3/B6/B9 start to force 50%-height (s)'\n",
    "\n",
    "sns.boxplot(y='Animal', x=column, data=df, fliersize=0, whis=999) # whis=999 ensures whiskers go to min and max\n",
    "# sns.swarmplot(y='Animal', x=column, data=df, color='0.25')\n",
    "\n",
    "# sns.boxplot(x=column, data=df, fliersize=0, whis=999) # whis=999 ensures whiskers go to min and max\n",
    "# sns.swarmplot(x=column, data=df, color='0.25')\n",
    "\n",
    "plt.axvline(x=0, ls=':', c='gray', zorder=-1)\n",
    "\n",
    "plt.tight_layout()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "column = 'Delay from B3/B6/B9 start to force 50%-height (s)'\n",
    "print_column_analysis(column)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# points that aren't where we expected\n",
    "column = 'Delay from B3/B6/B9 start to force 50%-height (s)'\n",
    "df_all[df_all[column] < 0][[column]]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "### Fig 5C ✅"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Plot B3/B6/B9 burst duration against time force is above 80% max height"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- **The Good**: All same positive trends, most are significant.\n",
    "\n",
    "- **The Bad**: Would be more satisfying if the points lay on the diagonal.\n",
    "\n",
    "- **Verdict**: Good result. Might be improved by choosing a lower plateau threshold with longer duration, such as 75%."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(5, 5))\n",
    "ax = plt.gca()\n",
    "\n",
    "data_subsets = [\n",
    "    'JG07 Tape nori',\n",
    "    'JG08 Tape nori',\n",
    "    'JG11 Tape nori',\n",
    "    'JG12 Tape nori',\n",
    "    'JG14 Tape nori',\n",
    "]\n",
    "data_subsets = {label:label2query(label) for label in data_subsets}\n",
    "\n",
    "# xlabel, xlim = 'B3 first burst duration (s)', [0, 5]\n",
    "# xlabel, xlim = 'B6/B9 first burst duration (s)', [0, 5]\n",
    "xlabel, xlim = 'B3/B6/B9 burst duration (s)', [0, 5]\n",
    "ylabel, ylim = 'Force 80%-height duration (s)', [0, 5]\n",
    "\n",
    "scatter2d(ax, data_subsets, xlabel, xlim, ylabel, ylim, trend=True, trend_separately=True, tooltips=False)\n",
    "plt.plot([0, 999], [0, 999], ls=':', c='gray', zorder=0)\n",
    "ax.legend()\n",
    "sns.despine(ax=ax, offset=20, trim=True)\n",
    "plt.tight_layout()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "### Fig 5D ❌"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Plot delay between EITHER B8a/b OR B3/B6/B9 activity ending (whichever comes first) and end of force plateau. Takeaway: Show that simultaneous B8a/b and B3/B6/B9 activity are needed to sustain force, i.e., force drops when either grasper opens or retraction stops"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- **The Good**: There are more points on the right than on the left\n",
    "\n",
    "- **The Bad**: Very large variability, can't really determine sign of the timing delay\n",
    "\n",
    "- The end of the \"simultaneous B8a/b and B3/B6/B9\" period is sensitive to several threshold parameters, so it may not be possible to locate it reliably.\n",
    "\n",
    "- Perhaps the hard rule of using 80%-height for the end of the plateau is not generally applicable.\n",
    "\n",
    "- **Verdict**: Not usable in current form."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(5, 5))\n",
    "ax = plt.gca()\n",
    "\n",
    "df = df_all.reset_index()\n",
    "column = 'Delay from either B8a/b or B3/B6/B9 end to force 80%-height end (s)'\n",
    "\n",
    "sns.boxplot(y='Animal', x=column, data=df, fliersize=0, whis=999) # whis=999 ensures whiskers go to min and max\n",
    "sns.swarmplot(y='Animal', x=column, data=df, color='0.25')\n",
    "\n",
    "# sns.boxplot(x=column, data=df, fliersize=0, whis=999) # whis=999 ensures whiskers go to min and max\n",
    "# sns.swarmplot(x=column, data=df, color='0.25')\n",
    "\n",
    "plt.axvline(x=0, ls=':', c='gray', zorder=-1)\n",
    "\n",
    "plt.tight_layout()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "column = 'Delay from either B8a/b or B3/B6/B9 end to force 80%-height end (s)'\n",
    "print_column_analysis(column)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# points that aren't where we expected\n",
    "column = 'Delay from either B8a/b or B3/B6/B9 end to force 80%-height end (s)'\n",
    "df_all[df_all[column] < 0][[column]]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "### Fig 5 Alternatives ❓"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "-"
    }
   },
   "source": [
    "__Other ideas:__\n",
    "\n",
    "* Plot mean voltage on BN2 during B3/6/9 acitivty vs slope or relative rise in force ?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [],
   "source": [
    "plt.figure(figsize=(5, 5))\n",
    "ax = plt.gca()\n",
    "\n",
    "data_subsets = [\n",
    "    'JG07 Tape nori',\n",
    "    'JG08 Tape nori',\n",
    "    'JG11 Tape nori',\n",
    "    'JG12 Tape nori',\n",
    "    'JG14 Tape nori',\n",
    "]\n",
    "data_subsets = {label:label2query(label) for label in data_subsets}\n",
    "\n",
    "# xlabel, xlim = 'B3/6/9/10 activity duration (s)', [0, 8]\n",
    "xlabel, xlim = 'B6/B9 first burst duration (s)', [0, 8]\n",
    "ylabel, ylim = 'Force rise and plateau duration (s)', [0, 8]\n",
    "\n",
    "scatter2d(ax, data_subsets, xlabel, xlim, ylabel, ylim, trend=True, trend_separately=True, tooltips=False)\n",
    "plt.plot([0, 999], [0, 999], ls=':', c='gray', zorder=0)\n",
    "ax.legend()\n",
    "sns.despine(ax=ax, offset=20, trim=True)\n",
    "plt.tight_layout()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(5, 5))\n",
    "ax = plt.gca()\n",
    "\n",
    "df = df_all.reset_index()\n",
    "df = df.rename(columns={\n",
    "    'Delay from B3 start to force 80%-height start (s)': 'Start of burst',\n",
    "    'Delay from B3 end to force 80%-height end (s)':     'End of burst'})\n",
    "df = pd.melt(df,\n",
    "             id_vars=['Animal', 'Food', 'Bout_index', 'Behavior_index'],\n",
    "             value_vars=['Start of burst', 'End of burst'],\n",
    "             var_name='When?',\n",
    "             value_name='Delay from B3 to plateau (s)')\n",
    "sns.boxplot(hue='Animal', x='Delay from B3 to plateau (s)', y='When?', data=df, fliersize=0, whis=999) # whis=999 ensures whiskers go to min and max\n",
    "# sns.swarmplot(hue='Animal', x='Delay from B3 to plateau (s)', y='When?', data=df)\n",
    "\n",
    "plt.axvline(x=0, ls=':', c='gray', zorder=-1)\n",
    "\n",
    "plt.tight_layout()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [],
   "source": [
    "plt.figure(figsize=(5, 5))\n",
    "ax = plt.gca()\n",
    "\n",
    "data_subsets = [\n",
    "    'JG07 Tape nori',\n",
    "    'JG08 Tape nori',\n",
    "    'JG11 Tape nori',\n",
    "    'JG12 Tape nori',\n",
    "    'JG14 Tape nori',\n",
    "]\n",
    "data_subsets = {label:label2query(label) for label in data_subsets}\n",
    "\n",
    "# xlabel, xlim = 'B3/6/9/10 activity mean rectified voltage (μV)', [0, None]\n",
    "xlabel, xlim = 'B6/B9 first burst mean rectified voltage (μV)', [0, None]\n",
    "# ylabel, ylim = 'Force slope (mN/s)', [0, None]\n",
    "# ylabel, ylim = 'Force 80%-height (mN)', [0, None]\n",
    "ylabel, ylim = 'Force increase (mN)', [0, None]\n",
    "\n",
    "scatter2d(ax, data_subsets, xlabel, xlim, ylabel, ylim, trend=True, trend_separately=True, tooltips=True)\n",
    "ax.legend()\n",
    "sns.despine(ax=ax, offset=20, trim=True)\n",
    "plt.tight_layout()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(5, 5))\n",
    "ax = plt.gca()\n",
    "\n",
    "data_subsets = [\n",
    "    'JG07 Tape nori',\n",
    "    'JG08 Tape nori',\n",
    "    'JG11 Tape nori',\n",
    "    'JG12 Tape nori',\n",
    "    'JG14 Tape nori',\n",
    "]\n",
    "data_subsets = {label:label2query(label) for label in data_subsets}\n",
    "\n",
    "# xlabel, xlim = 'B3/6/9/10 activity mean rectified voltage (μV)', [0, None]\n",
    "xlabel, xlim = 'B6/B9 first burst mean frequency (Hz)', [0, None]\n",
    "# ylabel, ylim = 'Force slope (mN/s)', [0, None]\n",
    "# ylabel, ylim = 'Force 80%-height (mN)', [0, None]\n",
    "ylabel, ylim = 'Force increase (mN)', [0, None]\n",
    "\n",
    "scatter2d(ax, data_subsets, xlabel, xlim, ylabel, ylim, trend=True, trend_separately=True, tooltips=True)\n",
    "ax.legend()\n",
    "sns.despine(ax=ax, offset=20, trim=True)\n",
    "plt.tight_layout()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## [FIGURE 6] Fourth phase of swallowing: force shoulder during initial protraction"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "### Fig 6A ❌"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Example motor patterns, lines connecting B38 motor neuron activity and force shoulder"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "### Fig 6B ❌"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Plot delay between B38 motor neuron activity ending and force shoulder ending"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- **The Good**: \n",
    "\n",
    "- **The Bad**: Terrible variability. Certainly bad shoulders are contributing to this.\n",
    "\n",
    "- **Verdict**: This figure needs to use only the best hand-selected swallows with well-defined shoulders AND well-defined B38 burst"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(5, 5))\n",
    "ax = plt.gca()\n",
    "\n",
    "df = df_all.reset_index()\n",
    "column = 'Delay from B38 end to shoulder end (s)'\n",
    "\n",
    "sns.boxplot(y='Animal', x=column, data=df, fliersize=0, whis=999) # whis=999 ensures whiskers go to min and max\n",
    "sns.swarmplot(y='Animal', x=column, data=df, color='0.25')\n",
    "\n",
    "# sns.boxplot(x=column, data=df, fliersize=0, whis=999) # whis=999 ensures whiskers go to min and max\n",
    "# sns.swarmplot(x=column, data=df, color='0.25')\n",
    "\n",
    "plt.axvline(x=0, ls=':', c='gray', zorder=-1)\n",
    "\n",
    "plt.tight_layout()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "column = 'Delay from B38 end to shoulder end (s)'\n",
    "print_column_analysis(column)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# points that aren't where we expected\n",
    "column = 'Delay from B38 end to shoulder end (s)'\n",
    "df_all[df_all[column] < 0][[column]]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "### Fig 6 Alternatives ❓"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(5, 5))\n",
    "ax = plt.gca()\n",
    "\n",
    "data_subsets = [\n",
    "    'JG07 Tape nori',\n",
    "    'JG08 Tape nori',\n",
    "    'JG11 Tape nori',\n",
    "    'JG12 Tape nori',\n",
    "    'JG14 Tape nori',\n",
    "]\n",
    "data_subsets = {label:label2query(label) for label in data_subsets}\n",
    "\n",
    "# xlabel, xlim = 'B38 activity duration (s)', [0, 6]\n",
    "xlabel, xlim = 'B38 last burst duration (s)', [0, 6]\n",
    "ylabel, ylim = 'Force shoulder duration (s)', [0, 6]\n",
    "\n",
    "scatter2d(ax, data_subsets, xlabel, xlim, ylabel, ylim, trend=True, trend_separately=True, tooltips=False)\n",
    "plt.plot([0, 999], [0, 999], ls=':', c='gray', zorder=0)\n",
    "ax.legend()\n",
    "sns.despine(ax=ax, offset=20, trim=True)\n",
    "plt.tight_layout()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(5, 5))\n",
    "ax = plt.gca()\n",
    "\n",
    "data_subsets = [\n",
    "    'JG07 Tape nori',\n",
    "    'JG08 Tape nori',\n",
    "    'JG11 Tape nori',\n",
    "    'JG12 Tape nori',\n",
    "    'JG14 Tape nori',\n",
    "]\n",
    "data_subsets = {label:label2query(label) for label in data_subsets}\n",
    "\n",
    "xlabel, xlim = 'B38 last burst mean frequency (Hz)', [0, None]\n",
    "ylabel, ylim = 'Force shoulder duration (s)', [0, None]\n",
    "\n",
    "scatter2d(ax, data_subsets, xlabel, xlim, ylabel, ylim, trend=True, trend_separately=True, tooltips=False)\n",
    "ax.legend()\n",
    "sns.despine(ax=ax, offset=20, trim=True)\n",
    "plt.tight_layout()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## [FIGURE 7] Summary ❌"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Firing rate model (time permitting), or schematic summary of all phases (boxes for motor neuron activity, idealized force, etc.)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
