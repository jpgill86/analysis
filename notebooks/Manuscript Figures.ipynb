{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Jump to a Figure"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- [Figure 1](#[FIGURE-1])\n",
    "  - [Figure 1A](#ðŸŒ-Figure-1A)\n",
    "  - [Figures 1B & 1C](#ðŸŒ-Figures-1B-&-1C)\n",
    "- [Figure 2](#[FIGURE-2])\n",
    "  - [Figure 2A](#ðŸŒ-Figure-2A)\n",
    "  - [Figure 2B](#ðŸŒ-Figure-2B)\n",
    "  - [Figure 2C](#ðŸŒ-Figure-2C)\n",
    "  - [Figure 2D](#ðŸŒ-Figure-2D)\n",
    "  - [Figure 2E](#ðŸŒ-Figure-2E)\n",
    "- [Figure 3](#[FIGURE-3])\n",
    "  - [Figure 3A](#ðŸŒ-Figure-3A)\n",
    "  - [Figure 3B](#ðŸŒ-Figure-3B)\n",
    "  - [Figure 3C](#ðŸŒ-Figure-3C)\n",
    "  - [Figure 3D](#ðŸŒ-Figure-3D)\n",
    "  - [Figure 3E](#ðŸŒ-Figure-3E)\n",
    "  - [Figure 3F](#ðŸŒ-Figure-3F)\n",
    "  - [Figure 3G](#ðŸŒ-Figure-3G)\n",
    "- [Figure 4](#[FIGURE-4])\n",
    "  - [Figure 4A](#ðŸŒ-Figure-4A)\n",
    "  - [Figure 4B](#ðŸŒ-Figure-4B)\n",
    "- [Figure 5](#[FIGURE-5])\n",
    "  - [Figure 5A](#ðŸŒ-Figure-5A)\n",
    "  - [Figure 5B](#ðŸŒ-Figure-5B)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Preamble"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "source": [
    "## Import Packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import datetime\n",
    "import pickle\n",
    "import numpy as np\n",
    "import scipy as sp\n",
    "import quantities as pq\n",
    "import elephant\n",
    "import pandas as pd\n",
    "import statsmodels.api as sm\n",
    "import neurotic\n",
    "from neurotic.datasets.data import _detect_spikes\n",
    "from utils import BehaviorsDataFrame, DownsampleNeoSignal\n",
    "\n",
    "pq.markup.config.use_unicode = True  # allow symbols like mu for micro in output\n",
    "pq.mN = pq.UnitQuantity('millinewton', pq.N/1e3, symbol = 'mN');  # define millinewton\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.colors as mcolors\n",
    "import matplotlib.patches as patches\n",
    "import matplotlib.lines as mlines\n",
    "from matplotlib.markers import CARETLEFT, CARETRIGHT, CARETUP, CARETDOWN, CARETUPBASE\n",
    "from matplotlib.ticker import MultipleLocator\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "outputs": [],
   "source": [
    "import warnings\n",
    "\n",
    "# np.nanmax raises a warning if all values are NaN and returns NaN, which is the behavior we want\n",
    "warnings.filterwarnings('ignore', message='All-NaN slice encountered')\n",
    "\n",
    "# elephant.statistics.instantaneous_rate always complains about negative values\n",
    "warnings.filterwarnings('ignore', message='Instantaneous firing rate approximation contains '\n",
    "                                          'negative values, possibly caused due to machine '\n",
    "                                          'precision errors')\n",
    "\n",
    "# with matplotlib>=3.1 and seaborn<=0.9.0, deprecation warnings are raised\n",
    "# whenever tick marks are placed on the right axis but not the left\n",
    "from matplotlib.cbook import MatplotlibDeprecationWarning\n",
    "warnings.simplefilter('ignore', MatplotlibDeprecationWarning)\n",
    "\n",
    "# don't complain about opening too many figures\n",
    "plt.rcParams.update({'figure.max_open_warning': 0})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "outputs": [],
   "source": [
    "# make figures interactive and open in a separate window\n",
    "# %matplotlib qt\n",
    "\n",
    "# make figures interactive and inline\n",
    "%matplotlib notebook\n",
    "\n",
    "# make figures non-interactive and inline\n",
    "# %matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "source": [
    "## Plot Settings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "export_dir = 'manuscript-figures'\n",
    "if not os.path.exists(export_dir):\n",
    "    os.mkdir(export_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "outputs": [],
   "source": [
    "# general plot settings\n",
    "sns.set(\n",
    "#     context = 'poster',\n",
    "    style = 'ticks',\n",
    "    font_scale = 1,\n",
    "    font = 'Palatino Linotype',\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# display current color palette\n",
    "with sns.axes_style('darkgrid'):\n",
    "    sns.palplot(sns.color_palette(None), size=0.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "outputs": [],
   "source": [
    "unit_colors = {\n",
    "    'I2 spikes': 'C9', # light blue\n",
    "    'I2':        'C9', # light blue\n",
    "    'B8a/b':     'C6', # pink\n",
    "    'B6/B9':     'C2', # green\n",
    "    'B3':        'C3', # red\n",
    "    'B38':       'C1', # orange\n",
    "    'B4/B5':     'C0', # dark blue\n",
    "}\n",
    "force_colors = {\n",
    "    'dip':          unit_colors['I2 spikes'],\n",
    "    'initial rise': unit_colors['B8a/b'],\n",
    "    'rise':         unit_colors['B8a/b'],\n",
    "    'plateau':      unit_colors['B6/B9'],\n",
    "    'drop':         'gray',\n",
    "    'shoulder':     unit_colors['B38'],\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for unit, color_id in unit_colors.items():\n",
    "    if unit != 'I2 spikes':\n",
    "        color_index = int(color_id[1:])\n",
    "        color_tuple = sns.color_palette(None)[color_index]\n",
    "        color_hex = mcolors.to_hex(color_tuple)\n",
    "        print(f'{unit}\\t{color_hex}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "source": [
    "## Data Parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "burst_thresholds_default = {\n",
    "    'I2 spikes': (10,  5)*pq.Hz, # same as Cullins et al. 2015a (based on Hurwitz et al. 1996)\n",
    "    'B8a/b':     ( 3,  3)*pq.Hz, # same as Cullins et al. 2015a (based on Morton and Chiel 1993a)\n",
    "    'B6/B9':     (10,  5)*pq.Hz, # based on Lu et al. 2015\n",
    "    'B3':        ( 8,  2)*pq.Hz, # based on Lu et al. 2015\n",
    "    'B38':       ( 8,  5)*pq.Hz, # based on McManus et al. 2014\n",
    "    'B4/B5':     ( 3,  3)*pq.Hz, # same as Cullins et al. 2015a ? (Table 1 says 3 Hz, text says first/last spike; based on Warman and Chiel 1995 ?)\n",
    "}\n",
    "\n",
    "burst_thresholds_by_animal = {\n",
    "    'JG07': burst_thresholds_default.copy(),\n",
    "    'JG08': burst_thresholds_default.copy(),\n",
    "    'JG11': burst_thresholds_default.copy(),\n",
    "    'JG12': burst_thresholds_default.copy(),\n",
    "    'JG14': burst_thresholds_default.copy(),\n",
    "}\n",
    "\n",
    "# exceptions\n",
    "burst_thresholds_by_animal['JG08']['B6/B9'] = (10,   3  )*pq.Hz # end threshold reduced for this animal\n",
    "burst_thresholds_by_animal['JG11']['B4/B5'] = ( 1.5, 1.5)*pq.Hz # both thresholds reduced for this animal because only one neuron appeared to project\n",
    "burst_thresholds_by_animal['JG14']['B6/B9'] = ( 4,   2  )*pq.Hz # both thresholds reduced for this animal because B6/B9 always fired slowly"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "channel_units = ['uV', 'uV', 'uV', 'uV', 'mN']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "channel_names_by_animal = {\n",
    "    'JG07': ['I2-L', 'RN-L', 'BN2-L', 'BN3-L',    'Force'],\n",
    "    'JG08': ['I2',   'RN',   'BN2',   'BN3',      'Force'],\n",
    "    'JG11': ['I2',   'RN',   'BN2',   'BN3-PROX', 'Force'],\n",
    "    'JG12': ['I2',   'RN',   'BN2',   'BN3-DIST', 'Force'],\n",
    "    'JG14': ['I2',   'RN',   'BN2',   'BN3-PROX', 'Force'],\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sig_filters_by_animal = {\n",
    "    'JG07': [{'channel': 'I2-L', 'lowpass': 100}],\n",
    "    'JG08': [{'channel': 'I2',   'lowpass': 100}],\n",
    "    'JG11': [{'channel': 'I2',   'lowpass': 100}],\n",
    "    'JG12': [{'channel': 'I2',   'lowpass': 100}],\n",
    "    'JG14': [{'channel': 'I2',   'lowpass': 100}],\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "epoch_types_by_food = {\n",
    "    'Regular nori': ['Swallow (regular 5-cm nori strip)'],\n",
    "    'Tape nori':    ['Swallow (tape nori)'],\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "outputs": [],
   "source": [
    "feeding_bouts = {\n",
    "    # (animal, food, bout_index): (data_set_name, time_window)\n",
    "\n",
    "    ('JG07', 'Regular nori', 0): ('IN VIVO / JG07 / 2018-05-20 / 002', [1496, 1518]), # 4 swallows, last 2 inward food movement epochs not representative of retraction (strip broke, then finished strip mid-retraction)\n",
    "    ('JG08', 'Regular nori', 0): ('IN VIVO / JG08 / 2018-06-21 / 002', [ 256,  287]), # 4 swallows\n",
    "    ('JG08', 'Regular nori', 1): ('IN VIVO / JG08 / 2018-06-21 / 002', [ 454,  481]), # 4 swallows\n",
    "    ('JG11', 'Regular nori', 0): ('IN VIVO / JG11 / 2019-04-03 / 001', [1791, 1819]), # 5 swallows\n",
    "    ('JG11', 'Regular nori', 1): ('IN VIVO / JG11 / 2019-04-03 / 004', [ 551,  568]), # 3 swallows\n",
    "    ('JG12', 'Regular nori', 0): ('IN VIVO / JG12 / 2019-05-10 / 002', [ 147,  165]), # 3 swallows, last 1 inward food movement epoch not representative of retraction (finished strip mid-retraction)\n",
    "    ('JG12', 'Regular nori', 1): ('IN VIVO / JG12 / 2019-05-10 / 002', [ 229,  245]), # 3 swallows\n",
    "    ('JG12', 'Regular nori', 2): ('IN VIVO / JG12 / 2019-05-10 / 002', [ 277,  291]), # 3 swallows, last 1 inward food movement epoch not representative of retraction (finished strip mid-retraction)\n",
    "    ('JG14', 'Regular nori', 0): ('IN VIVO / JG14 / 2019-07-30 / 001', [1834, 1865]), # 4 swallows\n",
    "    ('JG14', 'Regular nori', 1): ('IN VIVO / JG14 / 2019-07-30 / 001', [1910, 1943]), # 5 swallows\n",
    "    ('JG14', 'Regular nori', 2): ('IN VIVO / JG14 / 2019-07-30 / 001', [2052, 2084]), # 5 swallows\n",
    "    \n",
    "    ('JG07', 'Tape nori',    0): ('IN VIVO / JG07 / 2018-05-20 / 002', [2718, 2755]), # 5 swallows\n",
    "    ('JG08', 'Tape nori',    0): ('IN VIVO / JG08 / 2018-06-21 / 002', [ 147,  208]), # 7 swallows, some bucket and head movement\n",
    "    ('JG08', 'Tape nori',    1): ('IN VIVO / JG08 / 2018-06-21 / 002', [ 664,  701]), # 5 swallows, large bucket movement\n",
    "    ('JG08', 'Tape nori',    2): ('IN VIVO / JG08 / 2018-06-21 / 002', [1451, 1477]), # 3 swallows, some bucket movement\n",
    "    ('JG11', 'Tape nori',    0): ('IN VIVO / JG11 / 2019-04-03 / 004', [1227, 1280]), # 5 swallows\n",
    "    ('JG12', 'Tape nori',    0): ('IN VIVO / JG12 / 2019-05-10 / 002', [ 436,  465]), # 4 swallows\n",
    "    ('JG12', 'Tape nori',    1): ('IN VIVO / JG12 / 2019-05-10 / 002', [2901, 2937]), # 5 swallows\n",
    "    ('JG14', 'Tape nori',    0): ('IN VIVO / JG14 / 2019-07-29 / 004', [ 829,  870]), # 5 swallows\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for example figures only -- not used in majority of analysis because of long inter-swallow intervals\n",
    "\n",
    "exemplary_bout    = ('JG12', 'Tape nori', 101)\n",
    "exemplary_swallow = ('JG12', 'Tape nori', 102)\n",
    "\n",
    "feeding_bouts[exemplary_bout]    = ('IN VIVO / JG12 / 2019-05-10 / 002', [2970.7, 2992.0]) # 3 swallows\n",
    "feeding_bouts[exemplary_swallow] = ('IN VIVO / JG12 / 2019-05-10 / 002', [2977.3, 2984.5]) # 1 swallow"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "source": [
    "## Helper Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "outputs": [],
   "source": [
    "def query_union(queries):\n",
    "    return '|'.join([f'({q})' for q in queries if q is not None])\n",
    "\n",
    "def label2query(label):\n",
    "    animal, food = label[:4], label[5:]\n",
    "    query = f'(Animal == \"{animal}\") & (Food == \"{food}\")'\n",
    "    return query\n",
    "\n",
    "def contains(series, string):\n",
    "#     return np.array([string in x for x in series])\n",
    "    return series.map(lambda x: string in x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "outputs": [],
   "source": [
    "def get_sig(blk, channel):\n",
    "    sig = next((sig for sig in blk.segments[0].analogsignals if sig.name == channel), None)\n",
    "    if sig is None:\n",
    "        raise Exception(f'Channel \"{channel}\" could not be found')\n",
    "    else:\n",
    "        return sig"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_sig_index(blk, channel):\n",
    "    index = next((i for i, sig in enumerate(blk.segments[0].analogsignals) if sig.name == channel), None)\n",
    "    if index is None:\n",
    "        raise Exception(f'Channel \"{channel}\" could not be found')\n",
    "    else:\n",
    "        return index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def apply_filters(blk, metadata):\n",
    "    # nearly identical to neurotic's implementation except\n",
    "    # time_slice ensures proxies are loaded\n",
    "    \n",
    "    for sig_filter in metadata['filters']:\n",
    "        index = get_sig_index(blk, sig_filter['channel'])\n",
    "        high = sig_filter.get('highpass', None)\n",
    "        low  = sig_filter.get('lowpass',  None)\n",
    "        if high:\n",
    "            high *= pq.Hz\n",
    "        if low:\n",
    "            low  *= pq.Hz\n",
    "        blk.segments[0].analogsignals[index] = elephant.signal_processing.butter(  # may raise a FutureWarning\n",
    "            signal = blk.segments[0].analogsignals[index].time_slice(None, None),\n",
    "            highpass_freq = high,\n",
    "            lowpass_freq  = low,\n",
    "        )\n",
    "    \n",
    "    return blk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "outputs": [],
   "source": [
    "# def finite_min(x, y):\n",
    "#     '''Workaround for Quantities warning about comparison to NaN'''\n",
    "#     if np.isfinite(x) and np.isfinite(y):\n",
    "#         return min(x, y)\n",
    "#     elif np.isfinite(x):\n",
    "#         return x\n",
    "#     elif np.isfinite(y):\n",
    "#         return y\n",
    "#     else:\n",
    "#         assert x.units == y.units\n",
    "#         return np.nan * x.units\n",
    "\n",
    "# def finite_max(x, y):\n",
    "#     '''Workaround for Quantities warning about comparison to NaN'''\n",
    "#     if np.isfinite(x) and np.isfinite(y):\n",
    "#         return max(x, y)\n",
    "#     elif np.isfinite(x):\n",
    "#         return x\n",
    "#     elif np.isfinite(y):\n",
    "#         return y\n",
    "#     else:\n",
    "#         assert x.units == y.units\n",
    "#         return np.nan * x.units"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "outputs": [],
   "source": [
    "def find_bursts(st, burst_thresholds):\n",
    "    '''Find every sequence of spikes that qualifies as a burst'''\n",
    "    \n",
    "    isi = elephant.statistics.isi(st).rescale('s')\n",
    "    iff = 1/isi\n",
    "\n",
    "    start_freq, end_freq = burst_thresholds\n",
    "    start_mask = iff > start_freq\n",
    "    end_mask = iff < end_freq\n",
    "\n",
    "    bursts = []\n",
    "    scan_index = -1\n",
    "    while scan_index < iff.size:\n",
    "        start_index = None\n",
    "        end_index = None\n",
    "\n",
    "        start_mask_indexes = np.where(start_mask)[0]\n",
    "        start_mask_indexes = start_mask_indexes[start_mask_indexes > scan_index]\n",
    "        if start_mask_indexes.size == 0:\n",
    "            break\n",
    "\n",
    "        start_index = start_mask_indexes[0] # first time that iff rises above start threshold\n",
    "\n",
    "        end_mask_indexes = np.where(end_mask)[0]\n",
    "        end_mask_indexes = end_mask_indexes[end_mask_indexes > start_index]\n",
    "        if end_mask_indexes.size > 0:\n",
    "            end_index = end_mask_indexes[0] # first time after start that iff drops below end theshold\n",
    "        else:\n",
    "            end_index = -1 # end of spike train (include all spikes after start)\n",
    "\n",
    "        burst = {\n",
    "            'Start (s)': st[start_index].rescale('s'),\n",
    "            'End (s)': st[end_index].rescale('s'),\n",
    "            'Duration (s)': (st[end_index] - st[start_index]).rescale('s'),\n",
    "            'Number of spikes': end_index-start_index+1 if end_index > 0 else st.size-start_index\n",
    "        }\n",
    "        bursts.append(burst)\n",
    "        if end_index == -1:\n",
    "            break\n",
    "        else:\n",
    "            scan_index = end_index\n",
    "    \n",
    "    return bursts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "outputs": [],
   "source": [
    "def is_good_burst(burst):\n",
    "    return burst['Duration (s)'] >= 0.5*pq.s and burst['Number of spikes'] > 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# this function runs much faster if args are first converted\n",
    "# from quantities to simple ndarrays (use .rescale('s').magnitude)\n",
    "def normalize_time(fixed_times, t):\n",
    "    if not isinstance(t, np.ndarray):\n",
    "        if type(t) is list:\n",
    "            t = np.array(t)\n",
    "        else:\n",
    "            t = np.array([t])\n",
    "    \n",
    "    assert np.all(np.diff(fixed_times[~np.isnan(fixed_times)])>=0), f'fixed_times must be sorted: {fixed_times}'\n",
    "    assert np.all(np.diff(t[~np.isnan(t)])>=0), f't must be sorted: {t}'\n",
    "    \n",
    "    t_min = fixed_times[~np.isnan(fixed_times)].min()\n",
    "    t_max = fixed_times[~np.isnan(fixed_times)].max()\n",
    "    \n",
    "    result = []\n",
    "    last_found_i = 0\n",
    "    for ti in t:\n",
    "        \n",
    "        found = False\n",
    "        \n",
    "        if np.isnan(ti) or ti < t_min or t_max < ti:\n",
    "#             print(f'time {ti:.3f} was out of bounds for normalization')\n",
    "            result.append(np.nan)\n",
    "            continue\n",
    "\n",
    "        # use a manual O(n) loop instead of using np.searchsorted's much faster binary\n",
    "        # search O(log(n)) algorithm because NaNs inside fixed_times can fool searchsorted\n",
    "        for i in range(last_found_i, len(fixed_times)-1):\n",
    "            before = fixed_times[i]\n",
    "            after = fixed_times[i+1]\n",
    "            if np.isfinite(before) and np.isfinite(after):\n",
    "                if before <= ti <= after:\n",
    "                    found = True\n",
    "                    last_found_i = i\n",
    "                    result.append((ti-before)/(after-before) + i)\n",
    "                    break\n",
    "\n",
    "        # if we haven't returned already, then there must be a NaN bordering where t would go\n",
    "        if not found:\n",
    "#             print(f'time {ti:.3f} would fall next to an undefined boundary')\n",
    "            result.append(np.nan)\n",
    "            continue\n",
    "    \n",
    "    return np.array(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# this function runs much faster if args are first converted\n",
    "# from quantities to simple ndarrays (use .rescale('s').magnitude)\n",
    "def unnormalize_time(fixed_times, t_normalized):\n",
    "    if not isinstance(t_normalized, np.ndarray):\n",
    "        if type(t_normalized) is list:\n",
    "            t_normalized = np.array(t_normalized)\n",
    "        else:\n",
    "            t_normalized = np.array([t_normalized])\n",
    "    \n",
    "    assert np.all(np.diff(fixed_times[~np.isnan(fixed_times)])>=0), f'fixed_times must be sorted: {fixed_times}'\n",
    "    \n",
    "    t_normalized_min = np.where(~np.isnan(fixed_times))[0].min()\n",
    "    t_normalized_max = np.where(~np.isnan(fixed_times))[0].max()\n",
    "    \n",
    "    result = []\n",
    "    for ti in t_normalized:\n",
    "        \n",
    "        if np.isnan(ti) or ti < t_normalized_min or t_normalized_max < ti:\n",
    "    #         print(f'normalized time {ti:.3f} was out of bounds for un-normalization')\n",
    "            result.append(np.nan)\n",
    "            continue\n",
    "\n",
    "        if np.isclose(ti, t_normalized_max):\n",
    "            # workaround for numerical imprecision issue\n",
    "            ti -= 0.000001\n",
    "\n",
    "        i = int(np.floor(ti))\n",
    "        before = fixed_times[i]\n",
    "        after = fixed_times[i+1]\n",
    "        if np.isfinite(before) and np.isfinite(after):\n",
    "            result.append((ti - i)*(after-before) + before)\n",
    "            continue\n",
    "        else:\n",
    "            # there is a NaN bordering where t would go\n",
    "#             print(f'normalized time {ti:.3f} would fall next to an undefined boundary')\n",
    "            result.append(np.nan)\n",
    "            continue\n",
    "    \n",
    "    return np.array(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# times_interp is the array of normalized times at which samples will be taken\n",
    "# - samples will be taken at regular intervals in normalized time\n",
    "times_interp = np.linspace(0, 9, 4000) # [0, 9] is the range of normalized times\n",
    "\n",
    "def resample_sig_in_normalized_time(fixed_times, sig, times_interp=times_interp):\n",
    "        \n",
    "        # get normalized times and signal values\n",
    "        # - normalize_time will put into times_normalized a np.nan wherever a time was not normalizable,\n",
    "        #   i.e., wherever the time occurred adjacent to a missing fixed time (np.nan in fixed_times)\n",
    "        times = sig.times.rescale('s').magnitude\n",
    "        times_normalized = normalize_time(fixed_times.magnitude, times)\n",
    "        y = sig.magnitude.flatten()\n",
    "        \n",
    "        # drop times that could not be normalized due to missing fixed times\n",
    "        # - interp1d will erroneously interpolate across the gaps created by this deletion,\n",
    "        #   but we will then replace those interpolated values with np.nan\n",
    "        where_normalizable = np.where(~np.isnan(times_normalized))[0]\n",
    "        times_normalized = times_normalized[where_normalizable]\n",
    "        y = y[where_normalizable]\n",
    "        \n",
    "        # resample evenly in normalized time\n",
    "        # - fill_value will only put np.nan in places outside the min and max of times_normalized\n",
    "        # - interp1d will interpolate across the regions we deleted, but we want np.nan there,\n",
    "        #   so we will insert them manually in the next step\n",
    "        interp_func = sp.interpolate.interp1d(times_normalized, y, kind='linear', bounds_error=False, fill_value=np.nan)\n",
    "        y_interp = interp_func(times_interp)\n",
    "        \n",
    "        # replace erroneously interpolated values with np.nan\n",
    "        # - now the points in y_interp which would correspond to times that could not be normalized\n",
    "        #   have been set to np.nan\n",
    "        where_not_normalizable = np.where(np.isnan(unnormalize_time(fixed_times.magnitude, times_interp)))[0]\n",
    "        y_interp[where_not_normalizable] = np.nan\n",
    "        \n",
    "        return y_interp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def print_column_analysis(column):\n",
    "    unit = column.split('(')[-1].split(')')[0]\n",
    "    mean = df_all[column].mean()\n",
    "    std = df_all[column].std()\n",
    "    cv = std/abs(mean)\n",
    "    print(f'Overall mean +/- std: {mean:.2f} +/- {std:.2f} {unit}')\n",
    "    print(f'Overall coefficient of variation CV: {cv:.2f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def differences_test(x, y):\n",
    "    # Shapiro-Wilk test for normality of differences\n",
    "    # - equivalent R test: shapiro.test(x-y)\n",
    "    shapiro_W, shapiro_p = sp.stats.shapiro(x-y)\n",
    "    print(f'H0: Differences have normal distribution, W = {shapiro_W:g},\\tp = {shapiro_p:g}')\n",
    "\n",
    "    if shapiro_p >= 0.05:\n",
    "        print('- Because the differences can be assumed to be normal, a paired t-test will be used')\n",
    "\n",
    "        # paired T-test for non-zero difference in means\n",
    "        # - equivalent R test: t.test(x, y, paired=TRUE)\n",
    "        ttest_t, ttest_p = sp.stats.ttest_rel(x, y)\n",
    "        print(f'H0: Difference in means is zero,          t = {ttest_t:g},\\tp = {ttest_p:g}')\n",
    "    \n",
    "    else:\n",
    "        print('- Because the differences cannot be assumed to be normal, a Wilcoxon signed rank test will be used')\n",
    "\n",
    "        # Wilcoxon signed rank test for non-zero difference in locations (medians?)\n",
    "        # - equivalent R test: wilcox.test(x, y, paired=TRUE, exact=FALSE)\n",
    "        # - a warning is raised for small sample sizes (N < 10) becauses SciPy's implementation\n",
    "        #   always calculates the p-value using a normal approximation of the test statistic\n",
    "        #   distribution, which is inaccurate for small sample size\n",
    "        # - use R to get exact p-value, with wilcox.test(x, y, paired=TRUE, exact=TRUE)\n",
    "        # - upcoming implementation of exact distribution: https://github.com/scipy/scipy/pull/10796\n",
    "        wilcoxon_W, wilcoxon_p = sp.stats.wilcoxon(x, y, correction=True)\n",
    "        print(f'H0: Difference in medians is zero,        W = {wilcoxon_W:g},\\tp = {wilcoxon_p:g}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def lighten_color(color, amount=0.5):\n",
    "    '''\n",
    "    Lightens the given color by multiplying (1-luminosity) by the given amount.\n",
    "    Input can be matplotlib color string, hex string, or RGB tuple.\n",
    "\n",
    "    Examples:\n",
    "    >> lighten_color('g', 0.3)\n",
    "    >> lighten_color('#F034A3', 0.6)\n",
    "    >> lighten_color((.3,.55,.1), 0.5)\n",
    "    \n",
    "    https://stackoverflow.com/a/49601444/3314376\n",
    "    '''\n",
    "    import matplotlib.colors as mc\n",
    "    import colorsys\n",
    "    try:\n",
    "        c = mc.cnames[color]\n",
    "    except:\n",
    "        c = color\n",
    "    c = colorsys.rgb_to_hls(*mc.to_rgb(c))\n",
    "    return colorsys.hls_to_rgb(c[0], 1 - amount * (1 - c[1]), c[2])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import and Process the Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# skip expensive calculations by loading the results from a file?\n",
    "# - with load_from_files=False, perform data processing from scratch,\n",
    "#   which takes several minutes\n",
    "# - with load_from_files=True, load the final results (dataframes)\n",
    "#   pickled last time the calculations were performed\n",
    "load_from_files = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pickled_vars = ['df_all', 'df_exemplary_bout', 'df_exemplary_swallow']\n",
    "if load_from_files:\n",
    "    \n",
    "    # TODO: why does unpickling generate this warning?\n",
    "    #     RuntimeWarning: invalid value encountered in greater\n",
    "    #         return self.magnitude > other\n",
    "    for var in pickled_vars:\n",
    "        filename = f'{var}.pickle'\n",
    "        with open(filename, 'rb') as f:\n",
    "            exec(f'{var} = pickle.load(f)')\n",
    "\n",
    "    print('calculation results loaded from files')\n",
    "    \n",
    "else:\n",
    "    \n",
    "    start = datetime.datetime.now()\n",
    "\n",
    "    # use Neo RawIO lazy loading to load much faster and using less memory\n",
    "    # - with lazy=True, filtering parameters specified in metadata are ignored\n",
    "    #     - note: filters are replaced below and applied manually anyway\n",
    "    # - with lazy=True, loading via time_slice requires neo>=0.8.0\n",
    "    lazy = True\n",
    "\n",
    "    # load the metadata containing file paths\n",
    "    metadata = neurotic.MetadataSelector(file='../../data/metadata.yml')\n",
    "\n",
    "    # filter epochs for each bout and perform calculations\n",
    "    df_list = []\n",
    "    last_data_set_name = None\n",
    "    for (animal, food, bout_index), (data_set_name, time_window) in feeding_bouts.items():\n",
    "\n",
    "        channel_names = channel_names_by_animal[animal]\n",
    "        epoch_types = epoch_types_by_food[food]\n",
    "        burst_thresholds = burst_thresholds_by_animal[animal]\n",
    "\n",
    "        ###\n",
    "        ### LOAD DATASET\n",
    "        ###\n",
    "\n",
    "        metadata.select(data_set_name)\n",
    "\n",
    "        if data_set_name is last_data_set_name:\n",
    "            # skip reloading the data if it's already in memory\n",
    "            pass\n",
    "        else:\n",
    "\n",
    "            # ensure that the right filters are used\n",
    "            metadata['filters'] = sig_filters_by_animal[animal]\n",
    "\n",
    "            blk = neurotic.load_dataset(metadata, lazy=lazy)\n",
    "\n",
    "            if lazy:\n",
    "                # manually perform filters\n",
    "                blk = apply_filters(blk, metadata)\n",
    "\n",
    "        last_data_set_name = data_set_name\n",
    "\n",
    "\n",
    "\n",
    "        ###\n",
    "        ### LOCATE BEHAVIOR EPOCHS AND SUBEPOCHS\n",
    "        ###\n",
    "\n",
    "        # construct a query for locating behaviors\n",
    "        behavior_query = f'(Type in {epoch_types}) & ({time_window[0]} <= Start) & (End <= {time_window[1]})'\n",
    "\n",
    "        # construct queries for locating epochs associated with each behavior\n",
    "        # - each query should match at most one epoch\n",
    "        # - dictionary keys are used as prefixes for the names of new columns\n",
    "        subepoch_queries = {}\n",
    "\n",
    "        subepoch_queries['I2 protraction activity'] = f'(Type == \"I2 protraction activity\") & ' \\\n",
    "                                                      f'(@behavior_start-1 <= Start) & (End <= @behavior_end)'\n",
    "                                                      # must start no earlier than 1 second before behavior and end within it\n",
    "\n",
    "        subepoch_queries['B8 activity']             = f'(Type == \"B8 activity\") & ' \\\n",
    "                                                      f'(@behavior_start <= Start) & (End <= @behavior_end)'\n",
    "                                                      # must be fully contained within behavior\n",
    "\n",
    "        subepoch_queries['B3/6/9/10 activity']      = f'(Type == \"B3/6/9/10 activity\") & ' \\\n",
    "                                                      f'(@behavior_start <= Start) & (End <= @behavior_end)'\n",
    "                                                      # must be fully contained within behavior\n",
    "\n",
    "        subepoch_queries['B38 activity']            = (f'(Type == \"B38 activity\") & ' \\\n",
    "                                                       f'(@behavior_start-3 <= End) & (End <= @behavior_start+4)',\n",
    "                                                       'last') # use last if there are multiple matches\n",
    "                                                      # must end within a few seconds of behavior start (3 before or 4 after)\n",
    "\n",
    "        subepoch_queries['B4/B5 activity']          = (f'(Type == \"B4/B5 activity\") & ' \\\n",
    "                                                       f'(@behavior_start <= Start) & (Start <= @behavior_end)',\n",
    "                                                       'first') # use first if there are multiple matches\n",
    "                                                      # must start within behavior\n",
    "        \n",
    "        subepoch_queries['Force shoulder end']      = f'(Type == \"Force shoulder end\") & ' \\\n",
    "                                                      f'(@behavior_start-3 <= End) & (End <= @behavior_start+3)'\n",
    "                                                      # must end within 3 seconds of behavior start\n",
    "        \n",
    "        subepoch_queries['Force rise start']        = f'(Type == \"Force rise start\") & ' \\\n",
    "                                                      f'(@behavior_start <= Start) & (Start <= @behavior_end)'\n",
    "                                                      # must start within behavior\n",
    "\n",
    "        subepoch_queries['Force plateau start']     = f'(Type == \"Force plateau start\") & ' \\\n",
    "                                                      f'(@behavior_start <= Start) & (Start <= @behavior_end)'\n",
    "                                                      # must start within behavior\n",
    "\n",
    "        subepoch_queries['Force plateau end']       = f'(Type == \"Force plateau end\") & ' \\\n",
    "                                                      f'(@behavior_end-2 <= Start) & (Start <= @behavior_end+2)'\n",
    "                                                      # must start within 2 seconds of behavior end\n",
    "\n",
    "        subepoch_queries['Force drop end']          = f'(Type == \"Force drop end\") & ' \\\n",
    "                                                      f'(@behavior_end-2 <= Start) & (Start <= @behavior_end+2)'\n",
    "                                                      # must start within 2 seconds of behavior end\n",
    "        \n",
    "        subepoch_queries['Inward movement']         = f'(Type == \"Inward movement\") & ' \\\n",
    "                                                      f'(@behavior_start <= Start) & (Start <= @behavior_end)'\n",
    "                                                      # must start within behavior\n",
    "\n",
    "        # construct a table in which each row is a behavior and subepoch data\n",
    "        # is added as columns, e.g. df['B38 activity start (s)']\n",
    "        df = BehaviorsDataFrame(blk.segments[0].epochs, behavior_query, subepoch_queries)\n",
    "\n",
    "        # renumber behaviors assuming all behaviors are from a single contiguous sequence\n",
    "        df = df.sort_values('Start (s)').reset_index(drop=True).rename_axis('Behavior_index')\n",
    "\n",
    "\n",
    "\n",
    "        ###\n",
    "        ### START CALCULATIONS\n",
    "        ###\n",
    "\n",
    "        # some columns must have type 'object', which\n",
    "        # can be accomplished by initializing with None or np.nan\n",
    "        df['Normalization fixed times (s)'] = None\n",
    "        df['Force, normalized time interpolation (mN)'] = None\n",
    "        units = [\n",
    "            'I2 spikes',\n",
    "            'B8a/b',\n",
    "            'B3',\n",
    "            'B6/B9',\n",
    "            'B38',\n",
    "            'B4/B5',\n",
    "        ]\n",
    "        for unit in units:\n",
    "            df[unit+' spike train'] = None\n",
    "            df[unit+' firing rate (Hz)'] = None\n",
    "            df[unit+' firing rate, normalized time interpolation (Hz)'] = None\n",
    "            df[unit+' inter-spike intervals (s)'] = None\n",
    "            df[unit+' all bursts (s)'] = None\n",
    "\n",
    "            # while we're at it, initialize some other things that might otherwise never be given values\n",
    "            df[unit+' first burst start (s)'] = np.nan\n",
    "            df[unit+' first burst end (s)'] = np.nan\n",
    "            df[unit+' first burst duration (s)'] = 0\n",
    "            df[unit+' first burst spike count'] = 0\n",
    "            df[unit+' first burst mean frequency (Hz)'] = np.nan\n",
    "            df[unit+' last burst start (s)'] = np.nan\n",
    "            df[unit+' last burst end (s)'] = np.nan\n",
    "            df[unit+' last burst duration (s)'] = 0\n",
    "            df[unit+' last burst spike count'] = 0\n",
    "            df[unit+' last burst mean frequency (Hz)'] = np.nan\n",
    "\n",
    "\n",
    "\n",
    "        # get smoothed force for entire time window\n",
    "        channel = 'Force'\n",
    "        sig = get_sig(blk, channel)\n",
    "        if lazy:\n",
    "            sig = sig.time_slice(None, None)\n",
    "        sig = elephant.signal_processing.butter(sig, lowpass_freq = 5*pq.Hz)\n",
    "        sig = sig.time_slice(time_window[0]*pq.s, time_window[1]*pq.s)\n",
    "        sig = sig.rescale('mN')\n",
    "        force_smoothed_sig = sig\n",
    "\n",
    "\n",
    "\n",
    "        df['End to next start (s)'] = np.nan\n",
    "        df['Start to next start (s)'] = np.nan\n",
    "        previous_i = None\n",
    "\n",
    "        # iterate over all swallows\n",
    "        for j, i in enumerate(df.index):\n",
    "\n",
    "            behavior_start = df.loc[i, 'Start (s)']*pq.s\n",
    "            behavior_end = df.loc[i, 'End (s)']*pq.s\n",
    "\n",
    "            # calculate interbehavior intervals assuming all behaviors are from a single contiguous sequence\n",
    "            if previous_i is not None:\n",
    "                df.loc[previous_i, 'End to next start (s)']   = df.loc[i, 'Start (s)'] - df.loc[previous_i, 'End (s)']\n",
    "                df.loc[previous_i, 'Start to next start (s)'] = df.loc[i, 'Start (s)'] - df.loc[previous_i, 'Start (s)']\n",
    "            previous_i = i\n",
    "\n",
    "\n",
    "\n",
    "            ###\n",
    "            ### FORCE SEGMENTATION\n",
    "            ###\n",
    "\n",
    "            force_shoulder_end  = df.loc[i, 'Force shoulder end start (s)']*pq.s  # start of \"Force shoulder end\" epoch\n",
    "            force_rise_start    = df.loc[i, 'Force rise start start (s)']*pq.s    # start of \"Force rise start\" epoch\n",
    "            force_plateau_start = df.loc[i, 'Force plateau start start (s)']*pq.s # start of \"Force plateau start\" epoch\n",
    "            force_plateau_end   = df.loc[i, 'Force plateau end start (s)']*pq.s   # start of \"Force plateau end\" epoch\n",
    "            force_drop_end      = df.loc[i, 'Force drop end start (s)']*pq.s      # start of \"Force drop end\" epoch\n",
    "\n",
    "            # force rise start, plateau start and end, and drop end are required\n",
    "            force_is_segmented = np.all(np.isfinite(np.array([\n",
    "                force_rise_start, force_plateau_start, force_plateau_end, force_drop_end])))\n",
    "\n",
    "            if force_is_segmented:\n",
    "                # get some times for the previous and next swallow\n",
    "                epochs_force_shoulder_end  = next((ep for ep in blk.segments[0].epochs if ep.name == 'Force shoulder end'), None)\n",
    "                epochs_force_rise_start    = next((ep for ep in blk.segments[0].epochs if ep.name == 'Force rise start'), None)\n",
    "                epochs_force_plateau_start = next((ep for ep in blk.segments[0].epochs if ep.name == 'Force plateau start'), None)\n",
    "                epochs_force_plateau_end   = next((ep for ep in blk.segments[0].epochs if ep.name == 'Force plateau end'), None)\n",
    "                epochs_force_drop_end      = next((ep for ep in blk.segments[0].epochs if ep.name == 'Force drop end'), None)\n",
    "                assert epochs_force_shoulder_end  is not None, 'failed to find \"Force shoulder end\" epochs'\n",
    "                assert epochs_force_rise_start    is not None, 'failed to find \"Force rise start\" epochs'\n",
    "                assert epochs_force_plateau_start is not None, 'failed to find \"Force plateau start\" epochs'\n",
    "                assert epochs_force_plateau_end   is not None, 'failed to find \"Force plateau end\" epochs'\n",
    "                assert epochs_force_drop_end      is not None, 'failed to find \"Force drop end\" epochs'\n",
    "\n",
    "                try:\n",
    "                    prev_force_plateau_start = df.loc[i, 'Previous force plateau start (s)'] = epochs_force_plateau_start.time_slice(None, force_rise_start)[-1]\n",
    "                    assert force_rise_start-prev_force_plateau_start < 16*pq.s, f'for swallow {i}, previous force plateau start is too far away'\n",
    "                except IndexError:\n",
    "                    prev_force_plateau_start = df.loc[i, 'Previous force plateau start (s)'] = np.nan\n",
    "\n",
    "                try:\n",
    "                    prev_force_plateau_end = df.loc[i, 'Previous force plateau end (s)'] = epochs_force_plateau_end.time_slice(None, force_rise_start)[-1]\n",
    "                    assert force_rise_start-prev_force_plateau_end < 12*pq.s, f'for swallow {i}, previous force plateau end is too far away'\n",
    "                except IndexError:\n",
    "                    prev_force_plateau_end = df.loc[i, 'Previous force plateau end (s)'] = np.nan\n",
    "\n",
    "                try:\n",
    "                    prev_force_drop_end = df.loc[i, 'Previous force drop end (s)'] = epochs_force_drop_end.time_slice(None, force_rise_start)[-1]\n",
    "                    assert force_rise_start-prev_force_drop_end < 12*pq.s, f'for swallow {i}, previous force drop end is too far away'\n",
    "                except IndexError:\n",
    "                    prev_force_drop_end = df.loc[i, 'Previous force drop end (s)'] = np.nan\n",
    "\n",
    "                try:\n",
    "                    next_force_rise_start = df.loc[i, 'Next force rise start (s)'] = epochs_force_rise_start.time_slice(force_drop_end, None)[0]\n",
    "                    assert next_force_rise_start-force_drop_end < 12*pq.s, f'for swallow {i}, next force rise start is too far away'\n",
    "                except IndexError:\n",
    "                    next_force_rise_start = df.loc[i, 'Next force rise start (s)'] = np.nan\n",
    "\n",
    "                try:\n",
    "                    next_force_shoulder_end = df.loc[i, 'Next force shoulder end (s)'] = epochs_force_shoulder_end.time_slice(force_drop_end, None)[0]\n",
    "                    if next_force_shoulder_end > next_force_rise_start:\n",
    "                        # next swallow did not have a shoulder and we instead grabbed a later shoulder\n",
    "                        next_force_shoulder_end = df.loc[i, 'Next force shoulder end (s)'] = np.nan\n",
    "                except IndexError:\n",
    "                    next_force_shoulder_end = df.loc[i, 'Next force shoulder end (s)'] = np.nan\n",
    "\n",
    "                # get the list of fixed times for normalization\n",
    "                normalization_fixed_times = df.at[i, 'Normalization fixed times (s)'] = np.array([\n",
    "                    prev_force_plateau_start,\n",
    "                    prev_force_plateau_end,\n",
    "                    prev_force_drop_end,\n",
    "                    force_shoulder_end,\n",
    "                    force_rise_start,\n",
    "                    force_plateau_start,\n",
    "                    force_plateau_end,\n",
    "                    force_drop_end,\n",
    "                    next_force_shoulder_end,\n",
    "                    next_force_rise_start,\n",
    "                ])*pq.s # 'at', not 'loc', is important for inserting list into cell\n",
    "\n",
    "            else: # force is not segmented\n",
    "                normalization_fixed_times = df.at[i, 'Normalization fixed times (s)'] = np.array([\n",
    "                    np.nan,\n",
    "                    np.nan,\n",
    "                    np.nan,\n",
    "                    np.nan,\n",
    "                    np.nan,\n",
    "                    np.nan,\n",
    "                    np.nan,\n",
    "                    np.nan,\n",
    "                    np.nan,\n",
    "                    np.nan,\n",
    "                ])*pq.s # 'at', not 'loc', is important for inserting list into cell\n",
    "\n",
    "\n",
    "\n",
    "            ###\n",
    "            ### FORCE QUANTIFICATION\n",
    "            ###\n",
    "\n",
    "            if force_is_segmented:\n",
    "\n",
    "                # get smoothed force for whole behavior for remaining force calculations\n",
    "                sig = force_smoothed_sig\n",
    "                if np.isfinite(force_shoulder_end):\n",
    "                    sig = sig.time_slice(force_shoulder_end - 0.01*pq.s, force_drop_end + 0.01*pq.s)\n",
    "                else:\n",
    "                    sig = sig.time_slice(force_rise_start - 1*pq.s, force_drop_end + 0.01*pq.s)\n",
    "                sig = sig.rescale('mN')\n",
    "\n",
    "                # find force peak, baseline, and the increase\n",
    "                force_min_time = df.loc[i, 'Force minimum time (s)'] = elephant.spike_train_generation.peak_detection(sig, 999*pq.mN, sign='below')[0]\n",
    "                force_min = df.loc[i, 'Force minimum (mN)'] = sig[sig.time_index(force_min_time)][0]\n",
    "                force_peak_time = df.loc[i, 'Force peak time (s)'] = elephant.spike_train_generation.peak_detection(sig, 0*pq.mN)[0]\n",
    "                force_peak = df.loc[i, 'Force peak (mN)'] = sig[sig.time_index(force_peak_time)][0]\n",
    "                force_baseline = df.loc[i, 'Force baseline (mN)'] = sig[sig.time_index(force_rise_start)][0]\n",
    "                force_increase = df.loc[i, 'Force increase (mN)'] = force_peak-force_baseline\n",
    "\n",
    "                # find force plateau, drop, and shoulder values\n",
    "                force_plateau_start_value = df.loc[i, 'Force plateau start value (mN)'] = sig[sig.time_index(force_plateau_start)][0]\n",
    "                force_plateau_end_value = df.loc[i, 'Force plateau end value (mN)'] = sig[sig.time_index(force_plateau_end)][0]\n",
    "                force_drop_end_value = df.loc[i, 'Force drop end value (mN)'] = sig[sig.time_index(force_drop_end)][0]\n",
    "                if np.isfinite(force_shoulder_end):\n",
    "                    force_shoulder_end_value = df.loc[i, 'Force shoulder end value (mN)'] = sig[sig.time_index(force_shoulder_end)][0]\n",
    "                else:\n",
    "                    force_shoulder_end_value = np.nan\n",
    "\n",
    "                # find force rise and plateau durations\n",
    "                force_rise_duration = df.loc[i, 'Force rise duration (s)'] = force_plateau_start - force_rise_start\n",
    "                force_plateau_duration = df.loc[i, 'Force plateau duration (s)'] = force_plateau_end - force_plateau_start\n",
    "                force_rise_plateau_duration = df.loc[i, 'Force rise and plateau duration (s)'] = force_plateau_end - force_rise_start\n",
    "\n",
    "                # find average slope during rising phase\n",
    "                force_rise_increase = df.loc[i, 'Force rise increase (mN)'] = force_plateau_start_value - force_baseline\n",
    "                force_slope = df.loc[i, 'Force slope (mN/s)'] = (force_rise_increase/force_rise_duration).rescale('mN/s')\n",
    "\n",
    "\n",
    "\n",
    "                ###\n",
    "                ### FORCE NORMALIZATION\n",
    "                ###\n",
    "\n",
    "                channel = 'Force'\n",
    "                sig = get_sig(blk, channel)\n",
    "                sig = sig.time_slice(prev_force_plateau_start+0.001*pq.s, next_force_rise_start-0.001*pq.s)\n",
    "                sig = sig.rescale(channel_units[channel_names.index(channel)])\n",
    "\n",
    "                force_interp = df.at[i, 'Force, normalized time interpolation (mN)'] = \\\n",
    "                    resample_sig_in_normalized_time(normalization_fixed_times, sig) # 'at', not 'loc', is important for inserting list into cell\n",
    "\n",
    "\n",
    "\n",
    "            ###\n",
    "            ### FIND SPIKE TRAINS\n",
    "            ###\n",
    "\n",
    "            if lazy:\n",
    "                if metadata['amplitude_discriminators'] is not None:\n",
    "                    for discriminator in metadata['amplitude_discriminators']:\n",
    "                        sig = get_sig(blk, discriminator['channel'])\n",
    "                        if sig is not None:\n",
    "                            sig = sig.time_slice(behavior_start - 5*pq.s, behavior_end + 5*pq.s)\n",
    "                            st = _detect_spikes(sig, discriminator, blk.segments[0].epochs)\n",
    "                            st_epoch_start = df.loc[i, discriminator['epoch']+' start (s)']*pq.s\n",
    "                            st_epoch_end = df.loc[i, discriminator['epoch']+' end (s)']*pq.s\n",
    "                            st = st.time_slice(st_epoch_start, st_epoch_end)\n",
    "                            df.at[i, st.name+' spike train'] = st # 'at', not 'loc', is important for inserting list into cell\n",
    "            else:\n",
    "                for spiketrain in blk.segments[0].spiketrains:\n",
    "                    discriminator = next((d for d in metadata['amplitude_discriminators'] if d['name'] == spiketrain.name), None)\n",
    "                    if discriminator is None:\n",
    "                        raise Exception(f'For data set \"{data_set_name}\", discriminator \"{spiketrain.name}\" could not be found')\n",
    "                    st_epoch_start = df.loc[i, discriminator['epoch']+' start (s)']*pq.s\n",
    "                    st_epoch_end = df.loc[i, discriminator['epoch']+' end (s)']*pq.s\n",
    "                    if np.isfinite(st_epoch_start) and np.isfinite(st_epoch_end):\n",
    "                        st = spiketrain.time_slice(st_epoch_start, st_epoch_end)\n",
    "                    else:\n",
    "                        # this unit's discriminator epoch was not located for this swallow\n",
    "                        st = None\n",
    "                    df.at[i, spiketrain.name+' spike train'] = st # 'at', not 'loc', is important for inserting list into cell\n",
    "\n",
    "\n",
    "\n",
    "            ###\n",
    "            ### QUANTIFY SPIKE TRAINS AND BURSTS\n",
    "            ###\n",
    "\n",
    "            for k, unit in enumerate(units):\n",
    "                st = df.loc[i, unit+' spike train']\n",
    "                if st is not None:\n",
    "                    df.loc[i, unit+' spike count'] = st.size\n",
    "\n",
    "                    # get the neural channel\n",
    "                    channel = st.annotations['channels'][0]\n",
    "                    sig = get_sig(blk, channel)\n",
    "\n",
    "                    # create a continuous smoothed firing rate representation\n",
    "                    # by convolving the spike train with a kernel\n",
    "                    smoothing_kernel = elephant.kernels.GaussianKernel(0.2*pq.s) # 200 ms standard deviation\n",
    "#                     smoothing_kernel = elephant.kernels.RectangularKernel(0.2*pq.s / (2*np.sqrt(3))) # 200 ms width, 2*sqrt(3) undoes elephant's scaling\n",
    "                    if force_is_segmented:\n",
    "                        # choice of t_start and t_stop here ensures firing rates are recorded as zero far from the burst\n",
    "                        t_start = prev_force_plateau_start+0.001*pq.s\n",
    "                        t_stop = next_force_rise_start-0.001*pq.s\n",
    "                    else:\n",
    "                        # force segmentation not available\n",
    "                        t_start = behavior_start-5*pq.s\n",
    "                        t_stop = behavior_end+5*pq.s\n",
    "                    firing_rate = df.at[i, unit+' firing rate (Hz)'] = elephant.statistics.instantaneous_rate(\n",
    "                        spiketrain=st,\n",
    "                        t_start=t_start,\n",
    "                        t_stop=t_stop,\n",
    "                        sampling_period=sig.sampling_period,\n",
    "                        kernel=smoothing_kernel,\n",
    "                    ) # 'at', not 'loc', is important for inserting list into cell\n",
    "\n",
    "                    # normalization\n",
    "                    if force_is_segmented:\n",
    "                        firing_rate_interp = df.at[i, unit+' firing rate, normalized time interpolation (Hz)'] = \\\n",
    "                            resample_sig_in_normalized_time(normalization_fixed_times, firing_rate) # 'at', not 'loc', is important for inserting list into cell\n",
    "\n",
    "                    if st.size > 0:\n",
    "\n",
    "                        # get the signal for the behavior with 10 seconds cushion before and after (for better baseline estimation)\n",
    "                        sig = sig.time_slice(behavior_start - 10*pq.s, behavior_end + 10*pq.s)\n",
    "                        sig = sig.rescale(channel_units[channel_names.index(channel)])\n",
    "\n",
    "                        # find every sequence of spikes that qualifies as a burst\n",
    "                        bursts = df.at[i, unit+' all bursts (s)'] = find_bursts(st, burst_thresholds[unit]) # 'at', not 'loc', is important for inserting list into cell\n",
    "\n",
    "                        first_burst_start = np.nan\n",
    "                        first_burst_end = np.nan\n",
    "                        first_burst_spike_count = 0\n",
    "                        first_burst_mean_freq = 0*pq.Hz\n",
    "                        last_burst_start = np.nan\n",
    "                        last_burst_end = np.nan\n",
    "                        last_burst_spike_count = 0\n",
    "                        last_burst_mean_freq = 0*pq.Hz\n",
    "                        if len(bursts) > 0:\n",
    "\n",
    "                            for burst in bursts:\n",
    "                                if is_good_burst(burst):\n",
    "                                    first_burst_start, first_burst_end = burst['Start (s)'], burst['End (s)']\n",
    "                                    first_burst_duration = first_burst_end-first_burst_start\n",
    "                                    df.loc[i, unit+' first burst start (s)'] = first_burst_start.rescale('s')\n",
    "                                    df.loc[i, unit+' first burst end (s)'] = first_burst_end.rescale('s')\n",
    "                                    first_burst_duration = df.loc[i, unit+' first burst duration (s)'] = first_burst_duration.rescale('s')\n",
    "                                    first_burst_spike_count = df.loc[i, unit+' first burst spike count'] = st.time_slice(first_burst_start, first_burst_end).size\n",
    "                                    first_burst_mean_freq = df.loc[i, unit+' first burst mean frequency (Hz)'] = ((first_burst_spike_count-1)/first_burst_duration).rescale('Hz')\n",
    "\n",
    "                                    # find burst RAUC and mean voltage\n",
    "                                    first_burst_rauc = df.loc[i, unit+' first burst RAUC (Î¼VÂ·s)'] = elephant.signal_processing.rauc(sig, baseline='mean', t_start=first_burst_start, t_stop=first_burst_end).rescale('uV*s')\n",
    "                                    first_burst_mean_rect_voltage = df.loc[i, unit+' first burst mean rectified voltage (Î¼V)'] = first_burst_rauc/first_burst_duration\n",
    "                                    \n",
    "                                    # normalization\n",
    "                                    if force_is_segmented:\n",
    "                                        df.loc[i, unit+' first burst start (normalized)'] = normalize_time(normalization_fixed_times.magnitude, float(first_burst_start.rescale('s')))\n",
    "\n",
    "                                    break # quit after finding first good burst\n",
    "\n",
    "                            for burst in reversed(bursts):\n",
    "                                if is_good_burst(burst):\n",
    "                                    last_burst_start, last_burst_end = burst['Start (s)'], burst['End (s)']\n",
    "                                    last_burst_duration = last_burst_end-last_burst_start\n",
    "                                    df.loc[i, unit+' last burst start (s)'] = last_burst_start.rescale('s')\n",
    "                                    df.loc[i, unit+' last burst end (s)'] = last_burst_end.rescale('s')\n",
    "                                    last_burst_duration = df.loc[i, unit+' last burst duration (s)'] = last_burst_duration.rescale('s')\n",
    "                                    last_burst_spike_count = df.loc[i, unit+' last burst spike count'] = st.time_slice(last_burst_start, last_burst_end).size\n",
    "                                    last_burst_mean_freq = df.loc[i, unit+' last burst mean frequency (Hz)'] = ((last_burst_spike_count-1)/last_burst_duration).rescale('Hz')\n",
    "\n",
    "                                    # find burst RAUC and mean voltage\n",
    "                                    last_burst_rauc = df.loc[i, unit+' last burst RAUC (Î¼VÂ·s)'] = elephant.signal_processing.rauc(sig, baseline='mean', t_start=last_burst_start, t_stop=last_burst_end).rescale('uV*s')\n",
    "                                    last_burst_mean_rect_voltage = df.loc[i, unit+' last burst mean rectified voltage (Î¼V)'] = last_burst_rauc/last_burst_duration\n",
    "\n",
    "                                    # normalization\n",
    "                                    if force_is_segmented:\n",
    "                                        df.loc[i, unit+' last burst end (normalized)'] = normalize_time(normalization_fixed_times.magnitude, float(last_burst_end.rescale('s')))\n",
    "                                    \n",
    "                                    break # quit after finding first (actually, last) good burst\n",
    "\n",
    "\n",
    "\n",
    "#             ###\n",
    "#             ### TIMING DELAYS\n",
    "#             ###\n",
    "\n",
    "#             i2_burst_start      = df.loc[i, 'I2 spikes first burst start (s)']*pq.s\n",
    "#             i2_burst_end        = df.loc[i, 'I2 spikes last burst end (s)']*pq.s\n",
    "#             i2_burst_duration   = df.loc[i, 'I2 spikes all bursts duration (s)'] = i2_burst_end - i2_burst_start\n",
    "#             b8_burst_start      = df.loc[i, 'B8a/b first burst start (s)']*pq.s\n",
    "#             b8_burst_end        = df.loc[i, 'B8a/b last burst end (s)']*pq.s\n",
    "#             b8_burst_duration   = df.loc[i, 'B8a/b all bursts duration (s)'] = b8_burst_end - b8_burst_start\n",
    "#             b6b9_burst_start    = df.loc[i, 'B6/B9 first burst start (s)']*pq.s\n",
    "#             b6b9_burst_end      = df.loc[i, 'B6/B9 last burst end (s)']*pq.s\n",
    "#             b6b9_burst_duration = df.loc[i, 'B6/B9 all bursts duration (s)'] = b6b9_burst_end - b6b9_burst_start\n",
    "#             b3_burst_start      = df.loc[i, 'B3 first burst start (s)']*pq.s\n",
    "#             b3_burst_end        = df.loc[i, 'B3 last burst end (s)']*pq.s\n",
    "#             b3_burst_duration   = df.loc[i, 'B3 all bursts duration (s)'] = b3_burst_end - b3_burst_start\n",
    "#             b38_burst_start     = df.loc[i, 'B38 first burst start (s)']*pq.s\n",
    "#             b38_burst_end       = df.loc[i, 'B38 last burst end (s)']*pq.s\n",
    "#             b38_burst_duration  = df.loc[i, 'B38 all bursts duration (s)'] = b38_burst_end - b38_burst_start\n",
    "\n",
    "#             df.loc[i, 'Next I2 spikes first burst start (s)'] = np.nan # will be set on next iteration\n",
    "#             df.loc[i, 'Next I2 spikes last burst end (s)'] = np.nan # will be set on next iteration\n",
    "#             df.loc[i, 'Next I2 spikes all bursts duration (s)'] = np.nan # will be set on next iteration\n",
    "#             if j != 0:\n",
    "#                 df.loc[df.index[j-1], 'Next I2 spikes first burst start (s)'] = i2_burst_start\n",
    "#                 df.loc[df.index[j-1], 'Next I2 spikes last burst end (s)'] = i2_burst_end\n",
    "#                 df.loc[df.index[j-1], 'Next I2 spikes all bursts duration (s)'] = i2_burst_end - i2_burst_start\n",
    "\n",
    "#             # consider B3/B6/B9 bursting if either B3 or B6/B9 is bursting\n",
    "#             b3b6b9_burst_start    = df.loc[i, 'B3/B6/B9 burst start (s)']    = finite_min(b6b9_burst_start, b3_burst_start)\n",
    "#             b3b6b9_burst_end      = df.loc[i, 'B3/B6/B9 burst end (s)']      = finite_max(b6b9_burst_end,   b3_burst_end)\n",
    "#             b3b6b9_burst_duration = df.loc[i, 'B3/B6/B9 burst duration (s)'] = b3b6b9_burst_end - b3b6b9_burst_start\n",
    "\n",
    "#             # consider bursting only if B8a/b and B3/B6/B9 are both bursting\n",
    "#             b8_or_b3b6b9_burst_end = df.loc[i, 'B8a/b and B3/B6/B9 conjunction end (s)'] = \\\n",
    "#                                                finite_min(b8_burst_end, b3b6b9_burst_end)\n",
    "\n",
    "#             # delays from neural to force\n",
    "#             i2_force_rise_start_delay        = df.loc[i, 'Delay from I2 end to force rise start (s)'] = \\\n",
    "#                                                          force_rise_start - i2_burst_end\n",
    "\n",
    "#             b8_force_rise_start_delay        = df.loc[i, 'Delay from B8a/b start to force rise start (s)'] = \\\n",
    "#                                                          force_rise_start - b8_burst_start\n",
    "#             b8_force_plateau_start_delay     = df.loc[i, 'Delay from B8a/b start to force plateau start (s)'] = \\\n",
    "#                                                          force_plateau_start - b8_burst_start\n",
    "#             b8_force_plateau_end_delay       = df.loc[i, 'Delay from B8a/b end to force plateau end (s)'] = \\\n",
    "#                                                          force_plateau_end - b8_burst_end\n",
    "\n",
    "#             b6b9_force_rise_start_delay      = df.loc[i, 'Delay from B6/B9 start to force rise start (s)'] = \\\n",
    "#                                                          force_rise_start - b6b9_burst_start\n",
    "#             b6b9_force_plateau_start_delay   = df.loc[i, 'Delay from B6/B9 start to force plateau start (s)'] = \\\n",
    "#                                                          force_plateau_start - b6b9_burst_start\n",
    "#             b6b9_force_plateau_end_delay     = df.loc[i, 'Delay from B6/B9 end to force plateau end (s)'] = \\\n",
    "#                                                          force_plateau_end - b6b9_burst_end\n",
    "\n",
    "#             b3b6b9_force_rise_start_delay    = df.loc[i, 'Delay from B3/B6/B9 start to force rise start (s)'] = \\\n",
    "#                                                          force_rise_start - b3b6b9_burst_start\n",
    "#             b3b6b9_force_plateau_start_delay = df.loc[i, 'Delay from B3/B6/B9 start to force plateau start (s)'] = \\\n",
    "#                                                          force_plateau_start - b3b6b9_burst_start\n",
    "#             b3b6b9_force_plateau_end_delay   = df.loc[i, 'Delay from B3/B6/B9 end to force plateau end (s)'] = \\\n",
    "#                                                          force_plateau_end - b3b6b9_burst_end\n",
    "\n",
    "#             b3_force_plateau_start_delay     = df.loc[i, 'Delay from B3 start to force plateau start (s)'] = \\\n",
    "#                                                          force_plateau_start - b3_burst_start\n",
    "#             b3_force_plateau_end_delay       = df.loc[i, 'Delay from B3 end to force plateau end (s)'] = \\\n",
    "#                                                          force_plateau_end - b3_burst_end\n",
    "#             b8_or_b3b6b9_force_plateau_end_delay = \\\n",
    "#                                                df.loc[i, 'Delay from either B8a/b or B3/B6/B9 end to force plateau end (s)'] = \\\n",
    "#                                                          force_plateau_end - b8_or_b3b6b9_burst_end\n",
    "\n",
    "#             b38_force_shoulder_end_delay     = df.loc[i, 'Delay from B38 end to force shoulder end (s)'] = \\\n",
    "#                                                          force_shoulder_end - b38_burst_end\n",
    "\n",
    "\n",
    "\n",
    "#             ###\n",
    "#             ### B8 ACTIVITY BEFORE B3/B6/B9\n",
    "#             ###\n",
    "\n",
    "#             st = df.loc[i, 'B8a/b spike train']\n",
    "#             if st is not None:\n",
    "#                 b8_preb3b6b9_burst_duration    = df.loc[i, 'B8a/b pre-B3/B6/B9 burst duration (s)'] = \\\n",
    "#                                                            b3b6b9_burst_start - b8_burst_start\n",
    "#                 b8_preb3b6b9_burst_spike_count = df.loc[i, 'B8a/b pre-B3/B6/B9 burst spike count'] = \\\n",
    "#                                                            st.time_slice(b8_burst_start, b3b6b9_burst_start).size\n",
    "#                 b8_preb3b6b9_burst_mean_freq   = df.loc[i, 'B8a/b pre-B3/B6/B9 burst mean frequency (Hz)'] = \\\n",
    "#                                                            ((b8_preb3b6b9_burst_spike_count-1)/b8_preb3b6b9_burst_duration).rescale('Hz')\n",
    "\n",
    "#                 # get the neural channel\n",
    "#                 channel = st.annotations['channels'][0]\n",
    "#                 sig = get_sig(blk, channel)\n",
    "\n",
    "#                 # get the signal for the behavior with 5 seconds cushion before and after (for better baseline estimation)\n",
    "#                 sig = sig.time_slice(behavior_start - 5*pq.s, behavior_end + 5*pq.s)\n",
    "#                 sig = sig.rescale('uV')\n",
    "\n",
    "#                 # for B8a/b before B3/B6/B9 start...\n",
    "#                 if np.isfinite(b8_burst_start) and np.isfinite(b3b6b9_burst_start):\n",
    "#                     # find RAUC and mean voltage\n",
    "#                     b8_preb3b6b9_rauc = df.loc[i, 'B8a/b pre-B3/B6/B9 burst RAUC (Î¼VÂ·s)'] = elephant.signal_processing.rauc(sig, baseline='mean', t_start=b8_burst_start, t_stop=b3b6b9_burst_start).rescale('uV*s')\n",
    "#                     b8_preb3b6b9_mean_rect_voltage = df.loc[i, 'B8a/b pre-B3/B6/B9 burst mean rectified voltage (Î¼V)'] = b8_preb3b6b9_rauc/b8_preb3b6b9_burst_duration\n",
    "\n",
    "#                     # get the peak smoothed frequency\n",
    "#                     firing_rate = elephant.statistics.instantaneous_rate(\n",
    "#                         spiketrain=st,\n",
    "#                         t_start=st.t_start,\n",
    "#                         sampling_period=sig.sampling_period,\n",
    "#                         kernel=smoothing_kernel,\n",
    "#                     )\n",
    "#                     b8_preb3b6b9_burst_peak_smoothed_freq = df.loc[i, 'B8a/b pre-B3/B6/B9 burst peak smoothed frequency (Hz)'] = \\\n",
    "#                                                                       firing_rate.time_slice(b8_burst_start, b3b6b9_burst_start).max().rescale('Hz')\n",
    "\n",
    "\n",
    "#                     if force_is_segmented:\n",
    "#                         # get force during rise and plateau\n",
    "#                         sig = get_sig(blk, 'Force')\n",
    "#                         sig = sig.time_slice(force_rise_start, force_plateau_end)\n",
    "#                         sig = sig.rescale('mN')\n",
    "\n",
    "#                         # get force at end of B8-only burst, offset by delay\n",
    "#                         force_b8_only_rise_end = df.loc[i, 'Force delayed B8-only rise end (s)'] = force_rise_start + b8_preb3b6b9_burst_duration\n",
    "#                         force_b8_only_rise_height = df.loc[i, 'Force at delayed B8-only rise end (mN)'] = sig[sig.time_index(force_b8_only_rise_end)][0]\n",
    "\n",
    "#                         # find average slope during initial rising phase (before B3/B6/B9 begin, offset by delay)\n",
    "#                         force_initial_increase = df.loc[i, 'Force initial increase (mN)'] = (force_b8_only_rise_height-force_baseline).rescale('mN')\n",
    "#                         force_initial_slope = df.loc[i, 'Force initial slope (mN/s)'] = (force_initial_increase/b8_preb3b6b9_burst_duration).rescale('mN/s')\n",
    "\n",
    "\n",
    "\n",
    "#         # perform the following after having gone through all behaviors once\n",
    "#         for j, i in enumerate(df.index):\n",
    "\n",
    "#             ###\n",
    "#             ### NORMALIZED TIMES\n",
    "#             ###\n",
    "\n",
    "#             normalization_fixed_times = df.loc[i, 'Normalization fixed times (s)']\n",
    "#             normalization_fixed_times = normalization_fixed_times.magnitude\n",
    "#             force_rise_start, force_plateau_start, force_plateau_end, force_drop_end = normalization_fixed_times[[4, 5, 6, 7]]\n",
    "#             force_is_segmented = np.all(np.isfinite(np.array([force_rise_start, force_plateau_start, force_plateau_end, force_drop_end])))\n",
    "\n",
    "#             if force_is_segmented:\n",
    "\n",
    "#                 i2_burst_start   = df.loc[i, 'I2 spikes first burst start (s)']\n",
    "#                 i2_burst_end     = df.loc[i, 'I2 spikes last burst end (s)']\n",
    "#                 b8_burst_start   = df.loc[i, 'B8a/b first burst start (s)']\n",
    "#                 b8_burst_end     = df.loc[i, 'B8a/b last burst end (s)']\n",
    "#                 b6b9_burst_start = df.loc[i, 'B6/B9 first burst start (s)']\n",
    "#                 b6b9_burst_end   = df.loc[i, 'B6/B9 last burst end (s)']\n",
    "#                 b3_burst_start   = df.loc[i, 'B3 first burst start (s)']\n",
    "#                 b3_burst_end     = df.loc[i, 'B3 last burst end (s)']\n",
    "#                 b38_burst_start  = df.loc[i, 'B38 first burst start (s)']\n",
    "#                 b38_burst_end    = df.loc[i, 'B38 last burst end (s)']\n",
    "#                 b4b5_burst_start = df.loc[i, 'B4/B5 first burst start (s)']\n",
    "#                 b4b5_burst_end   = df.loc[i, 'B4/B5 last burst end (s)']\n",
    "# #                 next_i2_burst_start = df.loc[i, 'Next I2 spikes first burst start (s)']\n",
    "# #                 next_i2_burst_end   = df.loc[i, 'Next I2 spikes last burst end (s)']\n",
    "\n",
    "#                 i2_burst_start_normalized      = df.loc[i, 'I2 first burst start (normalized)']      = normalize_time(normalization_fixed_times,\n",
    "#                                                            i2_burst_start)\n",
    "#                 i2_burst_end_normalized        = df.loc[i, 'I2 last burst end (normalized)']         = normalize_time(normalization_fixed_times,\n",
    "#                                                            i2_burst_end)\n",
    "\n",
    "#                 b8_burst_start_normalized      = df.loc[i, 'B8a/b first burst start (normalized)']   = normalize_time(normalization_fixed_times,\n",
    "#                                                            b8_burst_start)\n",
    "#                 b8_burst_end_normalized        = df.loc[i, 'B8a/b last burst end (normalized)']      = normalize_time(normalization_fixed_times,\n",
    "#                                                            b8_burst_end)\n",
    "\n",
    "#                 b6b9_burst_start_normalized    = df.loc[i, 'B6/B9 first burst start (normalized)']   = normalize_time(normalization_fixed_times,\n",
    "#                                                            b6b9_burst_start)\n",
    "#                 b6b9_burst_end_normalized      = df.loc[i, 'B6/B9 last burst end (normalized)']      = normalize_time(normalization_fixed_times,\n",
    "#                                                            b6b9_burst_end)\n",
    "\n",
    "#                 b3_burst_start_normalized      = df.loc[i, 'B3 first burst start (normalized)']      = normalize_time(normalization_fixed_times,\n",
    "#                                                            b3_burst_start)\n",
    "#                 b3_burst_end_normalized        = df.loc[i, 'B3 last burst end (normalized)']         = normalize_time(normalization_fixed_times,\n",
    "#                                                            b3_burst_end)\n",
    "\n",
    "#                 b38_burst_start_normalized     = df.loc[i, 'B38 first burst start (normalized)']     = normalize_time(normalization_fixed_times,\n",
    "#                                                            b38_burst_start)\n",
    "#                 b38_burst_end_normalized       = df.loc[i, 'B38 last burst end (normalized)']        = normalize_time(normalization_fixed_times,\n",
    "#                                                            b38_burst_end)\n",
    "\n",
    "#                 b4b5_burst_start_normalized    = df.loc[i, 'B4/B5 first burst start (normalized)']   = normalize_time(normalization_fixed_times,\n",
    "#                                                            b4b5_burst_start)\n",
    "#                 b4b5_burst_end_normalized      = df.loc[i, 'B4/B5 last burst end (normalized)']      = normalize_time(normalization_fixed_times,\n",
    "#                                                            b4b5_burst_end)\n",
    "\n",
    "# #                 next_i2_burst_start_normalized = df.loc[i, 'Next I2 first burst start (normalized)'] = normalize_time(normalization_fixed_times,\n",
    "# #                                                            next_i2_burst_start)\n",
    "# #                 next_i2_burst_end_normalized   = df.loc[i, 'Next I2 last burst end (normalized)']    = normalize_time(normalization_fixed_times,\n",
    "# #                                                            next_i2_burst_end)\n",
    "\n",
    "\n",
    "\n",
    "        ###\n",
    "        ### FINISH\n",
    "        ###\n",
    "\n",
    "        # index the table on 4 variables so that this dataframe can later be merged with others\n",
    "        df['Animal'] = animal\n",
    "        df['Food'] = food\n",
    "        df['Bout_index'] = bout_index\n",
    "        df = df.reset_index().set_index(['Animal', 'Food', 'Bout_index', 'Behavior_index'])\n",
    "\n",
    "        df_list += [df]\n",
    "\n",
    "    df_all = pd.concat(df_list, sort=False).sort_index()\n",
    "\n",
    "    if exemplary_swallow in feeding_bouts:\n",
    "        # move exemplar to separate dataframe\n",
    "        df_exemplary_swallow = df_all.loc[exemplary_swallow].copy()\n",
    "        df_all = df_all.drop(exemplary_swallow)\n",
    "\n",
    "    if exemplary_bout in feeding_bouts:\n",
    "        # move exemplar to separate dataframe\n",
    "        df_exemplary_bout = df_all.loc[exemplary_bout].copy()\n",
    "        df_all = df_all.drop(exemplary_bout)\n",
    "\n",
    "    # save dataframes to files so that calculations can be skipped in the future\n",
    "    for var in pickled_vars:\n",
    "        filename = f'{var}.pickle'\n",
    "        with open(filename, 'wb') as f:\n",
    "            exec(f'pickle.dump({var}, f)')\n",
    "\n",
    "    end = datetime.datetime.now()\n",
    "    print('elapsed time:', end-start)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ðŸ¤ª Sanity Checks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "skip_sanity_checks = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if not skip_sanity_checks:\n",
    "    start = datetime.datetime.now()\n",
    "\n",
    "    # reconstruct the original df_all, before exemplary_swallow and\n",
    "    # exemplary_bout were removed\n",
    "    df_list2 = [df_all]\n",
    "    if exemplary_swallow in feeding_bouts:\n",
    "        df_exemplary_swallow2 = df_exemplary_swallow.copy()\n",
    "        df_exemplary_swallow2['Animal'] = exemplary_swallow[0]\n",
    "        df_exemplary_swallow2['Food'] = exemplary_swallow[1]\n",
    "        df_exemplary_swallow2['Bout_index'] = exemplary_swallow[2]\n",
    "        df_exemplary_swallow2 = df_exemplary_swallow2.reset_index().set_index(['Animal', 'Food', 'Bout_index', 'Behavior_index'])\n",
    "        df_list2 += [df_exemplary_swallow2]\n",
    "    if exemplary_bout in feeding_bouts:\n",
    "        df_exemplary_bout2 = df_exemplary_bout.copy()\n",
    "        df_exemplary_bout2['Animal'] = exemplary_bout[0]\n",
    "        df_exemplary_bout2['Food'] = exemplary_bout[1]\n",
    "        df_exemplary_bout2['Bout_index'] = exemplary_bout[2]\n",
    "        df_exemplary_bout2 = df_exemplary_bout2.reset_index().set_index(['Animal', 'Food', 'Bout_index', 'Behavior_index'])\n",
    "        df_list2 += [df_exemplary_bout2]\n",
    "    df_all2 = pd.concat(df_list2, sort=False).sort_index()\n",
    "\n",
    "    # use Neo RawIO lazy loading to load much faster and using less memory\n",
    "    # - with lazy=True, filtering parameters specified in metadata are ignored\n",
    "    #     - note: filters are replaced below and applied manually anyway\n",
    "    # - with lazy=True, loading via time_slice requires neo>=0.8.0\n",
    "    lazy = True\n",
    "\n",
    "    # load the metadata containing file paths\n",
    "    metadata = neurotic.MetadataSelector(file='../../data/metadata.yml')\n",
    "\n",
    "    last_data_set_name = None\n",
    "    for (animal, food, bout_index), (data_set_name, time_window) in feeding_bouts.items():\n",
    "\n",
    "        channel_names = channel_names_by_animal[animal]\n",
    "        epoch_types = epoch_types_by_food[food]\n",
    "        burst_thresholds = burst_thresholds_by_animal[animal]\n",
    "\n",
    "        df = df_all2.loc[animal, food, bout_index]\n",
    "\n",
    "\n",
    "\n",
    "        ###\n",
    "        ### LOAD DATASET\n",
    "        ###\n",
    "\n",
    "        metadata.select(data_set_name)\n",
    "\n",
    "        if data_set_name is last_data_set_name:\n",
    "            # skip reloading the data if it's already in memory\n",
    "            pass\n",
    "        else:\n",
    "\n",
    "            # ensure that the right filters are used\n",
    "            metadata['filters'] = sig_filters_by_animal[animal]\n",
    "\n",
    "            blk = neurotic.load_dataset(metadata, lazy=lazy)\n",
    "\n",
    "            if lazy:\n",
    "                # manually perform filters\n",
    "                blk = apply_filters(blk, metadata)\n",
    "\n",
    "        last_data_set_name = data_set_name\n",
    "\n",
    "\n",
    "\n",
    "        ###\n",
    "        ### START FIGURE\n",
    "        ###\n",
    "\n",
    "#             figsize = (9.5, 10) # dimensions for notebook\n",
    "#             figsize = (11, 8.5) # dimensions for printing\n",
    "        figsize = (16, 9) # dimensions for filling wide screens\n",
    "        fig, axes = plt.subplots(len(channel_names), 1, sharex=True, figsize=figsize)\n",
    "\n",
    "\n",
    "\n",
    "        ###\n",
    "        ### PLOT SIGNALS\n",
    "        ###\n",
    "\n",
    "        # plot all channels for entire time window\n",
    "        for i, channel in enumerate(channel_names):\n",
    "            plt.sca(axes[i])\n",
    "            sig = get_sig(blk, channel)\n",
    "            sig = sig.time_slice(time_window[0]*pq.s, time_window[1]*pq.s)\n",
    "            sig = sig.rescale(channel_units[i])\n",
    "            plt.plot(sig.times, sig.magnitude, c='0.8', lw=1, zorder=-1)\n",
    "\n",
    "            if i == 0:\n",
    "                plt.title(f'({animal}, {food}, {bout_index}): {data_set_name}')\n",
    "\n",
    "            plt.ylabel(sig.name + ' (' + sig.units.dimensionality.string + ')')\n",
    "            axes[i].yaxis.set_label_coords(-0.06, 0.5)\n",
    "\n",
    "            if i < len(channel_names)-1:\n",
    "                # remove right, top, and bottom plot borders, and remove x-axis\n",
    "                sns.despine(ax=plt.gca(), bottom=True)\n",
    "                plt.gca().xaxis.set_visible(False)\n",
    "            else:\n",
    "                # remove right and top plot borders, and set x-label\n",
    "                sns.despine(ax=plt.gca())\n",
    "                plt.xlabel('Time (s)')\n",
    "\n",
    "        # plot smoothed force for entire time window\n",
    "        channel = 'Force'\n",
    "        sig = get_sig(blk, channel)\n",
    "        if lazy:\n",
    "            sig = sig.time_slice(None, None)\n",
    "        sig = elephant.signal_processing.butter(sig, lowpass_freq = 5*pq.Hz)\n",
    "        sig = sig.time_slice(time_window[0]*pq.s, time_window[1]*pq.s)\n",
    "        sig = sig.rescale('mN')\n",
    "        plt.plot(sig.times, sig.magnitude, c='k', lw=1, zorder=0)\n",
    "        force_smoothed_sig = sig\n",
    "\n",
    "\n",
    "\n",
    "        # iterate over all swallows\n",
    "        for j, i in enumerate(df.index):\n",
    "\n",
    "            behavior_start = df.loc[i, 'Start (s)']*pq.s\n",
    "            behavior_end   = df.loc[i, 'End (s)']*pq.s\n",
    "            \n",
    "            ###\n",
    "            ### MOVEMENTS\n",
    "            ###\n",
    "            \n",
    "            # plot inward food movement\n",
    "            inward_movement_start = df.loc[i, 'Inward movement start (s)']*pq.s\n",
    "            inward_movement_end   = df.loc[i, 'Inward movement end (s)']*pq.s\n",
    "            if np.isfinite(inward_movement_start):\n",
    "                channel = 'Force'\n",
    "                ax = axes[channel_names.index(channel)]\n",
    "                ax.axvspan(\n",
    "                    inward_movement_start, inward_movement_end,\n",
    "                    0.99, 1,\n",
    "                    facecolor='k', edgecolor=None, lw=0)\n",
    "            \n",
    "            \n",
    "\n",
    "            ###\n",
    "            ### FORCE SEGMENTATION\n",
    "            ###\n",
    "\n",
    "            force_shoulder_end  = df.loc[i, 'Force shoulder end start (s)']*pq.s  # start of \"Force shoulder end\" epoch\n",
    "            force_rise_start    = df.loc[i, 'Force rise start start (s)']*pq.s    # start of \"Force rise start\" epoch\n",
    "            force_plateau_start = df.loc[i, 'Force plateau start start (s)']*pq.s # start of \"Force plateau start\" epoch\n",
    "            force_plateau_end   = df.loc[i, 'Force plateau end start (s)']*pq.s   # start of \"Force plateau end\" epoch\n",
    "            force_drop_end      = df.loc[i, 'Force drop end start (s)']*pq.s      # start of \"Force drop end\" epoch\n",
    "\n",
    "            # force rise start, plateau start and end, and drop end are required\n",
    "            force_is_segmented = np.all(np.isfinite(np.array([\n",
    "                force_rise_start, force_plateau_start, force_plateau_end, force_drop_end])))\n",
    "\n",
    "            normalization_fixed_times = df.at[i, 'Normalization fixed times (s)']\n",
    "\n",
    "            if force_is_segmented:\n",
    "\n",
    "                force_min_time = df.loc[i, 'Force minimum time (s)']\n",
    "                force_min = df.loc[i, 'Force minimum (mN)']\n",
    "                force_peak_time = df.loc[i, 'Force peak time (s)']\n",
    "                force_peak = df.loc[i, 'Force peak (mN)']\n",
    "                force_baseline = df.loc[i, 'Force baseline (mN)']\n",
    "\n",
    "                force_plateau_start_value = df.loc[i, 'Force plateau start value (mN)']\n",
    "                force_plateau_end_value = df.loc[i, 'Force plateau end value (mN)']\n",
    "                force_drop_end_value = df.loc[i, 'Force drop end value (mN)']\n",
    "                force_shoulder_end_value = df.loc[i, 'Force shoulder end value (mN)']\n",
    "\n",
    "                # get smoothed force for whole behavior for remaining force calculations\n",
    "                sig = force_smoothed_sig\n",
    "                if np.isfinite(force_shoulder_end):\n",
    "                    sig = sig.time_slice(force_shoulder_end - 0.01*pq.s, force_drop_end + 0.01*pq.s)\n",
    "                else:\n",
    "                    sig = sig.time_slice(force_rise_start - 1*pq.s, force_drop_end + 0.01*pq.s)\n",
    "                sig = sig.rescale('mN')\n",
    "\n",
    "                # plot force rise in color\n",
    "                plt.sca(axes[channel_names.index('Force')])\n",
    "                sig2 = sig.time_slice(force_rise_start, force_plateau_start)\n",
    "                plt.plot(sig2.times, sig2.magnitude, c=force_colors['rise'], lw=2, zorder=1)\n",
    "\n",
    "                # plot force plateau in color\n",
    "                sig2 = sig.time_slice(force_plateau_start, force_plateau_end)\n",
    "                plt.plot(sig2.times, sig2.magnitude, c=force_colors['plateau'], lw=2, zorder=1)\n",
    "\n",
    "                # plot force shoulder in color\n",
    "                if np.isfinite(force_shoulder_end):\n",
    "                    sig2 = sig.time_slice(force_drop_end, force_shoulder_end)\n",
    "                    plt.plot(sig2.times, sig2.magnitude, c=force_colors['shoulder'], lw=2, zorder=1)\n",
    "\n",
    "                # plot force peak, baseline, and plateau values\n",
    "                plt.plot([force_peak_time],     [force_peak],                marker=CARETDOWN,  markersize=5, color='k')\n",
    "#                 plt.plot([force_min_time],      [force_min],                 marker=CARETUP,    markersize=5, color='k')\n",
    "                plt.plot([force_rise_start],    [force_baseline],            marker=CARETUP,    markersize=5, color='k')\n",
    "                plt.plot([force_plateau_start], [force_plateau_start_value], marker=CARETRIGHT, markersize=5, color='k')\n",
    "                plt.plot([force_plateau_end],   [force_plateau_end_value],   marker=CARETLEFT,  markersize=5, color='k')\n",
    "\n",
    "                # plot segmentation boundaries across all subplots\n",
    "                for (t, y, c) in [\n",
    "                        (force_shoulder_end,  force_shoulder_end_value,  force_colors['shoulder']),\n",
    "                        (force_rise_start,    force_baseline,            force_colors['rise']),\n",
    "                        (force_plateau_start, force_plateau_start_value, force_colors['plateau']),\n",
    "                        (force_plateau_end,   force_plateau_end_value,   force_colors['plateau']),\n",
    "                        (force_drop_end,      force_drop_end_value,      force_colors['drop'])]:\n",
    "                    if np.isfinite(y):\n",
    "                        axes[-1].add_artist(patches.ConnectionPatch(\n",
    "                            xyA=(t, y), xyB=(t, 1),\n",
    "                            coordsA='data', coordsB=axes[0].get_xaxis_transform(),\n",
    "                            axesA=axes[-1], axesB=axes[0],\n",
    "                            color=c, lw=1, ls=':', zorder=-2))\n",
    "\n",
    "\n",
    "\n",
    "            ###\n",
    "            ### SPIKES AND BURSTS\n",
    "            ###\n",
    "\n",
    "            units = [\n",
    "                'I2 spikes',\n",
    "                'B8a/b',\n",
    "                'B3',\n",
    "                'B6/B9',\n",
    "                'B38',\n",
    "                'B4/B5',\n",
    "            ]\n",
    "            for k, unit in enumerate(units):\n",
    "                st = df.loc[i, unit+' spike train']\n",
    "                if st is not None and st.size > 0:\n",
    "\n",
    "                    # get the signal for the behavior with 10 seconds cushion for spikes outside the behavior duration\n",
    "                    channel = st.annotations['channels'][0]\n",
    "                    sig = get_sig(blk, channel)\n",
    "                    sig = sig.time_slice(behavior_start - 10*pq.s, behavior_end + 10*pq.s)\n",
    "                    sig = sig.rescale(channel_units[channel_names.index(channel)])\n",
    "\n",
    "                    # get every sequence of spikes that qualifies as a burst\n",
    "                    bursts = df.at[i, unit+' all bursts (s)']\n",
    "\n",
    "                    # find the first and last good bursts\n",
    "                    first_burst_start = np.nan\n",
    "                    first_burst_end = np.nan\n",
    "                    last_burst_start = np.nan\n",
    "                    last_burst_end = np.nan\n",
    "                    if len(bursts) > 0:\n",
    "\n",
    "                        for burst in bursts:\n",
    "                            if is_good_burst(burst):\n",
    "                                first_burst_start, first_burst_end = burst['Start (s)'], burst['End (s)']\n",
    "                                break # quit after finding first good burst\n",
    "\n",
    "                        for burst in reversed(bursts):\n",
    "                            if is_good_burst(burst):\n",
    "                                last_burst_start, last_burst_end = burst['Start (s)'], burst['End (s)']\n",
    "                                break # quit after finding first (actually, last) good burst\n",
    "\n",
    "                    # plot spikes\n",
    "                    plt.sca(axes[channel_names.index(channel)])\n",
    "                    marker = ['.', 'x'][j%2] # alternate markers between behaviors\n",
    "                    spike_amplitudes = np.array([sig[sig.time_index(t)] for t in st]) * pq.Quantity(sig.units)\n",
    "                    plt.scatter(st.times.rescale('s'), spike_amplitudes, marker=marker, c=unit_colors[unit])\n",
    "\n",
    "                    # plot burst windows\n",
    "                    discriminator = next((d for d in metadata['amplitude_discriminators'] if d['name'] == st.name), None)\n",
    "                    if discriminator is None:\n",
    "                        raise Exception(f'For data set \"{data_set_name}\", discriminator \"{st.name}\" could not be found')\n",
    "                    bottom = pq.Quantity(discriminator['amplitude'][0], discriminator['units']).rescale(sig.units)\n",
    "                    top = pq.Quantity(discriminator['amplitude'][1], discriminator['units']).rescale(sig.units)\n",
    "                    height = top-bottom\n",
    "                    for burst in bursts:\n",
    "                        left = burst['Start (s)']\n",
    "                        right = burst['End (s)']\n",
    "                        width = right-left\n",
    "                        linestyle = '-' if is_good_burst(burst) else '--'\n",
    "                        rect = patches.Rectangle((left, bottom), width, height, ls=linestyle, edgecolor=unit_colors[unit], fill=False)\n",
    "                        plt.gca().add_patch(rect)\n",
    "\n",
    "                    # plot markers for edges of bursts\n",
    "                    if top > 0:\n",
    "                        plt.plot([first_burst_start], [top],    marker=CARETDOWN, markersize=5, color='k')\n",
    "                        plt.plot([last_burst_end],    [top],    marker=CARETDOWN, markersize=5, color='k')\n",
    "                    else:\n",
    "                        plt.plot([first_burst_start], [bottom], marker=CARETUP,   markersize=5, color='k')\n",
    "                        plt.plot([last_burst_end],    [bottom], marker=CARETUP,   markersize=5, color='k')\n",
    "\n",
    "\n",
    "\n",
    "        ###\n",
    "        ### FINISH FIGURE\n",
    "        ###\n",
    "\n",
    "        # optimize plot margins\n",
    "        plt.subplots_adjust(\n",
    "            left   = 0.1,\n",
    "            right  = 0.99,\n",
    "            top    = 0.96,\n",
    "            bottom = 0.06,\n",
    "            hspace = 0.15,\n",
    "        )\n",
    "\n",
    "        # export figure\n",
    "        export_dir2 = os.path.join(export_dir, 'sanity-checks')\n",
    "        if not os.path.exists(export_dir2):\n",
    "            os.mkdir(export_dir2)\n",
    "        plt.gcf().savefig(os.path.join(export_dir2, f'{animal} {food} {bout_index}.png'), dpi=300)\n",
    "\n",
    "    if exemplary_swallow in feeding_bouts:\n",
    "        # rename output file for exemplar\n",
    "        animal, food, bout_index = exemplary_swallow\n",
    "        old_path = os.path.join(export_dir2, f'{animal} {food} {bout_index}.png')\n",
    "        new_path = os.path.join(export_dir2, 'exemplary_swallow.png')\n",
    "        if os.path.exists(old_path):\n",
    "            if os.path.exists(new_path):\n",
    "                os.remove(new_path)\n",
    "            os.rename(old_path, new_path)\n",
    "\n",
    "    if exemplary_bout in feeding_bouts:\n",
    "        # rename output file for exemplar\n",
    "        animal, food, bout_index = exemplary_bout\n",
    "        old_path = os.path.join(export_dir2, f'{animal} {food} {bout_index}.png')\n",
    "        new_path = os.path.join(export_dir2, 'exemplary_bout.png')\n",
    "        if os.path.exists(old_path):\n",
    "            if os.path.exists(new_path):\n",
    "                os.remove(new_path)\n",
    "            os.rename(old_path, new_path)\n",
    "\n",
    "\n",
    "    del df_all2, df_list2\n",
    "\n",
    "    end = datetime.datetime.now()\n",
    "    print('elapsed time:', end-start)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if not skip_sanity_checks:\n",
    "    start = datetime.datetime.now()\n",
    "\n",
    "    for (animal, food, bout_index), (data_set_name, time_window) in feeding_bouts.items():\n",
    "\n",
    "        channel_names = channel_names_by_animal[animal]\n",
    "\n",
    "        if (animal, food, bout_index) == exemplary_swallow:\n",
    "            # skip the lone swallow\n",
    "            continue\n",
    "        elif (animal, food, bout_index) == exemplary_bout:\n",
    "            df = df_exemplary_bout\n",
    "        else:\n",
    "            df = df_all.loc[animal, food, bout_index]\n",
    "\n",
    "        # load the data\n",
    "        metadata = neurotic.MetadataSelector('../../data/metadata.yml')\n",
    "        metadata.select(data_set_name)\n",
    "        blk = neurotic.load_dataset(metadata, lazy=True)\n",
    "\n",
    "        units = [\n",
    "            'I2 spikes',\n",
    "            'B8a/b',\n",
    "            'B3',\n",
    "            'B6/B9',\n",
    "            'B38',\n",
    "            'B4/B5',\n",
    "        ]\n",
    "\n",
    "        # figsize = (9.5, 10) # dimensions for notebook\n",
    "        # figsize = (11, 8.5) # dimensions for printing\n",
    "        figsize = (16, 9) # dimensions for filling wide screens\n",
    "        fig, axes = plt.subplots(len(units)+1, 2, sharex='col', figsize=figsize)\n",
    "\n",
    "        for k, unit in enumerate(units):\n",
    "            # get the subplot axes handles\n",
    "            ax_left, ax_right = axes[k]\n",
    "\n",
    "            # set y-axis label\n",
    "            ax_left.set_ylabel(unit+' (Hz)')\n",
    "            ax_left.yaxis.set_label_coords(-0.06, 0.5)\n",
    "\n",
    "            # remove right, top, and bottom plot borders, and remove x-axis\n",
    "            sns.despine(ax=ax_left, bottom=True)\n",
    "            sns.despine(ax=ax_right, bottom=True)\n",
    "            ax_left.xaxis.set_visible(False)\n",
    "            ax_right.xaxis.set_visible(False)\n",
    "\n",
    "            # set normalized time plot range\n",
    "            ax_right.set_xlim([0, 9])\n",
    "\n",
    "            # elevate the Axes for units and remove background colors so that\n",
    "            # each vertical ConnectionPatch drawn later is visible behind it\n",
    "            ax_left.set_zorder(1)\n",
    "            ax_right.set_zorder(1)\n",
    "            ax_left.set_facecolor('none')\n",
    "            ax_right.set_facecolor('none')\n",
    "\n",
    "        # remove right and top plot borders from bottom panel, and set x-label\n",
    "        ax_left, ax_right = axes[-1]\n",
    "        sns.despine(ax=ax_left)\n",
    "        sns.despine(ax=ax_right)\n",
    "        ax_left.set_xlabel('Time (s)')\n",
    "        ax_right.set_xlabel('Time (normalized)')\n",
    "\n",
    "        # set normalized time plot range\n",
    "        ax_right.set_xlim([0, 9])\n",
    "\n",
    "        # plot force in real time\n",
    "        ax_left, ax_right = axes[-1]\n",
    "        channel = 'Force'\n",
    "        sig = get_sig(blk, channel)\n",
    "        sig = sig.time_slice(time_window[0]*pq.s, time_window[1]*pq.s)\n",
    "        sig = sig.rescale(channel_units[channel_names.index(channel)])\n",
    "        ax_left.plot(sig.times, sig.magnitude, c='0.8', lw=1)\n",
    "        ax_left.set_ylabel(sig.name + ' (' + sig.units.dimensionality.string + ')')\n",
    "        ax_left.yaxis.set_label_coords(-0.06, 0.5)\n",
    "\n",
    "        all_normalized_times_series = {}\n",
    "        for unit in units:\n",
    "            all_normalized_times_series[unit] = np.zeros((0, times_interp.size))\n",
    "        all_normalized_times_series['Force'] = np.zeros((0, times_interp.size))\n",
    "\n",
    "        for j, i in enumerate(df.index):\n",
    "            \n",
    "            \n",
    "            # plot inward food movement\n",
    "            inward_movement_start = df.loc[i, 'Inward movement start (s)']\n",
    "            inward_movement_end   = df.loc[i, 'Inward movement end (s)']\n",
    "            if np.isfinite(inward_movement_start):\n",
    "                ax_left, ax_right = axes[-1]\n",
    "                ax_left.axvspan(\n",
    "                    inward_movement_start, inward_movement_end,\n",
    "                    0.98, 1,\n",
    "                    facecolor='k', edgecolor=None, lw=0)\n",
    "            \n",
    "            \n",
    "            for k, unit in enumerate(units):\n",
    "                ax_left, ax_right = axes[k]\n",
    "\n",
    "\n",
    "                # raster plot\n",
    "                st = df.loc[i, unit+' spike train']\n",
    "                if st is not None:\n",
    "                    ax_left.eventplot(positions=st, lineoffsets=-1, colors=unit_colors[unit])\n",
    "\n",
    "\n",
    "                # plot the firing rates in real time\n",
    "                firing_rate = df.loc[i, unit+' firing rate (Hz)']\n",
    "                if firing_rate is not None:\n",
    "                    ax_left.plot(firing_rate.times.rescale('s'), firing_rate, c=unit_colors[unit])\n",
    "\n",
    "\n",
    "                # plot firing rates in normalized time\n",
    "                firing_rate_interp = df.loc[i, unit+' firing rate, normalized time interpolation (Hz)']\n",
    "                if firing_rate_interp is not None:\n",
    "                    all_normalized_times_series[unit] = np.concatenate([all_normalized_times_series[unit], firing_rate_interp[np.newaxis, :]])\n",
    "                    ax_right.plot(times_interp, firing_rate_interp, c=lighten_color(unit_colors[unit], amount=0.7))\n",
    "\n",
    "\n",
    "            # plot force in normalized time\n",
    "            ax_left, ax_right = axes[-1]\n",
    "            force_interp = df.at[i, 'Force, normalized time interpolation (mN)']\n",
    "            if force_interp is not None:\n",
    "                all_normalized_times_series['Force'] = np.concatenate([all_normalized_times_series['Force'], force_interp[np.newaxis, :]])\n",
    "                ax_right.plot(times_interp, force_interp, c='0.8', lw=1)\n",
    "\n",
    "\n",
    "            # plot force phase boundaries in real time\n",
    "            normalization_fixed_times = df.at[i, 'Normalization fixed times (s)'].rescale('s').magnitude\n",
    "            for m, t in enumerate(normalization_fixed_times[3:8]): # 3 = end of shoulder, 8 = end of next shoulder\n",
    "                if np.isfinite(t):\n",
    "                    if m == 1: # 1 = start of rise\n",
    "                        color = force_colors['rise']\n",
    "                    else:\n",
    "                        color = '0.75'\n",
    "                    axes[-1][0].add_artist(patches.ConnectionPatch(\n",
    "                        xyA=(t, 0), xyB=(t, 1),\n",
    "                        coordsA=axes[-1][0].get_xaxis_transform(), coordsB=axes[0][0].get_xaxis_transform(),\n",
    "                        axesA=axes[-1][0], axesB=axes[0][0],\n",
    "                        color=color, lw=1, ls=':'))\n",
    "\n",
    "\n",
    "        # plot force phase boundaries in normalized time\n",
    "        for m in range(len(normalization_fixed_times)):\n",
    "            if m == 4: # 4 = start of rise\n",
    "                color = force_colors['rise']\n",
    "            else:\n",
    "                color = '0.75'\n",
    "            axes[-1][1].add_artist(patches.ConnectionPatch(\n",
    "                xyA=(m, 0), xyB=(m, 1),\n",
    "                coordsA=axes[-1][1].get_xaxis_transform(), coordsB=axes[0][1].get_xaxis_transform(),\n",
    "                axesA=axes[-1][1], axesB=axes[0][1],\n",
    "                color=color, lw=1, ls=':'))\n",
    "\n",
    "\n",
    "        # plot firing rate distributions\n",
    "        for k, unit in enumerate(units):\n",
    "            ax_left, ax_right = axes[k]\n",
    "\n",
    "            firing_rate_median = np.nanmedian(all_normalized_times_series[unit], axis=0)\n",
    "            firing_rate_q1 = np.nanquantile(all_normalized_times_series[unit], q=0.25, axis=0)\n",
    "            firing_rate_q3 = np.nanquantile(all_normalized_times_series[unit], q=0.75, axis=0)\n",
    "            ax_right.plot(times_interp, firing_rate_median, c='k', lw=2, zorder=3)\n",
    "            ax_right.plot(times_interp, firing_rate_q1, c='gray', lw=1)\n",
    "            ax_right.plot(times_interp, firing_rate_q3, c='gray', lw=1)\n",
    "\n",
    "\n",
    "        # plot force distribution\n",
    "        ax_left, ax_right = axes[-1]\n",
    "\n",
    "        force_median = np.nanmedian(all_normalized_times_series['Force'], axis=0)\n",
    "        force_q1 = np.nanquantile(all_normalized_times_series['Force'], q=0.25, axis=0)\n",
    "        force_q3 = np.nanquantile(all_normalized_times_series['Force'], q=0.75, axis=0)\n",
    "        ax_right.plot(times_interp, force_median, c='k', lw=2, zorder=3)\n",
    "        ax_right.plot(times_interp, force_q1, c='gray', lw=1)\n",
    "        ax_right.plot(times_interp, force_q3, c='gray', lw=1)\n",
    "\n",
    "\n",
    "        plt.suptitle(f'({animal}, {food}, {bout_index}): {data_set_name}')\n",
    "        plt.tight_layout(rect=(0, 0, 1, 0.97))\n",
    "\n",
    "        # export figure\n",
    "        export_dir3 = os.path.join(export_dir, 'sanity-checks-firing-rates')\n",
    "        if not os.path.exists(export_dir3):\n",
    "            os.mkdir(export_dir3)\n",
    "        plt.gcf().savefig(os.path.join(export_dir3, f'{animal} {food} {bout_index}.png'), dpi=300)\n",
    "\n",
    "    if exemplary_bout in feeding_bouts:\n",
    "        # rename output file for exemplar\n",
    "        animal, food, bout_index = exemplary_bout\n",
    "        old_path = os.path.join(export_dir3, f'{animal} {food} {bout_index}.png')\n",
    "        new_path = os.path.join(export_dir3, 'exemplary_bout.png')\n",
    "        if os.path.exists(old_path):\n",
    "            if os.path.exists(new_path):\n",
    "                os.remove(new_path)\n",
    "            os.rename(old_path, new_path)\n",
    "\n",
    "    end = datetime.datetime.now()\n",
    "    print('elapsed time:', end-start)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "source": [
    "## Plotting Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def boxplot_with_points(x, y, hue, data, ax=None, show_points=False, describe=True):\n",
    "    if ax is None:\n",
    "        ax = plt.gca()\n",
    "    boxcolor = '0.75' if hue is None else None\n",
    "    pointcolor = 'k' if hue is None else None\n",
    "    edgecolor = '0.25'\n",
    "    linewidth = 0 if hue is None else 1\n",
    "    size = 4\n",
    "    \n",
    "    data = data.dropna(subset=[y])\n",
    "    \n",
    "    sns.boxplot(x=x, y=y, hue=hue, data=data, ax=ax, color=boxcolor, whis=999) # whiskers span extrema\n",
    "    \n",
    "    if show_points:\n",
    "        sns.swarmplot(x=x, y=y, hue=hue, data=data, ax=ax, color=pointcolor, linewidth=linewidth, edgecolor=edgecolor, size=size, dodge=True)\n",
    "        \n",
    "        if hue is not None:\n",
    "            # avoid duplicate legend entries\n",
    "            handles, labels = ax.get_legend_handles_labels()\n",
    "            n = int(len(labels)/2)\n",
    "            ax.legend(handles[:n], labels[:n], title=hue)\n",
    "    \n",
    "    ax.set_xlabel(None)\n",
    "\n",
    "    if describe:\n",
    "        by = [x] if hue is None else [x, hue]\n",
    "        print(y)\n",
    "#         print(data.groupby(by)[y].describe())\n",
    "        print(data.groupby(by)[y].apply(lambda y: {\n",
    "            'N': f'{y.count()}',\n",
    "            'Median': y.median(),\n",
    "#             'Q1': y.quantile(0.25),\n",
    "#             'Q3': y.quantile(0.75),\n",
    "        }).unstack())\n",
    "        print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "outputs": [],
   "source": [
    "default_markers = ['.', '+', 'x', '1', '4', 'o', 'D']\n",
    "default_colors = ['C0', 'C1', 'C2', 'C3', 'C4', 'C5', 'C6']\n",
    "\n",
    "def scatter2d(ax, data_subsets, xlabel, xlim, ylabel, ylim, trend=False, trend_separately=False, tooltips=False, padding=0.05, colors=default_colors, markers=default_markers):\n",
    "    \n",
    "    for j, (label, query) in enumerate(data_subsets.items()):\n",
    "        if query is not None:\n",
    "            df = df_all.query(query)\n",
    "            ax.scatter(df[xlabel], df[ylabel],\n",
    "                       label=label, marker=markers[j], c=colors[j], clip_on=False)\n",
    "            \n",
    "    all_points = df_all.query(query_union(data_subsets.values()))[[xlabel, ylabel]].dropna()\n",
    "    \n",
    "    if len(all_points) > 0:\n",
    "\n",
    "        xrange = np.ptp(all_points.iloc[:, 0])\n",
    "        xmin = min(all_points.iloc[:, 0]) - xrange * padding\n",
    "        xmax = max(all_points.iloc[:, 0]) + xrange * padding\n",
    "        if xlim is None:\n",
    "            xlim = [xmin, xmax]\n",
    "        if xlim[0] is None:\n",
    "            xlim[0] = xmin\n",
    "        if xlim[1] is None:\n",
    "            xlim[1] = xmax\n",
    "\n",
    "        yrange = np.ptp(all_points.iloc[:, 1])\n",
    "        ymin = min(all_points.iloc[:, 1]) - yrange * padding\n",
    "        ymax = max(all_points.iloc[:, 1]) + yrange * padding\n",
    "        if ylim is None:\n",
    "            ylim = [ymin, ymax]\n",
    "        if ylim[0] is None:\n",
    "            ylim[0] = ymin\n",
    "        if ylim[1] is None:\n",
    "            ylim[1] = ymax\n",
    "    \n",
    "    if trend_separately:\n",
    "        for j, (label, query) in enumerate(data_subsets.items()):\n",
    "            if query is not None:\n",
    "                df = df_all.query(query)[[xlabel, ylabel]].dropna()\n",
    "                model = sm.OLS(df.iloc[:,1], sm.add_constant(df.iloc[:,0])).fit()\n",
    "                model_stats = 'R$^2$ = {:.2f}, p = {:.3f}, n = {}'.format(model.rsquared, model.pvalues[1], len(df))\n",
    "                print(label+':', model_stats)\n",
    "                model_x = np.linspace(xlim[0], xlim[1], 100)\n",
    "                model_y = model.params[0] + model.params[1] * model_x\n",
    "                ax.plot(model_x, model_y, color=colors[j])#, label=model_stats)\n",
    "                \n",
    "    if trend:\n",
    "        model = sm.OLS(all_points.iloc[:,1], sm.add_constant(all_points.iloc[:,0])).fit()\n",
    "        model_stats = 'R$^2$ = {:.2f}, p = {:.3f}, n = {}'.format(model.rsquared, model.pvalues[1], len(all_points))\n",
    "        print('All points:', model_stats)\n",
    "        model_x = np.linspace(xlim[0], xlim[1], 100)\n",
    "        model_y = model.params[0] + model.params[1] * model_x\n",
    "        ax.plot(model_x, model_y, color='gray')#, label=model_stats)\n",
    "    \n",
    "    if tooltips:\n",
    "        # create a transparent layer containing all points for detecting mouse events\n",
    "        sc = ax.scatter(all_points.iloc[:, 0], all_points.iloc[:, 1], label=None,\n",
    "                        alpha=0, # transparent points\n",
    "                        s=0.001, # small radius of tooltip activation\n",
    "                       )\n",
    "        \n",
    "        # initialize a hidden empty tooltip\n",
    "        annot = ax.annotate(\n",
    "            '', xy=(0, 0),                              # initialize empty at origin\n",
    "            xytext=(0, 15), textcoords='offset points', # position text above point\n",
    "            color='k', size=10, ha='center',            # small black centered text\n",
    "            bbox=dict(fc='w', lw=0, alpha=0.6),         # transparent white background\n",
    "            arrowprops=dict(shrink=0, headlength=7, headwidth=7, width=0, lw=0, color='k'), # small black arrow\n",
    "        )\n",
    "        annot.set_visible(False)\n",
    "        \n",
    "        # prepare tooltip contents\n",
    "        tooltip_text = [' '.join([str(x) for x in index]) for index in list(all_points.index)]\n",
    "        \n",
    "        # bind the animation of tooltips to a hover event\n",
    "        def hover(event):\n",
    "            if event.inaxes == ax:\n",
    "                cont, ind = sc.contains(event)\n",
    "                if cont:\n",
    "                    point_index = ind['ind'][0]\n",
    "                    pos = sc.get_offsets()[point_index]\n",
    "                    annot.xy = pos\n",
    "                    annot.set_text(tooltip_text[point_index])\n",
    "                    annot.set_visible(True)\n",
    "                    ax.figure.canvas.draw_idle()\n",
    "                else:\n",
    "                    if annot.get_visible():\n",
    "                        annot.set_visible(False)\n",
    "                        ax.figure.canvas.draw_idle()\n",
    "        ax.figure.canvas.mpl_connect('motion_notify_event', hover)\n",
    "        \n",
    "    ax.set_xlabel(xlabel)\n",
    "    ax.set_xlim(xlim)\n",
    "    ax.set_ylabel(ylabel)#.replace('rectified ',''))\n",
    "    ax.set_ylim(ylim)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from matplotlib.offsetbox import AnchoredOffsetbox\n",
    "class AnchoredScaleBar(AnchoredOffsetbox):\n",
    "    def __init__(self, transform, sizex=0, sizey=0, labelx=None, labely=None, loc=4,\n",
    "                 pad=0.1, borderpad=0.1, sep=2, prop=None, barcolor=\"black\", barwidth=None, \n",
    "                 **kwargs):\n",
    "        \"\"\"\n",
    "        Draw a horizontal and/or vertical  bar with the size in data coordinate\n",
    "        of the give axes. A label will be drawn underneath (center-aligned).\n",
    "        - transform : the coordinate frame (typically axes.transData)\n",
    "        - sizex,sizey : width of x,y bar, in data units. 0 to omit\n",
    "        - labelx,labely : labels for x,y bars; None to omit\n",
    "        - loc : position in containing axes\n",
    "        - pad, borderpad : padding, in fraction of the legend font size (or prop)\n",
    "        - sep : separation between labels and bars in points.\n",
    "        - **kwargs : additional arguments passed to base class constructor\n",
    "        \"\"\"\n",
    "        from matplotlib.patches import Rectangle\n",
    "        from matplotlib.offsetbox import AuxTransformBox, VPacker, HPacker, TextArea, DrawingArea\n",
    "        bars = AuxTransformBox(transform)\n",
    "        if sizex:\n",
    "#             bars.add_artist(Rectangle((0,0), sizex, 0, ec=barcolor, lw=barwidth, fc=\"none\"))\n",
    "            bars.add_artist(Rectangle((0,0), -sizex, 0, ec=barcolor, lw=barwidth, fc=\"none\"))\n",
    "        if sizey:\n",
    "            bars.add_artist(Rectangle((0,0), 0, sizey, ec=barcolor, lw=barwidth, fc=\"none\"))\n",
    "\n",
    "        if sizex and labelx:\n",
    "            self.xlabel = TextArea(labelx, minimumdescent=False)\n",
    "            bars = VPacker(children=[bars, self.xlabel], align=\"center\", pad=0, sep=sep)\n",
    "        if sizey and labely:\n",
    "            self.ylabel = TextArea(labely)\n",
    "#             bars = HPacker(children=[self.ylabel, bars], align=\"center\", pad=0, sep=sep)\n",
    "            bars = HPacker(children=[bars, self.ylabel], align=\"center\", pad=0, sep=sep)\n",
    "\n",
    "        AnchoredOffsetbox.__init__(self, loc, pad=pad, borderpad=borderpad,\n",
    "                                   child=bars, prop=prop, frameon=False, **kwargs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def prettyplot_with_scalebars(\n",
    "    blk,\n",
    "    t_start,\n",
    "    t_stop,\n",
    "    plots,\n",
    "    \n",
    "    outfile_basename=None, # base name of output files\n",
    "    export_only=False,     # if True, will not render in notebook\n",
    "    formats=['pdf', 'svg', 'png'], # extensions of output files\n",
    "    dpi=300,               # resolution (applicable only for PNG)\n",
    "    \n",
    "    figsize=(14, 7),       # figure size in inches\n",
    "    linewidth=1,           # thickness of lines in points\n",
    "    layout_settings=None,  # positioning of plot edges and the space between plots\n",
    "    \n",
    "    x_scalebar=1*pq.s,     # size of the time scale bar in seconds\n",
    "    ylabel_padding=10,     # space between trace labels and plots\n",
    "    scalebar_padding=1,    # space between scale bars and plots\n",
    "    scalebar_sep=5,        # space between scale bars and scale labels\n",
    "    barwidth=2,            # thickness of scale bars\n",
    "):\n",
    "    \n",
    "    if export_only:\n",
    "        plt.ioff()\n",
    "        \n",
    "    fig, axes = plt.subplots(len(plots), 1, sharex=True, figsize=figsize, squeeze=False)\n",
    "    axes = axes.flatten()\n",
    "\n",
    "    for i, p in enumerate(plots):\n",
    "\n",
    "        # get the subplot axes handle\n",
    "        ax = axes[i]\n",
    "\n",
    "        # select and rescale a channel for the subplot\n",
    "        sig = next((sig for sig in blk.segments[0].analogsignals if sig.name == p['channel']), None)\n",
    "        assert sig is not None, f\"Signal with name {p['channel']} not found\"\n",
    "        sig = sig.time_slice(t_start, t_stop)\n",
    "        sig = sig.rescale(p['units'])\n",
    "\n",
    "        # downsample the data\n",
    "        sig_downsampled = DownsampleNeoSignal(sig, p.get('decimation_factor', 1))\n",
    "\n",
    "        # specify the x- and y-data for the subplot\n",
    "        ax.plot(\n",
    "            sig_downsampled.times,\n",
    "            sig_downsampled.as_quantity(),\n",
    "            linewidth=linewidth,\n",
    "            color=p.get('color', 'k'),\n",
    "        )\n",
    "        \n",
    "        # hide the box around the subplot\n",
    "        ax.set_frame_on(False)\n",
    "\n",
    "        # specify the y-axis label\n",
    "        ylabel = p.get('ylabel', sig.name)\n",
    "        if ylabel is not None:\n",
    "            ax.set_ylabel(ylabel, rotation='horizontal', ha='right', va='center', labelpad=ylabel_padding)\n",
    "\n",
    "        # specify the plot range\n",
    "        ax.set_xlim([t_start, t_stop])\n",
    "        ax.set_ylim(p['ylim'])\n",
    "\n",
    "        # disable tick marks\n",
    "        ax.tick_params(\n",
    "            bottom=False,\n",
    "            left=False,\n",
    "            labelbottom=False,\n",
    "            labelleft=False)\n",
    "\n",
    "        # add y-axis scale bar\n",
    "        if p['scalebar'] is not None:\n",
    "            ax.add_artist(AnchoredScaleBar(\n",
    "                ax.transData,\n",
    "                sizey=p['scalebar'],\n",
    "                labely=f'{p[\"scalebar\"]} {sig.units.dimensionality.string}',\n",
    "\n",
    "                loc='center left',\n",
    "                bbox_to_anchor=(1, 0.5),\n",
    "                bbox_transform=ax.transAxes,\n",
    "\n",
    "                pad=0,\n",
    "                borderpad=scalebar_padding,\n",
    "                sep=scalebar_sep,\n",
    "                barwidth=barwidth,\n",
    "            ))\n",
    "        \n",
    "    # add time scale bar below final plot\n",
    "    if x_scalebar is not None:\n",
    "        axes[-1].add_artist(AnchoredScaleBar(\n",
    "            axes[-1].transData,\n",
    "            sizex=x_scalebar.rescale(sig.times.units).magnitude,\n",
    "            labelx=f'{x_scalebar.magnitude:g} {x_scalebar.units.dimensionality.string}',\n",
    "\n",
    "            loc='upper right',\n",
    "            bbox_to_anchor=(1, 0),\n",
    "            bbox_transform=axes[-1].transAxes,\n",
    "\n",
    "            pad=0,\n",
    "            borderpad=scalebar_padding,\n",
    "            sep=scalebar_sep,\n",
    "            barwidth=barwidth,\n",
    "        ))\n",
    "\n",
    "    # adjust the white space around and between the subplots\n",
    "    if layout_settings is None:\n",
    "        fig.tight_layout(h_pad=0, w_pad=0, pad=0)\n",
    "    else:\n",
    "        plt.subplots_adjust(**layout_settings)\n",
    "\n",
    "    if outfile_basename is not None:\n",
    "        # specify file metadata (applicable only for PDF)\n",
    "        metadata = dict(\n",
    "            Subject = 'Data file: '  + blk.file_origin + '\\n' +\n",
    "                      'Start time: ' + str(t_start)    + '\\n' +\n",
    "                      'End time: '   + str(t_stop),\n",
    "        )\n",
    "\n",
    "        # write the figure to files\n",
    "        for ext in formats:\n",
    "            fig.savefig(outfile_basename+'.'+ext, metadata=metadata, dpi=dpi)\n",
    "\n",
    "    if export_only:\n",
    "        plt.ion()\n",
    "    \n",
    "    return fig, axes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Figures"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## [FIGURE 1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ðŸŒ Figure 1A"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "start = datetime.datetime.now()\n",
    "\n",
    "df = df_exemplary_swallow\n",
    "(data_set_name, time_window) = feeding_bouts[exemplary_swallow]\n",
    "animal, _, _ = exemplary_swallow\n",
    "\n",
    "t_start, t_stop = time_window*pq.s\n",
    "plots = [\n",
    "    {'channel': 'I2',       'units': 'uV', 'ylim': [ -35,  35], 'scalebar': 50}, #, 'decimation_factor': 100},\n",
    "    {'channel': 'RN',       'units': 'uV', 'ylim': [ -25,  25], 'scalebar': 25}, #, 'decimation_factor': 100},\n",
    "    {'channel': 'BN2',      'units': 'uV', 'ylim': [ -45,  45], 'scalebar': 50}, #, 'decimation_factor': 100},\n",
    "    {'channel': 'BN3-DIST', 'units': 'uV', 'ylim': [ -70,  70], 'scalebar': 50, 'ylabel': 'BN3'}, #, 'decimation_factor': 100},\n",
    "    {'channel': 'Force',    'units': 'mN', 'ylim': [-100, 400], 'scalebar': 200}, #, 'decimation_factor': 100},\n",
    "]\n",
    "plot_names = [p['channel'] for p in plots]\n",
    "plot_units = [p['units'] for p in plots]\n",
    "\n",
    "kwargs = dict(\n",
    "    figsize = (7, 9),\n",
    "    linewidth = 0.5,\n",
    "    x_scalebar = 1*pq.s,\n",
    ")\n",
    "\n",
    "# load the metadata\n",
    "metadata = neurotic.MetadataSelector('../../data/metadata.yml')\n",
    "metadata.select(data_set_name)\n",
    "\n",
    "# ensure that the right filters are used\n",
    "metadata['filters'] = sig_filters_by_animal[animal]\n",
    "\n",
    "# load the data\n",
    "blk = neurotic.load_dataset(metadata, lazy=True)\n",
    "\n",
    "# manually perform filters\n",
    "blk = apply_filters(blk, metadata)\n",
    "\n",
    "# plot the signal\n",
    "fig, axes = prettyplot_with_scalebars(blk, t_start, t_stop, plots, **kwargs)\n",
    "\n",
    "units = [\n",
    "    'I2 spikes',\n",
    "    'B8a/b',\n",
    "    'B6/B9',\n",
    "    'B3',\n",
    "    'B38',\n",
    "    'B4/B5',\n",
    "]\n",
    "unit_burst_boxes = {\n",
    "    'I2 spikes': [-30, 25],\n",
    "    'B8a/b':     [-20, 12],\n",
    "    'B6/B9':     [-20, 15],\n",
    "    'B3':        [-45, 35],\n",
    "    'B38':       [-12, 12],\n",
    "    'B4/B5':     [-60, 55],\n",
    "}\n",
    "\n",
    "for j, i in enumerate(df.index):\n",
    "    for k, unit in enumerate(units):\n",
    "        st = df.loc[i, unit+' spike train']\n",
    "        if st is not None and st.size > 0:\n",
    "\n",
    "            # get the neural channel\n",
    "            channel = st.annotations['channels'][0]\n",
    "            sig = get_sig(blk, channel)\n",
    "\n",
    "            # get the signal for the entire bout\n",
    "            sig = sig.time_slice(t_start, t_stop)\n",
    "            sig = sig.rescale(plot_units[plot_names.index(channel)])\n",
    "\n",
    "            # plot spikes\n",
    "            ax = axes[plot_names.index(channel)]\n",
    "            spike_amplitudes = np.array([sig[sig.time_index(t)] for t in st]) * pq.Quantity(sig.units)\n",
    "            ax.scatter(st.times.rescale('s'), spike_amplitudes, marker='.', s=20, c=unit_colors[unit], zorder=3)\n",
    "\n",
    "            # plot burst windows\n",
    "            bursts = df.at[i, unit+' all bursts (s)']\n",
    "            bottom, top = unit_burst_boxes[unit]\n",
    "            height = top-bottom\n",
    "            left = right = np.nan\n",
    "            for burst in bursts:\n",
    "                if is_good_burst(burst):\n",
    "                    if np.isnan(left) or burst['End (s)'] < left:\n",
    "                        left = burst['Start (s)']\n",
    "                    if np.isnan(right) or burst['End (s)'] > right:\n",
    "                        right = burst['End (s)']\n",
    "            if np.isfinite(left) and np.isfinite(right):\n",
    "                width = right-left\n",
    "                rect = patches.Rectangle((left, bottom), width, height, linewidth=2, ls='-', edgecolor=unit_colors[unit], fill=False, zorder=3, clip_on=False)\n",
    "                ax.add_patch(rect)\n",
    "\n",
    "# plot a zero baseline for force\n",
    "force_zero = -11.5 # mN, average before animal began swallowing, not zero because of DC offset\n",
    "axes[-1].axhline(force_zero, color='0.75', lw=1, ls='--', zorder=-1)\n",
    "\n",
    "# plot force phase boundaries\n",
    "times = df.loc[0, 'Normalization fixed times (s)'][2:2+6]\n",
    "for t in times:\n",
    "    axes[-1].axvline(x=t, ymin=0.15, lw=1, ls=':', c='gray', zorder=-1, clip_on=False)\n",
    "#     axes[-1].add_artist(patches.ConnectionPatch(\n",
    "#         xyA=(t, 0), xyB=(t, 1),\n",
    "#         coordsA=axes[-1].get_xaxis_transform(), coordsB=axes[0].get_xaxis_transform(),\n",
    "#         axesA=axes[-1], axesB=axes[0],\n",
    "#         color='gray', lw=1, ls=':', zorder=-1))\n",
    "\n",
    "# add arabic numerals for force phase boundaries\n",
    "axes[-1].annotate('1', xy=(times[0], 0), xycoords=('data', 'axes fraction'), ha='center', va='bottom')\n",
    "axes[-1].annotate('2', xy=(times[1], 0), xycoords=('data', 'axes fraction'), ha='center', va='bottom')\n",
    "axes[-1].annotate('3', xy=(times[2], 0), xycoords=('data', 'axes fraction'), ha='center', va='bottom')\n",
    "axes[-1].annotate('4', xy=(times[3], 0), xycoords=('data', 'axes fraction'), ha='center', va='bottom')\n",
    "axes[-1].annotate('5', xy=(times[4], 0), xycoords=('data', 'axes fraction'), ha='center', va='bottom')\n",
    "axes[-1].annotate('1', xy=(times[5], 0), xycoords=('data', 'axes fraction'), ha='center', va='bottom')\n",
    "\n",
    "# add roman numerals for force phases\n",
    "axes[-1].annotate('I',   xy=(times[0:2].mean(), 1), xycoords=('data', 'axes fraction'), ha='center', va='top')\n",
    "axes[-1].annotate('II',  xy=(times[1:3].mean(), 1), xycoords=('data', 'axes fraction'), ha='center', va='top')\n",
    "axes[-1].annotate('III', xy=(times[2:4].mean(), 1), xycoords=('data', 'axes fraction'), ha='center', va='top')\n",
    "axes[-1].annotate('IV',  xy=(times[3:5].mean(), 1), xycoords=('data', 'axes fraction'), ha='center', va='top')\n",
    "axes[-1].annotate('V',   xy=(times[4:6].mean(), 1), xycoords=('data', 'axes fraction'), ha='center', va='top')\n",
    "\n",
    "# add unit name labels\n",
    "axes[0].annotate('I2',    xy=(2979.40, 0.78), xycoords=('data', 'axes fraction'), ha='left',   c=unit_colors['I2 spikes'])\n",
    "axes[1].annotate('B8a/b', xy=(2981.10, 0.80), xycoords=('data', 'axes fraction'), ha='center', c=unit_colors['B8a/b'])\n",
    "axes[2].annotate('B6/B9', xy=(2980.04, 0.73), xycoords=('data', 'axes fraction'), ha='left',   c=unit_colors['B6/B9'])\n",
    "axes[2].annotate('B3',    xy=(2981.85, 0.82), xycoords=('data', 'axes fraction'), ha='left',   c=unit_colors['B3'])\n",
    "axes[2].annotate('B38',   xy=(2978.15, 0.70), xycoords=('data', 'axes fraction'), ha='center', c=unit_colors['B38'])\n",
    "axes[3].annotate('B4/B5', xy=(2979.10, 0.82), xycoords=('data', 'axes fraction'), ha='right',  c=unit_colors['B4/B5'])\n",
    "\n",
    "# add markers for video frame times\n",
    "video_times = {\n",
    "    'B': 2979.8,\n",
    "    'C': 2982.5,\n",
    "}\n",
    "for label, video_time in video_times.items():\n",
    "    axes[-1].plot([video_time], [-0.01], marker=CARETUP, markersize=8, color='k', transform=axes[-1].get_xaxis_transform(), clip_on=False)\n",
    "    axes[-1].annotate(label, xy=(video_time, -0.1), xycoords=('data', 'axes fraction'), ha='center', va='top')\n",
    "\n",
    "# add protraction box\n",
    "left, right = df.loc[0, ['I2 spikes first burst start (s)', 'I2 spikes last burst end (s)']]\n",
    "bottom, top = (1, 1.15)\n",
    "width = right-left\n",
    "height = top-bottom\n",
    "rect = patches.Rectangle((left, bottom), width, height, linewidth=2, ls='-', edgecolor='k', fill=False, zorder=3, clip_on=False, transform=axes[0].get_xaxis_transform())\n",
    "axes[0].add_patch(rect)\n",
    "\n",
    "# add retraction box\n",
    "left, right = df.loc[0, ['I2 spikes last burst end (s)', 'End (s)']] # behavior ends with end of B43 burst\n",
    "bottom, top = (1, 1.15)\n",
    "width = right-left\n",
    "height = top-bottom\n",
    "rect = patches.Rectangle((left, bottom), width, height, linewidth=2, ls='-', edgecolor='k', facecolor='k', fill=True, zorder=3, clip_on=False, transform=axes[0].get_xaxis_transform())\n",
    "axes[0].add_patch(rect)\n",
    "\n",
    "fig.tight_layout(h_pad=0, w_pad=0, pad=0)\n",
    "\n",
    "fig.savefig(os.path.join(export_dir, 'figure-1A.png'), dpi=600)\n",
    "\n",
    "end = datetime.datetime.now()\n",
    "print('render time:', end-start)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ðŸŒ Figures 1B & 1C"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Video frames (see code for Figure 1A for times of video frames)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## [FIGURE 2]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "### ðŸŒ Figure 2A"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "NOTE: The plot output by this code is much longer than it will be in the final figure and must be cropped manually. It is rendered with the same amount of time showing as Fig 2B so that time scales are identical."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "start = datetime.datetime.now()\n",
    "\n",
    "data_set_name = 'IN VIVO / JG12 / 2019-05-10 / 002'\n",
    "animal = 'JG12'\n",
    "t_start, t_stop = [223.4, 391.1] * pq.s # t=273.71, twidth=167.7, 1 bite + a few regular nori strip swallows\n",
    "t_crop = 264.4 * pq.s\n",
    "plots = [\n",
    "    {'channel': 'I2',       'units': 'uV', 'ylim': [ -60,  60], 'scalebar': 50}, #, 'decimation_factor': 400},\n",
    "    {'channel': 'RN',       'units': 'uV', 'ylim': [ -25,  25], 'scalebar': 25}, #, 'decimation_factor': 400},\n",
    "    {'channel': 'BN2',      'units': 'uV', 'ylim': [ -45,  45], 'scalebar': 50}, #, 'decimation_factor': 400},\n",
    "    {'channel': 'BN3-DIST', 'units': 'uV', 'ylim': [ -60,  60], 'scalebar': 50, 'ylabel': 'BN3'}, #, 'decimation_factor': 400},\n",
    "    {'channel': 'Force',    'units': 'mN', 'ylim': [ -50, 450], 'scalebar': 300}, #, 'decimation_factor': 100},\n",
    "]\n",
    "\n",
    "kwargs = dict(\n",
    "    formats = ['png'],\n",
    "    dpi = 600,\n",
    "    figsize = (14, 5),\n",
    "    linewidth = 0.5,\n",
    "    x_scalebar = 10*pq.s,\n",
    ")\n",
    "\n",
    "# load the metadata\n",
    "metadata = neurotic.MetadataSelector('../../data/metadata.yml')\n",
    "metadata.select(data_set_name)\n",
    "\n",
    "# ensure that the right filters are used\n",
    "metadata['filters'] = sig_filters_by_animal[animal]\n",
    "\n",
    "# load the data\n",
    "blk = neurotic.load_dataset(metadata, lazy=True)\n",
    "\n",
    "# manually perform filters\n",
    "blk = apply_filters(blk, metadata)\n",
    "\n",
    "# zero the signals after the time where the figure should be manually cropped\n",
    "for i, sig in enumerate(blk.segments[0].analogsignals):\n",
    "    sig = sig.time_slice(t_start, t_stop) # load needed if lazy\n",
    "    sig[sig.time_index(t_crop):] = 0*sig.units\n",
    "    blk.segments[0].analogsignals[i] = sig\n",
    "\n",
    "# plot the data\n",
    "fig, axes = prettyplot_with_scalebars(blk, t_start, t_stop, plots, **kwargs)\n",
    "\n",
    "fig.savefig(os.path.join(export_dir, 'figure-2A-needs-cropped.png'), dpi=600)\n",
    "\n",
    "end = datetime.datetime.now()\n",
    "print('render time:', end-start)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "### ðŸŒ Figure 2B"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "start = datetime.datetime.now()\n",
    "\n",
    "data_set_name = 'IN VIVO / JG12 / 2019-05-10 / 002'\n",
    "animal = 'JG12'\n",
    "t_start, t_stop = [2875.3, 3043] * pq.s # t=2925.61, twidth=167.7, 1 bite + 19 tape nori swallows\n",
    "plots = [\n",
    "    {'channel': 'I2',       'units': 'uV', 'ylim': [ -60,  60], 'scalebar': 50}, #, 'decimation_factor': 400},\n",
    "    {'channel': 'RN',       'units': 'uV', 'ylim': [ -25,  25], 'scalebar': 25}, #, 'decimation_factor': 400},\n",
    "    {'channel': 'BN2',      'units': 'uV', 'ylim': [ -45,  45], 'scalebar': 50}, #, 'decimation_factor': 400},\n",
    "    {'channel': 'BN3-DIST', 'units': 'uV', 'ylim': [ -60,  60], 'scalebar': 50, 'ylabel': 'BN3'}, #, 'decimation_factor': 400},\n",
    "    {'channel': 'Force',    'units': 'mN', 'ylim': [ -50, 450], 'scalebar': 300}, #, 'decimation_factor': 100},\n",
    "]\n",
    "\n",
    "kwargs = dict(\n",
    "    formats = ['png'],\n",
    "    dpi = 600,\n",
    "    figsize = (14, 5),\n",
    "    linewidth = 0.5,\n",
    "    x_scalebar = 10*pq.s,\n",
    ")\n",
    "\n",
    "# load the metadata\n",
    "metadata = neurotic.MetadataSelector('../../data/metadata.yml')\n",
    "metadata.select(data_set_name)\n",
    "\n",
    "# ensure that the right filters are used\n",
    "metadata['filters'] = sig_filters_by_animal[animal]\n",
    "\n",
    "# load the data\n",
    "blk = neurotic.load_dataset(metadata, lazy=True)\n",
    "\n",
    "# manually perform filters\n",
    "blk = apply_filters(blk, metadata)\n",
    "\n",
    "# plot the data\n",
    "fig, axes = prettyplot_with_scalebars(blk, t_start, t_stop, plots, **kwargs)\n",
    "\n",
    "# plot a zero baseline for force\n",
    "ax = axes[-1]\n",
    "force_zero = -11.5 # mN, average before animal began swallowing, not zero because of DC offset\n",
    "ax.axhline(force_zero, color='0.5', lw=1, ls='--', zorder=-1)\n",
    "\n",
    "# plot a gray rectangle highlighting portion of the record expanded in other figures\n",
    "exemplar_plot_range = feeding_bouts[exemplary_swallow][1]\n",
    "axes[-1].set_zorder(-1) # needed for trick below\n",
    "axes[-1].axvspan(\n",
    "    exemplar_plot_range[0], exemplar_plot_range[1],\n",
    "    0, 999, clip_on=False, # trick for getting to span entire figure\n",
    "    facecolor='0.8', edgecolor=None, lw=0, zorder=-2)\n",
    "\n",
    "fig.savefig(os.path.join(export_dir, 'figure-2B.png'), dpi=600)\n",
    "\n",
    "end = datetime.datetime.now()\n",
    "print('render time:', end-start)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ðŸŒ Figure 2C"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(1, 1, figsize=(4, 5))\n",
    "\n",
    "df = df_all.reset_index()\n",
    "df.loc[df['Food'] == 'Regular nori', 'Food'] = 'Unloaded'\n",
    "df.loc[df['Food'] == 'Tape nori',    'Food'] = 'Loaded'\n",
    "\n",
    "x = 'Food'\n",
    "y = 'Start to next start (s)'\n",
    "hue = 'Animal'\n",
    "\n",
    "sns.stripplot(\n",
    "    x=x, y=y, hue=hue,\n",
    "    data=df.groupby(['Animal', 'Food'])[y].mean().reset_index(),\n",
    "    order=['Unloaded', 'Loaded'],\n",
    "    jitter=False,\n",
    "    color='0.25',\n",
    ")\n",
    "ax.legend_.remove()\n",
    "\n",
    "ax.plot([\n",
    "    df.query('Food == \"Unloaded\"').groupby('Animal')[y].mean(),\n",
    "    df.query('Food == \"Loaded\"').groupby('Animal')[y].mean()\n",
    "], color='0.5')\n",
    "\n",
    "ax.set_xlim([-0.5, 1.5])\n",
    "ax.set_ylim([0, 10])\n",
    "ax.set_xlabel(None)\n",
    "ax.set_ylabel('Time from one motor pattern to the next (s)')\n",
    "plt.tight_layout()\n",
    "\n",
    "plt.gcf().savefig(os.path.join(export_dir, 'figure-2C.png'), dpi=300)\n",
    "\n",
    "df.groupby(['Animal', 'Food'])[y].mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y = 'Start to next start (s)'\n",
    "y_tape_nori = df_all.query('Food == \"Tape nori\"').groupby('Animal')[y].mean()\n",
    "y_reg_nori = df_all.query('Food == \"Regular nori\"').groupby('Animal')[y].mean()\n",
    "\n",
    "differences_test(y_tape_nori, y_reg_nori)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# fig, ax = plt.subplots(1, 1, figsize=(4, 4))\n",
    "\n",
    "# df = df_all.reset_index()\n",
    "# df.loc[df['Food'] == 'Regular nori', 'Food'] = 'Unloaded'\n",
    "# df.loc[df['Food'] == 'Tape nori',    'Food'] = 'Loaded'\n",
    "\n",
    "# x = 'Food'\n",
    "# y = 'Start to next start (s)'\n",
    "# hue = 'Animal'\n",
    "# show_points = True\n",
    "\n",
    "# boxplot_with_points(x, y, hue, df, ax, show_points)\n",
    "# ax.set_ylim([0, 10])\n",
    "# ax.set_ylabel('Time from one motor pattern to the next (s)')\n",
    "# plt.tight_layout()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ðŸŒ Figure 2D"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(1, 1, figsize=(4, 5))\n",
    "\n",
    "df = df_all.reset_index()\n",
    "df.loc[df['Food'] == 'Regular nori', 'Food'] = 'Unloaded'\n",
    "df.loc[df['Food'] == 'Tape nori',    'Food'] = 'Loaded'\n",
    "\n",
    "x = 'Food'\n",
    "y = 'Duration (s)'\n",
    "hue = 'Animal'\n",
    "\n",
    "sns.stripplot(\n",
    "    x=x, y=y, hue=hue,\n",
    "    data=df.groupby(['Animal', 'Food'])[y].mean().reset_index(),\n",
    "    order=['Unloaded', 'Loaded'],\n",
    "    jitter=False,\n",
    "    color='0.25',\n",
    ")\n",
    "ax.legend_.remove()\n",
    "\n",
    "ax.plot([\n",
    "    df.query('Food == \"Unloaded\"').groupby('Animal')[y].mean(),\n",
    "    df.query('Food == \"Loaded\"').groupby('Animal')[y].mean()\n",
    "], color='0.5')\n",
    "\n",
    "ax.set_xlim([-0.5, 1.5])\n",
    "ax.set_ylim([0, 10])\n",
    "ax.set_xlabel(None)\n",
    "ax.set_ylabel('Motor pattern duration (s)')\n",
    "plt.tight_layout()\n",
    "\n",
    "plt.gcf().savefig(os.path.join(export_dir, 'figure-2D.png'), dpi=300)\n",
    "\n",
    "df.groupby(['Animal', 'Food'])[y].mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y = 'Duration (s)'\n",
    "y_tape_nori = df_all.query('Food == \"Tape nori\"').groupby('Animal')[y].mean()\n",
    "y_reg_nori = df_all.query('Food == \"Regular nori\"').groupby('Animal')[y].mean()\n",
    "\n",
    "differences_test(y_tape_nori, y_reg_nori)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# fig, ax = plt.subplots(1, 1, figsize=(4, 4))\n",
    "\n",
    "# df = df_all.reset_index()\n",
    "# df.loc[df['Food'] == 'Regular nori', 'Food'] = 'Unloaded'\n",
    "# df.loc[df['Food'] == 'Tape nori',    'Food'] = 'Loaded'\n",
    "\n",
    "# x = 'Food'\n",
    "# y = 'Duration (s)'\n",
    "# hue = 'Animal'\n",
    "# show_points = True\n",
    "\n",
    "# boxplot_with_points(x, y, hue, df, ax, show_points)\n",
    "# ax.set_ylim([0, 10])\n",
    "# ax.set_ylabel('Motor pattern duration (s)')\n",
    "# plt.tight_layout()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ðŸŒ Figure 2E"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(1, 1, figsize=(4, 5))\n",
    "\n",
    "df = df_all.reset_index()\n",
    "df.loc[df['Food'] == 'Regular nori', 'Food'] = 'Unloaded'\n",
    "df.loc[df['Food'] == 'Tape nori',    'Food'] = 'Loaded'\n",
    "\n",
    "x = 'Food'\n",
    "y = 'End to next start (s)'\n",
    "hue = 'Animal'\n",
    "\n",
    "sns.stripplot(\n",
    "    x=x, y=y, hue=hue,\n",
    "    data=df.groupby(['Animal', 'Food'])[y].mean().reset_index(),\n",
    "    order=['Unloaded', 'Loaded'],\n",
    "    jitter=False,\n",
    "    color='0.25',\n",
    ")\n",
    "ax.legend_.remove()\n",
    "\n",
    "ax.plot([\n",
    "    df.query('Food == \"Unloaded\"').groupby('Animal')[y].mean(),\n",
    "    df.query('Food == \"Loaded\"').groupby('Animal')[y].mean()\n",
    "], color='0.5')\n",
    "\n",
    "ax.axhline(y=0, ls=':', c='gray', zorder=-1)\n",
    "ax.set_xlim([-0.5, 1.5])\n",
    "ax.set_ylim([-1, 2])\n",
    "ax.set_xlabel(None)\n",
    "ax.set_ylabel('Time between motor patterns (s)')\n",
    "plt.tight_layout()\n",
    "\n",
    "plt.gcf().savefig(os.path.join(export_dir, 'figure-2E.png'), dpi=300)\n",
    "\n",
    "df.groupby(['Animal', 'Food'])[y].mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y = 'End to next start (s)'\n",
    "y_tape_nori = df_all.query('Food == \"Tape nori\"').groupby('Animal')[y].mean()\n",
    "y_reg_nori = df_all.query('Food == \"Regular nori\"').groupby('Animal')[y].mean()\n",
    "\n",
    "differences_test(y_tape_nori, y_reg_nori)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# fig, ax = plt.subplots(1, 1, figsize=(4, 4))\n",
    "\n",
    "# df = df_all.reset_index()\n",
    "# df.loc[df['Food'] == 'Regular nori', 'Food'] = 'Unloaded'\n",
    "# df.loc[df['Food'] == 'Tape nori',    'Food'] = 'Loaded'\n",
    "\n",
    "# x = 'Food'\n",
    "# y = 'End to next start (s)'\n",
    "# hue = 'Animal'\n",
    "# show_points = True\n",
    "\n",
    "# boxplot_with_points(x, y, hue, df, ax, show_points)\n",
    "# ax.axhline(y=0, ls=':', c='gray', zorder=-1)\n",
    "# ax.set_ylabel('Time between motor patterns (s)')\n",
    "# plt.tight_layout()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## [FIGURE 3]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ðŸŒ Figure 3A"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Biomechanics schematic"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "### ðŸŒ Figure 3B"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "start = datetime.datetime.now()\n",
    "\n",
    "df = df_exemplary_swallow\n",
    "(data_set_name, time_window) = feeding_bouts[exemplary_swallow]\n",
    "animal, _, _ = exemplary_swallow\n",
    "\n",
    "t_start, t_stop = time_window*pq.s\n",
    "plots = [\n",
    "    {'channel': 'I2',       'units': 'uV', 'ylim': [ -50,  50], 'scalebar': 50}, #, 'decimation_factor': 100},\n",
    "#     {'channel': 'RN',       'units': 'uV', 'ylim': [ -25,  25], 'scalebar': 25}, #, 'decimation_factor': 100},\n",
    "#     {'channel': 'BN2',      'units': 'uV', 'ylim': [ -45,  45], 'scalebar': 50}, #, 'decimation_factor': 100},\n",
    "#     {'channel': 'BN3-DIST', 'units': 'uV', 'ylim': [ -60,  60], 'scalebar': 50, 'ylabel': 'BN3'}, #, 'decimation_factor': 100},\n",
    "    {'channel': 'Force',    'units': 'mN', 'ylim': [ -20, 375], 'scalebar': 300}, #, 'decimation_factor': 100},\n",
    "]\n",
    "\n",
    "kwargs = dict(\n",
    "    figsize = (12, 1), #1.5),\n",
    "    linewidth = 0.5,\n",
    "    x_scalebar = None, #5*pq.s,\n",
    ")\n",
    "\n",
    "# load the metadata\n",
    "metadata = neurotic.MetadataSelector('../../data/metadata.yml')\n",
    "metadata.select(data_set_name)\n",
    "\n",
    "# ensure that the right filters are used\n",
    "metadata['filters'] = sig_filters_by_animal[animal]\n",
    "\n",
    "# load the data\n",
    "blk = neurotic.load_dataset(metadata, lazy=True)\n",
    "\n",
    "# manually perform filters\n",
    "blk = apply_filters(blk, metadata)\n",
    "\n",
    "# plot the signal\n",
    "fig, axes = prettyplot_with_scalebars(blk, t_start, t_stop, plots, **kwargs)\n",
    "\n",
    "units = [\n",
    "    'I2 spikes',\n",
    "#     'B8a/b',\n",
    "#     'B6/B9',\n",
    "#     'B3',\n",
    "#     'B38',\n",
    "]\n",
    "\n",
    "# # plot a zero baseline for force\n",
    "# ax = axes[-1]\n",
    "# force_zero = -11.5 # mN, average before animal began swallowing, not zero because of DC offset\n",
    "# ax.axhline(force_zero, color='0.75', lw=1, ls='--', zorder=-1)\n",
    "\n",
    "for j, i in enumerate(df.index):\n",
    "    \n",
    "    # plot force markers\n",
    "    force_shoulder_end = df.loc[i, 'Force shoulder end start (s)']*pq.s\n",
    "    force_shoulder_end_value = df.loc[i, 'Force shoulder end value (mN)']*pq.mN\n",
    "    force_min_time = df.loc[i, 'Force minimum time (s)']*pq.s\n",
    "    force_min = df.loc[i, 'Force minimum (mN)']*pq.mN\n",
    "    ax = axes[-1]\n",
    "    ax.plot([force_shoulder_end], [force_shoulder_end_value], marker=CARETDOWN, markersize=8, color='k')\n",
    "    ax.plot([force_min_time],     [force_min],                marker=CARETUP,   markersize=8, color='k')\n",
    "    \n",
    "    for k, unit in enumerate(units):\n",
    "                \n",
    "        # plot burst windows\n",
    "        burst_start = df.loc[i, unit+' first burst start (s)']\n",
    "        if np.isfinite(burst_start) and burst_start < t_stop:\n",
    "            burst_end = df.loc[i, unit+' last burst end (s)']\n",
    "            axes[-1].set_zorder(-1) # needed for trick below\n",
    "            axes[-1].axvspan(\n",
    "                burst_start, burst_end,\n",
    "                0, 999, clip_on=False, # trick for getting to span entire figure\n",
    "                facecolor=lighten_color(unit_colors[unit], amount=0.7), edgecolor=None, lw=0)\n",
    "\n",
    "fig.savefig(os.path.join(export_dir, 'figure-3B.png'), dpi=600)\n",
    "\n",
    "end = datetime.datetime.now()\n",
    "print('render time:', end-start)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ðŸŒ Figure 3C"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "start = datetime.datetime.now()\n",
    "\n",
    "df = df_exemplary_swallow\n",
    "(data_set_name, time_window) = feeding_bouts[exemplary_swallow]\n",
    "animal, _, _ = exemplary_swallow\n",
    "\n",
    "t_start, t_stop = time_window*pq.s\n",
    "plots = [\n",
    "#     {'channel': 'I2',       'units': 'uV', 'ylim': [ -50,  50], 'scalebar': 50}, #, 'decimation_factor': 100},\n",
    "#     {'channel': 'RN',       'units': 'uV', 'ylim': [ -25,  25], 'scalebar': 25}, #, 'decimation_factor': 100},\n",
    "    {'channel': 'BN2',      'units': 'uV', 'ylim': [ -45,  45], 'scalebar': 50}, #, 'decimation_factor': 100},\n",
    "#     {'channel': 'BN3-DIST', 'units': 'uV', 'ylim': [ -60,  60], 'scalebar': 50, 'ylabel': 'BN3'}, #, 'decimation_factor': 100},\n",
    "    {'channel': 'Force',    'units': 'mN', 'ylim': [ -20, 375], 'scalebar': 300}, #, 'decimation_factor': 100},\n",
    "]\n",
    "\n",
    "kwargs = dict(\n",
    "    figsize = (12, 1), #1.5),\n",
    "    linewidth = 0.5,\n",
    "    x_scalebar = None, #5*pq.s,\n",
    ")\n",
    "\n",
    "# load the metadata\n",
    "metadata = neurotic.MetadataSelector('../../data/metadata.yml')\n",
    "metadata.select(data_set_name)\n",
    "\n",
    "# ensure that the right filters are used\n",
    "metadata['filters'] = sig_filters_by_animal[animal]\n",
    "\n",
    "# load the data\n",
    "blk = neurotic.load_dataset(metadata, lazy=True)\n",
    "\n",
    "# manually perform filters\n",
    "blk = apply_filters(blk, metadata)\n",
    "\n",
    "# plot the signal\n",
    "fig, axes = prettyplot_with_scalebars(blk, t_start, t_stop, plots, **kwargs)\n",
    "\n",
    "units = [\n",
    "#     'I2 spikes',\n",
    "#     'B8a/b',\n",
    "#     'B6/B9',\n",
    "#     'B3',\n",
    "    'B38',\n",
    "]\n",
    "\n",
    "# # plot a zero baseline for force\n",
    "# ax = axes[-1]\n",
    "# force_zero = -11.5 # mN, average before animal began swallowing, not zero because of DC offset\n",
    "# ax.axhline(force_zero, color='0.75', lw=1, ls='--', zorder=-1)\n",
    "\n",
    "for j, i in enumerate(df.index):\n",
    "    \n",
    "    # plot force markers\n",
    "    force_shoulder_end = df.loc[i, 'Force shoulder end start (s)']*pq.s\n",
    "    force_shoulder_end_value = df.loc[i, 'Force shoulder end value (mN)']*pq.mN\n",
    "    ax = axes[-1]\n",
    "    ax.plot([force_shoulder_end], [force_shoulder_end_value], marker=CARETDOWN, markersize=8, color='k')\n",
    "    \n",
    "    for k, unit in enumerate(units):\n",
    "                \n",
    "        # plot burst windows\n",
    "        burst_start = df.loc[i, unit+' first burst start (s)']\n",
    "        if np.isfinite(burst_start) and burst_start < t_stop:\n",
    "            burst_end = df.loc[i, unit+' last burst end (s)']\n",
    "            burst_end = min(burst_end, t_stop) # hack to prevent unclipped rect entering margin\n",
    "            axes[-1].set_zorder(-1) # needed for trick below\n",
    "            axes[-1].axvspan(\n",
    "                burst_start, burst_end,\n",
    "                0, 999, clip_on=False, # trick for getting to span entire figure\n",
    "                facecolor=lighten_color(unit_colors[unit], amount=0.7), edgecolor=None, lw=0)\n",
    "\n",
    "fig.savefig(os.path.join(export_dir, 'figure-3C.png'), dpi=600)\n",
    "\n",
    "end = datetime.datetime.now()\n",
    "print('render time:', end-start)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "### ðŸŒ Figure 3D"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "start = datetime.datetime.now()\n",
    "\n",
    "df = df_exemplary_swallow\n",
    "(data_set_name, time_window) = feeding_bouts[exemplary_swallow]\n",
    "animal, _, _ = exemplary_swallow\n",
    "\n",
    "t_start, t_stop = time_window*pq.s\n",
    "plots = [\n",
    "#     {'channel': 'I2',       'units': 'uV', 'ylim': [ -50,  50], 'scalebar': 50}, #, 'decimation_factor': 100},\n",
    "    {'channel': 'RN',       'units': 'uV', 'ylim': [ -25,  25], 'scalebar': 25}, #, 'decimation_factor': 100},\n",
    "#     {'channel': 'BN2',      'units': 'uV', 'ylim': [ -45,  45], 'scalebar': 50}, #, 'decimation_factor': 100},\n",
    "#     {'channel': 'BN3-DIST', 'units': 'uV', 'ylim': [ -60,  60], 'scalebar': 50, 'ylabel': 'BN3'}, #, 'decimation_factor': 100},\n",
    "    {'channel': 'Force',    'units': 'mN', 'ylim': [ -20, 375], 'scalebar': 300}, #, 'decimation_factor': 100},\n",
    "]\n",
    "\n",
    "kwargs = dict(\n",
    "    figsize = (12, 1), #1.5),\n",
    "    linewidth = 0.5,\n",
    "    x_scalebar = None, #5*pq.s,\n",
    ")\n",
    "\n",
    "# load the metadata\n",
    "metadata = neurotic.MetadataSelector('../../data/metadata.yml')\n",
    "metadata.select(data_set_name)\n",
    "\n",
    "# ensure that the right filters are used\n",
    "metadata['filters'] = sig_filters_by_animal[animal]\n",
    "\n",
    "# load the data\n",
    "blk = neurotic.load_dataset(metadata, lazy=True)\n",
    "\n",
    "# manually perform filters\n",
    "blk = apply_filters(blk, metadata)\n",
    "\n",
    "# plot the signal\n",
    "fig, axes = prettyplot_with_scalebars(blk, t_start, t_stop, plots, **kwargs)\n",
    "\n",
    "units = [\n",
    "#     'I2 spikes',\n",
    "    'B8a/b',\n",
    "#     'B6/B9',\n",
    "#     'B3',\n",
    "#     'B38',\n",
    "]\n",
    "\n",
    "# # plot a zero baseline for force\n",
    "# ax = axes[-1]\n",
    "# force_zero = -11.5 # mN, average before animal began swallowing, not zero because of DC offset\n",
    "# ax.axhline(force_zero, color='0.75', lw=1, ls='--', zorder=-1)\n",
    "\n",
    "for j, i in enumerate(df.index):\n",
    "    \n",
    "    # plot force markers\n",
    "    force_rise_start = df.loc[i, 'Force rise start start (s)']*pq.s\n",
    "    force_baseline = df.loc[i, 'Force baseline (mN)']*pq.mN\n",
    "    force_plateau_end = df.loc[i, 'Force plateau end start (s)']*pq.s\n",
    "    force_plateau_end_value = df.loc[i, 'Force plateau end value (mN)']*pq.mN\n",
    "    ax = axes[-1]\n",
    "    ax.plot([force_rise_start],  [force_baseline],          marker=CARETUP,   markersize=8, color='k')\n",
    "    ax.plot([force_plateau_end], [force_plateau_end_value], marker=CARETLEFT, markersize=8, color='k')\n",
    "    \n",
    "    for k, unit in enumerate(units):\n",
    "                \n",
    "        # plot burst windows\n",
    "        burst_start = df.loc[i, unit+' first burst start (s)']\n",
    "        if np.isfinite(burst_start) and burst_start < t_stop:\n",
    "            burst_end = df.loc[i, unit+' last burst end (s)']\n",
    "            burst_end = min(burst_end, t_stop) # hack to prevent unclipped rect entering margin\n",
    "            axes[-1].set_zorder(-1) # needed for trick below\n",
    "            axes[-1].axvspan(\n",
    "                burst_start, burst_end,\n",
    "                0, 999, clip_on=False, # trick for getting to span entire figure\n",
    "                facecolor=lighten_color(unit_colors[unit], amount=0.7), edgecolor=None, lw=0)\n",
    "\n",
    "fig.savefig(os.path.join(export_dir, 'figure-3D.png'), dpi=600)\n",
    "\n",
    "end = datetime.datetime.now()\n",
    "print('render time:', end-start)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ðŸŒ Figure 3E"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "start = datetime.datetime.now()\n",
    "\n",
    "df = df_exemplary_swallow\n",
    "(data_set_name, time_window) = feeding_bouts[exemplary_swallow]\n",
    "animal, _, _ = exemplary_swallow\n",
    "\n",
    "t_start, t_stop = time_window*pq.s\n",
    "plots = [\n",
    "#     {'channel': 'I2',       'units': 'uV', 'ylim': [ -50,  50], 'scalebar': 50}, #, 'decimation_factor': 100},\n",
    "#     {'channel': 'RN',       'units': 'uV', 'ylim': [ -25,  25], 'scalebar': 25}, #, 'decimation_factor': 100},\n",
    "#     {'channel': 'BN2',      'units': 'uV', 'ylim': [ -45,  45], 'scalebar': 50}, #, 'decimation_factor': 100},\n",
    "    {'channel': 'BN3-DIST', 'units': 'uV', 'ylim': [ -60,  60], 'scalebar': 50, 'ylabel': 'BN3'}, #, 'decimation_factor': 100},\n",
    "    {'channel': 'Force',    'units': 'mN', 'ylim': [ -20, 375], 'scalebar': 300}, #, 'decimation_factor': 100},\n",
    "]\n",
    "\n",
    "kwargs = dict(\n",
    "    figsize = (12, 1), #1.5),\n",
    "    linewidth = 0.5,\n",
    "    x_scalebar = None, #5*pq.s,\n",
    ")\n",
    "\n",
    "# load the metadata\n",
    "metadata = neurotic.MetadataSelector('../../data/metadata.yml')\n",
    "metadata.select(data_set_name)\n",
    "\n",
    "# ensure that the right filters are used\n",
    "metadata['filters'] = sig_filters_by_animal[animal]\n",
    "\n",
    "# load the data\n",
    "blk = neurotic.load_dataset(metadata, lazy=True)\n",
    "\n",
    "# manually perform filters\n",
    "blk = apply_filters(blk, metadata)\n",
    "\n",
    "# plot the signal\n",
    "fig, axes = prettyplot_with_scalebars(blk, t_start, t_stop, plots, **kwargs)\n",
    "\n",
    "units = [\n",
    "#     'I2 spikes',\n",
    "#     'B8a/b',\n",
    "#     'B6/B9',\n",
    "#     'B3',\n",
    "#     'B38',\n",
    "    'B4/B5',\n",
    "]\n",
    "\n",
    "# # plot a zero baseline for force\n",
    "# ax = axes[-1]\n",
    "# force_zero = -11.5 # mN, average before animal began swallowing, not zero because of DC offset\n",
    "# ax.axhline(force_zero, color='0.75', lw=1, ls='--', zorder=-1)\n",
    "\n",
    "for j, i in enumerate(df.index):\n",
    "    \n",
    "    # plot force markers\n",
    "    force_rise_start = df.loc[i, 'Force rise start start (s)']*pq.s\n",
    "    force_baseline = df.loc[i, 'Force baseline (mN)']*pq.mN\n",
    "    ax = axes[-1]\n",
    "    ax.plot([force_rise_start], [force_baseline], marker=CARETUP, markersize=8, color='k')\n",
    "    \n",
    "    for k, unit in enumerate(units):\n",
    "                \n",
    "        # plot burst windows\n",
    "        burst_start = df.loc[i, unit+' first burst start (s)']\n",
    "        if np.isfinite(burst_start) and burst_start < t_stop:\n",
    "            burst_end = df.loc[i, unit+' last burst end (s)']\n",
    "            burst_end = min(burst_end, t_stop) # hack to prevent unclipped rect entering margin\n",
    "            axes[-1].set_zorder(-1) # needed for trick below\n",
    "            axes[-1].axvspan(\n",
    "                burst_start, burst_end,\n",
    "                0, 999, clip_on=False, # trick for getting to span entire figure\n",
    "                facecolor=lighten_color(unit_colors[unit], amount=0.7), edgecolor=None, lw=0)\n",
    "\n",
    "fig.savefig(os.path.join(export_dir, 'figure-3E.png'), dpi=600)\n",
    "\n",
    "end = datetime.datetime.now()\n",
    "print('render time:', end-start)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ðŸŒ Figure 3F"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "start = datetime.datetime.now()\n",
    "\n",
    "df = df_exemplary_swallow\n",
    "(data_set_name, time_window) = feeding_bouts[exemplary_swallow]\n",
    "animal, _, _ = exemplary_swallow\n",
    "\n",
    "t_start, t_stop = time_window*pq.s\n",
    "plots = [\n",
    "#     {'channel': 'I2',       'units': 'uV', 'ylim': [ -50,  50], 'scalebar': 50}, #, 'decimation_factor': 100},\n",
    "#     {'channel': 'RN',       'units': 'uV', 'ylim': [ -25,  25], 'scalebar': 25}, #, 'decimation_factor': 100},\n",
    "    {'channel': 'BN2',      'units': 'uV', 'ylim': [ -45,  45], 'scalebar': 50}, #, 'decimation_factor': 100},\n",
    "#     {'channel': 'BN3-DIST', 'units': 'uV', 'ylim': [ -60,  60], 'scalebar': 50, 'ylabel': 'BN3'}, #, 'decimation_factor': 100},\n",
    "    {'channel': 'Force',    'units': 'mN', 'ylim': [ -20, 375], 'scalebar': 300}, #, 'decimation_factor': 100},\n",
    "]\n",
    "\n",
    "kwargs = dict(\n",
    "    figsize = (12, 1), #1.5),\n",
    "    linewidth = 0.5,\n",
    "    x_scalebar = None, #5*pq.s,\n",
    ")\n",
    "\n",
    "# load the metadata\n",
    "metadata = neurotic.MetadataSelector('../../data/metadata.yml')\n",
    "metadata.select(data_set_name)\n",
    "\n",
    "# ensure that the right filters are used\n",
    "metadata['filters'] = sig_filters_by_animal[animal]\n",
    "\n",
    "# load the data\n",
    "blk = neurotic.load_dataset(metadata, lazy=True)\n",
    "\n",
    "# manually perform filters\n",
    "blk = apply_filters(blk, metadata)\n",
    "\n",
    "# plot the signal\n",
    "fig, axes = prettyplot_with_scalebars(blk, t_start, t_stop, plots, **kwargs)\n",
    "\n",
    "units = [\n",
    "#     'I2 spikes',\n",
    "#     'B8a/b',\n",
    "    'B6/B9',\n",
    "#     'B3',\n",
    "#     'B38',\n",
    "]\n",
    "\n",
    "# # plot a zero baseline for force\n",
    "# ax = axes[-1]\n",
    "# force_zero = -11.5 # mN, average before animal began swallowing, not zero because of DC offset\n",
    "# ax.axhline(force_zero, color='0.75', lw=1, ls='--', zorder=-1)\n",
    "\n",
    "for j, i in enumerate(df.index):\n",
    "    \n",
    "    # plot force markers\n",
    "    force_rise_start = df.loc[i, 'Force rise start start (s)']*pq.s\n",
    "    force_baseline = df.loc[i, 'Force baseline (mN)']*pq.mN\n",
    "    force_plateau_end = df.loc[i, 'Force plateau end start (s)']*pq.s\n",
    "    force_plateau_end_value = df.loc[i, 'Force plateau end value (mN)']*pq.mN\n",
    "    ax = axes[-1]\n",
    "    ax.plot([force_rise_start],  [force_baseline],          marker=CARETUP,   markersize=8, color='k')\n",
    "    ax.plot([force_plateau_end], [force_plateau_end_value], marker=CARETLEFT, markersize=8, color='k')\n",
    "    \n",
    "    for k, unit in enumerate(units):\n",
    "                \n",
    "        # plot burst windows\n",
    "        burst_start = df.loc[i, unit+' first burst start (s)']\n",
    "        if np.isfinite(burst_start) and burst_start < t_stop:\n",
    "            burst_end = df.loc[i, unit+' last burst end (s)']\n",
    "            burst_end = min(burst_end, t_stop) # hack to prevent unclipped rect entering margin\n",
    "            axes[-1].set_zorder(-1) # needed for trick below\n",
    "            axes[-1].axvspan(\n",
    "                burst_start, burst_end,\n",
    "                0, 999, clip_on=False, # trick for getting to span entire figure\n",
    "                facecolor=lighten_color(unit_colors[unit], amount=0.7), edgecolor=None, lw=0)\n",
    "\n",
    "fig.savefig(os.path.join(export_dir, 'figure-3F.png'), dpi=600)\n",
    "\n",
    "end = datetime.datetime.now()\n",
    "print('render time:', end-start)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ðŸŒ Figure 3G"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "start = datetime.datetime.now()\n",
    "\n",
    "df = df_exemplary_swallow\n",
    "(data_set_name, time_window) = feeding_bouts[exemplary_swallow]\n",
    "animal, _, _ = exemplary_swallow\n",
    "\n",
    "t_start, t_stop = time_window*pq.s\n",
    "plots = [\n",
    "#     {'channel': 'I2',       'units': 'uV', 'ylim': [ -50,  50], 'scalebar': 50}, #, 'decimation_factor': 100},\n",
    "#     {'channel': 'RN',       'units': 'uV', 'ylim': [ -25,  25], 'scalebar': 25}, #, 'decimation_factor': 100},\n",
    "    {'channel': 'BN2',      'units': 'uV', 'ylim': [ -45,  45], 'scalebar': 50}, #, 'decimation_factor': 100},\n",
    "#     {'channel': 'BN3-DIST', 'units': 'uV', 'ylim': [ -60,  60], 'scalebar': 50, 'ylabel': 'BN3'}, #, 'decimation_factor': 100},\n",
    "    {'channel': 'Force',    'units': 'mN', 'ylim': [ -20, 375], 'scalebar': 300}, #, 'decimation_factor': 100},\n",
    "]\n",
    "\n",
    "kwargs = dict(\n",
    "    figsize = (12, 1.5), #1),\n",
    "    linewidth = 0.5,\n",
    "    x_scalebar = 5*pq.s, #None,\n",
    ")\n",
    "\n",
    "# load the metadata\n",
    "metadata = neurotic.MetadataSelector('../../data/metadata.yml')\n",
    "metadata.select(data_set_name)\n",
    "\n",
    "# ensure that the right filters are used\n",
    "metadata['filters'] = sig_filters_by_animal[animal]\n",
    "\n",
    "# load the data\n",
    "blk = neurotic.load_dataset(metadata, lazy=True)\n",
    "\n",
    "# manually perform filters\n",
    "blk = apply_filters(blk, metadata)\n",
    "\n",
    "# plot the signal\n",
    "fig, axes = prettyplot_with_scalebars(blk, t_start, t_stop, plots, **kwargs)\n",
    "\n",
    "units = [\n",
    "#     'I2 spikes',\n",
    "#     'B8a/b',\n",
    "#     'B6/B9',\n",
    "    'B3',\n",
    "#     'B38',\n",
    "]\n",
    "\n",
    "# # plot a zero baseline for force\n",
    "# ax = axes[-1]\n",
    "# force_zero = -11.5 # mN, average before animal began swallowing, not zero because of DC offset\n",
    "# ax.axhline(force_zero, color='0.75', lw=1, ls='--', zorder=-1)\n",
    "\n",
    "for j, i in enumerate(df.index):\n",
    "    \n",
    "    # plot force markers\n",
    "    force_plateau_start = df.loc[i, 'Force plateau start start (s)']*pq.s\n",
    "    force_plateau_start_value = df.loc[i, 'Force plateau start value (mN)']*pq.mN\n",
    "    force_plateau_end = df.loc[i, 'Force plateau end start (s)']*pq.s\n",
    "    force_plateau_end_value = df.loc[i, 'Force plateau end value (mN)']*pq.mN\n",
    "    ax = axes[-1]\n",
    "    ax.plot([force_plateau_start], [force_plateau_start_value], marker=CARETRIGHT, markersize=8, color='k')\n",
    "    ax.plot([force_plateau_end],   [force_plateau_end_value],   marker=CARETLEFT,  markersize=8, color='k')\n",
    "    \n",
    "    for k, unit in enumerate(units):\n",
    "                \n",
    "        # plot burst windows\n",
    "        burst_start = df.loc[i, unit+' first burst start (s)']\n",
    "        if np.isfinite(burst_start) and burst_start < t_stop:\n",
    "            burst_end = df.loc[i, unit+' last burst end (s)']\n",
    "            burst_end = min(burst_end, t_stop) # hack to prevent unclipped rect entering margin\n",
    "            axes[-1].set_zorder(-1) # needed for trick below\n",
    "            axes[-1].axvspan(\n",
    "                burst_start, burst_end,\n",
    "                0, 999, clip_on=False, # trick for getting to span entire figure\n",
    "                facecolor=lighten_color(unit_colors[unit], amount=0.7), edgecolor=None, lw=0)\n",
    "\n",
    "fig.savefig(os.path.join(export_dir, 'figure-3G.png'), dpi=600)\n",
    "\n",
    "end = datetime.datetime.now()\n",
    "print('render time:', end-start)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## [FIGURE 4]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# normalization_fixed_times_labels = [\n",
    "#     'prev_force_plateau_start',\n",
    "#     'prev_force_plateau_end',\n",
    "#     'prev_force_drop_end',\n",
    "#     'force_shoulder_end',\n",
    "#     'force_rise_start',\n",
    "#     'force_plateau_start',\n",
    "#     'force_plateau_end',\n",
    "#     'force_drop_end',\n",
    "#     'next_force_shoulder_end',\n",
    "#     'next_force_rise_start'\n",
    "# ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# use only tape nori swallows\n",
    "df = df_all.query('Food == \"Tape nori\"')\n",
    "\n",
    "# get all normalization times from previous force drop end to current drop end\n",
    "t = np.array([times.magnitude[2:8] for times in df['Normalization fixed times (s)']])\n",
    "\n",
    "# get all phase durations\n",
    "all_phase_durations = np.diff(t).T\n",
    "\n",
    "# find median phase durations\n",
    "# - 0: partial force maintenance\n",
    "# - 1: force dip\n",
    "# - 2: force rise\n",
    "# - 3: force maintenance\n",
    "# - 4: major force drop\n",
    "median_phase_durations = np.nanmedian(all_phase_durations, axis=1)\n",
    "\n",
    "# copy phases to represent \"previous\" and \"next\" swallows\n",
    "# - 0: previous force maintenance\n",
    "# - 1: previous major force drop\n",
    "# - 2: partial force maintenance\n",
    "# - 3: force dip\n",
    "# - 4: force rise\n",
    "# - 5: force maintenance\n",
    "# - 6: major force drop\n",
    "# - 7: next partial force maintenance\n",
    "# - 8: next force dip\n",
    "median_phase_durations = np.concatenate([\n",
    "    median_phase_durations[-2:],\n",
    "    median_phase_durations,\n",
    "    median_phase_durations[:2]\n",
    "])\n",
    "\n",
    "# convert durations into boundary timings\n",
    "median_phase_boundaries = np.concatenate([[0], median_phase_durations]).cumsum()\n",
    "\n",
    "# phase_labels = [\n",
    "#     'IV\\nPrevious force\\nmaintenance',\n",
    "#     'V\\nPrevious major\\nforce drop',\n",
    "#     'I\\nPartial force\\nmaintenance',\n",
    "#     'II\\nForce dip',\n",
    "#     'III\\nForce rise',\n",
    "#     'IV\\nForce\\nmaintenance',\n",
    "#     'V\\nMajor\\nforce drop',\n",
    "#     'I\\nNext partial\\nforce maintenance',\n",
    "#     'II\\nNext\\nforce dip',\n",
    "# ]\n",
    "phase_labels = [\n",
    "    '',\n",
    "    'V',\n",
    "    'I',\n",
    "    'II',\n",
    "    'III',\n",
    "    'IV',\n",
    "    'V',\n",
    "    '',\n",
    "    '',\n",
    "]\n",
    "\n",
    "# shared settings for Figures 4A and 4B\n",
    "figure_4_xlim = [1.2, 10.3]\n",
    "figure_4_unit_fontsize = 12"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure()\n",
    "\n",
    "plt.boxplot(\n",
    "    [a[np.isfinite(a)] for a in list(all_phase_durations)],\n",
    "    labels=phase_labels[2:7],\n",
    "    showmeans=True,\n",
    ")\n",
    "\n",
    "plt.ylabel('Duration (s)')\n",
    "plt.tight_layout()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for t, l in zip(all_phase_durations, phase_labels[2:7]):\n",
    "    l = l.replace('\\n', ' ')\n",
    "    print(f'{l}:\\tmedian {np.nanmedian(t):g}, mean {np.nanmean(t):g} (n={t[np.isfinite(t)].size})')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ðŸŒ Figure 4A"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plt.figure(figsize=(9, 5))\n",
    "plt.figure(figsize=(7, 4))\n",
    "ax = plt.gca()\n",
    "\n",
    "units = ['I2 spikes', 'B8a/b', 'B6/B9', 'B3', 'B38', 'B4/B5']\n",
    "\n",
    "# use only tape nori swallows\n",
    "df = df_all.query('Food == \"Tape nori\"')\n",
    "\n",
    "for i, unit in enumerate(units):\n",
    "    t0_data   = df[f'{unit} first burst start (normalized)'].dropna()\n",
    "    t0_data[:] = unnormalize_time(median_phase_boundaries, t0_data.values)\n",
    "    t0_median = t0_data.median()\n",
    "    t0_q1     = t0_data.quantile(0.25)\n",
    "    t0_q3     = t0_data.quantile(0.75)\n",
    "    \n",
    "    t1_data   = df[f'{unit} last burst end (normalized)'].dropna()\n",
    "    t1_data[:] = unnormalize_time(median_phase_boundaries, t1_data.values)\n",
    "    t1_median = t1_data.median()\n",
    "    t1_q1     = t1_data.quantile(0.25)\n",
    "    t1_q3     = t1_data.quantile(0.75)\n",
    "    \n",
    "    # plot boxes using medians\n",
    "    height = 0.8\n",
    "    lw = 1\n",
    "    rect = patches.Rectangle((t0_median, i-height/2), t1_median-t0_median, height, facecolor=unit_colors[unit], edgecolor='k', lw=lw, clip_on=False)\n",
    "    ax.add_patch(rect)\n",
    "    \n",
    "    # plot quartiles (25% and 75% quantiles)\n",
    "    ax.add_line(mlines.Line2D([t0_q1, t0_q1], [i-0.2, i+0.2], color='k', lw=lw, clip_on=False))\n",
    "    ax.add_line(mlines.Line2D([t0_q3, t0_q3], [i-0.2, i+0.2], color='k', lw=lw, clip_on=False))\n",
    "    ax.add_line(mlines.Line2D([t1_q1, t1_q1], [i-0.2, i+0.2], color='k', lw=lw, clip_on=False))\n",
    "    ax.add_line(mlines.Line2D([t1_q3, t1_q3], [i-0.2, i+0.2], color='k', lw=lw, clip_on=False))\n",
    "    ax.add_line(mlines.Line2D([t0_q1, t0_q3], [i, i], color='k', lw=lw, clip_on=False))\n",
    "    ax.add_line(mlines.Line2D([t1_q1, t1_q3], [i, i], color='k', lw=lw, clip_on=False))\n",
    "\n",
    "###\n",
    "### LABELS AND ANNOTATIONS\n",
    "###\n",
    "\n",
    "# drop some phases\n",
    "trimmed_median_phase_boundaries = median_phase_boundaries[1:8]\n",
    "trimmed_phase_labels = phase_labels[1:8]\n",
    "\n",
    "for x in trimmed_median_phase_boundaries:\n",
    "    plt.axvline(x=x, ls=':', lw=1, c='gray', zorder=-1, clip_on=False)\n",
    "\n",
    "plt.xlabel(None)\n",
    "plt.ylabel(None)\n",
    "\n",
    "sns.despine(bottom=True, left=True)\n",
    "plt.tick_params(bottom=False, left=False) # disable tick marks\n",
    "plt.xticks(trimmed_median_phase_boundaries[:-1]+np.diff(trimmed_median_phase_boundaries)/2, trimmed_phase_labels)\n",
    "units2 = units\n",
    "units2[0] = 'I2'\n",
    "plt.yticks(range(len(units)), units2, fontsize=figure_4_unit_fontsize)\n",
    "\n",
    "plt.xlim(figure_4_xlim)\n",
    "plt.ylim(5.9, -0.5)\n",
    "\n",
    "ax.tick_params(\n",
    "    axis='x',\n",
    "    labelsize='small',\n",
    ")\n",
    "\n",
    "ax.add_artist(AnchoredScaleBar(\n",
    "    ax.transData,\n",
    "    sizex=1,\n",
    "    labelx='1 s',\n",
    "\n",
    "    loc='lower right',\n",
    "    bbox_to_anchor=(1, 0),\n",
    "    bbox_transform=ax.transAxes,\n",
    "\n",
    "    pad=0,\n",
    "    borderpad=1,\n",
    "    sep=5,\n",
    "    barwidth=2,\n",
    "))\n",
    "\n",
    "# plt.tight_layout(h_pad=0, pad=0)\n",
    "plt.subplots_adjust(\n",
    "    left   = 0.08,\n",
    "    right  = 0.90,\n",
    "    bottom = 0.10,\n",
    "    top    = 0.99,\n",
    "    wspace = 0.2,\n",
    "    hspace = 0.2,\n",
    ")\n",
    "\n",
    "plt.gcf().savefig(os.path.join(export_dir, 'figure-4A.png'), dpi=600)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# use only tape nori swallows\n",
    "df = df_all.query('Food == \"Tape nori\"')\n",
    "\n",
    "for i, unit in enumerate(['I2 spikes', 'B8a/b', 'B6/B9', 'B3', 'B38', 'B4/B5']):\n",
    "    t0_data   = df[f'{unit} first burst start (normalized)'].dropna()\n",
    "    t0_data[:] = unnormalize_time(median_phase_boundaries, t0_data.values)\n",
    "    t0_median = t0_data.median()\n",
    "    t0_N      = t0_data.size\n",
    "    \n",
    "    t1_data   = df[f'{unit} last burst end (normalized)'].dropna()\n",
    "    t1_data[:] = unnormalize_time(median_phase_boundaries, t1_data.values)\n",
    "    t1_median = t1_data.median()\n",
    "    t1_N      = t1_data.size\n",
    "\n",
    "    print(f'{unit}:\\t[{t0_median:.2f} (n={t0_N}), {t1_median:.2f} (n={t1_N})], duration: {t1_median-t0_median:.2f}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ðŸŒ Figure 4B"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "times_interp_unnormalized = unnormalize_time(median_phase_boundaries, times_interp)\n",
    "\n",
    "# find the number of data points in one cycle\n",
    "n = np.where((4 <= times_interp) & (times_interp <= 9))[0].size # 4 = start of rise, 9 = start of next rise\n",
    "\n",
    "units = [\n",
    "    'I2 spikes',\n",
    "    'B8a/b',\n",
    "    'B6/B9',\n",
    "    'B3',\n",
    "    'B38',\n",
    "    'B4/B5',\n",
    "]\n",
    "\n",
    "# figsize = (9, 8)\n",
    "figsize = (7, 6)\n",
    "# figsize = (9.5, 10) # dimensions for notebook\n",
    "# figsize = (11, 8.5) # dimensions for printing\n",
    "# figsize = (16, 9) # dimensions for filling wide screens\n",
    "fig, axes = plt.subplots(len(units)+1, 1, sharex='col', figsize=figsize)\n",
    "\n",
    "###\n",
    "### UNITS\n",
    "###\n",
    "\n",
    "# use only tape nori swallows\n",
    "df = df_all.query('Food == \"Tape nori\"')\n",
    "\n",
    "for i, unit in enumerate(units):\n",
    "    ax = axes[i]\n",
    "    \n",
    "    # elevate the Axes for units and remove background colors so that\n",
    "    # each vertical ConnectionPatch drawn later is visible behind it\n",
    "    ax.set_zorder(1)\n",
    "    ax.set_facecolor('none')\n",
    "    \n",
    "    # find the firing rate median and quartiles\n",
    "    firing_rate_data = np.array(list(df[unit+' firing rate, normalized time interpolation (Hz)']))\n",
    "    firing_rate_median = np.nanmedian(firing_rate_data, axis=0)\n",
    "    firing_rate_q1 = np.nanquantile(firing_rate_data, q=0.25, axis=0)\n",
    "    firing_rate_q3 = np.nanquantile(firing_rate_data, q=0.75, axis=0)\n",
    "\n",
    "    # plot the firing rate median and quartiles (median last so it's on top)\n",
    "    ax.plot(times_interp_unnormalized, firing_rate_q1,     c=lighten_color(unit_colors[unit], amount=0.7), lw=1, zorder=2)\n",
    "    ax.plot(times_interp_unnormalized, firing_rate_q3,     c=lighten_color(unit_colors[unit], amount=0.7), lw=1, zorder=2)\n",
    "    ax.plot(times_interp_unnormalized, firing_rate_median, c=unit_colors[unit], lw=2, zorder=2)\n",
    "\n",
    "    \n",
    "    ax.set_ylim([0, None])\n",
    "    if unit == 'I2 spikes':\n",
    "        ax.set_ylabel('I2', rotation='horizontal', ha='right', va='center', labelpad=10, fontsize=figure_4_unit_fontsize)\n",
    "    else:\n",
    "        ax.set_ylabel(unit, rotation='horizontal', ha='right', va='center', labelpad=10, fontsize=figure_4_unit_fontsize)\n",
    "#     ax.yaxis.set_label_coords(-0.06, 0.5)\n",
    "\n",
    "# remove right and top plot borders, and remove x-axis\n",
    "#     sns.despine(ax=ax)#, bottom=True)\n",
    "    sns.despine(ax=ax, left=True, right=False)#, trim=True)\n",
    "#     ax.xaxis.set_visible(False)\n",
    "\n",
    "#     ax.tick_params(bottom=False) # disable tick marks\n",
    "    # disable tick marks\n",
    "    ax.tick_params(\n",
    "        bottom=False,\n",
    "        left=False,\n",
    "        right=True,\n",
    "        labelbottom=False,\n",
    "        labelleft=False)\n",
    "\n",
    "#     ax.set_yticks([0, 10, 20])\n",
    "#     ax.set_yticklabels([0, 10, '20 Hz'])\n",
    "#     ax.set_yticks(ax.get_yticks()) # trick to prevent tight_layout from changing ticks\n",
    "#     yticklabels = [f'{y:g}' for y in ax.get_yticks()]\n",
    "#     yticklabels[-1] += ' Hz'\n",
    "#     ax.set_yticklabels(yticklabels)\n",
    "    \n",
    "\n",
    "\n",
    "#     # add freq scale bar\n",
    "#     ax.add_artist(AnchoredScaleBar(\n",
    "#         ax.transData,\n",
    "#         sizey=10,\n",
    "#         labely='10 Hz',\n",
    "\n",
    "#         loc='center left',\n",
    "#         bbox_to_anchor=(1, 0.5),\n",
    "#         bbox_transform=ax.transAxes,\n",
    "\n",
    "#         pad=0,\n",
    "#         borderpad=1,\n",
    "#         sep=5,\n",
    "#         barwidth=2,\n",
    "#     ))\n",
    "\n",
    "###\n",
    "### FORCE\n",
    "###\n",
    "\n",
    "ax = axes[-1]\n",
    "\n",
    "force_data = np.array(list(df['Force, normalized time interpolation (mN)']))\n",
    "\n",
    "# def tile_array(arr, i_start, i_stop, axis=1):\n",
    "#     arr = arr.copy()\n",
    "#     n = i_stop - i_start\n",
    "    \n",
    "#     ind_before, ind_after = [slice(None)]*arr.ndim, [slice(None)]*arr.ndim\n",
    "#     ind_before[axis] = slice(None, i_start)\n",
    "#     ind_after[axis] = slice(i_stop+1, None)\n",
    "    \n",
    "#     # replace values outside of range with NaN\n",
    "#     arr[tuple(ind_before)] = np.nan\n",
    "#     arr[tuple(ind_after)] = np.nan\n",
    "    \n",
    "#     # construct versions of arr shifted to the left and right\n",
    "#     arr_nan = np.full_like(arr, np.nan)\n",
    "#     arr_nan = arr_nan\n",
    "#     arr_nan = np.full((arr.shape[0], n), np.nan)\n",
    "#     left = np.concatenate((arr[:, n:], arr_nan), axis=1)\n",
    "#     right = np.concatenate((arr_nan, arr[:, :-n]), axis=1)\n",
    "    \n",
    "#     # merge arrays\n",
    "#     arr = np.nanmax([\n",
    "#         arr,\n",
    "#         left,\n",
    "#         right\n",
    "#     ], axis=0) # can axis be generalized?\n",
    "    \n",
    "#     return arr\n",
    "\n",
    "# # replace the \"previous\" swallow force data with a repeat of the \"current\" swallow\n",
    "# force_data = tile_array(force_data, i_start, i_stop)\n",
    "\n",
    "# find the force median and quartiles\n",
    "force_median = np.nanmedian(force_data, axis=0)\n",
    "force_q1 = np.nanquantile(force_data, q=0.25, axis=0)\n",
    "force_q3 = np.nanquantile(force_data, q=0.75, axis=0)\n",
    "\n",
    "# plot the force median and quartiles (median last so it's on top)\n",
    "ax.plot(times_interp_unnormalized, force_q1,     c=lighten_color('k', amount=0.7), lw=1, zorder=2)\n",
    "ax.plot(times_interp_unnormalized, force_q3,     c=lighten_color('k', amount=0.7), lw=1, zorder=2)\n",
    "ax.plot(times_interp_unnormalized, force_median, c='k', lw=2, zorder=2)\n",
    "\n",
    "ax.set_ylim([0, None])\n",
    "ax.set_ylabel('Force', rotation='horizontal', ha='right', va='center', labelpad=10, fontsize=figure_4_unit_fontsize)\n",
    "# ax.yaxis.set_label_coords(-0.06, 0.5)\n",
    "\n",
    "# drop some phases\n",
    "trimmed_median_phase_boundaries = median_phase_boundaries[1:8]\n",
    "trimmed_phase_labels = phase_labels[1:8]\n",
    "\n",
    "# remove right and top plot borders from bottom panel, and set x-label\n",
    "sns.despine(ax=ax, left=True, right=False)#, trim=True)\n",
    "ax.set_xlim(figure_4_xlim)\n",
    "# ax.tick_params(bottom=False) # disable tick marks\n",
    "# disable tick marks\n",
    "ax.tick_params(\n",
    "    bottom=False,\n",
    "    left=False,\n",
    "    right=True,\n",
    "#     labelbottom=False,\n",
    "    labelleft=False)\n",
    "ax.tick_params(\n",
    "    axis='x',\n",
    "    labelsize='small',\n",
    ")\n",
    "\n",
    "ax.set_xticks(trimmed_median_phase_boundaries[:-1]+np.diff(trimmed_median_phase_boundaries)/2)\n",
    "ax.set_xticklabels(trimmed_phase_labels)\n",
    "\n",
    "# ax.set_yticks([0, 100, 200])\n",
    "# ax.set_yticklabels([0, 100, '200 mN'])\n",
    "# ax.set_yticks(ax.get_yticks()) # trick to prevent tight_layout from changing ticks\n",
    "# yticklabels = [f'{y:g}' for y in ax.get_yticks()]\n",
    "# yticklabels[-1] += ' mN'\n",
    "# ax.set_yticklabels(yticklabels)\n",
    "       \n",
    "# plot force phase boundaries in normalized time\n",
    "for t in trimmed_median_phase_boundaries:\n",
    "    ax.add_artist(patches.ConnectionPatch(\n",
    "        xyA=(t, 0), xyB=(t, 1),\n",
    "        coordsA=ax.get_xaxis_transform(), coordsB=axes[0].get_xaxis_transform(),\n",
    "        axesA=ax, axesB=axes[0],\n",
    "        color='gray', lw=1, ls=':', zorder=0))\n",
    "\n",
    "# add time scale bar\n",
    "ax.add_artist(AnchoredScaleBar(\n",
    "    ax.transData,\n",
    "    sizex=1,\n",
    "    labelx='1 s',\n",
    "\n",
    "    loc='upper right',\n",
    "    bbox_to_anchor=(1, 1),\n",
    "    bbox_transform=ax.transAxes,\n",
    "\n",
    "    pad=0,\n",
    "    borderpad=1,\n",
    "    sep=5,\n",
    "    barwidth=2,\n",
    "))\n",
    "\n",
    "# fig.tight_layout(h_pad=0, pad=0) # first tight_layout removes excess margins and sets reasonable ylims\n",
    "# fig.tight_layout(pad=0)\n",
    "\n",
    "# ylims = [\n",
    "#     [0, 20], # I2\n",
    "#     [0, 40], # B8a/b\n",
    "#     [0, 50], # B6/B9\n",
    "#     [0, 10], # B3\n",
    "#     [0, 15], # B38\n",
    "#     [0, 20], # B4/B5\n",
    "#     [0, 300], # Force\n",
    "# ]\n",
    "# for i, ax in enumerate(axes):\n",
    "#     ax.set_ylim(ylims[i])\n",
    "\n",
    "yticks = [\n",
    "    [0,  10,  20], # I2\n",
    "    [0,  20,  40], # B8a/b\n",
    "    [0,  25,  50], # B6/B9\n",
    "    [0,   5,  10], # B3\n",
    "    [0,  10,  20], # B38\n",
    "    [0,  10,  20], # B4/B5\n",
    "    [0, 150, 300], # Force\n",
    "]\n",
    "for i, ax in enumerate(axes):\n",
    "    ax.set_ylim([yticks[i][0], yticks[i][-1]])\n",
    "\n",
    "for i, unit in enumerate(units):\n",
    "    ax = axes[i]\n",
    "    ax.grid(axis='y', clip_on=False)\n",
    "#     ax.set_yticks(ax.get_yticks()) # trick to prevent tight_layout from changing ticks\n",
    "    ax.set_yticks(yticks[i])\n",
    "    yticklabels = [f'{y:g}' for y in ax.get_yticks()]\n",
    "    yticklabels[-1] += ' Hz'\n",
    "    ax.set_yticklabels(yticklabels)\n",
    "ax = axes[-1]\n",
    "ax.grid(axis='y', clip_on=False)\n",
    "# ax.set_yticks(ax.get_yticks()) # trick to prevent tight_layout from changing ticks\n",
    "ax.set_yticks(yticks[-1])\n",
    "yticklabels = [f'{y:g}' for y in ax.get_yticks()]\n",
    "yticklabels[-1] += ' mN'\n",
    "ax.set_yticklabels(yticklabels)\n",
    "\n",
    "# fig.tight_layout(h_pad=0, pad=0) # second tight_layout makes room for units added to y tick labels\n",
    "# fig.tight_layout(pad=0)\n",
    "\n",
    "plt.subplots_adjust(\n",
    "    left   = 0.08,\n",
    "    right  = 0.90,\n",
    "    bottom = 0.05,\n",
    "    top    = 0.99,\n",
    "    wspace = 0.2,\n",
    "    hspace = 0.2,\n",
    ")\n",
    "\n",
    "fig.savefig(os.path.join(export_dir, 'figure-4B.png'), dpi=600)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## [FIGURE 5]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ðŸŒ Figure 5A"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(1, 1, figsize=(4, 4))\n",
    "\n",
    "df = df_all.reset_index()\n",
    "df.loc[df['Food'] == 'Regular nori', 'Food'] = 'Unloaded'\n",
    "df.loc[df['Food'] == 'Tape nori',    'Food'] = 'Loaded'\n",
    "\n",
    "x = 'Food'\n",
    "y = 'B3/B6/B9 burst duration (s)'\n",
    "hue = 'Animal'\n",
    "\n",
    "sns.stripplot(\n",
    "    x=x, y=y, hue=hue,\n",
    "    data=df.groupby(['Animal', 'Food'])[y].mean().reset_index(),\n",
    "    order=['Unloaded', 'Loaded'],\n",
    "    jitter=False,\n",
    "    color='0.25',\n",
    ")\n",
    "ax.legend_.remove()\n",
    "\n",
    "ax.plot([\n",
    "    df.query('Food == \"Unloaded\"').groupby('Animal')[y].mean(),\n",
    "    df.query('Food == \"Loaded\"').groupby('Animal')[y].mean()\n",
    "], color='0.5')\n",
    "\n",
    "ax.set_xlim([-0.5, 1.5])\n",
    "ax.set_ylim([0, 4])\n",
    "ax.set_xlabel(None)\n",
    "plt.tight_layout()\n",
    "\n",
    "plt.gcf().savefig(os.path.join(export_dir, 'figure-5A.png'), dpi=300)\n",
    "\n",
    "df.groupby(['Animal', 'Food'])[y].mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y = 'B3/B6/B9 burst duration (s)'\n",
    "y_tape_nori = df_all.query('Food == \"Tape nori\"').groupby('Animal')[y].mean()\n",
    "y_reg_nori = df_all.query('Food == \"Regular nori\"').groupby('Animal')[y].mean()\n",
    "\n",
    "differences_test(y_tape_nori, y_reg_nori)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# fig, ax = plt.subplots(1, 1, figsize=(4, 4))\n",
    "\n",
    "# df = df_all.reset_index()\n",
    "# df.loc[df['Food'] == 'Regular nori', 'Food'] = 'Unloaded'\n",
    "# df.loc[df['Food'] == 'Tape nori',    'Food'] = 'Loaded'\n",
    "\n",
    "# x = 'Food'\n",
    "# y = 'B3/B6/B9 burst duration (s)'\n",
    "# hue = 'Animal'\n",
    "# show_points = True\n",
    "\n",
    "# boxplot_with_points(x, y, hue, df, ax, show_points)\n",
    "# ax.set_ylim([0, None])\n",
    "# plt.tight_layout()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ðŸŒ Figure 5B"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_all['B3/B6/B9 burst duration (s)'] = \\\n",
    "    df_all[['B6/B9 last burst end (s)',    'B3 last burst end (s)']]   .max(axis=1) - \\\n",
    "    df_all[['B6/B9 first burst start (s)', 'B3 first burst start (s)']].min(axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(5, 5))\n",
    "ax = plt.gca()\n",
    "\n",
    "data_subsets = [\n",
    "    'JG07 Tape nori',\n",
    "    'JG08 Tape nori',\n",
    "    'JG11 Tape nori',\n",
    "    'JG12 Tape nori',\n",
    "    'JG14 Tape nori',\n",
    "]\n",
    "data_subsets = {label:label2query(label) for label in data_subsets}\n",
    "\n",
    "# xlabel, xlim = 'B3 all bursts duration (s)', [0, 6]\n",
    "# xlabel, xlim = 'B6/B9 all bursts duration (s)', [0, 6]\n",
    "xlabel, xlim = 'B3/B6/B9 burst duration (s)', [0, 6]\n",
    "ylabel, ylabel_alt, ylim = 'Force plateau duration (s)', 'Force maintenance duration (s)', [0, 6]\n",
    "\n",
    "scatter2d(ax, data_subsets, xlabel, xlim, ylabel, ylim, trend=True, trend_separately=True, tooltips=False)\n",
    "plt.plot([0, 999], [0, 999], ls=':', c='gray', zorder=0)\n",
    "plt.ylabel(ylabel_alt)\n",
    "ax.legend()\n",
    "sns.despine(ax=ax, offset=20, trim=True)\n",
    "plt.tight_layout()\n",
    "\n",
    "plt.gcf().savefig(os.path.join(export_dir, 'figure-5B.png'), dpi=300)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(5, 5))\n",
    "ax = plt.gca()\n",
    "\n",
    "data_subsets = [\n",
    "    'JG07 Tape nori',\n",
    "#     'JG08 Tape nori',\n",
    "#     'JG11 Tape nori',\n",
    "#     'JG12 Tape nori',\n",
    "#     'JG14 Tape nori',\n",
    "]\n",
    "data_subsets = {label:label2query(label) for label in data_subsets}\n",
    "\n",
    "# xlabel, xlim = 'B3 all bursts duration (s)', [0, 6]\n",
    "# xlabel, xlim = 'B6/B9 all bursts duration (s)', [0, 6]\n",
    "xlabel, xlim = 'B3/B6/B9 burst duration (s)', [0, 6]\n",
    "ylabel, ylabel_alt, ylim = 'Force plateau duration (s)', 'Force maintenance duration (s)', [0, 6]\n",
    "\n",
    "scatter2d(ax, data_subsets, xlabel, xlim, ylabel, ylim, trend_separately=True, tooltips=False, colors=['k'])\n",
    "plt.plot([0, 999], [0, 999], ls=':', c='gray', zorder=0)\n",
    "plt.ylabel(ylabel_alt)\n",
    "# ax.legend()\n",
    "sns.despine(ax=ax, offset=20, trim=True)\n",
    "plt.tight_layout()\n",
    "\n",
    "plt.gcf().savefig(os.path.join(export_dir, 'figure-5B-JG07.png'), dpi=300)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(5, 5))\n",
    "ax = plt.gca()\n",
    "\n",
    "data_subsets = [\n",
    "#     'JG07 Tape nori',\n",
    "    'JG08 Tape nori',\n",
    "#     'JG11 Tape nori',\n",
    "#     'JG12 Tape nori',\n",
    "#     'JG14 Tape nori',\n",
    "]\n",
    "data_subsets = {label:label2query(label) for label in data_subsets}\n",
    "\n",
    "# xlabel, xlim = 'B3 all bursts duration (s)', [0, 6]\n",
    "# xlabel, xlim = 'B6/B9 all bursts duration (s)', [0, 6]\n",
    "xlabel, xlim = 'B3/B6/B9 burst duration (s)', [0, 6]\n",
    "ylabel, ylabel_alt, ylim = 'Force plateau duration (s)', 'Force maintenance duration (s)', [0, 6]\n",
    "\n",
    "scatter2d(ax, data_subsets, xlabel, xlim, ylabel, ylim, trend_separately=True, tooltips=False, colors=['k'])\n",
    "plt.plot([0, 999], [0, 999], ls=':', c='gray', zorder=0)\n",
    "plt.ylabel(ylabel_alt)\n",
    "# ax.legend()\n",
    "sns.despine(ax=ax, offset=20, trim=True)\n",
    "plt.tight_layout()\n",
    "\n",
    "plt.gcf().savefig(os.path.join(export_dir, 'figure-5B-JG08.png'), dpi=300)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(5, 5))\n",
    "ax = plt.gca()\n",
    "\n",
    "data_subsets = [\n",
    "#     'JG07 Tape nori',\n",
    "#     'JG08 Tape nori',\n",
    "    'JG11 Tape nori',\n",
    "#     'JG12 Tape nori',\n",
    "#     'JG14 Tape nori',\n",
    "]\n",
    "data_subsets = {label:label2query(label) for label in data_subsets}\n",
    "\n",
    "# xlabel, xlim = 'B3 all bursts duration (s)', [0, 6]\n",
    "# xlabel, xlim = 'B6/B9 all bursts duration (s)', [0, 6]\n",
    "xlabel, xlim = 'B3/B6/B9 burst duration (s)', [0, 6]\n",
    "ylabel, ylabel_alt, ylim = 'Force plateau duration (s)', 'Force maintenance duration (s)', [0, 6]\n",
    "\n",
    "scatter2d(ax, data_subsets, xlabel, xlim, ylabel, ylim, trend_separately=True, tooltips=False, colors=['k'])\n",
    "plt.plot([0, 999], [0, 999], ls=':', c='gray', zorder=0)\n",
    "plt.ylabel(ylabel_alt)\n",
    "# ax.legend()\n",
    "sns.despine(ax=ax, offset=20, trim=True)\n",
    "plt.tight_layout()\n",
    "\n",
    "plt.gcf().savefig(os.path.join(export_dir, 'figure-5B-JG11.png'), dpi=300)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(5, 5))\n",
    "ax = plt.gca()\n",
    "\n",
    "data_subsets = [\n",
    "#     'JG07 Tape nori',\n",
    "#     'JG08 Tape nori',\n",
    "#     'JG11 Tape nori',\n",
    "    'JG12 Tape nori',\n",
    "#     'JG14 Tape nori',\n",
    "]\n",
    "data_subsets = {label:label2query(label) for label in data_subsets}\n",
    "\n",
    "# xlabel, xlim = 'B3 all bursts duration (s)', [0, 6]\n",
    "# xlabel, xlim = 'B6/B9 all bursts duration (s)', [0, 6]\n",
    "xlabel, xlim = 'B3/B6/B9 burst duration (s)', [0, 6]\n",
    "ylabel, ylabel_alt, ylim = 'Force plateau duration (s)', 'Force maintenance duration (s)', [0, 6]\n",
    "\n",
    "scatter2d(ax, data_subsets, xlabel, xlim, ylabel, ylim, trend_separately=True, tooltips=False, colors=['k'])\n",
    "plt.plot([0, 999], [0, 999], ls=':', c='gray', zorder=0)\n",
    "plt.ylabel(ylabel_alt)\n",
    "# ax.legend()\n",
    "sns.despine(ax=ax, offset=20, trim=True)\n",
    "plt.tight_layout()\n",
    "\n",
    "plt.gcf().savefig(os.path.join(export_dir, 'figure-5B-JG12.png'), dpi=300)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(5, 5))\n",
    "ax = plt.gca()\n",
    "\n",
    "data_subsets = [\n",
    "#     'JG07 Tape nori',\n",
    "#     'JG08 Tape nori',\n",
    "#     'JG11 Tape nori',\n",
    "#     'JG12 Tape nori',\n",
    "    'JG14 Tape nori',\n",
    "]\n",
    "data_subsets = {label:label2query(label) for label in data_subsets}\n",
    "\n",
    "# xlabel, xlim = 'B3 all bursts duration (s)', [0, 6]\n",
    "# xlabel, xlim = 'B6/B9 all bursts duration (s)', [0, 6]\n",
    "xlabel, xlim = 'B3/B6/B9 burst duration (s)', [0, 6]\n",
    "ylabel, ylabel_alt, ylim = 'Force plateau duration (s)', 'Force maintenance duration (s)', [0, 6]\n",
    "\n",
    "scatter2d(ax, data_subsets, xlabel, xlim, ylabel, ylim, trend_separately=True, tooltips=False, colors=['k'])\n",
    "plt.plot([0, 999], [0, 999], ls=':', c='gray', zorder=0)\n",
    "plt.ylabel(ylabel_alt)\n",
    "# ax.legend()\n",
    "sns.despine(ax=ax, offset=20, trim=True)\n",
    "plt.tight_layout()\n",
    "\n",
    "plt.gcf().savefig(os.path.join(export_dir, 'figure-5B-JG14.png'), dpi=300)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "-"
    }
   },
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Random old figures"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_all['Delay from I2 end to force rise start (s)'] = \\\n",
    "    df_all['Force rise start start (s)'] - \\\n",
    "    df_all['I2 spikes last burst end (s)']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(5, 5))\n",
    "ax = plt.gca()\n",
    "\n",
    "df = df_all.reset_index()\n",
    "# column = 'Delay from I2 end to force min (s)'\n",
    "column = 'Delay from I2 end to force rise start (s)'\n",
    "\n",
    "sns.boxplot(y='Animal', x=column, data=df, fliersize=0, whis=999) # whis=999 ensures whiskers go to min and max\n",
    "# sns.swarmplot(y='Animal', x=column, data=df, color='0.25')\n",
    "\n",
    "# sns.boxplot(x=column, data=df, fliersize=0, whis=999) # whis=999 ensures whiskers go to min and max\n",
    "# sns.swarmplot(x=column, data=df, color='0.25')\n",
    "\n",
    "# plot zero line\n",
    "plt.axvline(x=0, ls=':', c='gray', zorder=-1)\n",
    "\n",
    "plt.tight_layout()\n",
    "\n",
    "# plt.gcf().savefig(os.path.join(export_dir, 'figure-X.png'), dpi=300)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_all['Delay from B3/B6/B9 start to force rise start (s)'] = \\\n",
    "    df_all['Force rise start start (s)'] - \\\n",
    "    df_all[['B6/B9 first burst start (s)', 'B3 first burst start (s)']].min(axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(5, 5))\n",
    "ax = plt.gca()\n",
    "\n",
    "df = df_all.reset_index()\n",
    "# column = 'Delay from B3/B6/B9 start to force start (s)'\n",
    "column = 'Delay from B3/B6/B9 start to force rise start (s)'\n",
    "\n",
    "sns.boxplot(y='Animal', x=column, data=df, fliersize=0, whis=999) # whis=999 ensures whiskers go to min and max\n",
    "sns.swarmplot(y='Animal', x=column, data=df, color='0.25')\n",
    "\n",
    "# sns.boxplot(x=column, data=df, fliersize=0, whis=999) # whis=999 ensures whiskers go to min and max\n",
    "# sns.swarmplot(x=column, data=df, color='0.25')\n",
    "\n",
    "# plot zero line\n",
    "plt.axvline(x=0, ls=':', c='gray', zorder=-1)\n",
    "\n",
    "plt.tight_layout()\n",
    "\n",
    "# plt.gcf().savefig(os.path.join(export_dir, 'figure-X.png'), dpi=300)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_all['Delay from B8a/b start to force rise start (s)'] = \\\n",
    "    df_all['Force rise start start (s)'] - \\\n",
    "    df_all['B8a/b first burst start (s)']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(5, 5))\n",
    "ax = plt.gca()\n",
    "\n",
    "df = df_all.reset_index()\n",
    "# column = 'Delay from B8a/b start to force start (s)'\n",
    "column = 'Delay from B8a/b start to force rise start (s)'\n",
    "\n",
    "sns.boxplot(y='Animal', x=column, data=df, fliersize=0, whis=999) # whis=999 ensures whiskers go to min and max\n",
    "sns.swarmplot(y='Animal', x=column, data=df, color='0.25')\n",
    "\n",
    "# sns.boxplot(x=column, data=df, fliersize=0, whis=999) # whis=999 ensures whiskers go to min and max\n",
    "# sns.swarmplot(x=column, data=df, color='0.25')\n",
    "\n",
    "# plot zero line\n",
    "plt.axvline(x=0, ls=':', c='gray', zorder=-1)\n",
    "\n",
    "plt.tight_layout()\n",
    "\n",
    "# plt.gcf().savefig(os.path.join(export_dir, 'figure-X.png'), dpi=300)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plt.figure(figsize=(5, 5))\n",
    "# ax = plt.gca()\n",
    "\n",
    "# data_subsets = [\n",
    "#     'JG07 Tape nori',\n",
    "#     'JG08 Tape nori',\n",
    "#     'JG11 Tape nori',\n",
    "#     'JG12 Tape nori',\n",
    "#     'JG14 Tape nori',\n",
    "# ]\n",
    "# data_subsets = {label:label2query(label) for label in data_subsets}\n",
    "\n",
    "# # xlabel, xlim = 'B8 activity mean rectified voltage (Î¼V)', [0, None]\n",
    "# # xlabel, xlim = 'B8a/b first burst mean rectified voltage (Î¼V)', [0, None]\n",
    "# xlabel, xlim = 'B8a/b pre-B3/B6/B9 burst mean rectified voltage (Î¼V)', [0, None]\n",
    "# # xlabel, xlim = 'B8a/b pre-B3/B6/B9 burst mean frequency (Hz)', [0, None]\n",
    "# # ylabel, ylim = 'Force slope (mN/s)', [0, None]\n",
    "# ylabel, ylim = 'Force initial slope (mN/s)', [0, None]\n",
    "# # ylabel, ylim = 'Force initial increase (mN)', [0, None]\n",
    "\n",
    "# scatter2d(ax, data_subsets, xlabel, xlim, ylabel, ylim, trend=True, trend_separately=True, tooltips=True)\n",
    "# ax.legend()\n",
    "# sns.despine(ax=ax, offset=20, trim=True)\n",
    "# plt.tight_layout()\n",
    "\n",
    "# # plt.gcf().savefig(os.path.join(export_dir, 'figure-X.png'), dpi=300)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [],
   "source": [
    "# plt.figure(figsize=(5, 5))\n",
    "# ax = plt.gca()\n",
    "\n",
    "# data_subsets = [\n",
    "#     'JG07 Tape nori',\n",
    "#     'JG08 Tape nori',\n",
    "#     'JG11 Tape nori',\n",
    "#     'JG12 Tape nori',\n",
    "#     'JG14 Tape nori',\n",
    "# ]\n",
    "# data_subsets = {label:label2query(label) for label in data_subsets}\n",
    "\n",
    "# # xlabel, xlim = 'B8 activity mean rectified voltage (Î¼V)', [0, None]\n",
    "# # xlabel, xlim = 'B8a/b first burst mean rectified voltage (Î¼V)', [0, None]\n",
    "# # xlabel, xlim = 'B8a/b pre-B3/B6/B9 burst mean rectified voltage (Î¼V)', [0, None]\n",
    "# xlabel, xlim = 'B8a/b pre-B3/B6/B9 burst mean frequency (Hz)', [0, None]\n",
    "# # ylabel, ylim = 'Force slope (mN/s)', [0, None]\n",
    "# ylabel, ylim = 'Force initial slope (mN/s)', [0, None]\n",
    "# # ylabel, ylim = 'Force initial increase (mN)', [0, None]\n",
    "\n",
    "# scatter2d(ax, data_subsets, xlabel, xlim, ylabel, ylim, trend=True, trend_separately=True, tooltips=True)\n",
    "# ax.legend()\n",
    "# sns.despine(ax=ax, offset=20, trim=True)\n",
    "# plt.tight_layout()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plt.figure(figsize=(5, 5))\n",
    "# ax = plt.gca()\n",
    "\n",
    "# data_subsets = [\n",
    "#     'JG07 Tape nori',\n",
    "#     'JG08 Tape nori',\n",
    "#     'JG11 Tape nori',\n",
    "#     'JG12 Tape nori',\n",
    "#     'JG14 Tape nori',\n",
    "# ]\n",
    "# data_subsets = {label:label2query(label) for label in data_subsets}\n",
    "\n",
    "# # xlabel, xlim = 'B8 activity mean rectified voltage (Î¼V)', [0, None]\n",
    "# # xlabel, xlim = 'B8a/b first burst mean rectified voltage (Î¼V)', [0, None]\n",
    "# xlabel, xlim = 'B8a/b pre-B3/B6/B9 burst mean rectified voltage (Î¼V)', [0, None]\n",
    "# # xlabel, xlim = 'B8a/b pre-B3/B6/B9 burst mean frequency (Hz)', [0, None]\n",
    "# # ylabel, ylim = 'Force slope (mN/s)', [0, None]\n",
    "# # ylabel, ylim = 'Force initial slope (mN/s)', [0, None]\n",
    "# ylabel, ylim = 'Force initial increase (mN)', [0, None]\n",
    "\n",
    "# scatter2d(ax, data_subsets, xlabel, xlim, ylabel, ylim, trend=True, trend_separately=True, tooltips=True)\n",
    "# ax.legend()\n",
    "# sns.despine(ax=ax, offset=20, trim=True)\n",
    "# plt.tight_layout()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plt.figure(figsize=(5, 5))\n",
    "# ax = plt.gca()\n",
    "\n",
    "# data_subsets = [\n",
    "#     'JG07 Tape nori',\n",
    "#     'JG08 Tape nori',\n",
    "#     'JG11 Tape nori',\n",
    "#     'JG12 Tape nori',\n",
    "#     'JG14 Tape nori',\n",
    "# ]\n",
    "# data_subsets = {label:label2query(label) for label in data_subsets}\n",
    "\n",
    "# # xlabel, xlim = 'B8 activity mean rectified voltage (Î¼V)', [0, None]\n",
    "# # xlabel, xlim = 'B8a/b first burst mean rectified voltage (Î¼V)', [0, None]\n",
    "# # xlabel, xlim = 'B8a/b pre-B3/B6/B9 burst mean rectified voltage (Î¼V)', [0, None]\n",
    "# xlabel, xlim = 'B8a/b pre-B3/B6/B9 burst mean frequency (Hz)', [0, None]\n",
    "# # ylabel, ylim = 'Force slope (mN/s)', [0, None]\n",
    "# ylabel, ylim = 'Force increase (mN)', [0, None]\n",
    "# # ylabel, ylim = 'Force initial slope (mN/s)', [0, None]\n",
    "# # ylabel, ylim = 'Force initial increase (mN)', [0, None]\n",
    "\n",
    "# scatter2d(ax, data_subsets, xlabel, xlim, ylabel, ylim, trend=True, trend_separately=True, tooltips=True)\n",
    "# ax.legend()\n",
    "# sns.despine(ax=ax, offset=20, trim=True)\n",
    "# plt.tight_layout()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [],
   "source": [
    "plt.figure(figsize=(5, 5))\n",
    "ax = plt.gca()\n",
    "\n",
    "data_subsets = [\n",
    "    'JG07 Tape nori',\n",
    "    'JG08 Tape nori',\n",
    "    'JG11 Tape nori',\n",
    "    'JG12 Tape nori',\n",
    "    'JG14 Tape nori',\n",
    "]\n",
    "data_subsets = {label:label2query(label) for label in data_subsets}\n",
    "\n",
    "# xlabel, xlim = 'B8 activity duration (s)', [0, 8]\n",
    "xlabel, xlim = 'B8a/b first burst duration (s)', [0, 8]\n",
    "ylabel, ylim = 'Force rise and plateau duration (s)', [0, 8]\n",
    "\n",
    "scatter2d(ax, data_subsets, xlabel, xlim, ylabel, ylim, trend=True, trend_separately=True, tooltips=False)\n",
    "plt.plot([0, 999], [0, 999], ls=':', c='gray', zorder=0)\n",
    "ax.legend()\n",
    "sns.despine(ax=ax, offset=20, trim=True)\n",
    "plt.tight_layout()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_all['Delay from B3/B6/B9 start to force plateau start (s)'] = \\\n",
    "    df_all['Force plateau start start (s)'] - \\\n",
    "    df_all[['B6/B9 first burst start (s)', 'B3 first burst start (s)']].min(axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(5, 5))\n",
    "ax = plt.gca()\n",
    "\n",
    "df = df_all.reset_index()\n",
    "# column = 'Delay from B3/B6/B9 start to force 50%-height (s)'\n",
    "column = 'Delay from B3/B6/B9 start to force plateau start (s)'\n",
    "\n",
    "sns.boxplot(y='Animal', x=column, data=df, fliersize=0, whis=999) # whis=999 ensures whiskers go to min and max\n",
    "# sns.swarmplot(y='Animal', x=column, data=df, color='0.25')\n",
    "\n",
    "# sns.boxplot(x=column, data=df, fliersize=0, whis=999) # whis=999 ensures whiskers go to min and max\n",
    "# sns.swarmplot(x=column, data=df, color='0.25')\n",
    "\n",
    "# plot zero line\n",
    "plt.axvline(x=0, ls=':', c='gray', zorder=-1)\n",
    "\n",
    "plt.tight_layout()\n",
    "\n",
    "# plt.gcf().savefig(os.path.join(export_dir, 'figure-X.png'), dpi=300)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_all['Delay from either B8a/b or B3/B6/B9 end to force plateau end (s)'] = \\\n",
    "    df_all['Force plateau end start (s)'] - \\\n",
    "    pd.concat([\n",
    "        df_all['B8a/b last burst end (s)'],\n",
    "        df_all[['B6/B9 last burst end (s)', 'B3 last burst end (s)']].max(axis=1)\n",
    "    ], axis=1).min(axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(5, 5))\n",
    "ax = plt.gca()\n",
    "\n",
    "df = df_all.reset_index()\n",
    "# column = 'Delay from either B8a/b or B3/B6/B9 end to force 80%-height end (s)'\n",
    "column = 'Delay from either B8a/b or B3/B6/B9 end to force plateau end (s)'\n",
    "\n",
    "sns.boxplot(y='Animal', x=column, data=df, fliersize=0, whis=999) # whis=999 ensures whiskers go to min and max\n",
    "sns.swarmplot(y='Animal', x=column, data=df, color='0.25')\n",
    "\n",
    "# sns.boxplot(x=column, data=df, fliersize=0, whis=999) # whis=999 ensures whiskers go to min and max\n",
    "# sns.swarmplot(x=column, data=df, color='0.25')\n",
    "\n",
    "# plot zero line\n",
    "plt.axvline(x=0, ls=':', c='gray', zorder=-1)\n",
    "\n",
    "plt.tight_layout()\n",
    "\n",
    "# plt.gcf().savefig(os.path.join(export_dir, 'figure-X.png'), dpi=300)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_all['B6/B9 all bursts duration (s)'] = \\\n",
    "    df_all['B6/B9 last burst end (s)'] - df_all['B6/B9 first burst start (s)']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [],
   "source": [
    "plt.figure(figsize=(5, 5))\n",
    "ax = plt.gca()\n",
    "\n",
    "data_subsets = [\n",
    "    'JG07 Tape nori',\n",
    "    'JG08 Tape nori',\n",
    "    'JG11 Tape nori',\n",
    "    'JG12 Tape nori',\n",
    "    'JG14 Tape nori',\n",
    "]\n",
    "data_subsets = {label:label2query(label) for label in data_subsets}\n",
    "\n",
    "# xlabel, xlim = 'B3/6/9/10 activity duration (s)', [0, 8]\n",
    "# xlabel, xlim = 'B6/B9 first burst duration (s)', [0, 8]\n",
    "xlabel, xlim = 'B6/B9 all bursts duration (s)', [0, 8]\n",
    "ylabel, ylim = 'Force rise and plateau duration (s)', [0, 8]\n",
    "\n",
    "scatter2d(ax, data_subsets, xlabel, xlim, ylabel, ylim, trend=True, trend_separately=True, tooltips=False)\n",
    "plt.plot([0, 999], [0, 999], ls=':', c='gray', zorder=0)\n",
    "ax.legend()\n",
    "sns.despine(ax=ax, offset=20, trim=True)\n",
    "plt.tight_layout()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_all['Delay from B3 start to force plateau start (s)'] = \\\n",
    "    df_all['Force plateau start start (s)'] - \\\n",
    "    df_all['B3 first burst start (s)']\n",
    "\n",
    "df_all['Delay from B3 end to force plateau end (s)'] = \\\n",
    "    df_all['Force plateau end start (s)'] - \\\n",
    "    df_all['B3 last burst end (s)']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(5, 5))\n",
    "ax = plt.gca()\n",
    "\n",
    "df = df_all.reset_index()\n",
    "df = df.rename(columns={\n",
    "#     'Delay from B3 start to force 80%-height start (s)': 'Start of burst',\n",
    "#     'Delay from B3 end to force 80%-height end (s)':     'End of burst'})\n",
    "    'Delay from B3 start to force plateau start (s)': 'Start of burst',\n",
    "    'Delay from B3 end to force plateau end (s)':     'End of burst'})\n",
    "df = pd.melt(df,\n",
    "             id_vars=['Animal', 'Food', 'Bout_index', 'Behavior_index'],\n",
    "             value_vars=['Start of burst', 'End of burst'],\n",
    "             var_name='When?',\n",
    "             value_name='Delay from B3 to plateau (s)')\n",
    "sns.boxplot(hue='Animal', x='Delay from B3 to plateau (s)', y='When?', data=df, fliersize=0, whis=999) # whis=999 ensures whiskers go to min and max\n",
    "# sns.swarmplot(hue='Animal', x='Delay from B3 to plateau (s)', y='When?', data=df)\n",
    "\n",
    "# plot zero line\n",
    "plt.axvline(x=0, ls=':', c='gray', zorder=-1)\n",
    "\n",
    "plt.tight_layout()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [],
   "source": [
    "# plt.figure(figsize=(5, 5))\n",
    "# ax = plt.gca()\n",
    "\n",
    "# data_subsets = [\n",
    "#     'JG07 Tape nori',\n",
    "#     'JG08 Tape nori',\n",
    "#     'JG11 Tape nori',\n",
    "#     'JG12 Tape nori',\n",
    "#     'JG14 Tape nori',\n",
    "# ]\n",
    "# data_subsets = {label:label2query(label) for label in data_subsets}\n",
    "\n",
    "# # xlabel, xlim = 'B3/6/9/10 activity mean rectified voltage (Î¼V)', [0, None]\n",
    "# xlabel, xlim = 'B6/B9 first burst mean rectified voltage (Î¼V)', [0, None]\n",
    "# # ylabel, ylim = 'Force slope (mN/s)', [0, None]\n",
    "# # ylabel, ylim = 'Force 80%-height (mN)', [0, None]\n",
    "# ylabel, ylim = 'Force increase (mN)', [0, None]\n",
    "\n",
    "# scatter2d(ax, data_subsets, xlabel, xlim, ylabel, ylim, trend=True, trend_separately=True, tooltips=True)\n",
    "# ax.legend()\n",
    "# sns.despine(ax=ax, offset=20, trim=True)\n",
    "# plt.tight_layout()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plt.figure(figsize=(5, 5))\n",
    "# ax = plt.gca()\n",
    "\n",
    "# data_subsets = [\n",
    "#     'JG07 Tape nori',\n",
    "#     'JG08 Tape nori',\n",
    "#     'JG11 Tape nori',\n",
    "#     'JG12 Tape nori',\n",
    "#     'JG14 Tape nori',\n",
    "# ]\n",
    "# data_subsets = {label:label2query(label) for label in data_subsets}\n",
    "\n",
    "# # xlabel, xlim = 'B3/6/9/10 activity mean rectified voltage (Î¼V)', [0, None]\n",
    "# xlabel, xlim = 'B6/B9 first burst mean frequency (Hz)', [0, None]\n",
    "# # ylabel, ylim = 'Force slope (mN/s)', [0, None]\n",
    "# ylabel, ylim = 'Force plateau start value (mN)', [0, None]\n",
    "# # ylabel, ylim = 'Force increase (mN)', [0, None]\n",
    "# # ylabel, ylim = 'Force rise increase (mN)', [0, None]\n",
    "\n",
    "# scatter2d(ax, data_subsets, xlabel, xlim, ylabel, ylim, trend=True, trend_separately=True, tooltips=True)\n",
    "# ax.legend()\n",
    "# sns.despine(ax=ax, offset=20, trim=True)\n",
    "# plt.tight_layout()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_all['Delay from B38 end to force shoulder end (s)'] = \\\n",
    "    df_all['Force shoulder end start (s)'] - \\\n",
    "    df_all['B38 last burst end (s)']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(5, 5))\n",
    "ax = plt.gca()\n",
    "\n",
    "df = df_all.reset_index()\n",
    "# column = 'Delay from B38 end to shoulder end (s)'\n",
    "column = 'Delay from B38 end to force shoulder end (s)'\n",
    "\n",
    "sns.boxplot(y='Animal', x=column, data=df, fliersize=0, whis=999) # whis=999 ensures whiskers go to min and max\n",
    "sns.swarmplot(y='Animal', x=column, data=df, color='0.25')\n",
    "\n",
    "# sns.boxplot(x=column, data=df, fliersize=0, whis=999) # whis=999 ensures whiskers go to min and max\n",
    "# sns.swarmplot(x=column, data=df, color='0.25')\n",
    "\n",
    "# plot zero line\n",
    "plt.axvline(x=0, ls=':', c='gray', zorder=-1)\n",
    "\n",
    "plt.tight_layout()\n",
    "\n",
    "# plt.gcf().savefig(os.path.join(export_dir, 'figure-X.png'), dpi=300)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plt.figure(figsize=(5, 5))\n",
    "# ax = plt.gca()\n",
    "\n",
    "# data_subsets = [\n",
    "#     'JG07 Tape nori',\n",
    "#     'JG08 Tape nori',\n",
    "#     'JG11 Tape nori',\n",
    "#     'JG12 Tape nori',\n",
    "#     'JG14 Tape nori',\n",
    "# ]\n",
    "# data_subsets = {label:label2query(label) for label in data_subsets}\n",
    "\n",
    "# xlabel, xlim = 'B8a/b pre-B3/B6/B9 burst peak smoothed frequency (Hz)', [0, None]\n",
    "# ylabel, ylim = 'Force slope (mN/s)', [0, None]\n",
    "\n",
    "# scatter2d(ax, data_subsets, xlabel, xlim, ylabel, ylim, trend=True, trend_separately=True, tooltips=True)\n",
    "# ax.legend()\n",
    "# sns.despine(ax=ax, offset=20, trim=True)\n",
    "# plt.tight_layout()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(5, 5))\n",
    "ax = plt.gca()\n",
    "\n",
    "data_subsets = [\n",
    "    'JG07 Tape nori',\n",
    "    'JG08 Tape nori',\n",
    "    'JG11 Tape nori',\n",
    "    'JG12 Tape nori',\n",
    "    'JG14 Tape nori',\n",
    "]\n",
    "data_subsets = {label:label2query(label) for label in data_subsets}\n",
    "\n",
    "xlabel, xlim = 'Force rise duration (s)', [0, None]\n",
    "ylabel, ylim = 'Force rise increase (mN)', [0, None]\n",
    "\n",
    "scatter2d(ax, data_subsets, xlabel, xlim, ylabel, ylim, trend=True, trend_separately=True, tooltips=True)\n",
    "ax.legend()\n",
    "sns.despine(ax=ax, offset=20, trim=True)\n",
    "plt.tight_layout()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# start = datetime.datetime.now()\n",
    "\n",
    "# df = df_exemplary_bout\n",
    "# (data_set_name, time_window) = feeding_bouts[exemplary_bout]\n",
    "\n",
    "# # t_start, t_stop = time_window*pq.s\n",
    "# t_start, t_stop = [2944.5, 3010]*pq.s # 7 swallows\n",
    "\n",
    "# plots = [\n",
    "#     {'channel': 'I2',       'units': 'uV', 'ylim': [ -60,  60], 'scalebar': 50}, #, 'decimation_factor': 100},\n",
    "#     {'channel': 'RN',       'units': 'uV', 'ylim': [ -25,  25], 'scalebar': 25}, #, 'decimation_factor': 100},\n",
    "#     {'channel': 'BN2',      'units': 'uV', 'ylim': [ -45,  45], 'scalebar': 50}, #, 'decimation_factor': 100},\n",
    "#     {'channel': 'BN3-DIST', 'units': 'uV', 'ylim': [ -60,  60], 'scalebar': 50, 'ylabel': 'BN3'}, #, 'decimation_factor': 100},\n",
    "#     {'channel': 'Force',    'units': 'mN', 'ylim': [ -50, 450], 'scalebar': 300, 'decimation_factor': 100},\n",
    "# ]\n",
    "# plot_names = [p['channel'] for p in plots]\n",
    "# plot_units = [p['units'] for p in plots]\n",
    "\n",
    "# kwargs = dict(\n",
    "#     figsize = (12, 6),\n",
    "#     linewidth = 0.5,\n",
    "#     x_scalebar = 10*pq.s,\n",
    "# )\n",
    "\n",
    "# # load the data\n",
    "# metadata = neurotic.MetadataSelector('../../data/metadata.yml')\n",
    "# metadata.select(data_set_name)\n",
    "# blk = neurotic.load_dataset(metadata) # not lazy so that I2 filter is applied\n",
    "\n",
    "# # plot the signal\n",
    "# fig, axes = prettyplot_with_scalebars(blk, t_start, t_stop, plots, **kwargs)\n",
    "\n",
    "# units = [\n",
    "#     'I2 spikes',\n",
    "#     'B8a/b',\n",
    "#     'B6/B9',\n",
    "#     'B3',\n",
    "#     'B38',\n",
    "# ]\n",
    "# unit_burst_boxes = {\n",
    "#     'I2 spikes': [-35, 30],\n",
    "#     'B8a/b':     [-20, 12],\n",
    "#     'B6/B9':     [-15, 12],\n",
    "#     'B3':        [-45, 35],\n",
    "#     'B38':       [-12, 12],\n",
    "# }\n",
    "\n",
    "# # plot a zero baseline for force\n",
    "# ax = axes[-1]\n",
    "# force_zero = -11.5 # mN, average before animal began swallowing, not zero because of DC offset\n",
    "# ax.axhline(force_zero, color='0.75', lw=1, ls='--', zorder=-1)\n",
    "\n",
    "# for j, i in enumerate(df.index):\n",
    "#     for k, unit in enumerate(units):\n",
    "#         st = df.loc[i, unit+' spike train']\n",
    "#         if st is not None and st.size > 0:\n",
    "                \n",
    "#             # get the neural channel\n",
    "#             channel = st.annotations['channels'][0]\n",
    "#             sig = get_sig(blk, channel)\n",
    "\n",
    "#             # get the signal for the entire bout\n",
    "#             sig = sig.time_slice(t_start, t_stop)\n",
    "#             sig = sig.rescale(plot_units[plot_names.index(channel)])\n",
    "\n",
    "#             # plot spikes\n",
    "#             ax = axes[plot_names.index(channel)]\n",
    "#             spike_amplitudes = np.array([sig[sig.time_index(t)] for t in st]) * pq.Quantity(sig.units)\n",
    "#             ax.scatter(st.times.rescale('s'), spike_amplitudes, marker='.', s=4, c=unit_colors[unit], zorder=3)\n",
    "\n",
    "#             # plot burst windows\n",
    "#             bursts = df.at[i, unit+' all bursts (s)']\n",
    "#             bottom, top = unit_burst_boxes[unit]\n",
    "#             height = top-bottom\n",
    "#             for burst in bursts:\n",
    "#                 if is_good_burst(burst):\n",
    "#                     left = burst['Start (s)']\n",
    "#                     right = burst['End (s)']\n",
    "#                     width = right-left\n",
    "#                     rect = patches.Rectangle((left, bottom), width, height, linewidth=2, ls='-', edgecolor=unit_colors[unit], fill=False, zorder=3, clip_on=False)\n",
    "#                     ax.add_patch(rect)\n",
    "\n",
    "# # fig.savefig(os.path.join(export_dir, 'figure-exemplary-bout-export.png'), dpi=600)\n",
    "\n",
    "# end = datetime.datetime.now()\n",
    "# print('render time:', end-start)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model stuff"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from utils import CausalAlphaKernel\n",
    "\n",
    "swallow_id = ('JG07', 'Tape nori', 0, 0)\n",
    "\n",
    "(data_set_name, time_window) = feeding_bouts[swallow_id[:3]]\n",
    "\n",
    "# load the data\n",
    "metadata = neurotic.MetadataSelector('../../data/metadata.yml')\n",
    "metadata.select(data_set_name)\n",
    "blk = neurotic.load_dataset(metadata, lazy=True)\n",
    "sig = get_sig(blk, 'Force')\n",
    "sig = sig.time_slice(time_window[0]*pq.s, time_window[1]*pq.s)\n",
    "sig = sig.rescale('mN')\n",
    "sig = elephant.signal_processing.butter(sig, lowpass_freq = 10*pq.Hz)\n",
    "\n",
    "st_b6b9 = df_all.loc[swallow_id]['B6/B9 spike train']\n",
    "st_b3 = df_all.loc[swallow_id]['B3 spike train']\n",
    "\n",
    "weight_b6b9, tau_b6b9 = 1.75, 1\n",
    "weight_b3,   tau_b3   = 1.75, 0.2\n",
    "model_scale           = 100\n",
    "model_baseline        = 85\n",
    "u_to_y_constant       = 0.005\n",
    "\n",
    "rate_b6b9 = elephant.statistics.instantaneous_rate(\n",
    "    spiketrain=st_b6b9,\n",
    "    sampling_period=0.0002*pq.s,\n",
    "    kernel=CausalAlphaKernel(tau_b6b9*pq.s),\n",
    ")\n",
    "\n",
    "rate_b3 = elephant.statistics.instantaneous_rate(\n",
    "    spiketrain=st_b3,\n",
    "    sampling_period=0.0002*pq.s,\n",
    "    kernel=CausalAlphaKernel(tau_b3*pq.s),\n",
    ")\n",
    "\n",
    "# derivation and assumptions of this *very* crude and simple model:\n",
    "# - force (which is approximately isometric) is a linear function\n",
    "#   of grasper position, x\n",
    "# - the grasper is always spherical, and therefore its position is\n",
    "#   related to the I1/I3 torus contact altitude, y, by the equation\n",
    "#   for a circle, x^2 + y^2 = r, where r is the grasper radius\n",
    "#   (here r=1 with arbitrary units)\n",
    "# - the contact altitude y is approimately equivalent to the major\n",
    "#   radius of the torus (i.e., the minor radius is negligible)\n",
    "# - the major radius of the I1/I3 torus decreases from its max radius,\n",
    "#   ymax (here ymax=1 with arbitrary units), to its min radius (here\n",
    "#   set to 0) as muscle activation, u, increases\n",
    "#     - this may be modeled as an asymptotical approach from ymax to 0,\n",
    "#       e.g., y = ymax*exp(-c*u), or as a piecewise linear function,\n",
    "#       e.g., y = ymax-c*u with floor 0 and ceiling ymax\n",
    "# - the muscle activation u is a weighted sum of the synaptic potentials\n",
    "#   generated by the relevant motor neurons, modeled as alpha functions\n",
    "#   with fixed time constants and size (i.e., changes in size due to\n",
    "#   changing driving force as the muscle depolarizes are ignored)\n",
    "u = rate_total = rate_b6b9 * weight_b6b9 + rate_b3 * weight_b3\n",
    "u = np.clip(u.magnitude.flatten(), 0, None) # replace with 0 any negative values (caused by numerical imprecision)\n",
    "# y = np.exp(-u_to_y_constant*u)\n",
    "y = np.clip(1-u_to_y_constant*u, 0, 1)\n",
    "x = np.sqrt(1-y**2)\n",
    "model_force = x * model_scale + model_baseline\n",
    "\n",
    "\n",
    "plt.figure(figsize=(8,4))\n",
    "plt.plot(rate_total.times.rescale('s'), rate_total)\n",
    "plt.plot(rate_total.times.rescale('s'), model_force)\n",
    "plt.plot(sig.times.rescale('s'), sig.magnitude, color='0.75', zorder=-1)\n",
    "plt.xlim([df_all.loc[swallow_id]['Start (s)'], df_all.loc[swallow_id]['End (s)']])\n",
    "\n",
    "plt.title(f'Scale: {model_scale} | Baseline: {model_baseline} | B6/B9: ({weight_b6b9}, {tau_b6b9}) | B3: ({weight_b3}, {tau_b3})')\n",
    "\n",
    "export_dir4 = os.path.join(export_dir, 'firing-rate-models')\n",
    "if not os.path.exists(export_dir4):\n",
    "    os.mkdir(export_dir4)\n",
    "plt.gcf().savefig(os.path.join(export_dir4, f'S {model_scale} BL {model_baseline} B6B9 {weight_b6b9} {tau_b6b9} B3 {weight_b3} {tau_b3}.png'), dpi=300)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
