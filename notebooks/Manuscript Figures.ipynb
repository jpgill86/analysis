{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- [Figure 1](#[FIGURE-1])\n",
    "  - [Figure 1A](#🐌-Figure-1A)\n",
    "- [Figure 2](#[FIGURE-2])\n",
    "- [Figure 3](#[FIGURE-3])\n",
    "  - [Figure 3A](#🐌-Figure-3A)\n",
    "  - [Figure 3B](#🐌-Figure-3B)\n",
    "  - [Figure 3C](#🐌-Figure-3C)\n",
    "  - [Figure 3D](#🐌-Figure-3D)\n",
    "  - [Figure 3E](#🐌-Figure-3E)\n",
    "  - [Figure 3F](#🐌-Figure-3F)\n",
    "  - [Figure 3G](#🐌-Figure-3G)\n",
    "  - [Figure 3H](#🐌-Figure-3H)\n",
    "  - [Figure 3I ?](#🐌-Figure-3I-?)\n",
    "- [Figure 4](#[FIGURE-4])\n",
    "- [Figure 5](#[FIGURE-5])\n",
    "  - [Figure 5A](#🐌-Figure-5A)\n",
    "  - [Figure 5B](#🐌-Figure-5B)\n",
    "- [Figure 6](#[FIGURE-6])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Preamble"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "source": [
    "## Import Packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import datetime\n",
    "import numpy as np\n",
    "from scipy import interpolate\n",
    "import quantities as pq\n",
    "import elephant\n",
    "import pandas as pd\n",
    "import statsmodels.api as sm\n",
    "import neurotic\n",
    "from neurotic.datasets.data import _detect_spikes\n",
    "from utils import BehaviorsDataFrame, CausalAlphaKernel, DownsampleNeoSignal\n",
    "\n",
    "pq.markup.config.use_unicode = True  # allow symbols like mu for micro in output\n",
    "pq.mN = pq.UnitQuantity('millinewton', pq.N/1e3, symbol = 'mN');  # define millinewton\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.patches as patches\n",
    "import matplotlib.lines as mlines\n",
    "from matplotlib.ticker import MultipleLocator\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "outputs": [],
   "source": [
    "import warnings\n",
    "\n",
    "# np.nanmax raises a warning if all values are NaN and returns NaN, which is the behavior we want\n",
    "warnings.filterwarnings('ignore', message='All-NaN slice encountered')\n",
    "\n",
    "# elephant.statistics.instantaneous_rate always complains about negative values\n",
    "warnings.filterwarnings('ignore', message='Instantaneous firing rate approximation contains '\n",
    "                                          'negative values, possibly caused due to machine '\n",
    "                                          'precision errors')\n",
    "\n",
    "# with matplotlib>=3.1 and seaborn<=0.9.0, deprecation warnings are raised\n",
    "# whenever tick marks are placed on the right axis but not the left\n",
    "from matplotlib.cbook import MatplotlibDeprecationWarning\n",
    "warnings.simplefilter('ignore', MatplotlibDeprecationWarning)\n",
    "\n",
    "# don't complain about opening too many figures\n",
    "plt.rcParams.update({'figure.max_open_warning': 0})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "outputs": [],
   "source": [
    "# make figures interactive and open in a separate window\n",
    "# %matplotlib qt\n",
    "\n",
    "# make figures interactive and inline\n",
    "%matplotlib notebook\n",
    "\n",
    "# make figures non-interactive and inline\n",
    "# %matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "source": [
    "## Plot Settings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "export_dir = 'manuscript-figures'\n",
    "if not os.path.exists(export_dir):\n",
    "    os.mkdir(export_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "outputs": [],
   "source": [
    "# general plot settings\n",
    "sns.set(\n",
    "#     context = 'poster',\n",
    "    style = 'ticks',\n",
    "    font_scale = 1,\n",
    "    font = 'Palatino Linotype',\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# display current color palette\n",
    "with sns.axes_style(\"darkgrid\"):\n",
    "    sns.palplot(sns.color_palette(None), size=0.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "outputs": [],
   "source": [
    "markers = ['.', '+', 'x', '1', '4', 'o', 'D']\n",
    "colors = ['C0', 'C1', 'C2', 'C3', 'C4', 'C5', 'C6']\n",
    "\n",
    "unit_colors = {\n",
    "    'I2 spikes': 'C9', # light blue\n",
    "    'I2':        'C9', # light blue\n",
    "    'B8a/b':     'C6', # pink\n",
    "    'B3':        'C3', # red\n",
    "    'B6/B9':     'C2', # green\n",
    "    'B38':       'C1', # orange\n",
    "    'B4/B5':     'C0', # dark blue\n",
    "}\n",
    "force_colors = {\n",
    "    'dip':          unit_colors['I2 spikes'],\n",
    "    'initial rise': unit_colors['B8a/b'],\n",
    "    'rise':         unit_colors['B8a/b'],\n",
    "    'plateau':      unit_colors['B6/B9'],\n",
    "    'drop':         'gray',\n",
    "    'shoulder':     unit_colors['B38'],\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "source": [
    "## Data Parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "outputs": [],
   "source": [
    "feeding_bouts = {\n",
    "    # (animal, food, bout_index): (\n",
    "    #     data_set_name,\n",
    "    #     channel_names,\n",
    "    #     time_window,\n",
    "    #     epoch_types_to_keep,\n",
    "    #     burst_thresholds,\n",
    "    # )\n",
    "\n",
    "    ('JG07', 'Tape nori', 0): (\n",
    "        'IN VIVO / JG07 / 2018-05-20 / 002',\n",
    "        ['I2-L', 'RN-L', 'BN2-L', 'BN3-L', 'Force'],\n",
    "        [2718, 2755], # 5 swallows\n",
    "        ['Swallow (tape nori)'],\n",
    "        {\n",
    "            'I2 spikes': (10,  5)*pq.Hz, # same as Cullins et al. 2015a (based on Hurwitz et al. 1996)\n",
    "            'B8a/b':     ( 3,  3)*pq.Hz, # same as Cullins et al. 2015a (based on Morton and Chiel 1993a)\n",
    "            'B3':        ( 8,  2)*pq.Hz, # based on Lu et al. 2015\n",
    "            'B6/B9':     (10,  5)*pq.Hz, # based on Lu et al. 2015\n",
    "            'B38':       ( 8,  5)*pq.Hz, # based on McManus et al. 2014\n",
    "            'B4/B5':     ( 3,  3)*pq.Hz, # same as Cullins et al. 2015a ? (Table 1 says 3 Hz, text says first/last spike; based on Warman and Chiel 1995 ?)\n",
    "        },\n",
    "    ),\n",
    "    \n",
    "    ('JG08', 'Tape nori', 0): (\n",
    "        'IN VIVO / JG08 / 2018-06-21 / 002',\n",
    "        ['I2', 'RN', 'BN2', 'BN3', 'Force'],\n",
    "        [148, 208], # 7 swallows, some bucket and head movement\n",
    "        ['Swallow (tape nori)'],\n",
    "        {\n",
    "            'I2 spikes': (10,  5)*pq.Hz, # same as Cullins et al. 2015a (based on Hurwitz et al. 1996)\n",
    "            'B8a/b':     ( 3,  3)*pq.Hz, # same as Cullins et al. 2015a (based on Morton and Chiel 1993a)\n",
    "            'B3':        ( 8,  2)*pq.Hz, # based on Lu et al. 2015\n",
    "#             'B6/B9':     (10,  5)*pq.Hz, # based on Lu et al. 2015\n",
    "            'B6/B9':     (10,  3)*pq.Hz, # based on Lu et al. 2015 (end threshold reduced for this animal)\n",
    "            'B38':       ( 8,  5)*pq.Hz, # based on McManus et al. 2014\n",
    "            'B4/B5':     ( 3,  3)*pq.Hz, # same as Cullins et al. 2015a ? (Table 1 says 3 Hz, text says first/last spike; based on Warman and Chiel 1995 ?)\n",
    "        },\n",
    "    ),\n",
    "\n",
    "    ('JG08', 'Tape nori', 1): (\n",
    "        'IN VIVO / JG08 / 2018-06-21 / 002',\n",
    "        ['I2', 'RN', 'BN2', 'BN3', 'Force'],\n",
    "        [664, 701], # 5 swallows, large bucket movement\n",
    "        ['Swallow (tape nori)'],\n",
    "        {\n",
    "            'I2 spikes': (10,  5)*pq.Hz, # same as Cullins et al. 2015a (based on Hurwitz et al. 1996)\n",
    "            'B8a/b':     ( 3,  3)*pq.Hz, # same as Cullins et al. 2015a (based on Morton and Chiel 1993a)\n",
    "            'B3':        ( 8,  2)*pq.Hz, # based on Lu et al. 2015\n",
    "#             'B6/B9':     (10,  5)*pq.Hz, # based on Lu et al. 2015\n",
    "            'B6/B9':     (10,  3)*pq.Hz, # based on Lu et al. 2015 (end threshold reduced for this animal)\n",
    "            'B38':       ( 8,  5)*pq.Hz, # based on McManus et al. 2014\n",
    "            'B4/B5':     ( 3,  3)*pq.Hz, # same as Cullins et al. 2015a ? (Table 1 says 3 Hz, text says first/last spike; based on Warman and Chiel 1995 ?)\n",
    "        },\n",
    "    ),\n",
    "\n",
    "    ('JG08', 'Tape nori', 2): (\n",
    "        'IN VIVO / JG08 / 2018-06-21 / 002',\n",
    "        ['I2', 'RN', 'BN2', 'BN3', 'Force'],\n",
    "        [1452, 1477], # 3 swallows, some bucket movement\n",
    "        ['Swallow (tape nori)'],\n",
    "        {\n",
    "            'I2 spikes': (10,  5)*pq.Hz, # same as Cullins et al. 2015a (based on Hurwitz et al. 1996)\n",
    "            'B8a/b':     ( 3,  3)*pq.Hz, # same as Cullins et al. 2015a (based on Morton and Chiel 1993a)\n",
    "            'B3':        ( 8,  2)*pq.Hz, # based on Lu et al. 2015\n",
    "#             'B6/B9':     (10,  5)*pq.Hz, # based on Lu et al. 2015\n",
    "            'B6/B9':     (10,  3)*pq.Hz, # based on Lu et al. 2015 (end threshold reduced for this animal)\n",
    "            'B38':       ( 8,  5)*pq.Hz, # based on McManus et al. 2014\n",
    "            'B4/B5':     ( 3,  3)*pq.Hz, # same as Cullins et al. 2015a ? (Table 1 says 3 Hz, text says first/last spike; based on Warman and Chiel 1995 ?)\n",
    "        },\n",
    "    ),\n",
    "\n",
    "    ('JG11', 'Tape nori', 0): (\n",
    "        'IN VIVO / JG11 / 2019-04-03 / 004',\n",
    "        ['I2', 'RN', 'BN2', 'BN3-PROX', 'Force'],\n",
    "        [1233, 1280], # 5 swallows\n",
    "        ['Swallow (tape nori)'],\n",
    "        {\n",
    "            'I2 spikes': (10,  5)*pq.Hz, # same as Cullins et al. 2015a (based on Hurwitz et al. 1996)\n",
    "            'B8a/b':     ( 3,  3)*pq.Hz, # same as Cullins et al. 2015a (based on Morton and Chiel 1993a)\n",
    "            'B3':        ( 8,  2)*pq.Hz, # based on Lu et al. 2015\n",
    "            'B6/B9':     (10,  5)*pq.Hz, # based on Lu et al. 2015\n",
    "            'B38':       ( 8,  5)*pq.Hz, # based on McManus et al. 2014\n",
    "#             'B4/B5':     ( 3,  3)*pq.Hz, # same as Cullins et al. 2015a ? (Table 1 says 3 Hz, text says first/last spike; based on Warman and Chiel 1995 ?)\n",
    "            'B4/B5':     (1.5, 1.5)*pq.Hz, # threshold reduced for this animal because only one neuron appeared to project\n",
    "        },\n",
    "    ),\n",
    "\n",
    "    ('JG12', 'Tape nori', 0): (\n",
    "        'IN VIVO / JG12 / 2019-05-10 / 002',\n",
    "        ['I2', 'RN', 'BN2', 'BN3-DIST', 'Force'],\n",
    "        [437, 465], # 4 swallows\n",
    "        ['Swallow (tape nori)'],\n",
    "        {\n",
    "            'I2 spikes': (10,  5)*pq.Hz, # same as Cullins et al. 2015a (based on Hurwitz et al. 1996)\n",
    "            'B8a/b':     ( 3,  3)*pq.Hz, # same as Cullins et al. 2015a (based on Morton and Chiel 1993a)\n",
    "            'B3':        ( 8,  2)*pq.Hz, # based on Lu et al. 2015\n",
    "            'B6/B9':     (10,  5)*pq.Hz, # based on Lu et al. 2015\n",
    "            'B38':       ( 8,  5)*pq.Hz, # based on McManus et al. 2014\n",
    "            'B4/B5':     ( 3,  3)*pq.Hz, # same as Cullins et al. 2015a ? (Table 1 says 3 Hz, text says first/last spike; based on Warman and Chiel 1995 ?)\n",
    "        },\n",
    "    ),\n",
    "    \n",
    "    ('JG12', 'Tape nori', 1): (\n",
    "        'IN VIVO / JG12 / 2019-05-10 / 002',\n",
    "        ['I2', 'RN', 'BN2', 'BN3-DIST', 'Force'],\n",
    "        [2901, 2937], # 5 swallows\n",
    "        ['Swallow (tape nori)'],\n",
    "        {\n",
    "            'I2 spikes': (10,  5)*pq.Hz, # same as Cullins et al. 2015a (based on Hurwitz et al. 1996)\n",
    "            'B8a/b':     ( 3,  3)*pq.Hz, # same as Cullins et al. 2015a (based on Morton and Chiel 1993a)\n",
    "            'B3':        ( 8,  2)*pq.Hz, # based on Lu et al. 2015\n",
    "            'B6/B9':     (10,  5)*pq.Hz, # based on Lu et al. 2015\n",
    "            'B38':       ( 8,  5)*pq.Hz, # based on McManus et al. 2014\n",
    "            'B4/B5':     ( 3,  3)*pq.Hz, # same as Cullins et al. 2015a ? (Table 1 says 3 Hz, text says first/last spike; based on Warman and Chiel 1995 ?)\n",
    "        },\n",
    "    ),\n",
    "\n",
    "    ('JG14', 'Tape nori', 0): (\n",
    "        'IN VIVO / JG14 / 2019-07-29 / 004',\n",
    "        ['I2', 'RN', 'BN2', 'BN3-PROX', 'Force'],\n",
    "        [831, 870], # 5 swallows\n",
    "        ['Swallow (tape nori)'],\n",
    "        {\n",
    "            'I2 spikes': (10,  5)*pq.Hz, # same as Cullins et al. 2015a (based on Hurwitz et al. 1996)\n",
    "            'B8a/b':     ( 3,  3)*pq.Hz, # same as Cullins et al. 2015a (based on Morton and Chiel 1993a)\n",
    "            'B3':        ( 8,  2)*pq.Hz, # based on Lu et al. 2015\n",
    "            'B6/B9':     (10,  5)*pq.Hz, # based on Lu et al. 2015\n",
    "            'B38':       ( 8,  5)*pq.Hz, # based on McManus et al. 2014\n",
    "            'B4/B5':     ( 3,  3)*pq.Hz, # same as Cullins et al. 2015a ? (Table 1 says 3 Hz, text says first/last spike; based on Warman and Chiel 1995 ?)\n",
    "        },\n",
    "    ),\n",
    "\n",
    "\n",
    "    \n",
    "    # for example figures only -- not used in majority of analysis because of long inter-swallow intervals\n",
    "    ('JG12', 'Tape nori', 101): (\n",
    "        'IN VIVO / JG12 / 2019-05-10 / 002',\n",
    "        ['I2', 'RN', 'BN2', 'BN3-DIST', 'Force'],\n",
    "        [2944.5, 3010], # 6+1 swallows (last one included for plotting its I2 burst)\n",
    "        ['Swallow (tape nori)'],\n",
    "        {\n",
    "            'I2 spikes': (10,  5)*pq.Hz, # same as Cullins et al. 2015a (based on Hurwitz et al. 1996)\n",
    "            'B8a/b':     ( 3,  3)*pq.Hz, # same as Cullins et al. 2015a (based on Morton and Chiel 1993a)\n",
    "            'B3':        ( 8,  2)*pq.Hz, # based on Lu et al. 2015\n",
    "            'B6/B9':     (10,  5)*pq.Hz, # based on Lu et al. 2015\n",
    "            'B38':       ( 8,  5)*pq.Hz, # based on McManus et al. 2014\n",
    "            'B4/B5':     ( 3,  3)*pq.Hz, # same as Cullins et al. 2015a ? (Table 1 says 3 Hz, text says first/last spike; based on Warman and Chiel 1995 ?)\n",
    "        },\n",
    "    ),\n",
    "    \n",
    "    # for example figures only -- not used in majority of analysis because of long inter-swallow intervals\n",
    "    ('JG12', 'Tape nori', 102): (\n",
    "        'IN VIVO / JG12 / 2019-05-10 / 002',\n",
    "        ['I2', 'RN', 'BN2', 'BN3-DIST', 'Force'],\n",
    "        [2999.3, 3010], # 1 swallow\n",
    "        ['Swallow (tape nori)'],\n",
    "        {\n",
    "            'I2 spikes': (10,  5)*pq.Hz, # same as Cullins et al. 2015a (based on Hurwitz et al. 1996)\n",
    "            'B8a/b':     ( 3,  3)*pq.Hz, # same as Cullins et al. 2015a (based on Morton and Chiel 1993a)\n",
    "            'B3':        ( 8,  2)*pq.Hz, # based on Lu et al. 2015\n",
    "            'B6/B9':     (10,  5)*pq.Hz, # based on Lu et al. 2015\n",
    "            'B38':       ( 8,  5)*pq.Hz, # based on McManus et al. 2014\n",
    "            'B4/B5':     ( 3,  3)*pq.Hz, # same as Cullins et al. 2015a ? (Table 1 says 3 Hz, text says first/last spike; based on Warman and Chiel 1995 ?)\n",
    "        },\n",
    "    ),\n",
    "}\n",
    "\n",
    "\n",
    "exemplary_bout = ('JG12', 'Tape nori', 101)\n",
    "exemplary_bout_plot_range = [2944.5, 2969.5] # first 3 swallows\n",
    "exemplary_swallow = ('JG12', 'Tape nori', 102)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "source": [
    "## Helper Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "outputs": [],
   "source": [
    "def query_union(queries):\n",
    "    return '|'.join([f'({q})' for q in queries if q is not None])\n",
    "\n",
    "def label2query(label):\n",
    "    animal, food = label[:4], label[5:]\n",
    "    query = f'(Animal == \"{animal}\") & (Food == \"{food}\")'\n",
    "    return query\n",
    "\n",
    "def contains(series, string):\n",
    "#     return np.array([string in x for x in series])\n",
    "    return series.map(lambda x: string in x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def update_filter(metadata, new_filter):\n",
    "    i = next((i for i, f in enumerate(metadata['filters']) if f['channel'] == new_filter['channel']), None)\n",
    "    if i is not None:\n",
    "        metadata['filters'][i] = new_filter\n",
    "    else:\n",
    "        metadata['filters'].append(new_filter)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "outputs": [],
   "source": [
    "def get_sig(blk, channel):\n",
    "    sig = next((sig for sig in blk.segments[0].analogsignals if sig.name == channel), None)\n",
    "    if sig is None:\n",
    "        raise Exception(f'Channel \"{channel}\" could not be found')\n",
    "    else:\n",
    "        return sig"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "outputs": [],
   "source": [
    "def finite_min(x, y):\n",
    "    '''Workaround for Quantities warning about comparison to NaN'''\n",
    "    if np.isfinite(x) and np.isfinite(y):\n",
    "        return min(x, y)\n",
    "    elif np.isfinite(x):\n",
    "        return x\n",
    "    elif np.isfinite(y):\n",
    "        return y\n",
    "    else:\n",
    "        return np.nan\n",
    "\n",
    "def finite_max(x, y):\n",
    "    '''Workaround for Quantities warning about comparison to NaN'''\n",
    "    if np.isfinite(x) and np.isfinite(y):\n",
    "        return max(x, y)\n",
    "    elif np.isfinite(x):\n",
    "        return x\n",
    "    elif np.isfinite(y):\n",
    "        return y\n",
    "    else:\n",
    "        return np.nan"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "outputs": [],
   "source": [
    "def find_bursts(st, burst_thresholds):\n",
    "    '''Find every sequence of spikes that qualifies as a burst'''\n",
    "    \n",
    "    isi = elephant.statistics.isi(st).rescale('s')\n",
    "    iff = 1/isi\n",
    "\n",
    "    start_freq, end_freq = burst_thresholds\n",
    "    start_mask = iff > start_freq\n",
    "    end_mask = iff < end_freq\n",
    "\n",
    "    bursts = []\n",
    "    scan_index = -1\n",
    "    while scan_index < iff.size:\n",
    "        start_index = None\n",
    "        end_index = None\n",
    "\n",
    "        start_mask_indexes = np.where(start_mask)[0]\n",
    "        start_mask_indexes = start_mask_indexes[start_mask_indexes > scan_index]\n",
    "        if start_mask_indexes.size == 0:\n",
    "            break\n",
    "\n",
    "        start_index = start_mask_indexes[0] # first time that iff rises above start threshold\n",
    "\n",
    "        end_mask_indexes = np.where(end_mask)[0]\n",
    "        end_mask_indexes = end_mask_indexes[end_mask_indexes > start_index]\n",
    "        if end_mask_indexes.size > 0:\n",
    "            end_index = end_mask_indexes[0] # first time after start that iff drops below end theshold\n",
    "        else:\n",
    "            end_index = -1 # end of spike train (include all spikes after start)\n",
    "\n",
    "        burst = {\n",
    "            'Start (s)': st[start_index].rescale('s'),\n",
    "            'End (s)': st[end_index].rescale('s'),\n",
    "            'Duration (s)': (st[end_index] - st[start_index]).rescale('s'),\n",
    "            'Number of spikes': end_index-start_index+1 if end_index > 0 else st.size-start_index\n",
    "        }\n",
    "        bursts.append(burst)\n",
    "        if end_index == -1:\n",
    "            break\n",
    "        else:\n",
    "            scan_index = end_index\n",
    "    \n",
    "    return bursts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "outputs": [],
   "source": [
    "def is_good_burst(burst):\n",
    "    return burst['Duration (s)'] >= 0.5*pq.s and burst['Number of spikes'] > 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# this function runs much faster if args are first converted\n",
    "# from quantities to simple ndarrays (use .rescale('s').magnitude)\n",
    "def normalize_time(fixed_times, t):\n",
    "    if not isinstance(t, np.ndarray):\n",
    "        if type(t) is list:\n",
    "            t = np.array(t)\n",
    "        else:\n",
    "            t = np.array([t])\n",
    "    \n",
    "    assert np.all(np.diff(fixed_times[~np.isnan(fixed_times)])>=0), f'fixed_times must be sorted: {fixed_times}'\n",
    "    assert np.all(np.diff(t[~np.isnan(t)])>=0), f't must be sorted: {t}'\n",
    "    \n",
    "    t_min = fixed_times[~np.isnan(fixed_times)].min()\n",
    "    t_max = fixed_times[~np.isnan(fixed_times)].max()\n",
    "    \n",
    "    result = []\n",
    "    last_found_i = 0\n",
    "    for ti in t:\n",
    "        \n",
    "        found = False\n",
    "        \n",
    "        if np.isnan(ti) or ti < t_min or t_max < ti:\n",
    "#             print(f'time {ti:.3f} was out of bounds for normalization')\n",
    "            result.append(np.nan)\n",
    "            continue\n",
    "\n",
    "        # use a manual O(n) loop instead of using np.searchsorted's much faster binary\n",
    "        # search O(log(n)) algorithm because NaNs inside fixed_times can fool searchsorted\n",
    "        for i in range(last_found_i, len(fixed_times)-1):\n",
    "            before = fixed_times[i]\n",
    "            after = fixed_times[i+1]\n",
    "            if np.isfinite(before) and np.isfinite(after):\n",
    "                if before <= ti <= after:\n",
    "                    found = True\n",
    "                    last_found_i = i\n",
    "                    result.append((ti-before)/(after-before) + i)\n",
    "                    break\n",
    "\n",
    "        # if we haven't returned already, then there must be a NaN bordering where t would go\n",
    "        if not found:\n",
    "#             print(f'time {ti:.3f} would fall next to an undefined boundary')\n",
    "            result.append(np.nan)\n",
    "            continue\n",
    "    \n",
    "    return np.array(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# this function runs much faster if args are first converted\n",
    "# from quantities to simple ndarrays (use .rescale('s').magnitude)\n",
    "def unnormalize_time(fixed_times, t_normalized):\n",
    "    if not isinstance(t_normalized, np.ndarray):\n",
    "        if type(t_normalized) is list:\n",
    "            t_normalized = np.array(t_normalized)\n",
    "        else:\n",
    "            t_normalized = np.array([t_normalized])\n",
    "    \n",
    "    assert np.all(np.diff(fixed_times[~np.isnan(fixed_times)])>=0), f'fixed_times must be sorted: {fixed_times}'\n",
    "    \n",
    "    t_normalized_min = np.where(~np.isnan(fixed_times))[0].min()\n",
    "    t_normalized_max = np.where(~np.isnan(fixed_times))[0].max()\n",
    "    \n",
    "    result = []\n",
    "    for ti in t_normalized:\n",
    "        \n",
    "        if np.isnan(ti) or ti < t_normalized_min or t_normalized_max < ti:\n",
    "    #         print(f'normalized time {ti:.3f} was out of bounds for un-normalization')\n",
    "            result.append(np.nan)\n",
    "            continue\n",
    "\n",
    "        if np.isclose(ti, t_normalized_max):\n",
    "            # workaround for numerical imprecision issue\n",
    "            ti -= 0.000001\n",
    "\n",
    "        i = int(np.floor(ti))\n",
    "        before = fixed_times[i]\n",
    "        after = fixed_times[i+1]\n",
    "        if np.isfinite(before) and np.isfinite(after):\n",
    "            result.append((ti - i)*(after-before) + before)\n",
    "            continue\n",
    "        else:\n",
    "            # there is a NaN bordering where t would go\n",
    "#             print(f'normalized time {ti:.3f} would fall next to an undefined boundary')\n",
    "            result.append(np.nan)\n",
    "            continue\n",
    "    \n",
    "    return np.array(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# times_interp is the array of normalized times at which samples will be taken\n",
    "# - samples will be taken at regular intervals in normalized time\n",
    "times_interp = np.linspace(0, 9, 4000) # [0, 9] is the range of normalized times\n",
    "\n",
    "def resample_sig_in_normalized_time(fixed_times, sig, times_interp=times_interp):\n",
    "        \n",
    "        # get normalized times and signal values\n",
    "        # - normalize_time will put into times_normalized a np.nan wherever a time was not normalizable,\n",
    "        #   i.e., wherever the time occurred adjacent to a missing fixed time (np.nan in fixed_times)\n",
    "        times = sig.times.rescale('s').magnitude\n",
    "        times_normalized = normalize_time(fixed_times.magnitude, times)\n",
    "        y = sig.magnitude.flatten()\n",
    "        \n",
    "        # drop times that could not be normalized due to missing fixed times\n",
    "        # - interp1d will erroneously interpolate across the gaps created by this deletion,\n",
    "        #   but we will then replace those interpolated values with np.nan\n",
    "        where_normalizable = np.where(~np.isnan(times_normalized))[0]\n",
    "        times_normalized = times_normalized[where_normalizable]\n",
    "        y = y[where_normalizable]\n",
    "        \n",
    "        # resample evenly in normalized time\n",
    "        # - fill_value will only put np.nan in places outside the min and max of times_normalized\n",
    "        # - interp1d will interpolate across the regions we deleted, but we want np.nan there,\n",
    "        #   so we will insert them manually in the next step\n",
    "        interp_func = interpolate.interp1d(times_normalized, y, kind='linear', bounds_error=False, fill_value=np.nan)\n",
    "        y_interp = interp_func(times_interp)\n",
    "        \n",
    "        # replace erroneously interpolated values with np.nan\n",
    "        # - now the points in y_interp which would correspond to times that could not be normalized\n",
    "        #   have been set to np.nan\n",
    "        where_not_normalizable = np.where(np.isnan(unnormalize_time(fixed_times.magnitude, times_interp)))[0]\n",
    "        y_interp[where_not_normalizable] = np.nan\n",
    "        \n",
    "        return y_interp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def print_column_analysis(column):\n",
    "    unit = column.split('(')[-1].split(')')[0]\n",
    "    mean = df_all[column].mean()\n",
    "    std = df_all[column].std()\n",
    "    cv = std/abs(mean)\n",
    "    print(f'Overall mean +/- std: {mean:.2f} +/- {std:.2f} {unit}')\n",
    "    print(f'Overall coefficient of variation CV: {cv:.2f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def plot_vertical_lines_with_delay(axes, t, delay, force_y, color, clip_on=False):\n",
    "\n",
    "#     # plot vertical line in force plot at time t\n",
    "#     axes[-1].add_artist(patches.ConnectionPatch(\n",
    "#         xyA=(t, force_y), xyB=(t, 1),\n",
    "#         coordsA='data', coordsB=axes[-1].get_xaxis_transform(),\n",
    "#         axesA=axes[-1], axesB=axes[-1],\n",
    "#         color=color, lw=1, ls=':', clip_on=clip_on))\n",
    "    \n",
    "#     # plot vertical line through all neural plots at time t-delay\n",
    "#     axes[-1].add_artist(patches.ConnectionPatch(\n",
    "#         xyA=(t-delay, 0), xyB=(t-delay, 1),\n",
    "#         coordsA=axes[-2].get_xaxis_transform(), coordsB=axes[0].get_xaxis_transform(),\n",
    "#         axesA=axes[-2], axesB=axes[0],\n",
    "#         color=color, lw=1, ls=':', clip_on=clip_on))\n",
    "    \n",
    "#     # connect the two lines\n",
    "#     axes[-1].add_artist(patches.ConnectionPatch(\n",
    "#         xyA=(t-delay, 0), xyB=(t, 1),\n",
    "#         coordsA=axes[-2].get_xaxis_transform(), coordsB=axes[-1].get_xaxis_transform(),\n",
    "#         axesA=axes[-2], axesB=axes[-1],\n",
    "#         color=color, lw=1, ls=':', clip_on=clip_on))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def lighten_color(color, amount=0.5):\n",
    "    '''\n",
    "    Lightens the given color by multiplying (1-luminosity) by the given amount.\n",
    "    Input can be matplotlib color string, hex string, or RGB tuple.\n",
    "\n",
    "    Examples:\n",
    "    >> lighten_color('g', 0.3)\n",
    "    >> lighten_color('#F034A3', 0.6)\n",
    "    >> lighten_color((.3,.55,.1), 0.5)\n",
    "    \n",
    "    https://stackoverflow.com/a/49601444/3314376\n",
    "    '''\n",
    "    import matplotlib.colors as mc\n",
    "    import colorsys\n",
    "    try:\n",
    "        c = mc.cnames[color]\n",
    "    except:\n",
    "        c = color\n",
    "    c = colorsys.rgb_to_hls(*mc.to_rgb(c))\n",
    "    return colorsys.hls_to_rgb(c[0], 1 - amount * (1 - c[1]), c[2])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import and Process the Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Main dataframe used for most figures"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "start = datetime.datetime.now()\n",
    "\n",
    "# use Neo RawIO lazy loading to load much faster and using less memory\n",
    "# - with lazy=True, filtering parameters specified in metadata are ignored\n",
    "# - with lazy=True, loading via time_slice requires neo>=0.8.0.dev\n",
    "# - IMPORTANT: force and I2 filters affect smoothness and possibly threshold crossings and spike detection\n",
    "lazy = False\n",
    "\n",
    "# load the metadata containing file paths\n",
    "metadata = neurotic.MetadataSelector(file='../../data/metadata.yml')\n",
    "\n",
    "# filter epochs for each bout and perform calculations\n",
    "df_list = []\n",
    "last_data_set_name = None\n",
    "for (animal, food, bout_index), (data_set_name, channel_names, time_window, epoch_types_to_keep, burst_thresholds) in feeding_bouts.items():\n",
    "    \n",
    "    ###\n",
    "    ### LOCATE BEHAVIOR EPOCHS AND SUBEPOCHS\n",
    "    ###\n",
    "    \n",
    "    metadata.select(data_set_name)\n",
    "    if data_set_name is last_data_set_name:\n",
    "        # skip reloading the data if it's already in memory\n",
    "        pass\n",
    "    else:\n",
    "        blk = neurotic.load_dataset(metadata, lazy=lazy)\n",
    "    last_data_set_name = data_set_name\n",
    "    \n",
    "    # construct a query for locating behaviors\n",
    "    behavior_query = f'(Type in {epoch_types_to_keep}) & ({time_window[0]} <= Start) & (End <= {time_window[1]})'\n",
    "    \n",
    "    # construct queries for locating epochs associated with each behavior\n",
    "    # - each query should match at most one epoch\n",
    "    # - dictionary keys are used as prefixes for the names of new columns\n",
    "    subepoch_queries = {}\n",
    "    \n",
    "    subepoch_queries['I2 protraction activity'] = f'(Type == \"I2 protraction activity\") & ' \\\n",
    "                                                  f'(@behavior_start-1 <= Start) & (End <= @behavior_end)'\n",
    "                                                  # must start no earlier than 1 second before behavior and end within it\n",
    "    \n",
    "    subepoch_queries['B8 activity']             = f'(Type == \"B8 activity\") & ' \\\n",
    "                                                  f'(@behavior_start <= Start) & (End <= @behavior_end)'\n",
    "                                                  # must be fully contained within behavior\n",
    "    \n",
    "    subepoch_queries['B3/6/9/10 activity']      = f'(Type == \"B3/6/9/10 activity\") & ' \\\n",
    "                                                  f'(@behavior_start <= Start) & (End <= @behavior_end)'\n",
    "                                                  # must be fully contained within behavior\n",
    "\n",
    "    subepoch_queries['B38 activity']            = f'(Type == \"B38 activity\") & ' \\\n",
    "                                                  f'(@behavior_end-2 <= Start) & (Start <= @behavior_end+2)'\n",
    "                                                  # must start within 2 seconds of behavior end\n",
    "\n",
    "    subepoch_queries['B4/B5 activity']          = f'(Type == \"B4/B5 activity\") & ' \\\n",
    "                                                  f'(@behavior_start <= Start) & (Start <= @behavior_end)'\n",
    "                                                  # must start within behavior\n",
    "\n",
    "    subepoch_queries['Force rise start']        = f'(Type == \"Force rise start\") & ' \\\n",
    "                                                  f'(@behavior_start <= Start) & (Start <= @behavior_end)'\n",
    "                                                  # must start within behavior\n",
    "    \n",
    "    subepoch_queries['Force plateau start']     = f'(Type == \"Force plateau start\") & ' \\\n",
    "                                                  f'(@behavior_start <= Start) & (Start <= @behavior_end)'\n",
    "                                                  # must start within behavior\n",
    "    \n",
    "    subepoch_queries['Force plateau end']       = f'(Type == \"Force plateau end\") & ' \\\n",
    "                                                  f'(@behavior_end-2 <= Start) & (Start <= @behavior_end+2)'\n",
    "                                                  # must start within 2 seconds of behavior end\n",
    "    \n",
    "    subepoch_queries['Force drop end']          = f'(Type == \"Force drop end\") & ' \\\n",
    "                                                  f'(@behavior_end-2 <= Start) & (Start <= @behavior_end+2)'\n",
    "                                                  # must start within 2 seconds of behavior end\n",
    "    \n",
    "    subepoch_queries['Force shoulder end']      = f'(Type == \"Force shoulder end\") & ' \\\n",
    "                                                  f'(@behavior_end <= Start) & (Start <= @behavior_end+4)'\n",
    "                                                  # must start less than 4 seconds after behavior end\n",
    "    \n",
    "    # construct a table in which each row is a behavior and subepoch data\n",
    "    # is added as columns, e.g. df['B38 activity start (s)']\n",
    "    df = BehaviorsDataFrame(blk.segments[0].epochs, behavior_query, subepoch_queries)\n",
    "\n",
    "    # renumber behaviors assuming all behaviors are from a single contiguous sequence\n",
    "    df = df.sort_values('Start (s)').reset_index(drop=True).rename_axis('Behavior_index')\n",
    "\n",
    "    \n",
    "    \n",
    "    ###\n",
    "    ### START CALCULATIONS\n",
    "    ###\n",
    "\n",
    "    # some columns must have type 'object', which\n",
    "    # can be accomplished by initializing with None or np.nan\n",
    "    df['Normalization fixed times (s)'] = None\n",
    "    df['Force, normalized time interpolation (mN)'] = None\n",
    "    units = [\n",
    "        'I2 spikes',\n",
    "        'B8a/b',\n",
    "        'B3',\n",
    "        'B6/B9',\n",
    "        'B38',\n",
    "        'B4/B5',\n",
    "    ]\n",
    "    for unit in units:\n",
    "        df[unit+' spike train'] = None\n",
    "        df[unit+' firing rate (Hz)'] = None\n",
    "        df[unit+' firing rate, normalized time interpolation (Hz)'] = None\n",
    "        df[unit+' inter-spike intervals (s)'] = None\n",
    "        df[unit+' all bursts (s)'] = None\n",
    "\n",
    "        # while we're at it, initialize some other things that might otherwise never be given values\n",
    "        df[unit+' first burst start (s)'] = np.nan\n",
    "        df[unit+' first burst end (s)'] = np.nan\n",
    "        df[unit+' first burst duration (s)'] = 0\n",
    "        df[unit+' first burst spike count'] = 0\n",
    "        df[unit+' first burst mean frequency (Hz)'] = np.nan\n",
    "        df[unit+' last burst start (s)'] = np.nan\n",
    "        df[unit+' last burst end (s)'] = np.nan\n",
    "        df[unit+' last burst duration (s)'] = 0\n",
    "        df[unit+' last burst spike count'] = 0\n",
    "        df[unit+' last burst mean frequency (Hz)'] = np.nan\n",
    "\n",
    "\n",
    "    ### SANITY CHECK: plot all channels for entire time window\n",
    "#     figsize = (9.5, 10) # dimensions for notebook\n",
    "#     figsize = (11, 8.5) # dimensions for printing\n",
    "    figsize = (16, 9) # dimensions for wide screens\n",
    "    fig, axes = plt.subplots(len(channel_names), 1, sharex=True, figsize=figsize)\n",
    "    channel_units = ['uV', 'uV', 'uV', 'uV', 'mN']\n",
    "    for i, channel in enumerate(channel_names):\n",
    "        plt.sca(axes[i])\n",
    "        sig = get_sig(blk, channel)\n",
    "        sig = sig.time_slice(time_window[0]*pq.s, time_window[1]*pq.s)\n",
    "        sig = sig.rescale(channel_units[i])\n",
    "        plt.plot(sig.times, sig.magnitude, c='0.8', lw=1, zorder=-1)\n",
    "        \n",
    "        if i == 0:\n",
    "            plt.title(f'({animal}, {food}, {bout_index}): {data_set_name}')\n",
    "            \n",
    "        plt.ylabel(sig.name + ' (' + sig.units.dimensionality.string + ')')\n",
    "        axes[i].yaxis.set_label_coords(-0.06, 0.5)\n",
    "        \n",
    "        if i < len(channel_names)-1:\n",
    "            # remove right, top, and bottom plot borders, and remove x-axis\n",
    "            sns.despine(ax=plt.gca(), bottom=True)\n",
    "            plt.gca().xaxis.set_visible(False)\n",
    "        else:\n",
    "            # remove right and top plot borders, and set x-label\n",
    "            sns.despine(ax=plt.gca())\n",
    "            plt.xlabel('Time (s)')\n",
    "                \n",
    "\n",
    "    \n",
    "    ### SANITY CHECK: plot smoothed force for entire time window\n",
    "    channel = 'Force'\n",
    "    sig = get_sig(blk, channel)\n",
    "    if lazy:\n",
    "        sig = sig.time_slice(None, None)\n",
    "    sig = elephant.signal_processing.butter(sig, lowpass_freq = 5*pq.Hz)\n",
    "    sig = sig.time_slice(time_window[0]*pq.s, time_window[1]*pq.s)\n",
    "    sig = sig.rescale('mN')\n",
    "    plt.plot(sig.times, sig.magnitude, c='k', lw=1, zorder=0)\n",
    "    force_smoothed_sig = sig\n",
    "    \n",
    "    \n",
    "    \n",
    "    # iterate over all swallows\n",
    "    for j, i in enumerate(df.index):\n",
    "        \n",
    "        behavior_start = df.loc[i, 'Start (s)']*pq.s\n",
    "        behavior_end = df.loc[i, 'End (s)']*pq.s\n",
    "        \n",
    "        ###\n",
    "        ### FORCE\n",
    "        ###\n",
    "        \n",
    "        # quantify force in each behavior\n",
    "        \n",
    "        force_rise_start = df.loc[i, 'Force rise start start (s)']*pq.s # start of \"Force rise start\" epoch\n",
    "        force_plateau_start = df.loc[i, 'Force plateau start start (s)']*pq.s # start of \"Force plateau start\" epoch\n",
    "        force_plateau_end = df.loc[i, 'Force plateau end start (s)']*pq.s # start of \"Force plateau end\" epoch\n",
    "        force_drop_end = df.loc[i, 'Force drop end start (s)']*pq.s # start of \"Force drop end\" epoch\n",
    "        force_shoulder_end = df.loc[i, 'Force shoulder end start (s)']*pq.s # start of \"Force shoulder end\" epoch\n",
    "        \n",
    "        # get the drop time for the previous swallow and the rise time for the next swallow\n",
    "        epochs_force_rise_start = next((ep for ep in blk.segments[0].epochs if ep.name == 'Force rise start'), None)\n",
    "        epochs_force_plateau_start = next((ep for ep in blk.segments[0].epochs if ep.name == 'Force plateau start'), None)\n",
    "        epochs_force_plateau_end = next((ep for ep in blk.segments[0].epochs if ep.name == 'Force plateau end'), None)\n",
    "        epochs_force_drop_end = next((ep for ep in blk.segments[0].epochs if ep.name == 'Force drop end'), None)\n",
    "        epochs_force_shoulder_end = next((ep for ep in blk.segments[0].epochs if ep.name == 'Force shoulder end'), None)\n",
    "        assert epochs_force_rise_start is not None, 'failed to find \"Force rise start\" epochs'\n",
    "        assert epochs_force_plateau_start is not None, 'failed to find \"Force plateau start\" epochs'\n",
    "        assert epochs_force_plateau_end is not None, 'failed to find \"Force plateau end\" epochs'\n",
    "        assert epochs_force_drop_end is not None, 'failed to find \"Force drop end\" epochs'\n",
    "        assert epochs_force_shoulder_end is not None, 'failed to find \"Force shoulder end\" epochs'\n",
    "        \n",
    "        try:\n",
    "            prev_force_plateau_start = df.loc[i, 'Previous force plateau start (s)'] = epochs_force_plateau_start.time_slice(None, force_rise_start)[-1]\n",
    "            assert force_rise_start-prev_force_plateau_start < 16*pq.s, f'for swallow {i}, previous force plateau start is too far away'\n",
    "        except IndexError:\n",
    "            prev_force_plateau_start = df.loc[i, 'Previous force plateau start (s)'] = np.nan\n",
    "            \n",
    "        try:\n",
    "            prev_force_plateau_end = df.loc[i, 'Previous force plateau end (s)'] = epochs_force_plateau_end.time_slice(None, force_rise_start)[-1]\n",
    "            assert force_rise_start-prev_force_plateau_end < 12*pq.s, f'for swallow {i}, previous force plateau end is too far away'\n",
    "        except IndexError:\n",
    "            prev_force_plateau_end = df.loc[i, 'Previous force plateau end (s)'] = np.nan\n",
    "        \n",
    "        try:\n",
    "            prev_force_drop_end = df.loc[i, 'Previous force drop end (s)'] = epochs_force_drop_end.time_slice(None, force_rise_start)[-1]\n",
    "            assert force_rise_start-prev_force_drop_end < 12*pq.s, f'for swallow {i}, previous force drop end is too far away'\n",
    "        except IndexError:\n",
    "            prev_force_drop_end = df.loc[i, 'Previous force drop end (s)'] = np.nan\n",
    "        \n",
    "        try:\n",
    "            prev_force_shoulder_end = df.loc[i, 'Previous force shoulder end (s)'] = epochs_force_shoulder_end.time_slice(None, force_rise_start)[-1]\n",
    "            if prev_force_shoulder_end < prev_force_drop_end:\n",
    "                # previous swallow did not have a shoulder and we instead grabbed an earlier shoulder\n",
    "                prev_force_shoulder_end = df.loc[i, 'Previous force shoulder end (s)'] = np.nan\n",
    "        except IndexError:\n",
    "            prev_force_shoulder_end = df.loc[i, 'Previous force shoulder end (s)'] = np.nan\n",
    "        \n",
    "        try:\n",
    "            next_force_rise_start = df.loc[i, 'Next force rise start (s)'] = epochs_force_rise_start.time_slice(force_drop_end, None)[0]\n",
    "            assert next_force_rise_start-force_drop_end < 12*pq.s, f'for swallow {i}, next force rise start is too far away'\n",
    "        except IndexError:\n",
    "            next_force_rise_start = df.loc[i, 'Next force rise start (s)'] = np.nan\n",
    "        \n",
    "        # get the list of fixed times for normalization\n",
    "        normalization_fixed_times = df.at[i, 'Normalization fixed times (s)'] = np.array([\n",
    "            prev_force_plateau_start,\n",
    "            prev_force_plateau_end,\n",
    "            prev_force_drop_end,\n",
    "            prev_force_shoulder_end,\n",
    "            force_rise_start,\n",
    "            force_plateau_start,\n",
    "            force_plateau_end,\n",
    "            force_drop_end,\n",
    "            force_shoulder_end,\n",
    "            next_force_rise_start,\n",
    "        ])*pq.s # 'at', not 'loc', is important for inserting list into cell\n",
    "\n",
    "        # get smoothed force for whole behavior for remaining force calculations\n",
    "        sig = force_smoothed_sig\n",
    "        if np.isfinite(force_shoulder_end):\n",
    "            sig = sig.time_slice(force_rise_start - 1*pq.s, force_shoulder_end + 0.01*pq.s)\n",
    "        else:\n",
    "            sig = sig.time_slice(force_rise_start - 1*pq.s, force_drop_end + 0.01*pq.s)\n",
    "        sig = sig.rescale('mN')\n",
    "\n",
    "        # find force peak, baseline, and the increase\n",
    "        force_min_time = df.loc[i, 'Force minimum time (s)'] = elephant.spike_train_generation.peak_detection(sig, 999*pq.mN, sign='below')[0]\n",
    "        force_min = df.loc[i, 'Force minimum (mN)'] = sig[sig.time_index(force_min_time)][0]\n",
    "        force_peak_time = df.loc[i, 'Force peak time (s)'] = elephant.spike_train_generation.peak_detection(sig, 0*pq.mN)[0]\n",
    "        force_peak = df.loc[i, 'Force peak (mN)'] = sig[sig.time_index(force_peak_time)][0]\n",
    "        force_baseline = df.loc[i, 'Force baseline (mN)'] = sig[sig.time_index(force_rise_start)][0]\n",
    "        force_increase = df.loc[i, 'Force increase (mN)'] = force_peak-force_baseline\n",
    "        \n",
    "        # find force plateau, drop, and shoulder values\n",
    "        force_plateau_start_value = df.loc[i, 'Force plateau start value (mN)'] = sig[sig.time_index(force_plateau_start)][0]\n",
    "        force_plateau_end_value = df.loc[i, 'Force plateau end value (mN)'] = sig[sig.time_index(force_plateau_end)][0]\n",
    "        force_drop_end_value = df.loc[i, 'Force drop end value (mN)'] = sig[sig.time_index(force_drop_end)][0]\n",
    "        if np.isfinite(force_shoulder_end):\n",
    "            force_shoulder_end_value = df.loc[i, 'Force shoulder end value (mN)'] = sig[sig.time_index(force_shoulder_end)][0]\n",
    "        else:\n",
    "            force_shoulder_end_value = np.nan\n",
    "\n",
    "        # find force rise and plateau durations\n",
    "        force_rise_duration = df.loc[i, 'Force rise duration (s)'] = force_plateau_start - force_rise_start\n",
    "        force_plateau_duration = df.loc[i, 'Force plateau duration (s)'] = force_plateau_end - force_plateau_start\n",
    "        force_rise_plateau_duration = df.loc[i, 'Force rise and plateau duration (s)'] = force_plateau_end - force_rise_start\n",
    "        \n",
    "        # find average slope during rising phase\n",
    "        force_rise_increase = df.loc[i, 'Force rise increase (mN)'] = force_plateau_start_value - force_baseline\n",
    "        force_slope = df.loc[i, 'Force slope (mN/s)'] = (force_rise_increase/force_rise_duration).rescale('mN/s')\n",
    "\n",
    "        \n",
    "        ### SANITY CHECK: plot force rise\n",
    "        plt.sca(axes[channel_names.index('Force')])\n",
    "        sig2 = sig.time_slice(force_rise_start, force_plateau_start)\n",
    "        plt.plot(sig2.times, sig2.magnitude, c=force_colors['rise'], lw=2, zorder=1)\n",
    "        \n",
    "        ### SANITY CHECK: plot force plateau\n",
    "        sig2 = sig.time_slice(force_plateau_start, force_plateau_end)\n",
    "        plt.plot(sig2.times, sig2.magnitude, c=force_colors['plateau'], lw=2, zorder=1)\n",
    "        \n",
    "        ### SANITY CHECK: plot force shoulder\n",
    "        if np.isfinite(force_shoulder_end):\n",
    "            sig2 = sig.time_slice(force_drop_end, force_shoulder_end)\n",
    "            plt.plot(sig2.times, sig2.magnitude, c=force_colors['shoulder'], lw=2, zorder=1)\n",
    "\n",
    "        ### SANITY CHECK: plot force peak, baseline, and plateau values\n",
    "        plt.plot([force_peak_time],     [force_peak],                marker=7, markersize=5, color='k')\n",
    "#         plt.plot([force_min_time],      [force_min],                 marker=6, markersize=5, color='k')\n",
    "        plt.plot([force_rise_start],    [force_baseline],            marker=6, markersize=5, color='k')\n",
    "        plt.plot([force_plateau_start], [force_plateau_start_value], marker=5, markersize=5, color='k')\n",
    "        plt.plot([force_plateau_end],   [force_plateau_end_value],   marker=4, markersize=5, color='k')\n",
    "        \n",
    "        \n",
    "        \n",
    "        ###\n",
    "        ### FORCE NORMALIZATION\n",
    "        ###\n",
    "        \n",
    "        channel = 'Force'\n",
    "        sig = get_sig(blk, channel)\n",
    "        sig = sig.time_slice(prev_force_plateau_start+0.001*pq.s, next_force_rise_start-0.001*pq.s)\n",
    "        sig = sig.rescale(channel_units[channel_names.index(channel)])\n",
    "        \n",
    "        force_interp = df.at[i, 'Force, normalized time interpolation (mN)'] = \\\n",
    "            resample_sig_in_normalized_time(normalization_fixed_times, sig) # 'at', not 'loc', is important for inserting list into cell\n",
    "\n",
    "        \n",
    "        \n",
    "        ###\n",
    "        ### FIND SPIKE TRAINS\n",
    "        ###\n",
    "        \n",
    "        if lazy:\n",
    "            if metadata['amplitude_discriminators'] is not None:\n",
    "                for discriminator in metadata['amplitude_discriminators']:\n",
    "                    sig = get_sig(blk, discriminator['channel'])\n",
    "                    if sig is not None:\n",
    "                        sig = sig.time_slice(behavior_start - 5*pq.s, behavior_end + 5*pq.s)\n",
    "                        st = _detect_spikes(sig, discriminator, blk.segments[0].epochs)\n",
    "                        st_epoch_start = df.loc[i, discriminator['epoch']+' start (s)']*pq.s\n",
    "                        st_epoch_end = df.loc[i, discriminator['epoch']+' end (s)']*pq.s\n",
    "                        st = st.time_slice(st_epoch_start, st_epoch_end)\n",
    "                        df.at[i, st.name+' spike train'] = st # 'at', not 'loc', is important for inserting list into cell\n",
    "        else:\n",
    "            for spiketrain in blk.segments[0].spiketrains:\n",
    "                discriminator = next((d for d in metadata['amplitude_discriminators'] if d['name'] == spiketrain.name), None)\n",
    "                if discriminator is None:\n",
    "                    raise Exception(f'For data set \"{data_set_name}\", discriminator \"{spiketrain.name}\" could not be found')\n",
    "                st_epoch_start = df.loc[i, discriminator['epoch']+' start (s)']*pq.s\n",
    "                st_epoch_end = df.loc[i, discriminator['epoch']+' end (s)']*pq.s\n",
    "                st = spiketrain.time_slice(st_epoch_start, st_epoch_end)\n",
    "                df.at[i, st.name+' spike train'] = st # 'at', not 'loc', is important for inserting list into cell\n",
    "    \n",
    "    \n",
    "            \n",
    "        ###\n",
    "        ### QUANTIFY SPIKE TRAINS AND BURSTS\n",
    "        ###\n",
    "        \n",
    "        for k, unit in enumerate(units):\n",
    "            st = df.loc[i, unit+' spike train']\n",
    "            if st is not None:\n",
    "                df.loc[i, unit+' spike count'] = st.size\n",
    "                \n",
    "                # get the neural channel\n",
    "                channel = st.annotations['channels'][0]\n",
    "                sig = get_sig(blk, channel)\n",
    "                    \n",
    "                # create a continuous smoothed firing rate representation\n",
    "                # by convolving the spike train with a kernel\n",
    "                smoothing_kernel = elephant.kernels.GaussianKernel(0.2*pq.s) # 200 ms standard deviation\n",
    "#                 smoothing_kernel = elephant.kernels.RectangularKernel(0.2*pq.s / (2*np.sqrt(3))) # 200 ms width, 2*sqrt(3) undoes elephant's scaling\n",
    "                firing_rate = df.at[i, unit+' firing rate (Hz)'] = elephant.statistics.instantaneous_rate(\n",
    "                    spiketrain=st,\n",
    "                    t_start=prev_force_plateau_start+0.001*pq.s, # choice of t_start and t_stop here ensures firing rates are recorded as zero far from the burst\n",
    "                    t_stop=next_force_rise_start-0.001*pq.s,\n",
    "                    sampling_period=sig.sampling_period,\n",
    "                    kernel=smoothing_kernel,\n",
    "                ) # 'at', not 'loc', is important for inserting list into cell\n",
    "                \n",
    "                # normalization\n",
    "                firing_rate_interp = df.at[i, unit+' firing rate, normalized time interpolation (Hz)'] = \\\n",
    "                    resample_sig_in_normalized_time(normalization_fixed_times, firing_rate) # 'at', not 'loc', is important for inserting list into cell\n",
    "                \n",
    "                if st.size > 0:\n",
    "\n",
    "                    # get the signal for the behavior with 10 seconds cushion before and after (for better baseline estimation)\n",
    "                    sig = sig.time_slice(behavior_start - 10*pq.s, behavior_end + 10*pq.s)\n",
    "                    sig = sig.rescale(channel_units[channel_names.index(channel)])\n",
    "                    \n",
    "                    # find every sequence of spikes that qualifies as a burst\n",
    "                    bursts = df.at[i, unit+' all bursts (s)'] = find_bursts(st, burst_thresholds[unit]) # 'at', not 'loc', is important for inserting list into cell\n",
    "                    \n",
    "                    first_burst_start = np.nan\n",
    "                    first_burst_end = np.nan\n",
    "                    first_burst_spike_count = 0\n",
    "                    first_burst_mean_freq = 0*pq.Hz\n",
    "                    last_burst_start = np.nan\n",
    "                    last_burst_end = np.nan\n",
    "                    last_burst_spike_count = 0\n",
    "                    last_burst_mean_freq = 0*pq.Hz\n",
    "                    if len(bursts) > 0:\n",
    "\n",
    "                        for burst in bursts:\n",
    "                            if is_good_burst(burst):\n",
    "                                first_burst_start, first_burst_end = burst['Start (s)'], burst['End (s)']\n",
    "                                first_burst_duration = first_burst_end-first_burst_start\n",
    "                                df.loc[i, unit+' first burst start (s)'] = first_burst_start.rescale('s')\n",
    "                                df.loc[i, unit+' first burst end (s)'] = first_burst_end.rescale('s')\n",
    "                                first_burst_duration = df.loc[i, unit+' first burst duration (s)'] = first_burst_duration.rescale('s')\n",
    "                                first_burst_spike_count = df.loc[i, unit+' first burst spike count'] = st.time_slice(first_burst_start, first_burst_end).size\n",
    "                                first_burst_mean_freq = df.loc[i, unit+' first burst mean frequency (Hz)'] = ((first_burst_spike_count-1)/first_burst_duration).rescale('Hz')\n",
    "                                \n",
    "                                # find burst RAUC and mean voltage\n",
    "                                first_burst_rauc = df.loc[i, unit+' first burst RAUC (μV·s)'] = elephant.signal_processing.rauc(sig, baseline='mean', t_start=first_burst_start, t_stop=first_burst_end).rescale('uV*s')\n",
    "                                first_burst_mean_rect_voltage = df.loc[i, unit+' first burst mean rectified voltage (μV)'] = first_burst_rauc/first_burst_duration\n",
    "\n",
    "                                break # quit after finding first good burst\n",
    "\n",
    "                        for burst in reversed(bursts):\n",
    "                            if is_good_burst(burst):\n",
    "                                last_burst_start, last_burst_end = burst['Start (s)'], burst['End (s)']\n",
    "                                last_burst_duration = last_burst_end-last_burst_start\n",
    "                                df.loc[i, unit+' last burst start (s)'] = last_burst_start.rescale('s')\n",
    "                                df.loc[i, unit+' last burst end (s)'] = last_burst_end.rescale('s')\n",
    "                                last_burst_duration = df.loc[i, unit+' last burst duration (s)'] = last_burst_duration.rescale('s')\n",
    "                                last_burst_spike_count = df.loc[i, unit+' last burst spike count'] = st.time_slice(last_burst_start, last_burst_end).size\n",
    "                                last_burst_mean_freq = df.loc[i, unit+' last burst mean frequency (Hz)'] = ((last_burst_spike_count-1)/last_burst_duration).rescale('Hz')\n",
    "\n",
    "                                # find burst RAUC and mean voltage\n",
    "                                last_burst_rauc = df.loc[i, unit+' last burst RAUC (μV·s)'] = elephant.signal_processing.rauc(sig, baseline='mean', t_start=last_burst_start, t_stop=last_burst_end).rescale('uV*s')\n",
    "                                last_burst_mean_rect_voltage = df.loc[i, unit+' last burst mean rectified voltage (μV)'] = last_burst_rauc/last_burst_duration\n",
    "    \n",
    "                                break # quit after finding first (actually, last) good burst\n",
    "\n",
    "                                    \n",
    "                    ### SANITY CHECK: plot spikes\n",
    "                    plt.sca(axes[channel_names.index(channel)])\n",
    "                    marker = ['.', 'x'][j%2] # alternate markers between behaviors\n",
    "                    \n",
    "                    spike_amplitudes = np.array([sig[sig.time_index(t)] for t in st]) * pq.Quantity(sig.units)\n",
    "                    plt.scatter(st.times.rescale('s'), spike_amplitudes, marker=marker, c=unit_colors[unit])\n",
    "\n",
    "                    ### SANITY CHECK: plot burst windows\n",
    "                    discriminator = next((d for d in metadata['amplitude_discriminators'] if d['name'] == st.name), None)\n",
    "                    if discriminator is None:\n",
    "                        raise Exception(f'For data set \"{data_set_name}\", discriminator \"{st.name}\" could not be found')\n",
    "                    bottom = pq.Quantity(discriminator['amplitude'][0], discriminator['units']).rescale(sig.units)\n",
    "                    top = pq.Quantity(discriminator['amplitude'][1], discriminator['units']).rescale(sig.units)\n",
    "                    height = top-bottom\n",
    "                    for burst in bursts:\n",
    "                        left = burst['Start (s)']\n",
    "                        right = burst['End (s)']\n",
    "                        width = right-left\n",
    "                        linestyle = '-' if is_good_burst(burst) else '--'\n",
    "                        rect = patches.Rectangle((left, bottom), width, height, ls=linestyle, edgecolor=unit_colors[unit], fill=False)\n",
    "                        plt.gca().add_patch(rect)\n",
    "\n",
    "                    ### SANITY CHECK: plot markers for edges of bursts\n",
    "                    if top > 0:\n",
    "                        plt.plot([first_burst_start], [top], marker=7, markersize=5, color='k')\n",
    "                        plt.plot([last_burst_end], [top], marker=7, markersize=5, color='k')\n",
    "                    else:\n",
    "                        plt.plot([first_burst_start], [bottom], marker=6, markersize=5, color='k')\n",
    "                        plt.plot([last_burst_end], [bottom], marker=6, markersize=5, color='k')\n",
    "        \n",
    "        \n",
    "        \n",
    "        ###\n",
    "        ### TIMING DELAYS\n",
    "        ###\n",
    "        \n",
    "        i2_burst_start      = df.loc[i, 'I2 spikes first burst start (s)']*pq.s\n",
    "        i2_burst_end        = df.loc[i, 'I2 spikes last burst end (s)']*pq.s\n",
    "        i2_burst_duration   = df.loc[i, 'I2 spikes all bursts duration (s)'] = i2_burst_end - i2_burst_start\n",
    "        b8_burst_start      = df.loc[i, 'B8a/b first burst start (s)']*pq.s\n",
    "        b8_burst_end        = df.loc[i, 'B8a/b last burst end (s)']*pq.s\n",
    "        b8_burst_duration   = df.loc[i, 'B8a/b all bursts duration (s)'] = b8_burst_end - b8_burst_start\n",
    "        b6b9_burst_start    = df.loc[i, 'B6/B9 first burst start (s)']*pq.s\n",
    "        b6b9_burst_end      = df.loc[i, 'B6/B9 last burst end (s)']*pq.s\n",
    "        b6b9_burst_duration = df.loc[i, 'B6/B9 all bursts duration (s)'] = b6b9_burst_end - b6b9_burst_start\n",
    "        b3_burst_start      = df.loc[i, 'B3 first burst start (s)']*pq.s\n",
    "        b3_burst_end        = df.loc[i, 'B3 last burst end (s)']*pq.s\n",
    "        b3_burst_duration   = df.loc[i, 'B3 all bursts duration (s)'] = b3_burst_end - b3_burst_start\n",
    "        b38_burst_start     = df.loc[i, 'B38 first burst start (s)']*pq.s\n",
    "        b38_burst_end       = df.loc[i, 'B38 last burst end (s)']*pq.s\n",
    "        b38_burst_duration  = df.loc[i, 'B38 all bursts duration (s)'] = b38_burst_end - b38_burst_start\n",
    "        \n",
    "        df.loc[i, 'Next I2 spikes first burst start (s)'] = np.nan # will be set on next iteration\n",
    "        df.loc[i, 'Next I2 spikes last burst end (s)'] = np.nan # will be set on next iteration\n",
    "        df.loc[i, 'Next I2 spikes all bursts duration (s)'] = np.nan # will be set on next iteration\n",
    "        if j != 0:\n",
    "            df.loc[df.index[j-1], 'Next I2 spikes first burst start (s)'] = i2_burst_start\n",
    "            df.loc[df.index[j-1], 'Next I2 spikes last burst end (s)'] = i2_burst_end\n",
    "            df.loc[df.index[j-1], 'Next I2 spikes all bursts duration (s)'] = i2_burst_end - i2_burst_start\n",
    "        \n",
    "        # consider B3/B6/B9 bursting if either B3 or B6/B9 is bursting\n",
    "        b3b6b9_burst_start    = df.loc[i, 'B3/B6/B9 burst start (s)']    = finite_min(b6b9_burst_start, b3_burst_start)\n",
    "        b3b6b9_burst_end      = df.loc[i, 'B3/B6/B9 burst end (s)']      = finite_max(b6b9_burst_end,   b3_burst_end)\n",
    "        b3b6b9_burst_duration = df.loc[i, 'B3/B6/B9 burst duration (s)'] = b3b6b9_burst_end - b3b6b9_burst_start\n",
    "        \n",
    "        # consider bursting only if B8a/b and B3/B6/B9 are both bursting\n",
    "        b8_or_b3b6b9_burst_end = df.loc[i, 'B8a/b and B3/B6/B9 conjunction end (s)'] = \\\n",
    "                                           finite_min(b8_burst_end, b3b6b9_burst_end)\n",
    "        \n",
    "        # delays from neural to force\n",
    "        i2_force_rise_start_delay        = df.loc[i, 'Delay from I2 end to force rise start (s)'] = \\\n",
    "                                                     force_rise_start - i2_burst_end\n",
    "\n",
    "        b8_force_rise_start_delay        = df.loc[i, 'Delay from B8a/b start to force rise start (s)'] = \\\n",
    "                                                     force_rise_start - b8_burst_start\n",
    "        b8_force_plateau_start_delay     = df.loc[i, 'Delay from B8a/b start to force plateau start (s)'] = \\\n",
    "                                                     force_plateau_start - b8_burst_start\n",
    "        b8_force_plateau_end_delay       = df.loc[i, 'Delay from B8a/b end to force plateau end (s)'] = \\\n",
    "                                                     force_plateau_end - b8_burst_end\n",
    "        \n",
    "        b6b9_force_rise_start_delay      = df.loc[i, 'Delay from B6/B9 start to force rise start (s)'] = \\\n",
    "                                                     force_rise_start - b6b9_burst_start\n",
    "        b6b9_force_plateau_start_delay   = df.loc[i, 'Delay from B6/B9 start to force plateau start (s)'] = \\\n",
    "                                                     force_plateau_start - b6b9_burst_start\n",
    "        b6b9_force_plateau_end_delay     = df.loc[i, 'Delay from B6/B9 end to force plateau end (s)'] = \\\n",
    "                                                     force_plateau_end - b6b9_burst_end\n",
    "\n",
    "        b3b6b9_force_rise_start_delay    = df.loc[i, 'Delay from B3/B6/B9 start to force rise start (s)'] = \\\n",
    "                                                     force_rise_start - b3b6b9_burst_start\n",
    "        b3b6b9_force_plateau_start_delay = df.loc[i, 'Delay from B3/B6/B9 start to force plateau start (s)'] = \\\n",
    "                                                     force_plateau_start - b3b6b9_burst_start\n",
    "        b3b6b9_force_plateau_end_delay   = df.loc[i, 'Delay from B3/B6/B9 end to force plateau end (s)'] = \\\n",
    "                                                     force_plateau_end - b3b6b9_burst_end\n",
    "        \n",
    "        b3_force_plateau_start_delay     = df.loc[i, 'Delay from B3 start to force plateau start (s)'] = \\\n",
    "                                                     force_plateau_start - b3_burst_start\n",
    "        b3_force_plateau_end_delay       = df.loc[i, 'Delay from B3 end to force plateau end (s)'] = \\\n",
    "                                                     force_plateau_end - b3_burst_end\n",
    "        b8_or_b3b6b9_force_plateau_end_delay = \\\n",
    "                                           df.loc[i, 'Delay from either B8a/b or B3/B6/B9 end to force plateau end (s)'] = \\\n",
    "                                                     force_plateau_end - b8_or_b3b6b9_burst_end\n",
    "        \n",
    "        b38_force_shoulder_end_delay     = df.loc[i, 'Delay from B38 end to force shoulder end (s)'] = \\\n",
    "                                                     force_shoulder_end - b38_burst_end\n",
    "\n",
    "        \n",
    "        \n",
    "        ###\n",
    "        ### B8 ACTIVITY BEFORE B3/B6/B9\n",
    "        ###\n",
    "        \n",
    "        st = df.loc[i, 'B8a/b spike train']\n",
    "        b8_preb3b6b9_burst_duration    = df.loc[i, 'B8a/b pre-B3/B6/B9 burst duration (s)'] = \\\n",
    "                                                   b3b6b9_burst_start - b8_burst_start\n",
    "        b8_preb3b6b9_burst_spike_count = df.loc[i, 'B8a/b pre-B3/B6/B9 burst spike count'] = \\\n",
    "                                                   st.time_slice(b8_burst_start, b3b6b9_burst_start).size\n",
    "        b8_preb3b6b9_burst_mean_freq   = df.loc[i, 'B8a/b pre-B3/B6/B9 burst mean frequency (Hz)'] = \\\n",
    "                                                   ((b8_preb3b6b9_burst_spike_count-1)/b8_preb3b6b9_burst_duration).rescale('Hz')\n",
    "        \n",
    "        # get the neural channel\n",
    "        channel = st.annotations['channels'][0]\n",
    "        sig = get_sig(blk, channel)\n",
    "        \n",
    "        # get the signal for the behavior with 5 seconds cushion before and after (for better baseline estimation)\n",
    "        sig = sig.time_slice(behavior_start - 5*pq.s, behavior_end + 5*pq.s)\n",
    "        sig = sig.rescale('uV')\n",
    "\n",
    "        # find RAUC and mean voltage for B8a/b before B3/B6/B9 start in each behavior\n",
    "        if np.isfinite(b8_burst_start) and np.isfinite(b3b6b9_burst_start):\n",
    "            b8_preb3b6b9_rauc = df.loc[i, 'B8a/b pre-B3/B6/B9 burst RAUC (μV·s)'] = elephant.signal_processing.rauc(sig, baseline='mean', t_start=b8_burst_start, t_stop=b3b6b9_burst_start).rescale('uV*s')\n",
    "            b8_preb3b6b9_mean_rect_voltage = df.loc[i, 'B8a/b pre-B3/B6/B9 burst mean rectified voltage (μV)'] = b8_preb3b6b9_rauc/b8_preb3b6b9_burst_duration\n",
    "        else:\n",
    "            print(f'Missing either B8a/b burst and/or B3/B6/B9 burst in data set \"{data_set_name}\" for swallow spanning times ({behavior_start}, {behavior_end})')\n",
    "\n",
    "        # get the peak smoothed frequency\n",
    "        firing_rate = elephant.statistics.instantaneous_rate(\n",
    "            spiketrain=st,\n",
    "            t_start=st.t_start,\n",
    "            sampling_period=sig.sampling_period,\n",
    "            kernel=smoothing_kernel,\n",
    "        )\n",
    "        b8_preb3b6b9_burst_peak_smoothed_freq = df.loc[i, 'B8a/b pre-B3/B6/B9 burst peak smoothed frequency (Hz)'] = \\\n",
    "                                                          firing_rate.time_slice(b8_burst_start, b3b6b9_burst_start).max().rescale('Hz')\n",
    "\n",
    "            \n",
    "        # get force during rise and plateau\n",
    "        sig = get_sig(blk, 'Force')\n",
    "        sig = sig.time_slice(force_rise_start, force_plateau_end)\n",
    "        sig = sig.rescale('mN')\n",
    "        \n",
    "        # get force at end of B8-only burst, offset by delay\n",
    "        force_b8_only_rise_end = df.loc[i, 'Force delayed B8-only rise end (s)'] = force_rise_start + b8_preb3b6b9_burst_duration\n",
    "        force_b8_only_rise_height = df.loc[i, 'Force at delayed B8-only rise end (mN)'] = sig[sig.time_index(force_b8_only_rise_end)][0]\n",
    "\n",
    "        # find average slope during initial rising phase (before B3/B6/B9 begin, offset by delay)\n",
    "        force_initial_increase = df.loc[i, 'Force initial increase (mN)'] = (force_b8_only_rise_height-force_baseline).rescale('mN')\n",
    "        force_initial_slope = df.loc[i, 'Force initial slope (mN/s)'] = (force_initial_increase/b8_preb3b6b9_burst_duration).rescale('mN/s')\n",
    "        \n",
    "        \n",
    "        \n",
    "        ### SANITY CHECK: plot important times across all subplots, with delays set by I2 end and force min\n",
    "#         if j == 0:\n",
    "#             # use first swallow's delay from peak protraction to force start for all units in all swallows\n",
    "#             muscle_delay = i2_force_rise_start_delay\n",
    "# #             muscle_delay = b8_force_rise_start_delay\n",
    "#             axes[-1].text(\n",
    "#                 force_rise_start, 1.05, f\"{muscle_delay.rescale('ms'):.0f} ms delay\",\n",
    "#                 horizontalalignment='right', verticalalignment='center', transform=axes[-1].get_xaxis_transform(),\n",
    "#                 fontsize=8)\n",
    "        \n",
    "        for (t, y, c) in [\n",
    "                (force_rise_start,    force_baseline,            force_colors['rise']),\n",
    "                (force_plateau_start, force_plateau_start_value, force_colors['plateau']),\n",
    "                (force_plateau_end,   force_plateau_end_value,   force_colors['plateau']),\n",
    "                (force_drop_end,      force_drop_end_value,      force_colors['drop']),\n",
    "                (force_shoulder_end,  force_shoulder_end_value,  force_colors['shoulder'])]:\n",
    "            if np.isfinite(y):\n",
    "#                 plot_vertical_lines_with_delay(axes, t, muscle_delay, y, c)\n",
    "                axes[-1].add_artist(patches.ConnectionPatch(\n",
    "                    xyA=(t, y), xyB=(t, 1),\n",
    "                    coordsA='data', coordsB=axes[0].get_xaxis_transform(),\n",
    "                    axesA=axes[-1], axesB=axes[0],\n",
    "                    color=c, lw=1, ls=':', zorder=-2))\n",
    "\n",
    "            \n",
    "    \n",
    "    # perform the following after having gone through all behaviors once\n",
    "    for j, i in enumerate(df.index):\n",
    "        \n",
    "        ###\n",
    "        ### NORMALIZED TIMES\n",
    "        ###\n",
    "        \n",
    "        normalization_fixed_times = df.loc[i, 'Normalization fixed times (s)']\n",
    "        normalization_fixed_times = normalization_fixed_times.magnitude\n",
    "        \n",
    "        i2_burst_start   = df.loc[i, 'I2 spikes first burst start (s)']\n",
    "        i2_burst_end     = df.loc[i, 'I2 spikes last burst end (s)']\n",
    "        b8_burst_start   = df.loc[i, 'B8a/b first burst start (s)']\n",
    "        b8_burst_end     = df.loc[i, 'B8a/b last burst end (s)']\n",
    "        b6b9_burst_start = df.loc[i, 'B6/B9 first burst start (s)']\n",
    "        b6b9_burst_end   = df.loc[i, 'B6/B9 last burst end (s)']\n",
    "        b3_burst_start   = df.loc[i, 'B3 first burst start (s)']\n",
    "        b3_burst_end     = df.loc[i, 'B3 last burst end (s)']\n",
    "        b38_burst_start  = df.loc[i, 'B38 first burst start (s)']\n",
    "        b38_burst_end    = df.loc[i, 'B38 last burst end (s)']\n",
    "        b4b5_burst_start = df.loc[i, 'B4/B5 first burst start (s)']\n",
    "        b4b5_burst_end   = df.loc[i, 'B4/B5 last burst end (s)']\n",
    "        next_i2_burst_start = df.loc[i, 'Next I2 spikes first burst start (s)']\n",
    "        next_i2_burst_end   = df.loc[i, 'Next I2 spikes last burst end (s)']\n",
    "\n",
    "        i2_burst_start_normalized      = df.loc[i, 'I2 first burst start (normalized)']      = normalize_time(normalization_fixed_times,\n",
    "                                                   i2_burst_start)\n",
    "        i2_burst_end_normalized        = df.loc[i, 'I2 last burst end (normalized)']         = normalize_time(normalization_fixed_times,\n",
    "                                                   i2_burst_end)\n",
    "        \n",
    "        b8_burst_start_normalized      = df.loc[i, 'B8a/b first burst start (normalized)']   = normalize_time(normalization_fixed_times,\n",
    "                                                   b8_burst_start)\n",
    "        b8_burst_end_normalized        = df.loc[i, 'B8a/b last burst end (normalized)']      = normalize_time(normalization_fixed_times,\n",
    "                                                   b8_burst_end)\n",
    "        \n",
    "        b6b9_burst_start_normalized    = df.loc[i, 'B6/B9 first burst start (normalized)']   = normalize_time(normalization_fixed_times,\n",
    "                                                   b6b9_burst_start)\n",
    "        b6b9_burst_end_normalized      = df.loc[i, 'B6/B9 last burst end (normalized)']      = normalize_time(normalization_fixed_times,\n",
    "                                                   b6b9_burst_end)\n",
    "        \n",
    "        b3_burst_start_normalized      = df.loc[i, 'B3 first burst start (normalized)']      = normalize_time(normalization_fixed_times,\n",
    "                                                   b3_burst_start)\n",
    "        b3_burst_end_normalized        = df.loc[i, 'B3 last burst end (normalized)']         = normalize_time(normalization_fixed_times,\n",
    "                                                   b3_burst_end)\n",
    "\n",
    "        b38_burst_start_normalized     = df.loc[i, 'B38 first burst start (normalized)']     = normalize_time(normalization_fixed_times,\n",
    "                                                   b38_burst_start)\n",
    "        b38_burst_end_normalized       = df.loc[i, 'B38 last burst end (normalized)']        = normalize_time(normalization_fixed_times,\n",
    "                                                   b38_burst_end)\n",
    "        \n",
    "        b4b5_burst_start_normalized    = df.loc[i, 'B4/B5 first burst start (normalized)']   = normalize_time(normalization_fixed_times,\n",
    "                                                   b4b5_burst_start)\n",
    "        b4b5_burst_end_normalized      = df.loc[i, 'B4/B5 last burst end (normalized)']      = normalize_time(normalization_fixed_times,\n",
    "                                                   b4b5_burst_end)\n",
    "        \n",
    "        next_i2_burst_start_normalized = df.loc[i, 'Next I2 first burst start (normalized)'] = normalize_time(normalization_fixed_times,\n",
    "                                                   next_i2_burst_start)\n",
    "        next_i2_burst_end_normalized   = df.loc[i, 'Next I2 last burst end (normalized)']    = normalize_time(normalization_fixed_times,\n",
    "                                                   next_i2_burst_end)\n",
    "\n",
    "        \n",
    "        \n",
    "    ###\n",
    "    ### FINISH\n",
    "    ###\n",
    "    \n",
    "    # optimize plot margins\n",
    "    plt.subplots_adjust(\n",
    "        left   = 0.1,\n",
    "        right  = 0.99,\n",
    "        top    = 0.96,\n",
    "        bottom = 0.06,\n",
    "        hspace = 0.15,\n",
    "    )\n",
    "    \n",
    "    # export figure\n",
    "    export_dir2 = os.path.join(export_dir, 'sanity-checks')\n",
    "    if not os.path.exists(export_dir2):\n",
    "        os.mkdir(export_dir2)\n",
    "    plt.gcf().savefig(os.path.join(export_dir2, f'{animal} {food} {bout_index}.png'), dpi=300)\n",
    "    \n",
    "    # index the table on 4 variables so that this dataframe can later be merged with others\n",
    "    df['Animal'] = animal\n",
    "    df['Food'] = food\n",
    "    df['Bout_index'] = bout_index\n",
    "    df = df.reset_index().set_index(['Animal', 'Food', 'Bout_index', 'Behavior_index'])\n",
    "    \n",
    "    df_list += [df]\n",
    "    \n",
    "df_all = pd.concat(df_list, sort=False).sort_index()\n",
    "\n",
    "# move exemplary behaviors to separate dataframes\n",
    "df_exemplary_swallow = df_all.loc[exemplary_swallow].copy()\n",
    "df_exemplary_bout = df_all.loc[exemplary_bout].copy()\n",
    "df_all = df_all.drop(exemplary_swallow)\n",
    "df_all = df_all.drop(exemplary_bout)\n",
    "\n",
    "# rename output files for exemplars\n",
    "old_path = os.path.join(export_dir2, f'{exemplary_swallow[0]} {exemplary_swallow[1]} {exemplary_swallow[2]}.png')\n",
    "new_path = os.path.join(export_dir2, 'exemplary_swallow.png')\n",
    "if os.path.exists(old_path):\n",
    "    if os.path.exists(new_path):\n",
    "        os.remove(new_path)\n",
    "    os.rename(old_path, new_path)\n",
    "\n",
    "old_path = os.path.join(export_dir2, f'{exemplary_bout[0]} {exemplary_bout[1]} {exemplary_bout[2]}.png')\n",
    "new_path = os.path.join(export_dir2, 'exemplary_bout.png')\n",
    "if os.path.exists(old_path):\n",
    "    if os.path.exists(new_path):\n",
    "        os.remove(new_path)\n",
    "    os.rename(old_path, new_path)\n",
    "\n",
    "end = datetime.datetime.now()\n",
    "print('elapsed time:', end-start)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "start = datetime.datetime.now()\n",
    "\n",
    "for (animal, food, bout_index), (data_set_name, channel_names, time_window, epoch_types_to_keep, burst_thresholds) in feeding_bouts.items():\n",
    "\n",
    "    if (animal, food, bout_index) == exemplary_swallow:\n",
    "        # skip the lone swallow\n",
    "        continue\n",
    "    elif (animal, food, bout_index) == exemplary_bout:\n",
    "        df = df_exemplary_bout\n",
    "    else:\n",
    "        df = df_all.loc[animal, food, bout_index]\n",
    "\n",
    "    # load the data\n",
    "    metadata = neurotic.MetadataSelector('../../data/metadata.yml')\n",
    "    metadata.select(data_set_name)\n",
    "    blk = neurotic.load_dataset(metadata, lazy=True)\n",
    "\n",
    "    units = [\n",
    "        'I2 spikes',\n",
    "        'B8a/b',\n",
    "        'B3',\n",
    "        'B6/B9',\n",
    "        'B38',\n",
    "        'B4/B5',\n",
    "    ]\n",
    "\n",
    "    # figsize = (9.5, 10) # dimensions for notebook\n",
    "    # figsize = (11, 8.5) # dimensions for printing\n",
    "    figsize = (16, 9) # dimensions for wide screens\n",
    "    fig, axes = plt.subplots(len(units)+1, 2, sharex='col', figsize=figsize)\n",
    "\n",
    "    for k, unit in enumerate(units):\n",
    "        # get the subplot axes handles\n",
    "        ax_left, ax_right = axes[k]\n",
    "\n",
    "        # set y-axis label\n",
    "        ax_left.set_ylabel(unit+' (Hz)')\n",
    "        ax_left.yaxis.set_label_coords(-0.06, 0.5)\n",
    "\n",
    "        # remove right, top, and bottom plot borders, and remove x-axis\n",
    "        sns.despine(ax=ax_left, bottom=True)\n",
    "        sns.despine(ax=ax_right, bottom=True)\n",
    "        ax_left.xaxis.set_visible(False)\n",
    "        ax_right.xaxis.set_visible(False)\n",
    "\n",
    "    # remove right and top plot borders from bottom panel, and set x-label\n",
    "    ax_left, ax_right = axes[-1]\n",
    "    sns.despine(ax=ax_left)\n",
    "    sns.despine(ax=ax_right)\n",
    "    ax_left.set_xlabel('Time (s)')\n",
    "    ax_right.set_xlabel('Time (normalized)')\n",
    "\n",
    "    # plot force in real time\n",
    "    ax_left, ax_right = axes[-1]\n",
    "    channel = 'Force'\n",
    "    sig = get_sig(blk, channel)\n",
    "    sig = sig.time_slice(time_window[0]*pq.s, time_window[1]*pq.s)\n",
    "    sig = sig.rescale(channel_units[channel_names.index(channel)])\n",
    "    ax_left.plot(sig.times, sig.magnitude, c='0.8', lw=1)\n",
    "    ax_left.set_ylabel(sig.name + ' (' + sig.units.dimensionality.string + ')')\n",
    "    ax_left.yaxis.set_label_coords(-0.06, 0.5)\n",
    "    \n",
    "    all_normalized_times_series = {}\n",
    "    for unit in units:\n",
    "        all_normalized_times_series[unit] = np.zeros((0, times_interp.size))\n",
    "    all_normalized_times_series['Force'] = np.zeros((0, times_interp.size))\n",
    "\n",
    "    for j, i in enumerate(df.index):\n",
    "        for k, unit in enumerate(units):\n",
    "            ax_left, ax_right = axes[k]\n",
    "\n",
    "            \n",
    "            # raster plot\n",
    "            st = df.loc[i, unit+' spike train']\n",
    "            ax_left.eventplot(positions=st, lineoffsets=-1, colors=unit_colors[unit])\n",
    "\n",
    "            \n",
    "            # plot the firing rates in real time\n",
    "            firing_rate = df.loc[i, unit+' firing rate (Hz)']\n",
    "            ax_left.plot(firing_rate.times.rescale('s'), firing_rate, c=unit_colors[unit])\n",
    "\n",
    "            \n",
    "            # plot firing rates in normalized time\n",
    "            firing_rate_interp = df.loc[i, unit+' firing rate, normalized time interpolation (Hz)']\n",
    "            all_normalized_times_series[unit] = np.concatenate([all_normalized_times_series[unit], firing_rate_interp[np.newaxis, :]])\n",
    "            ax_right.plot(times_interp, firing_rate_interp, c=lighten_color(unit_colors[unit], amount=0.7))\n",
    "\n",
    "            \n",
    "        # plot force in normalized time\n",
    "        ax_left, ax_right = axes[-1]\n",
    "        force_interp = df.at[i, 'Force, normalized time interpolation (mN)']\n",
    "        all_normalized_times_series['Force'] = np.concatenate([all_normalized_times_series['Force'], force_interp[np.newaxis, :]])\n",
    "        ax_right.plot(times_interp, force_interp, c='0.8', lw=1)\n",
    "\n",
    "        \n",
    "        # plot force phase boundaries in real time\n",
    "        normalization_fixed_times = df.at[i, 'Normalization fixed times (s)'].rescale('s').magnitude\n",
    "        for m, t in enumerate(normalization_fixed_times[3:8]):\n",
    "            if m == 0:\n",
    "                color = force_colors['rise']\n",
    "            else:\n",
    "                color = '0.75'\n",
    "#             axes[-1][0].axvline(x=t, lw=1, ls=':', c=color, zorder=-1)\n",
    "            axes[-1][0].add_artist(patches.ConnectionPatch(\n",
    "                xyA=(t, 0), xyB=(t, 1),\n",
    "                coordsA=axes[-1][0].get_xaxis_transform(), coordsB=axes[0][0].get_xaxis_transform(),\n",
    "                axesA=axes[-1][0], axesB=axes[0][0],\n",
    "                color=color, lw=1, ls=':'))\n",
    "\n",
    "            \n",
    "    # plot force phase boundaries in normalized time\n",
    "    for m in range(len(normalization_fixed_times)):\n",
    "        if m == 3:\n",
    "            color = force_colors['rise']\n",
    "        else:\n",
    "            color = '0.75'\n",
    "#         axes[-1][1].axvline(x=m, lw=1, ls=':', c=color, zorder=-1)\n",
    "        axes[-1][1].add_artist(patches.ConnectionPatch(\n",
    "            xyA=(m, 0), xyB=(m, 1),\n",
    "            coordsA=axes[-1][1].get_xaxis_transform(), coordsB=axes[0][1].get_xaxis_transform(),\n",
    "            axesA=axes[-1][1], axesB=axes[0][1],\n",
    "            color=color, lw=1, ls=':'))\n",
    "  \n",
    "        \n",
    "    # plot firing rate distributions\n",
    "    for k, unit in enumerate(units):\n",
    "        ax_left, ax_right = axes[k]\n",
    "\n",
    "        firing_rate_median = np.nanmedian(all_normalized_times_series[unit], axis=0)\n",
    "        firing_rate_q1 = np.nanquantile(all_normalized_times_series[unit], q=0.25, axis=0)\n",
    "        firing_rate_q3 = np.nanquantile(all_normalized_times_series[unit], q=0.75, axis=0)\n",
    "        ax_right.plot(times_interp, firing_rate_median, c='k', lw=2, zorder=3)\n",
    "        ax_right.plot(times_interp, firing_rate_q1, c='gray', lw=1)\n",
    "        ax_right.plot(times_interp, firing_rate_q3, c='gray', lw=1)\n",
    "\n",
    "    \n",
    "    # plot force distribution\n",
    "    ax_left, ax_right = axes[-1]\n",
    "\n",
    "    force_median = np.nanmedian(all_normalized_times_series['Force'], axis=0)\n",
    "    force_q1 = np.nanquantile(all_normalized_times_series['Force'], q=0.25, axis=0)\n",
    "    force_q3 = np.nanquantile(all_normalized_times_series['Force'], q=0.75, axis=0)\n",
    "    ax_right.plot(times_interp, force_median, c='k', lw=2, zorder=3)\n",
    "    ax_right.plot(times_interp, force_q1, c='gray', lw=1)\n",
    "    ax_right.plot(times_interp, force_q3, c='gray', lw=1)\n",
    "\n",
    "\n",
    "    plt.suptitle(f'({animal}, {food}, {bout_index}): {data_set_name}')\n",
    "    plt.tight_layout(rect=(0, 0, 1, 0.97))\n",
    "\n",
    "    # export figure\n",
    "    export_dir3 = os.path.join(export_dir, 'sanity-checks-firing-rates')\n",
    "    if not os.path.exists(export_dir3):\n",
    "        os.mkdir(export_dir3)\n",
    "    plt.gcf().savefig(os.path.join(export_dir3, f'{animal} {food} {bout_index}.png'), dpi=300)\n",
    "\n",
    "# rename output file for exemplar\n",
    "old_path = os.path.join(export_dir3, f'{exemplary_bout[0]} {exemplary_bout[1]} {exemplary_bout[2]}.png')\n",
    "new_path = os.path.join(export_dir3, 'exemplary_bout.png')\n",
    "if os.path.exists(old_path):\n",
    "    if os.path.exists(new_path):\n",
    "        os.remove(new_path)\n",
    "    os.rename(old_path, new_path)\n",
    "\n",
    "end = datetime.datetime.now()\n",
    "print('elapsed time:', end-start)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Special dataframe used for Fig 3C only"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "feeding_bouts_multiple_foods = {\n",
    "    # (animal, food, bout_index): (data_set_name, time_window, epoch_types_to_keep)\n",
    "        \n",
    "    ('JG12', 'Regular nori', 0): ('IN VIVO / JG12 / 2019-05-10 / 002', [ 147,  165], ['Swallow (regular 5-cm nori strip)']),\n",
    "    ('JG12', 'Regular nori', 1): ('IN VIVO / JG12 / 2019-05-10 / 002', [ 229,  245], ['Swallow (regular 5-cm nori strip)']),\n",
    "    ('JG12', 'Regular nori', 2): ('IN VIVO / JG12 / 2019-05-10 / 002', [ 277,  291], ['Swallow (regular 5-cm nori strip)']),\n",
    "\n",
    "    ('JG12', 'Tape nori',  103): ('IN VIVO / JG12 / 2019-05-10 / 002', [2890, 2941], ['Swallow (tape nori)']), # early swallows only\n",
    "}\n",
    "\n",
    "# filter epochs for each feeding condition and perform calculations\n",
    "df_list = []\n",
    "last_data_set_name = None\n",
    "for (animal, food, bout_index), (data_set_name, time_window, epoch_types_to_keep) in feeding_bouts_multiple_foods.items():\n",
    "    \n",
    "    metadata.select(data_set_name)\n",
    "    if data_set_name is last_data_set_name:\n",
    "        # skip reloading the data if it's already in memory\n",
    "        pass\n",
    "    else:\n",
    "        blk = neurotic.load_dataset(metadata, lazy=True)\n",
    "    last_data_set_name = data_set_name\n",
    "    \n",
    "    # construct a query for locating behaviors\n",
    "    behavior_query = f'(Type in {epoch_types_to_keep}) & ({time_window[0]} <= Start) & (End <= {time_window[1]})'\n",
    "    \n",
    "    # construct queries for locating epochs associated with each behavior\n",
    "    # - each query should match at most one epoch\n",
    "    # - dictionary keys are used as prefixes for the names of new columns\n",
    "    subepoch_queries = {}\n",
    "    \n",
    "    # construct a table in which each row is a behavior and subepoch data\n",
    "    # is added as columns, e.g. df['Force start (s)']\n",
    "    df = BehaviorsDataFrame(blk.segments[0].epochs, behavior_query, subepoch_queries)\n",
    "\n",
    "    # calculate interbehavior interval assuming all behaviors are from a single contiguous sequence\n",
    "    df['Interval after (s)'] = np.nan\n",
    "    previous_i = None\n",
    "    for i in df.index:\n",
    "        if previous_i is not None:\n",
    "            df.loc[previous_i, 'Interval after (s)']  = df.loc[i, 'Start (s)'] - df.loc[previous_i, 'End (s)']\n",
    "        previous_i = i\n",
    "\n",
    "    # renumber behaviors assuming all behaviors are from a single contiguous sequence\n",
    "    df = df.sort_values('Start (s)').reset_index(drop=True).rename_axis('Behavior_index')\n",
    "    \n",
    "    # index the table on 4 variables\n",
    "    df['Animal'] = animal\n",
    "    df['Food'] = food\n",
    "    df['Bout_index'] = bout_index\n",
    "    df = df.reset_index().set_index(['Animal', 'Food', 'Bout_index', 'Behavior_index'])\n",
    "    \n",
    "    df_list += [df]\n",
    "    \n",
    "df_durations_intervals = pd.concat(df_list, sort=False).sort_index()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "source": [
    "## Plotting Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "outputs": [],
   "source": [
    "def scatter2d(ax, data_subsets, xlabel, xlim, ylabel, ylim, trend=False, trend_separately=False, tooltips=False, padding=0.05):\n",
    "    \n",
    "    for j, (label, query) in enumerate(data_subsets.items()):\n",
    "        if query is not None:\n",
    "            df = df_all.query(query)\n",
    "            ax.scatter(df[xlabel], df[ylabel],\n",
    "                       label=label, marker=markers[j], c=colors[j], clip_on=False)\n",
    "            \n",
    "    all_points = df_all.query(query_union(data_subsets.values()))[[xlabel, ylabel]].dropna()\n",
    "    \n",
    "    if len(all_points) > 0:\n",
    "\n",
    "        xrange = np.ptp(all_points.iloc[:, 0])\n",
    "        xmin = min(all_points.iloc[:, 0]) - xrange * padding\n",
    "        xmax = max(all_points.iloc[:, 0]) + xrange * padding\n",
    "        if xlim is None:\n",
    "            xlim = [xmin, xmax]\n",
    "        if xlim[0] is None:\n",
    "            xlim[0] = xmin\n",
    "        if xlim[1] is None:\n",
    "            xlim[1] = xmax\n",
    "\n",
    "        yrange = np.ptp(all_points.iloc[:, 1])\n",
    "        ymin = min(all_points.iloc[:, 1]) - yrange * padding\n",
    "        ymax = max(all_points.iloc[:, 1]) + yrange * padding\n",
    "        if ylim is None:\n",
    "            ylim = [ymin, ymax]\n",
    "        if ylim[0] is None:\n",
    "            ylim[0] = ymin\n",
    "        if ylim[1] is None:\n",
    "            ylim[1] = ymax\n",
    "    \n",
    "    if trend_separately:\n",
    "        for j, (label, query) in enumerate(data_subsets.items()):\n",
    "            if query is not None:\n",
    "                df = df_all.query(query)[[xlabel, ylabel]].dropna()\n",
    "                model = sm.OLS(df.iloc[:,1], sm.add_constant(df.iloc[:,0])).fit()\n",
    "                model_stats = 'R$^2$ = {:.2f}, p = {:.3f}, n = {}'.format(model.rsquared, model.pvalues[1], len(df))\n",
    "                print(label+':', model_stats)\n",
    "                model_x = np.linspace(xlim[0], xlim[1], 100)\n",
    "                model_y = model.params[0] + model.params[1] * model_x\n",
    "                ax.plot(model_x, model_y, color=colors[j])#, label=model_stats)\n",
    "                \n",
    "    if trend:\n",
    "        model = sm.OLS(all_points.iloc[:,1], sm.add_constant(all_points.iloc[:,0])).fit()\n",
    "        model_stats = 'R$^2$ = {:.2f}, p = {:.3f}, n = {}'.format(model.rsquared, model.pvalues[1], len(all_points))\n",
    "        print('All points:', model_stats)\n",
    "        model_x = np.linspace(xlim[0], xlim[1], 100)\n",
    "        model_y = model.params[0] + model.params[1] * model_x\n",
    "        ax.plot(model_x, model_y, color='gray')#, label=model_stats)\n",
    "    \n",
    "    if tooltips:\n",
    "        # create a transparent layer containing all points for detecting mouse events\n",
    "        sc = ax.scatter(all_points.iloc[:, 0], all_points.iloc[:, 1], label=None,\n",
    "                        alpha=0, # transparent points\n",
    "                        s=0.001, # small radius of tooltip activation\n",
    "                       )\n",
    "        \n",
    "        # initialize a hidden empty tooltip\n",
    "        annot = ax.annotate(\n",
    "            '', xy=(0, 0),                              # initialize empty at origin\n",
    "            xytext=(0, 15), textcoords='offset points', # position text above point\n",
    "            color='k', size=10, ha='center',            # small black centered text\n",
    "            bbox=dict(fc='w', lw=0, alpha=0.6),         # transparent white background\n",
    "            arrowprops=dict(shrink=0, headlength=7, headwidth=7, width=0, lw=0, color='k'), # small black arrow\n",
    "        )\n",
    "        annot.set_visible(False)\n",
    "        \n",
    "        # prepare tooltip contents\n",
    "        tooltip_text = [' '.join([str(x) for x in index]) for index in list(all_points.index)]\n",
    "        \n",
    "        # bind the animation of tooltips to a hover event\n",
    "        def hover(event):\n",
    "            if event.inaxes == ax:\n",
    "                cont, ind = sc.contains(event)\n",
    "                if cont:\n",
    "                    point_index = ind['ind'][0]\n",
    "                    pos = sc.get_offsets()[point_index]\n",
    "                    annot.xy = pos\n",
    "                    annot.set_text(tooltip_text[point_index])\n",
    "                    annot.set_visible(True)\n",
    "                    ax.figure.canvas.draw_idle()\n",
    "                else:\n",
    "                    if annot.get_visible():\n",
    "                        annot.set_visible(False)\n",
    "                        ax.figure.canvas.draw_idle()\n",
    "        ax.figure.canvas.mpl_connect('motion_notify_event', hover)\n",
    "        \n",
    "    ax.set_xlabel(xlabel)\n",
    "    ax.set_xlim(xlim)\n",
    "    ax.set_ylabel(ylabel)#.replace('rectified ',''))\n",
    "    ax.set_ylim(ylim)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from matplotlib.offsetbox import AnchoredOffsetbox\n",
    "class AnchoredScaleBar(AnchoredOffsetbox):\n",
    "    def __init__(self, transform, sizex=0, sizey=0, labelx=None, labely=None, loc=4,\n",
    "                 pad=0.1, borderpad=0.1, sep=2, prop=None, barcolor=\"black\", barwidth=None, \n",
    "                 **kwargs):\n",
    "        \"\"\"\n",
    "        Draw a horizontal and/or vertical  bar with the size in data coordinate\n",
    "        of the give axes. A label will be drawn underneath (center-aligned).\n",
    "        - transform : the coordinate frame (typically axes.transData)\n",
    "        - sizex,sizey : width of x,y bar, in data units. 0 to omit\n",
    "        - labelx,labely : labels for x,y bars; None to omit\n",
    "        - loc : position in containing axes\n",
    "        - pad, borderpad : padding, in fraction of the legend font size (or prop)\n",
    "        - sep : separation between labels and bars in points.\n",
    "        - **kwargs : additional arguments passed to base class constructor\n",
    "        \"\"\"\n",
    "        from matplotlib.patches import Rectangle\n",
    "        from matplotlib.offsetbox import AuxTransformBox, VPacker, HPacker, TextArea, DrawingArea\n",
    "        bars = AuxTransformBox(transform)\n",
    "        if sizex:\n",
    "#             bars.add_artist(Rectangle((0,0), sizex, 0, ec=barcolor, lw=barwidth, fc=\"none\"))\n",
    "            bars.add_artist(Rectangle((0,0), -sizex, 0, ec=barcolor, lw=barwidth, fc=\"none\"))\n",
    "        if sizey:\n",
    "            bars.add_artist(Rectangle((0,0), 0, sizey, ec=barcolor, lw=barwidth, fc=\"none\"))\n",
    "\n",
    "        if sizex and labelx:\n",
    "            self.xlabel = TextArea(labelx, minimumdescent=False)\n",
    "            bars = VPacker(children=[bars, self.xlabel], align=\"center\", pad=0, sep=sep)\n",
    "        if sizey and labely:\n",
    "            self.ylabel = TextArea(labely)\n",
    "#             bars = HPacker(children=[self.ylabel, bars], align=\"center\", pad=0, sep=sep)\n",
    "            bars = HPacker(children=[bars, self.ylabel], align=\"center\", pad=0, sep=sep)\n",
    "\n",
    "        AnchoredOffsetbox.__init__(self, loc, pad=pad, borderpad=borderpad,\n",
    "                                   child=bars, prop=prop, frameon=False, **kwargs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def prettyplot_with_scalebars(\n",
    "    blk,\n",
    "    t_start,\n",
    "    t_stop,\n",
    "    plots,\n",
    "    \n",
    "    outfile_basename=None, # base name of output files\n",
    "    export_only=False,     # if True, will not render in notebook\n",
    "    formats=['pdf', 'svg', 'png'], # extensions of output files\n",
    "    dpi=300,               # resolution (applicable only for PNG)\n",
    "    \n",
    "    figsize=(14, 7),       # figure size in inches\n",
    "    linewidth=1,           # thickness of lines in points\n",
    "    layout_settings=None,  # positioning of plot edges and the space between plots\n",
    "    \n",
    "    x_scalebar=1*pq.s,     # size of the time scale bar in seconds\n",
    "    ylabel_padding=10,     # space between trace labels and plots\n",
    "    scalebar_padding=1,    # space between scale bars and plots\n",
    "    scalebar_sep=5,        # space between scale bars and scale labels\n",
    "    barwidth=2,            # thickness of scale bars\n",
    "):\n",
    "    \n",
    "    if export_only:\n",
    "        plt.ioff()\n",
    "        \n",
    "    fig, axes = plt.subplots(len(plots), 1, sharex=True, figsize=figsize, squeeze=False)\n",
    "    axes = axes.flatten()\n",
    "\n",
    "    for i, p in enumerate(plots):\n",
    "\n",
    "        # get the subplot axes handle\n",
    "        ax = axes[i]\n",
    "\n",
    "        # select and rescale a channel for the subplot\n",
    "        sig = next((sig for sig in blk.segments[0].analogsignals if sig.name == p['channel']), None)\n",
    "        assert sig is not None, f\"Signal with name {p['channel']} not found\"\n",
    "        sig = sig.time_slice(t_start, t_stop)\n",
    "        sig = sig.rescale(p['units'])\n",
    "\n",
    "        # downsample the data\n",
    "        sig_downsampled = DownsampleNeoSignal(sig, p.get('decimation_factor', 1))\n",
    "\n",
    "        # specify the x- and y-data for the subplot\n",
    "        ax.plot(\n",
    "            sig_downsampled.times,\n",
    "            sig_downsampled.as_quantity(),\n",
    "            linewidth=linewidth,\n",
    "            color=p.get('color', 'k'),\n",
    "        )\n",
    "        \n",
    "        # hide the box around the subplot\n",
    "        ax.set_frame_on(False)\n",
    "\n",
    "        # specify the y-axis label\n",
    "        ylabel = p.get('ylabel', sig.name)\n",
    "        if ylabel is not None:\n",
    "            ax.set_ylabel(ylabel, rotation='horizontal', ha='right', va='center', labelpad=ylabel_padding)\n",
    "\n",
    "        # specify the plot range\n",
    "        ax.set_xlim([t_start, t_stop])\n",
    "        ax.set_ylim(p['ylim'])\n",
    "\n",
    "        # disable tick marks\n",
    "        ax.tick_params(\n",
    "            bottom=False,\n",
    "            left=False,\n",
    "            labelbottom=False,\n",
    "            labelleft=False)\n",
    "\n",
    "        # add y-axis scale bar\n",
    "        if p['scalebar'] is not None:\n",
    "            ax.add_artist(AnchoredScaleBar(\n",
    "                ax.transData,\n",
    "                sizey=p['scalebar'],\n",
    "                labely=f'{p[\"scalebar\"]} {sig.units.dimensionality.string}',\n",
    "\n",
    "                loc='center left',\n",
    "                bbox_to_anchor=(1, 0.5),\n",
    "                bbox_transform=ax.transAxes,\n",
    "\n",
    "                pad=0,\n",
    "                borderpad=scalebar_padding,\n",
    "                sep=scalebar_sep,\n",
    "                barwidth=barwidth,\n",
    "            ))\n",
    "        \n",
    "    # add time scale bar below final plot\n",
    "    if x_scalebar is not None:\n",
    "        axes[-1].add_artist(AnchoredScaleBar(\n",
    "            axes[-1].transData,\n",
    "            sizex=x_scalebar.rescale(sig.times.units).magnitude,\n",
    "            labelx=f'{x_scalebar.magnitude:g} {x_scalebar.units.dimensionality.string}',\n",
    "\n",
    "            loc='upper right',\n",
    "            bbox_to_anchor=(1, 0),\n",
    "            bbox_transform=axes[-1].transAxes,\n",
    "\n",
    "            pad=0,\n",
    "            borderpad=scalebar_padding,\n",
    "            sep=scalebar_sep,\n",
    "            barwidth=barwidth,\n",
    "        ))\n",
    "\n",
    "    # adjust the white space around and between the subplots\n",
    "    if layout_settings is None:\n",
    "        fig.tight_layout(h_pad=0, w_pad=0, pad=0)\n",
    "    else:\n",
    "        plt.subplots_adjust(**layout_settings)\n",
    "\n",
    "    if outfile_basename is not None:\n",
    "        # specify file metadata (applicable only for PDF)\n",
    "        metadata = dict(\n",
    "            Subject = 'Data file: '  + blk.file_origin + '\\n' +\n",
    "                      'Start time: ' + str(t_start)    + '\\n' +\n",
    "                      'End time: '   + str(t_stop),\n",
    "        )\n",
    "\n",
    "        # write the figure to files\n",
    "        for ext in formats:\n",
    "            fig.savefig(outfile_basename+'.'+ext, metadata=metadata, dpi=dpi)\n",
    "\n",
    "    if export_only:\n",
    "        plt.ion()\n",
    "    \n",
    "    return fig, axes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Figures"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## [FIGURE 1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 🐌 Figure 1A"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "start = datetime.datetime.now()\n",
    "\n",
    "(data_set_name, channel_names, time_window, epoch_types_to_keep, burst_thresholds) = feeding_bouts[exemplary_bout]\n",
    "\n",
    "t_start, t_stop = exemplary_bout_plot_range*pq.s\n",
    "plots = [\n",
    "    {'channel': 'I2',       'units': 'uV', 'ylim': [ -60,  60], 'scalebar': 50}, #, 'decimation_factor': 100},\n",
    "    {'channel': 'RN',       'units': 'uV', 'ylim': [ -25,  25], 'scalebar': 25}, #, 'decimation_factor': 100},\n",
    "    {'channel': 'BN2',      'units': 'uV', 'ylim': [ -45,  45], 'scalebar': 50}, #, 'decimation_factor': 100},\n",
    "    {'channel': 'BN3-DIST', 'units': 'uV', 'ylim': [ -60,  60], 'scalebar': 50, 'ylabel': 'BN3'}, #, 'decimation_factor': 100},\n",
    "    {'channel': 'Force',    'units': 'mN', 'ylim': [ -20, 375], 'scalebar': 300, 'decimation_factor': 100},\n",
    "]\n",
    "channel_names = [p['channel'] for p in plots]\n",
    "channel_units = [p['units'] for p in plots]\n",
    "\n",
    "kwargs = dict(\n",
    "    formats = ['png'],\n",
    "    dpi = 600,\n",
    "    figsize = (7, 5),\n",
    "    linewidth = 0.5,\n",
    "    x_scalebar = 5*pq.s,\n",
    ")\n",
    "\n",
    "# load the data\n",
    "metadata = neurotic.MetadataSelector('../../data/metadata.yml')\n",
    "metadata.select(data_set_name)\n",
    "blk = neurotic.load_dataset(metadata) # not lazy so that I2 filter is applied\n",
    "\n",
    "# plot the data\n",
    "fig, axes = prettyplot_with_scalebars(blk, t_start, t_stop, plots, **kwargs)\n",
    "\n",
    "# plot a zero baseline for force\n",
    "# ax = axes[channel_names.index('Force')]\n",
    "# force_zero = -11.5 # mN, average before animal began swallowing, not zero because of DC offset\n",
    "# ax.axhline(force_zero, color='0.5', lw=1, ls='--', zorder=-1)\n",
    "\n",
    "# plot a vertical line marking time of video frame\n",
    "video_time = 2955 # sec\n",
    "axes[-1].set_zorder(-1)\n",
    "axes[-1].add_artist(patches.ConnectionPatch(\n",
    "    xyA=(video_time, 0), xyB=(video_time, 1),\n",
    "    coordsA=axes[-1].get_xaxis_transform(), coordsB=axes[0].get_xaxis_transform(),\n",
    "    axesA=axes[-1], axesB=axes[0],\n",
    "    color='gray', lw=1, ls=':'))\n",
    "\n",
    "fig.savefig(os.path.join(export_dir, 'figure-1A.png'), dpi=600)\n",
    "\n",
    "end = datetime.datetime.now()\n",
    "print('render time:', end-start)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## [FIGURE 2]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Biomechanics of swallowing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## [FIGURE 3]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "### 🐌 Figure 3A"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "NOTE: The plot output by this code is much longer than it will be in the final figure and must be cropped manually. It is rendered with the same amount of time showing as Fig 3B so that time scales are identical."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "start = datetime.datetime.now()\n",
    "\n",
    "data_set_name = 'IN VIVO / JG12 / 2019-05-10 / 002'\n",
    "t_start, t_stop = [228.8, 392.8] * pq.s # t=278, twidth=164, first few are regular nori strip swallows\n",
    "plots = [\n",
    "    {'channel': 'I2',       'units': 'uV', 'ylim': [ -60,  60], 'scalebar': 50}, #, 'decimation_factor': 400},\n",
    "    {'channel': 'RN',       'units': 'uV', 'ylim': [ -25,  25], 'scalebar': 25}, #, 'decimation_factor': 400},\n",
    "    {'channel': 'BN2',      'units': 'uV', 'ylim': [ -45,  45], 'scalebar': 50}, #, 'decimation_factor': 400},\n",
    "    {'channel': 'BN3-DIST', 'units': 'uV', 'ylim': [ -60,  60], 'scalebar': 50, 'ylabel': 'BN3'}, #, 'decimation_factor': 400},\n",
    "    {'channel': 'Force',    'units': 'mN', 'ylim': [ -50, 450], 'scalebar': 300, 'decimation_factor': 100},\n",
    "]\n",
    "channel_names = [p['channel'] for p in plots]\n",
    "channel_units = [p['units'] for p in plots]\n",
    "\n",
    "kwargs = dict(\n",
    "    formats = ['png'],\n",
    "    dpi = 600,\n",
    "    figsize = (14, 5),\n",
    "    linewidth = 0.5,\n",
    "    x_scalebar = 10*pq.s,\n",
    ")\n",
    "\n",
    "# load the data\n",
    "metadata = neurotic.MetadataSelector('../../data/metadata.yml')\n",
    "metadata.select(data_set_name)\n",
    "blk = neurotic.load_dataset(metadata) # not lazy so that I2 filter is applied\n",
    "\n",
    "# plot the data\n",
    "fig, axes = prettyplot_with_scalebars(blk, t_start, t_stop, plots, **kwargs)\n",
    "\n",
    "fig.savefig(os.path.join(export_dir, 'figure-3A-needs-cropped.png'), dpi=600)\n",
    "\n",
    "end = datetime.datetime.now()\n",
    "print('render time:', end-start)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "### 🐌 Figure 3B"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "start = datetime.datetime.now()\n",
    "\n",
    "data_set_name = 'IN VIVO / JG12 / 2019-05-10 / 002'\n",
    "t_start, t_stop = [2879, 3043] * pq.s # t=2928.2, twidth=164, 19 tape nori swallows\n",
    "plots = [\n",
    "    {'channel': 'I2',       'units': 'uV', 'ylim': [ -60,  60], 'scalebar': 50}, #, 'decimation_factor': 400},\n",
    "    {'channel': 'RN',       'units': 'uV', 'ylim': [ -25,  25], 'scalebar': 25}, #, 'decimation_factor': 400},\n",
    "    {'channel': 'BN2',      'units': 'uV', 'ylim': [ -45,  45], 'scalebar': 50}, #, 'decimation_factor': 400},\n",
    "    {'channel': 'BN3-DIST', 'units': 'uV', 'ylim': [ -60,  60], 'scalebar': 50, 'ylabel': 'BN3'}, #, 'decimation_factor': 400},\n",
    "    {'channel': 'Force',    'units': 'mN', 'ylim': [ -50, 450], 'scalebar': 300, 'decimation_factor': 100},\n",
    "]\n",
    "channel_names = [p['channel'] for p in plots]\n",
    "channel_units = [p['units'] for p in plots]\n",
    "\n",
    "kwargs = dict(\n",
    "    formats = ['png'],\n",
    "    dpi = 600,\n",
    "    figsize = (14, 5),\n",
    "    linewidth = 0.5,\n",
    "    x_scalebar = 10*pq.s,\n",
    ")\n",
    "\n",
    "# load the data\n",
    "metadata = neurotic.MetadataSelector('../../data/metadata.yml')\n",
    "metadata.select(data_set_name)\n",
    "blk = neurotic.load_dataset(metadata) # not lazy so that I2 filter is applied\n",
    "\n",
    "# plot the data\n",
    "fig, axes = prettyplot_with_scalebars(blk, t_start, t_stop, plots, **kwargs)\n",
    "\n",
    "# plot a zero baseline for force\n",
    "ax = axes[channel_names.index('Force')]\n",
    "force_zero = -11.5 # mN, average before animal began swallowing, not zero because of DC offset\n",
    "ax.axhline(force_zero, color='0.5', lw=1, ls='--', zorder=-1)\n",
    "\n",
    "# plot a gray rectangle highlighting sequence expanded in other parts of the figure\n",
    "axes[-1].set_zorder(-1) # needed for trick below\n",
    "axes[-1].axvspan(\n",
    "    exemplary_bout_plot_range[0], exemplary_bout_plot_range[1],\n",
    "    0, 999, clip_on=False, # trick for getting to span entire figure\n",
    "    facecolor='0.8', edgecolor=None, lw=0, zorder=-2)\n",
    "\n",
    "fig.savefig(os.path.join(export_dir, 'figure-3B.png'), dpi=600)\n",
    "\n",
    "end = datetime.datetime.now()\n",
    "print('render time:', end-start)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "### 🐌 Figure 3C"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plt.figure(figsize=(5, 5))\n",
    "# ax = plt.gca()\n",
    "\n",
    "# df = df_durations_intervals.reset_index()\n",
    "# df = df.rename(columns={\n",
    "#     'Duration (s)':       'Swallow duration',\n",
    "#     'Interval after (s)': 'Inter-swallow interval'})\n",
    "# df = pd.melt(df,\n",
    "#              id_vars=['Animal', 'Food', 'Bout_index', 'Behavior_index'],\n",
    "#              value_vars=['Swallow duration', 'Inter-swallow interval'],\n",
    "#              var_name='',\n",
    "#              value_name='Duration/interval (s)')\n",
    "# sns.boxplot(hue='Food', y='Duration/interval (s)', x='', data=df, fliersize=0, whis=999) # whis=999 ensures whiskers go to min and max\n",
    "# # sns.swarmplot(hue='Food', y='Duration/interval (s)', x='', data=df)\n",
    "\n",
    "# # plot zero line\n",
    "# plt.axhline(y=0, ls=':', c='gray', zorder=-1)\n",
    "\n",
    "# plt.tight_layout()\n",
    "\n",
    "# plt.gcf().savefig(os.path.join(export_dir, 'figure-3C.png'), dpi=300)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axes = plt.subplots(1, 2, figsize=(8, 4))\n",
    "\n",
    "df = df_durations_intervals.reset_index()\n",
    "df = df.rename(columns={\n",
    "    'Duration (s)':       'Swallow duration (s)',\n",
    "    'Interval after (s)': 'Inter-swallow interval (s)'})\n",
    "\n",
    "sns.boxplot(x='Food', y='Swallow duration (s)', data=df, ax=axes[0], color='0.75', fliersize=0, whis=999) # whis=999 ensures whiskers go to min and max\n",
    "# sns.swarmplot(x='Food', y='Swallow duration (s)', data=df, ax=axes[0], color='0.25')\n",
    "axes[0].set_ylim([0, None])\n",
    "axes[0].set_xlabel(None)\n",
    "\n",
    "sns.boxplot(x='Food', y='Inter-swallow interval (s)', data=df, ax=axes[1], color='0.75', fliersize=0, whis=999) # whis=999 ensures whiskers go to min and max\n",
    "# sns.swarmplot(x='Food', y='Inter-swallow interval (s)', data=df, ax=axes[1], color='0.25')\n",
    "axes[1].set_xlabel(None)\n",
    "axes[1].axhline(y=0, ls=':', c='gray', zorder=-1)\n",
    "\n",
    "plt.tight_layout(w_pad=2)\n",
    "\n",
    "plt.gcf().savefig(os.path.join(export_dir, 'figure-3C.png'), dpi=300)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "### 🐌 Figure 3D"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "start = datetime.datetime.now()\n",
    "\n",
    "df = df_exemplary_bout\n",
    "(data_set_name, channel_names, time_window, epoch_types_to_keep, burst_thresholds) = feeding_bouts[exemplary_bout]\n",
    "\n",
    "t_start, t_stop = exemplary_bout_plot_range*pq.s\n",
    "plots = [\n",
    "    {'channel': 'I2',       'units': 'uV', 'ylim': [ -60,  60], 'scalebar': 50}, #, 'decimation_factor': 100},\n",
    "#     {'channel': 'RN',       'units': 'uV', 'ylim': [ -25,  25], 'scalebar': 25}, #, 'decimation_factor': 100},\n",
    "#     {'channel': 'BN2',      'units': 'uV', 'ylim': [ -45,  45], 'scalebar': 50}, #, 'decimation_factor': 100},\n",
    "#     {'channel': 'BN3-DIST', 'units': 'uV', 'ylim': [ -60,  60], 'scalebar': 50, 'ylabel': 'BN3'}, #, 'decimation_factor': 100},\n",
    "    {'channel': 'Force',    'units': 'mN', 'ylim': [ -20, 375], 'scalebar': 300, 'decimation_factor': 100},\n",
    "]\n",
    "channel_names = [p['channel'] for p in plots]\n",
    "channel_units = [p['units'] for p in plots]\n",
    "\n",
    "kwargs = dict(\n",
    "#     figsize = (9, 3),\n",
    "    figsize = (6, 3),\n",
    "    linewidth = 0.5,\n",
    "    x_scalebar = 5*pq.s,\n",
    ")\n",
    "\n",
    "# load the data\n",
    "metadata = neurotic.MetadataSelector('../../data/metadata.yml')\n",
    "metadata.select(data_set_name)\n",
    "blk = neurotic.load_dataset(metadata) # not lazy so that I2 filter is applied\n",
    "\n",
    "# plot the signal\n",
    "fig, axes = prettyplot_with_scalebars(blk, t_start, t_stop, plots, **kwargs)\n",
    "\n",
    "units = [\n",
    "    'I2 spikes',\n",
    "#     'B8a/b',\n",
    "#     'B6/B9',\n",
    "#     'B3',\n",
    "#     'B38',\n",
    "]\n",
    "\n",
    "# # plot a zero baseline for force\n",
    "# ax = axes[channel_names.index('Force')]\n",
    "# force_zero = -11.5 # mN, average before animal began swallowing, not zero because of DC offset\n",
    "# ax.axhline(force_zero, color='0.75', lw=1, ls='--', zorder=-1)\n",
    "\n",
    "for j, i in enumerate(df.index):\n",
    "    \n",
    "    # plot force markers\n",
    "    force_shoulder_end = df.loc[i, 'Force shoulder end start (s)']*pq.s\n",
    "    force_shoulder_end_value = df.loc[i, 'Force shoulder end value (mN)']*pq.mN\n",
    "    force_min_time = df.loc[i, 'Force minimum time (s)']*pq.s\n",
    "    force_min = df.loc[i, 'Force minimum (mN)']*pq.mN\n",
    "    ax = axes[channel_names.index('Force')]\n",
    "    ax.plot([force_shoulder_end], [force_shoulder_end_value], marker=7, markersize=8, color='k')\n",
    "    ax.plot([force_min_time], [force_min],                    marker=6, markersize=8, color='k')\n",
    "    \n",
    "    for k, unit in enumerate(units):\n",
    "                \n",
    "        # plot burst windows\n",
    "        burst_start = df.loc[i, unit+' first burst start (s)']\n",
    "        if np.isfinite(burst_start) and burst_start < t_stop:\n",
    "            burst_end = df.loc[i, unit+' last burst end (s)']\n",
    "            axes[-1].set_zorder(-1) # needed for trick below\n",
    "            axes[-1].axvspan(\n",
    "                burst_start, burst_end,\n",
    "                0, 999, clip_on=False, # trick for getting to span entire figure\n",
    "                facecolor=lighten_color(unit_colors[unit], amount=0.7), edgecolor=None, lw=0)\n",
    "\n",
    "fig.savefig(os.path.join(export_dir, 'figure-3D.png'), dpi=600)\n",
    "\n",
    "end = datetime.datetime.now()\n",
    "print('render time:', end-start)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 🐌 Figure 3E"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "start = datetime.datetime.now()\n",
    "\n",
    "df = df_exemplary_bout\n",
    "(data_set_name, channel_names, time_window, epoch_types_to_keep, burst_thresholds) = feeding_bouts[exemplary_bout]\n",
    "\n",
    "t_start, t_stop = exemplary_bout_plot_range*pq.s\n",
    "plots = [\n",
    "#     {'channel': 'I2',       'units': 'uV', 'ylim': [ -60,  60], 'scalebar': 50}, #, 'decimation_factor': 100},\n",
    "    {'channel': 'RN',       'units': 'uV', 'ylim': [ -25,  25], 'scalebar': 25}, #, 'decimation_factor': 100},\n",
    "#     {'channel': 'BN2',      'units': 'uV', 'ylim': [ -45,  45], 'scalebar': 50}, #, 'decimation_factor': 100},\n",
    "#     {'channel': 'BN3-DIST', 'units': 'uV', 'ylim': [ -60,  60], 'scalebar': 50, 'ylabel': 'BN3'}, #, 'decimation_factor': 100},\n",
    "    {'channel': 'Force',    'units': 'mN', 'ylim': [ -20, 375], 'scalebar': 300, 'decimation_factor': 100},\n",
    "]\n",
    "channel_names = [p['channel'] for p in plots]\n",
    "channel_units = [p['units'] for p in plots]\n",
    "\n",
    "kwargs = dict(\n",
    "#     figsize = (9, 3),\n",
    "    figsize = (6, 3),\n",
    "    linewidth = 0.5,\n",
    "    x_scalebar = 5*pq.s,\n",
    ")\n",
    "\n",
    "# load the data\n",
    "metadata = neurotic.MetadataSelector('../../data/metadata.yml')\n",
    "metadata.select(data_set_name)\n",
    "blk = neurotic.load_dataset(metadata, lazy=True)\n",
    "\n",
    "# plot the signal\n",
    "fig, axes = prettyplot_with_scalebars(blk, t_start, t_stop, plots, **kwargs)\n",
    "\n",
    "units = [\n",
    "#     'I2 spikes',\n",
    "    'B8a/b',\n",
    "#     'B6/B9',\n",
    "#     'B3',\n",
    "#     'B38',\n",
    "]\n",
    "\n",
    "# # plot a zero baseline for force\n",
    "# ax = axes[channel_names.index('Force')]\n",
    "# force_zero = -11.5 # mN, average before animal began swallowing, not zero because of DC offset\n",
    "# ax.axhline(force_zero, color='0.75', lw=1, ls='--', zorder=-1)\n",
    "\n",
    "for j, i in enumerate(df.index):\n",
    "    \n",
    "    # plot force markers\n",
    "    force_rise_start = df.loc[i, 'Force rise start start (s)']*pq.s\n",
    "    force_baseline = df.loc[i, 'Force baseline (mN)']*pq.mN\n",
    "    force_plateau_end = df.loc[i, 'Force plateau end start (s)']*pq.s\n",
    "    force_plateau_end_value = df.loc[i, 'Force plateau end value (mN)']*pq.mN\n",
    "    ax = axes[channel_names.index('Force')]\n",
    "    ax.plot([force_rise_start],  [force_baseline],          marker=6, markersize=8, color='k')\n",
    "    ax.plot([force_plateau_end], [force_plateau_end_value], marker=4, markersize=8, color='k')\n",
    "    \n",
    "    for k, unit in enumerate(units):\n",
    "                \n",
    "        # plot burst windows\n",
    "        burst_start = df.loc[i, unit+' first burst start (s)']\n",
    "        if np.isfinite(burst_start) and burst_start < t_stop:\n",
    "            burst_end = df.loc[i, unit+' last burst end (s)']\n",
    "            burst_end = min(burst_end, t_stop) # hack to prevent unclipped rect entering margin\n",
    "            axes[-1].set_zorder(-1) # needed for trick below\n",
    "            axes[-1].axvspan(\n",
    "                burst_start, burst_end,\n",
    "                0, 999, clip_on=False, # trick for getting to span entire figure\n",
    "                facecolor=lighten_color(unit_colors[unit], amount=0.7), edgecolor=None, lw=0)\n",
    "\n",
    "fig.savefig(os.path.join(export_dir, 'figure-3E.png'), dpi=600)\n",
    "\n",
    "end = datetime.datetime.now()\n",
    "print('render time:', end-start)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 🐌 Figure 3F"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "start = datetime.datetime.now()\n",
    "\n",
    "df = df_exemplary_bout\n",
    "(data_set_name, channel_names, time_window, epoch_types_to_keep, burst_thresholds) = feeding_bouts[exemplary_bout]\n",
    "\n",
    "t_start, t_stop = exemplary_bout_plot_range*pq.s\n",
    "plots = [\n",
    "#     {'channel': 'I2',       'units': 'uV', 'ylim': [ -60,  60], 'scalebar': 50}, #, 'decimation_factor': 100},\n",
    "#     {'channel': 'RN',       'units': 'uV', 'ylim': [ -25,  25], 'scalebar': 25}, #, 'decimation_factor': 100},\n",
    "    {'channel': 'BN2',      'units': 'uV', 'ylim': [ -45,  45], 'scalebar': 50}, #, 'decimation_factor': 100},\n",
    "#     {'channel': 'BN3-DIST', 'units': 'uV', 'ylim': [ -60,  60], 'scalebar': 50, 'ylabel': 'BN3'}, #, 'decimation_factor': 100},\n",
    "    {'channel': 'Force',    'units': 'mN', 'ylim': [ -20, 375], 'scalebar': 300, 'decimation_factor': 100},\n",
    "]\n",
    "channel_names = [p['channel'] for p in plots]\n",
    "channel_units = [p['units'] for p in plots]\n",
    "\n",
    "kwargs = dict(\n",
    "#     figsize = (9, 3),\n",
    "    figsize = (6, 3),\n",
    "    linewidth = 0.5,\n",
    "    x_scalebar = 5*pq.s,\n",
    ")\n",
    "\n",
    "# load the data\n",
    "metadata = neurotic.MetadataSelector('../../data/metadata.yml')\n",
    "metadata.select(data_set_name)\n",
    "blk = neurotic.load_dataset(metadata, lazy=True)\n",
    "\n",
    "# plot the signal\n",
    "fig, axes = prettyplot_with_scalebars(blk, t_start, t_stop, plots, **kwargs)\n",
    "\n",
    "units = [\n",
    "#     'I2 spikes',\n",
    "#     'B8a/b',\n",
    "    'B6/B9',\n",
    "#     'B3',\n",
    "#     'B38',\n",
    "]\n",
    "\n",
    "# # plot a zero baseline for force\n",
    "# ax = axes[channel_names.index('Force')]\n",
    "# force_zero = -11.5 # mN, average before animal began swallowing, not zero because of DC offset\n",
    "# ax.axhline(force_zero, color='0.75', lw=1, ls='--', zorder=-1)\n",
    "\n",
    "for j, i in enumerate(df.index):\n",
    "    \n",
    "    # plot force markers\n",
    "    force_rise_start = df.loc[i, 'Force rise start start (s)']*pq.s\n",
    "    force_baseline = df.loc[i, 'Force baseline (mN)']*pq.mN\n",
    "#     force_plateau_start = df.loc[i, 'Force plateau start start (s)']*pq.s\n",
    "#     force_plateau_start_value = df.loc[i, 'Force plateau start value (mN)']*pq.mN\n",
    "    force_plateau_end = df.loc[i, 'Force plateau end start (s)']*pq.s\n",
    "    force_plateau_end_value = df.loc[i, 'Force plateau end value (mN)']*pq.mN\n",
    "    ax = axes[channel_names.index('Force')]\n",
    "    ax.plot([force_rise_start],    [force_baseline],            marker=6, markersize=8, color='k')\n",
    "#     ax.plot([force_plateau_start], [force_plateau_start_value], marker=5, markersize=8, color='k')\n",
    "    ax.plot([force_plateau_end],   [force_plateau_end_value],   marker=4, markersize=8, color='k')\n",
    "    \n",
    "    for k, unit in enumerate(units):\n",
    "                \n",
    "        # plot burst windows\n",
    "        burst_start = df.loc[i, unit+' first burst start (s)']\n",
    "        if np.isfinite(burst_start) and burst_start < t_stop:\n",
    "            burst_end = df.loc[i, unit+' last burst end (s)']\n",
    "            burst_end = min(burst_end, t_stop) # hack to prevent unclipped rect entering margin\n",
    "            axes[-1].set_zorder(-1) # needed for trick below\n",
    "            axes[-1].axvspan(\n",
    "                burst_start, burst_end,\n",
    "                0, 999, clip_on=False, # trick for getting to span entire figure\n",
    "                facecolor=lighten_color(unit_colors[unit], amount=0.7), edgecolor=None, lw=0)\n",
    "\n",
    "fig.savefig(os.path.join(export_dir, 'figure-3F.png'), dpi=600)\n",
    "\n",
    "end = datetime.datetime.now()\n",
    "print('render time:', end-start)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 🐌 Figure 3G"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "start = datetime.datetime.now()\n",
    "\n",
    "df = df_exemplary_bout\n",
    "(data_set_name, channel_names, time_window, epoch_types_to_keep, burst_thresholds) = feeding_bouts[exemplary_bout]\n",
    "\n",
    "t_start, t_stop = exemplary_bout_plot_range*pq.s\n",
    "plots = [\n",
    "#     {'channel': 'I2',       'units': 'uV', 'ylim': [ -60,  60], 'scalebar': 50}, #, 'decimation_factor': 100},\n",
    "#     {'channel': 'RN',       'units': 'uV', 'ylim': [ -25,  25], 'scalebar': 25}, #, 'decimation_factor': 100},\n",
    "    {'channel': 'BN2',      'units': 'uV', 'ylim': [ -45,  45], 'scalebar': 50}, #, 'decimation_factor': 100},\n",
    "#     {'channel': 'BN3-DIST', 'units': 'uV', 'ylim': [ -60,  60], 'scalebar': 50, 'ylabel': 'BN3'}, #, 'decimation_factor': 100},\n",
    "    {'channel': 'Force',    'units': 'mN', 'ylim': [ -20, 375], 'scalebar': 300, 'decimation_factor': 100},\n",
    "]\n",
    "channel_names = [p['channel'] for p in plots]\n",
    "channel_units = [p['units'] for p in plots]\n",
    "\n",
    "kwargs = dict(\n",
    "#     figsize = (9, 3),\n",
    "    figsize = (6, 3),\n",
    "    linewidth = 0.5,\n",
    "    x_scalebar = 5*pq.s,\n",
    ")\n",
    "\n",
    "# load the data\n",
    "metadata = neurotic.MetadataSelector('../../data/metadata.yml')\n",
    "metadata.select(data_set_name)\n",
    "blk = neurotic.load_dataset(metadata, lazy=True)\n",
    "\n",
    "# plot the signal\n",
    "fig, axes = prettyplot_with_scalebars(blk, t_start, t_stop, plots, **kwargs)\n",
    "\n",
    "units = [\n",
    "#     'I2 spikes',\n",
    "#     'B8a/b',\n",
    "#     'B6/B9',\n",
    "    'B3',\n",
    "#     'B38',\n",
    "]\n",
    "\n",
    "# # plot a zero baseline for force\n",
    "# ax = axes[channel_names.index('Force')]\n",
    "# force_zero = -11.5 # mN, average before animal began swallowing, not zero because of DC offset\n",
    "# ax.axhline(force_zero, color='0.75', lw=1, ls='--', zorder=-1)\n",
    "\n",
    "for j, i in enumerate(df.index):\n",
    "    \n",
    "    # plot force markers\n",
    "#     force_rise_start = df.loc[i, 'Force rise start start (s)']*pq.s\n",
    "#     force_baseline = df.loc[i, 'Force baseline (mN)']*pq.mN\n",
    "    force_plateau_start = df.loc[i, 'Force plateau start start (s)']*pq.s\n",
    "    force_plateau_start_value = df.loc[i, 'Force plateau start value (mN)']*pq.mN\n",
    "    force_plateau_end = df.loc[i, 'Force plateau end start (s)']*pq.s\n",
    "    force_plateau_end_value = df.loc[i, 'Force plateau end value (mN)']*pq.mN\n",
    "    ax = axes[channel_names.index('Force')]\n",
    "#     ax.plot([force_rise_start],    [force_baseline],            marker=6, markersize=8, color='k')\n",
    "    ax.plot([force_plateau_start], [force_plateau_start_value], marker=5, markersize=8, color='k')\n",
    "    ax.plot([force_plateau_end],   [force_plateau_end_value],   marker=4, markersize=8, color='k')\n",
    "    \n",
    "    for k, unit in enumerate(units):\n",
    "                \n",
    "        # plot burst windows\n",
    "        burst_start = df.loc[i, unit+' first burst start (s)']\n",
    "        if np.isfinite(burst_start) and burst_start < t_stop:\n",
    "            burst_end = df.loc[i, unit+' last burst end (s)']\n",
    "            burst_end = min(burst_end, t_stop) # hack to prevent unclipped rect entering margin\n",
    "            axes[-1].set_zorder(-1) # needed for trick below\n",
    "            axes[-1].axvspan(\n",
    "                burst_start, burst_end,\n",
    "                0, 999, clip_on=False, # trick for getting to span entire figure\n",
    "                facecolor=lighten_color(unit_colors[unit], amount=0.7), edgecolor=None, lw=0)\n",
    "\n",
    "fig.savefig(os.path.join(export_dir, 'figure-3G.png'), dpi=600)\n",
    "\n",
    "end = datetime.datetime.now()\n",
    "print('render time:', end-start)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 🐌 Figure 3H"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "start = datetime.datetime.now()\n",
    "\n",
    "df = df_exemplary_bout\n",
    "(data_set_name, channel_names, time_window, epoch_types_to_keep, burst_thresholds) = feeding_bouts[exemplary_bout]\n",
    "\n",
    "t_start, t_stop = exemplary_bout_plot_range*pq.s\n",
    "plots = [\n",
    "#     {'channel': 'I2',       'units': 'uV', 'ylim': [ -60,  60], 'scalebar': 50}, #, 'decimation_factor': 100},\n",
    "#     {'channel': 'RN',       'units': 'uV', 'ylim': [ -25,  25], 'scalebar': 25}, #, 'decimation_factor': 100},\n",
    "    {'channel': 'BN2',      'units': 'uV', 'ylim': [ -45,  45], 'scalebar': 50}, #, 'decimation_factor': 100},\n",
    "#     {'channel': 'BN3-DIST', 'units': 'uV', 'ylim': [ -60,  60], 'scalebar': 50, 'ylabel': 'BN3'}, #, 'decimation_factor': 100},\n",
    "    {'channel': 'Force',    'units': 'mN', 'ylim': [ -20, 375], 'scalebar': 300, 'decimation_factor': 100},\n",
    "]\n",
    "channel_names = [p['channel'] for p in plots]\n",
    "channel_units = [p['units'] for p in plots]\n",
    "\n",
    "kwargs = dict(\n",
    "#     figsize = (9, 3),\n",
    "    figsize = (6, 3),\n",
    "    linewidth = 0.5,\n",
    "    x_scalebar = 5*pq.s,\n",
    ")\n",
    "\n",
    "# load the data\n",
    "metadata = neurotic.MetadataSelector('../../data/metadata.yml')\n",
    "metadata.select(data_set_name)\n",
    "blk = neurotic.load_dataset(metadata, lazy=True)\n",
    "\n",
    "# plot the signal\n",
    "fig, axes = prettyplot_with_scalebars(blk, t_start, t_stop, plots, **kwargs)\n",
    "\n",
    "units = [\n",
    "#     'I2 spikes',\n",
    "#     'B8a/b',\n",
    "#     'B6/B9',\n",
    "#     'B3',\n",
    "    'B38',\n",
    "]\n",
    "\n",
    "# # plot a zero baseline for force\n",
    "# ax = axes[channel_names.index('Force')]\n",
    "# force_zero = -11.5 # mN, average before animal began swallowing, not zero because of DC offset\n",
    "# ax.axhline(force_zero, color='0.75', lw=1, ls='--', zorder=-1)\n",
    "\n",
    "for j, i in enumerate(df.index):\n",
    "    \n",
    "    # plot force markers\n",
    "    force_shoulder_end = df.loc[i, 'Force shoulder end start (s)']*pq.s\n",
    "    force_shoulder_end_value = df.loc[i, 'Force shoulder end value (mN)']*pq.mN\n",
    "    ax = axes[channel_names.index('Force')]\n",
    "    ax.plot([force_shoulder_end], [force_shoulder_end_value], marker=7, markersize=8, color='k')\n",
    "    \n",
    "    for k, unit in enumerate(units):\n",
    "                \n",
    "        # plot burst windows\n",
    "        burst_start = df.loc[i, unit+' first burst start (s)']\n",
    "        if np.isfinite(burst_start) and burst_start < t_stop:\n",
    "            burst_end = df.loc[i, unit+' last burst end (s)']\n",
    "            burst_end = min(burst_end, t_stop) # hack to prevent unclipped rect entering margin\n",
    "            axes[-1].set_zorder(-1) # needed for trick below\n",
    "            axes[-1].axvspan(\n",
    "                burst_start, burst_end,\n",
    "                0, 999, clip_on=False, # trick for getting to span entire figure\n",
    "                facecolor=lighten_color(unit_colors[unit], amount=0.7), edgecolor=None, lw=0)\n",
    "\n",
    "fig.savefig(os.path.join(export_dir, 'figure-3H.png'), dpi=600)\n",
    "\n",
    "end = datetime.datetime.now()\n",
    "print('render time:', end-start)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 🐌 Figure 3I ?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "start = datetime.datetime.now()\n",
    "\n",
    "df = df_exemplary_bout\n",
    "(data_set_name, channel_names, time_window, epoch_types_to_keep, burst_thresholds) = feeding_bouts[exemplary_bout]\n",
    "\n",
    "t_start, t_stop = exemplary_bout_plot_range*pq.s\n",
    "plots = [\n",
    "#     {'channel': 'I2',       'units': 'uV', 'ylim': [ -60,  60], 'scalebar': 50}, #, 'decimation_factor': 100},\n",
    "#     {'channel': 'RN',       'units': 'uV', 'ylim': [ -25,  25], 'scalebar': 25}, #, 'decimation_factor': 100},\n",
    "#     {'channel': 'BN2',      'units': 'uV', 'ylim': [ -45,  45], 'scalebar': 50}, #, 'decimation_factor': 100},\n",
    "    {'channel': 'BN3-DIST', 'units': 'uV', 'ylim': [ -60,  60], 'scalebar': 50, 'ylabel': 'BN3'}, #, 'decimation_factor': 100},\n",
    "    {'channel': 'Force',    'units': 'mN', 'ylim': [ -20, 375], 'scalebar': 300, 'decimation_factor': 100},\n",
    "]\n",
    "channel_names = [p['channel'] for p in plots]\n",
    "channel_units = [p['units'] for p in plots]\n",
    "\n",
    "kwargs = dict(\n",
    "#     figsize = (9, 3),\n",
    "    figsize = (6, 3),\n",
    "    linewidth = 0.5,\n",
    "    x_scalebar = 5*pq.s,\n",
    ")\n",
    "\n",
    "# load the data\n",
    "metadata = neurotic.MetadataSelector('../../data/metadata.yml')\n",
    "metadata.select(data_set_name)\n",
    "blk = neurotic.load_dataset(metadata, lazy=True)\n",
    "\n",
    "# plot the signal\n",
    "fig, axes = prettyplot_with_scalebars(blk, t_start, t_stop, plots, **kwargs)\n",
    "\n",
    "units = [\n",
    "#     'I2 spikes',\n",
    "#     'B8a/b',\n",
    "#     'B6/B9',\n",
    "#     'B3',\n",
    "#     'B38',\n",
    "    'B4/B5',\n",
    "]\n",
    "\n",
    "# # plot a zero baseline for force\n",
    "# ax = axes[channel_names.index('Force')]\n",
    "# force_zero = -11.5 # mN, average before animal began swallowing, not zero because of DC offset\n",
    "# ax.axhline(force_zero, color='0.75', lw=1, ls='--', zorder=-1)\n",
    "\n",
    "for j, i in enumerate(df.index):\n",
    "    \n",
    "    # plot force markers\n",
    "    force_rise_start = df.loc[i, 'Force rise start start (s)']*pq.s\n",
    "    force_baseline = df.loc[i, 'Force baseline (mN)']*pq.mN\n",
    "    ax = axes[channel_names.index('Force')]\n",
    "    ax.plot([force_rise_start],  [force_baseline],          marker=6, markersize=8, color='k')\n",
    "    \n",
    "    for k, unit in enumerate(units):\n",
    "                \n",
    "        # plot burst windows\n",
    "        burst_start = df.loc[i, unit+' first burst start (s)']\n",
    "        if np.isfinite(burst_start) and burst_start < t_stop:\n",
    "            burst_end = df.loc[i, unit+' last burst end (s)']\n",
    "            burst_end = min(burst_end, t_stop) # hack to prevent unclipped rect entering margin\n",
    "            axes[-1].set_zorder(-1) # needed for trick below\n",
    "            axes[-1].axvspan(\n",
    "                burst_start, burst_end,\n",
    "                0, 999, clip_on=False, # trick for getting to span entire figure\n",
    "                facecolor=lighten_color(unit_colors[unit], amount=0.7), edgecolor=None, lw=0)\n",
    "\n",
    "fig.savefig(os.path.join(export_dir, 'figure-3I.png'), dpi=600)\n",
    "\n",
    "end = datetime.datetime.now()\n",
    "print('render time:', end-start)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## [FIGURE 4]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "start = datetime.datetime.now()\n",
    "\n",
    "df = df_exemplary_swallow\n",
    "(data_set_name, channel_names, time_window, epoch_types_to_keep, burst_thresholds) = feeding_bouts[exemplary_swallow]\n",
    "\n",
    "t_start = (df.loc[0, 'I2 spikes first burst start (s)'] - 0.4)*pq.s\n",
    "t_stop = (df.loc[0, 'Next force rise start (s)'] + 0.4)*pq.s\n",
    "plots = [\n",
    "    {'channel': 'I2',       'units': 'uV', 'ylim': [ -60,  60], 'scalebar': 50}, #, 'decimation_factor': 100},\n",
    "    {'channel': 'RN',       'units': 'uV', 'ylim': [ -25,  25], 'scalebar': 25}, #, 'decimation_factor': 100},\n",
    "    {'channel': 'BN2',      'units': 'uV', 'ylim': [ -45,  45], 'scalebar': 50}, #, 'decimation_factor': 100},\n",
    "    {'channel': 'BN3-DIST', 'units': 'uV', 'ylim': [ -60,  60], 'scalebar': 50, 'ylabel': 'BN3'}, #, 'decimation_factor': 100},\n",
    "    {'channel': 'Force',    'units': 'mN', 'ylim': [ -50, 260], 'scalebar': 100, 'decimation_factor': 100},\n",
    "]\n",
    "channel_names = [p['channel'] for p in plots]\n",
    "channel_units = [p['units'] for p in plots]\n",
    "\n",
    "kwargs = dict(\n",
    "    figsize = (7, 8),\n",
    "    linewidth = 0.5,\n",
    "    x_scalebar = 1*pq.s,\n",
    ")\n",
    "\n",
    "# load the metadata\n",
    "metadata = neurotic.MetadataSelector('../../data/metadata.yml')\n",
    "metadata.select(data_set_name)\n",
    "\n",
    "# add/update the force filter\n",
    "new_force_filter = {'channel': 'Force', 'lowpass': 10}\n",
    "update_filter(metadata, new_force_filter)\n",
    "\n",
    "# load the data\n",
    "blk = neurotic.load_dataset(metadata) # not lazy so that I2 and force filters are applied\n",
    "\n",
    "# plot the signal\n",
    "fig, axes = prettyplot_with_scalebars(blk, t_start, t_stop, plots, **kwargs)\n",
    "\n",
    "units = [\n",
    "    'I2 spikes',\n",
    "    'B8a/b',\n",
    "    'B6/B9',\n",
    "    'B3',\n",
    "    'B38',\n",
    "    'B4/B5',\n",
    "]\n",
    "unit_burst_boxes = {\n",
    "    'I2 spikes': [-35, 45],\n",
    "    'B8a/b':     [-20, 12],\n",
    "    'B6/B9':     [-15, 12],\n",
    "    'B3':        [-45, 35],\n",
    "    'B38':       [-12, 12],\n",
    "    'B4/B5':     [-55, 45],\n",
    "}\n",
    "\n",
    "ax = axes[channel_names.index('Force')]\n",
    "\n",
    "# plot a zero baseline for force\n",
    "# force_zero = -11.5 # mN, average before animal began swallowing, not zero because of DC offset\n",
    "# ax.axhline(force_zero, color='0.75', lw=1, ls='--', zorder=-1)\n",
    "\n",
    "# plot force phase boundaries\n",
    "times = df.loc[0, 'Normalization fixed times (s)'][3:]\n",
    "for t in times[:-1]:\n",
    "    ax.axvline(x=t, lw=1, ls=':', c='gray', zorder=-1, clip_on=False)\n",
    "#     axes[-1].add_artist(patches.ConnectionPatch(\n",
    "#         xyA=(t, 0), xyB=(t, 1),\n",
    "#         coordsA=axes[-1].get_xaxis_transform(), coordsB=axes[0].get_xaxis_transform(),\n",
    "#         axesA=axes[-1], axesB=axes[0],\n",
    "#         color='gray', lw=1, ls=':', zorder=-1))\n",
    "\n",
    "# add roman numerals for force phases\n",
    "ax.annotate('I',   xy=(times[0],          5), xycoords=('data', 'axes points'), ha='right',  # final drop\n",
    "                                              xytext=(-10, 0), textcoords='offset points')\n",
    "ax.annotate('II',  xy=(times[0:2].mean(), 5), xycoords=('data', 'axes points'), ha='center') # rise\n",
    "ax.annotate('III', xy=(times[1:3].mean(), 5), xycoords=('data', 'axes points'), ha='center') # maintenance\n",
    "ax.annotate('IV',  xy=(times[2:4].mean(), 5), xycoords=('data', 'axes points'), ha='center') # major drop\n",
    "ax.annotate('V',   xy=(times[3:5].mean(), 5), xycoords=('data', 'axes points'), ha='center') # partial maintenance\n",
    "ax.annotate('I',   xy=(times[4:6].mean(), 5), xycoords=('data', 'axes points'), ha='center') # final drop\n",
    "\n",
    "for j, i in enumerate(df.index):\n",
    "    for k, unit in enumerate(units):\n",
    "        st = df.loc[i, unit+' spike train']\n",
    "        if st is not None and st.size > 0:\n",
    "\n",
    "            # get the neural channel\n",
    "            channel = st.annotations['channels'][0]\n",
    "            sig = get_sig(blk, channel)\n",
    "\n",
    "            # get the signal for the entire bout\n",
    "            sig = sig.time_slice(t_start, t_stop)\n",
    "            sig = sig.rescale(channel_units[channel_names.index(channel)])\n",
    "\n",
    "            # plot spikes\n",
    "            ax = axes[channel_names.index(channel)]\n",
    "            spike_amplitudes = np.array([sig[sig.time_index(t)] for t in st]) * pq.Quantity(sig.units)\n",
    "            ax.scatter(st.times.rescale('s'), spike_amplitudes, marker='.', s=20, c=unit_colors[unit], zorder=3)\n",
    "\n",
    "            # plot burst windows\n",
    "            bursts = df.at[i, unit+' all bursts (s)']\n",
    "            bottom, top = unit_burst_boxes[unit]\n",
    "            height = top-bottom\n",
    "            for burst in bursts:\n",
    "                if is_good_burst(burst):\n",
    "                    left = burst['Start (s)']\n",
    "                    right = burst['End (s)']\n",
    "                    width = right-left\n",
    "                    rect = patches.Rectangle((left, bottom), width, height, linewidth=2, ls='-', edgecolor=unit_colors[unit], fill=False, zorder=3, clip_on=False)\n",
    "                    ax.add_patch(rect)\n",
    "\n",
    "fig.savefig(os.path.join(export_dir, 'figure-4.png'), dpi=600)\n",
    "\n",
    "end = datetime.datetime.now()\n",
    "print('render time:', end-start)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## [FIGURE 5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get all normalization times starting with force rise start\n",
    "t = np.array([times.magnitude[4:] for times in df_all['Normalization fixed times (s)']])\n",
    "\n",
    "# get all phase durations\n",
    "all_phase_durations = np.diff(t).T\n",
    "\n",
    "# find median phase durations\n",
    "median_phase_durations = np.nanmedian(all_phase_durations, axis=1)\n",
    "\n",
    "# copy last 4 phases to beginning to represent \"previous\" swallow\n",
    "median_phase_durations = np.concatenate([median_phase_durations[-4:], median_phase_durations])\n",
    "\n",
    "# convert durations into boundary timings\n",
    "median_phase_boundaries = np.concatenate([[0], median_phase_durations]).cumsum()\n",
    "\n",
    "phase_labels = [\n",
    "    'Previous force\\nmaintenance',\n",
    "    'Previous major\\nforce drop',\n",
    "    'Previous\\npartial force\\nmaintenance',\n",
    "    'Previous final\\nforce drop',\n",
    "    'Force rise',\n",
    "    'Force\\nmaintenance',\n",
    "    'Major\\nforce drop',\n",
    "    'Partial force\\nmaintenance',\n",
    "    'Final\\nforce drop',\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure()\n",
    "\n",
    "plt.boxplot(\n",
    "    [a[np.isfinite(a)] for a in list(all_phase_durations)],\n",
    "    labels=phase_labels[4:],\n",
    "    showmeans=True,\n",
    ")\n",
    "\n",
    "plt.ylabel('Duration (s)');"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for t, l in zip(all_phase_durations, phase_labels[4:]):\n",
    "    l = l.replace('\\n', ' ')\n",
    "    print(f'{l}:\\tmedian {np.nanmedian(t):g}, mean {np.nanmean(t):g} (n={t[np.isfinite(t)].size})')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 🐌 Figure 5A"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(9, 5))\n",
    "ax = plt.gca()\n",
    "\n",
    "units = ['I2', 'B8a/b', 'B6/B9', 'B3', 'B38', 'B4/B5']\n",
    "\n",
    "for i, unit in enumerate(units):\n",
    "    t0_data   = df_all[f'{unit} first burst start (normalized)'].dropna()\n",
    "    t0_data[:] = unnormalize_time(median_phase_boundaries, t0_data.values)\n",
    "    t0_median = t0_data.median()\n",
    "    t0_q1     = t0_data.quantile(0.25)\n",
    "    t0_q3     = t0_data.quantile(0.75)\n",
    "    \n",
    "    t1_data   = df_all[f'{unit} last burst end (normalized)'].dropna()\n",
    "    t1_data[:] = unnormalize_time(median_phase_boundaries, t1_data.values)\n",
    "    t1_median = t1_data.median()\n",
    "    t1_q1     = t1_data.quantile(0.25)\n",
    "    t1_q3     = t1_data.quantile(0.75)\n",
    "    \n",
    "    # plot boxes using medians\n",
    "    height = 0.8\n",
    "    lw = 1\n",
    "    rect = patches.Rectangle((t0_median, i-height/2), t1_median-t0_median, height, facecolor=unit_colors[unit], edgecolor='k', lw=lw, clip_on=False)\n",
    "    ax.add_patch(rect)\n",
    "    \n",
    "    # plot quartiles (25% and 75% quantiles)\n",
    "    ax.add_line(mlines.Line2D([t0_q1, t0_q1], [i-0.2, i+0.2], color='k', lw=lw, clip_on=False))\n",
    "    ax.add_line(mlines.Line2D([t0_q3, t0_q3], [i-0.2, i+0.2], color='k', lw=lw, clip_on=False))\n",
    "    ax.add_line(mlines.Line2D([t1_q1, t1_q1], [i-0.2, i+0.2], color='k', lw=lw, clip_on=False))\n",
    "    ax.add_line(mlines.Line2D([t1_q3, t1_q3], [i-0.2, i+0.2], color='k', lw=lw, clip_on=False))\n",
    "    ax.add_line(mlines.Line2D([t0_q1, t0_q3], [i, i], color='k', lw=lw, clip_on=False))\n",
    "    ax.add_line(mlines.Line2D([t1_q1, t1_q3], [i, i], color='k', lw=lw, clip_on=False))\n",
    "    \n",
    "    if unit == 'I2':\n",
    "        # plot I2 again shifted one cycle (5 phases)\n",
    "        t0_data   = df_all[f'{unit} first burst start (normalized)'].dropna()\n",
    "        t0_data[:] = unnormalize_time(median_phase_boundaries, t0_data.values+5)\n",
    "        t0_median = t0_data.median()\n",
    "        t0_q1     = t0_data.quantile(0.25)\n",
    "        t0_q3     = t0_data.quantile(0.75)\n",
    "        t1_data   = df_all[f'{unit} last burst end (normalized)'].dropna()\n",
    "        t1_data[:] = unnormalize_time(median_phase_boundaries, t1_data.values+5)\n",
    "        t1_median = t1_data.median()\n",
    "        t1_q1     = t1_data.quantile(0.25)\n",
    "        t1_q3     = t1_data.quantile(0.75)\n",
    "        rect = patches.Rectangle((t0_median, i-height/2), t1_median-t0_median, height, facecolor=unit_colors[unit], edgecolor='k', lw=lw, clip_on=False)\n",
    "        ax.add_patch(rect)\n",
    "        ax.add_line(mlines.Line2D([t0_q1, t0_q1], [i-0.2, i+0.2], color='k', lw=lw, clip_on=False))\n",
    "        ax.add_line(mlines.Line2D([t0_q3, t0_q3], [i-0.2, i+0.2], color='k', lw=lw, clip_on=False))\n",
    "        ax.add_line(mlines.Line2D([t1_q1, t1_q1], [i-0.2, i+0.2], color='k', lw=lw, clip_on=False))\n",
    "        ax.add_line(mlines.Line2D([t1_q3, t1_q3], [i-0.2, i+0.2], color='k', lw=lw, clip_on=False))\n",
    "        ax.add_line(mlines.Line2D([t0_q1, t0_q3], [i, i], color='k', lw=lw, clip_on=False))\n",
    "        ax.add_line(mlines.Line2D([t1_q1, t1_q3], [i, i], color='k', lw=lw, clip_on=False))\n",
    "\n",
    "###\n",
    "### LABELS AND ANNOTATIONS\n",
    "###\n",
    "\n",
    "# drop \"Previous force maintenance\" because I2 distribution starts after it\n",
    "trimmed_median_phase_boundaries = median_phase_boundaries[1:]\n",
    "trimmed_phase_labels = phase_labels[1:]\n",
    "\n",
    "for x in trimmed_median_phase_boundaries:\n",
    "    plt.axvline(x=x, ls=':', c='gray', zorder=-1, clip_on=False)\n",
    "\n",
    "plt.xlabel(None)\n",
    "plt.ylabel(None)\n",
    "\n",
    "sns.despine(bottom=True, left=True)\n",
    "plt.tick_params(bottom=False, left=False) # disable tick marks\n",
    "plt.xticks(trimmed_median_phase_boundaries[:-1]+np.diff(trimmed_median_phase_boundaries)/2, trimmed_phase_labels)\n",
    "plt.yticks(range(len(units)), units)\n",
    "\n",
    "plt.xlim(trimmed_median_phase_boundaries[[0, -1]])\n",
    "plt.ylim(5.9, -0.5)\n",
    "\n",
    "ax.tick_params(\n",
    "    axis='x',\n",
    "    labelsize='small',\n",
    ")\n",
    "\n",
    "ax.add_artist(AnchoredScaleBar(\n",
    "    ax.transData,\n",
    "    sizex=1,\n",
    "    labelx='1 s',\n",
    "\n",
    "    loc='lower left',\n",
    "    bbox_to_anchor=(0, 0),\n",
    "    bbox_transform=ax.transAxes,\n",
    "\n",
    "    pad=0,\n",
    "    borderpad=1,\n",
    "    sep=5,\n",
    "    barwidth=2,\n",
    "))\n",
    "\n",
    "plt.tight_layout()\n",
    "\n",
    "plt.gcf().savefig(os.path.join(export_dir, 'figure-5A.png'), dpi=300)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i, unit in enumerate(['I2', 'B8a/b', 'B6/B9', 'B3', 'B38', 'B4/B5']):\n",
    "    t0_data   = df_all[f'{unit} first burst start (normalized)'].dropna()\n",
    "    t0_data[:] = unnormalize_time(median_phase_boundaries, t0_data.values)\n",
    "    t0_median = t0_data.median()\n",
    "    t0_N      = t0_data.size\n",
    "    \n",
    "    t1_data   = df_all[f'{unit} last burst end (normalized)'].dropna()\n",
    "    t1_data[:] = unnormalize_time(median_phase_boundaries, t1_data.values)\n",
    "    t1_median = t1_data.median()\n",
    "    t1_N      = t1_data.size\n",
    "\n",
    "    print(f'{unit}:\\t[{t0_median:.2f} (n={t0_N}), {t1_median:.2f} (n={t1_N})], duration: {t1_median-t0_median:.2f}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 🐌 Figure 5B"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "times_interp_unnormalized = unnormalize_time(median_phase_boundaries, times_interp)\n",
    "\n",
    "# find the number of data points in one cycle\n",
    "n = np.where((4 <= times_interp) & (times_interp <= 9))[0].size # 4 = start of rise, 9 = end of final drop\n",
    "\n",
    "units = [\n",
    "    'I2 spikes',\n",
    "    'B8a/b',\n",
    "    'B6/B9',\n",
    "    'B3',\n",
    "    'B38',\n",
    "    'B4/B5',\n",
    "]\n",
    "\n",
    "figsize = (9, 8)\n",
    "# figsize = (6, 8)\n",
    "# figsize = (9.5, 10) # dimensions for notebook\n",
    "# figsize = (11, 8.5) # dimensions for printing\n",
    "# figsize = (16, 9) # dimensions for wide screens\n",
    "fig, axes = plt.subplots(len(units)+1, 1, sharex='col', figsize=figsize)\n",
    "\n",
    "###\n",
    "### UNITS\n",
    "###\n",
    "\n",
    "for i, unit in enumerate(units):\n",
    "    ax = axes[i]\n",
    "    \n",
    "    # elevate the Axes for units and remove background colors so that\n",
    "    # each vertical ConnectionPatch drawn later is visible behind it\n",
    "    ax.set_zorder(1)\n",
    "    ax.set_facecolor('none')\n",
    "    \n",
    "    # find the firing rate median and quartiles\n",
    "    firing_rate_data = np.array(list(df_all[unit+' firing rate, normalized time interpolation (Hz)']))\n",
    "    firing_rate_median = np.nanmedian(firing_rate_data, axis=0)\n",
    "    firing_rate_q1 = np.nanquantile(firing_rate_data, q=0.25, axis=0)\n",
    "    firing_rate_q3 = np.nanquantile(firing_rate_data, q=0.75, axis=0)\n",
    "\n",
    "    # represent repetative swallowing by duplicating the bursts one cycle forward and backward\n",
    "    firing_rate_median = np.nanmax([\n",
    "        firing_rate_median,\n",
    "        np.concatenate((np.zeros(n), firing_rate_median[:-n])), # shifted forward one cycle\n",
    "        np.concatenate((firing_rate_median[n:], np.zeros(n))),  # shifted backward one cycle\n",
    "    ], axis=0)\n",
    "    firing_rate_q1 = np.nanmax([\n",
    "        firing_rate_q1,\n",
    "        np.concatenate((np.zeros(n), firing_rate_q1[:-n])), # shifted forward one cycle\n",
    "        np.concatenate((firing_rate_q1[n:], np.zeros(n))),  # shifted backward one cycle\n",
    "    ], axis=0)\n",
    "    firing_rate_q3 = np.nanmax([\n",
    "        firing_rate_q3,\n",
    "        np.concatenate((np.zeros(n), firing_rate_q3[:-n])), # shifted forward one cycle\n",
    "        np.concatenate((firing_rate_q3[n:], np.zeros(n))),  # shifted backward one cycle\n",
    "    ], axis=0)\n",
    "\n",
    "    # plot the firing rate median and quartiles (median last so it's on top)\n",
    "    ax.plot(times_interp_unnormalized, firing_rate_q1,     c=lighten_color(unit_colors[unit], amount=0.7), lw=1, zorder=2)\n",
    "    ax.plot(times_interp_unnormalized, firing_rate_q3,     c=lighten_color(unit_colors[unit], amount=0.7), lw=1, zorder=2)\n",
    "    ax.plot(times_interp_unnormalized, firing_rate_median, c=unit_colors[unit], lw=2, zorder=2)\n",
    "\n",
    "    \n",
    "    ax.set_ylim([0, None])\n",
    "    if unit == 'I2 spikes':\n",
    "        ax.set_ylabel('I2', rotation='horizontal', ha='right', va='center', labelpad=10)\n",
    "    else:\n",
    "        ax.set_ylabel(unit, rotation='horizontal', ha='right', va='center', labelpad=10)\n",
    "#     ax.yaxis.set_label_coords(-0.06, 0.5)\n",
    "\n",
    "# remove right and top plot borders, and remove x-axis\n",
    "#     sns.despine(ax=ax)#, bottom=True)\n",
    "    sns.despine(ax=ax, left=True, right=False)#, trim=True)\n",
    "#     ax.xaxis.set_visible(False)\n",
    "\n",
    "#     ax.tick_params(bottom=False) # disable tick marks\n",
    "    # disable tick marks\n",
    "    ax.tick_params(\n",
    "        bottom=False,\n",
    "        left=False,\n",
    "        right=True,\n",
    "        labelbottom=False,\n",
    "        labelleft=False)\n",
    "\n",
    "#     ax.set_yticks([0, 10, 20])\n",
    "#     ax.set_yticklabels([0, 10, '20 Hz'])\n",
    "#     ax.set_yticks(ax.get_yticks()) # trick to prevent tight_layout from changing ticks\n",
    "#     yticklabels = [f'{y:g}' for y in ax.get_yticks()]\n",
    "#     yticklabels[-1] += ' Hz'\n",
    "#     ax.set_yticklabels(yticklabels)\n",
    "    \n",
    "\n",
    "\n",
    "#     # add freq scale bar\n",
    "#     ax.add_artist(AnchoredScaleBar(\n",
    "#         ax.transData,\n",
    "#         sizey=10,\n",
    "#         labely='10 Hz',\n",
    "\n",
    "#         loc='center left',\n",
    "#         bbox_to_anchor=(1, 0.5),\n",
    "#         bbox_transform=ax.transAxes,\n",
    "\n",
    "#         pad=0,\n",
    "#         borderpad=1,\n",
    "#         sep=5,\n",
    "#         barwidth=2,\n",
    "#     ))\n",
    "\n",
    "###\n",
    "### FORCE\n",
    "###\n",
    "\n",
    "ax = axes[-1]\n",
    "\n",
    "force_data = np.array(list(df_all['Force, normalized time interpolation (mN)']))\n",
    "\n",
    "# def tile_array(arr, i_start, i_stop, axis=1):\n",
    "#     arr = arr.copy()\n",
    "#     n = i_stop - i_start\n",
    "    \n",
    "#     ind_before, ind_after = [slice(None)]*arr.ndim, [slice(None)]*arr.ndim\n",
    "#     ind_before[axis] = slice(None, i_start)\n",
    "#     ind_after[axis] = slice(i_stop+1, None)\n",
    "    \n",
    "#     # replace values outside of range with NaN\n",
    "#     arr[tuple(ind_before)] = np.nan\n",
    "#     arr[tuple(ind_after)] = np.nan\n",
    "    \n",
    "#     # construct versions of arr shifted to the left and right\n",
    "#     arr_nan = np.full_like(arr, np.nan)\n",
    "#     arr_nan = arr_nan\n",
    "#     arr_nan = np.full((arr.shape[0], n), np.nan)\n",
    "#     left = np.concatenate((arr[:, n:], arr_nan), axis=1)\n",
    "#     right = np.concatenate((arr_nan, arr[:, :-n]), axis=1)\n",
    "    \n",
    "#     # merge arrays\n",
    "#     arr = np.nanmax([\n",
    "#         arr,\n",
    "#         left,\n",
    "#         right\n",
    "#     ], axis=0) # can axis be generalized?\n",
    "    \n",
    "#     return arr\n",
    "\n",
    "# # replace the \"previous\" swallow force data with a repeat of the \"current\" swallow\n",
    "# force_data = tile_array(force_data, i_start, i_stop)\n",
    "\n",
    "# find the force median and quartiles\n",
    "force_median = np.nanmedian(force_data, axis=0)\n",
    "force_q1 = np.nanquantile(force_data, q=0.25, axis=0)\n",
    "force_q3 = np.nanquantile(force_data, q=0.75, axis=0)\n",
    "\n",
    "# plot the force median and quartiles (median last so it's on top)\n",
    "ax.plot(times_interp_unnormalized, force_q1,     c=lighten_color('k', amount=0.7), lw=1, zorder=2)\n",
    "ax.plot(times_interp_unnormalized, force_q3,     c=lighten_color('k', amount=0.7), lw=1, zorder=2)\n",
    "ax.plot(times_interp_unnormalized, force_median, c='k', lw=2, zorder=2)\n",
    "\n",
    "ax.set_ylim([0, None])\n",
    "ax.set_ylabel('Force', rotation='horizontal', ha='right', va='center', labelpad=10)\n",
    "# ax.yaxis.set_label_coords(-0.06, 0.5)\n",
    "\n",
    "# drop \"Previous force maintenance\" because I2 distribution starts after it\n",
    "trimmed_median_phase_boundaries = median_phase_boundaries[1:]\n",
    "trimmed_phase_labels = phase_labels[1:]\n",
    "\n",
    "# remove right and top plot borders from bottom panel, and set x-label\n",
    "sns.despine(ax=ax, left=True, right=False)#, trim=True)\n",
    "ax.set_xlim(trimmed_median_phase_boundaries[[0, -1]])\n",
    "# ax.tick_params(bottom=False) # disable tick marks\n",
    "# disable tick marks\n",
    "ax.tick_params(\n",
    "    bottom=False,\n",
    "    left=False,\n",
    "    right=True,\n",
    "#     labelbottom=False,\n",
    "    labelleft=False)\n",
    "ax.tick_params(\n",
    "    axis='x',\n",
    "    labelsize='small',\n",
    ")\n",
    "\n",
    "ax.set_xticks(trimmed_median_phase_boundaries[:-1]+np.diff(trimmed_median_phase_boundaries)/2)\n",
    "ax.set_xticklabels(trimmed_phase_labels)\n",
    "\n",
    "# ax.set_yticks([0, 100, 200])\n",
    "# ax.set_yticklabels([0, 100, '200 mN'])\n",
    "# ax.set_yticks(ax.get_yticks()) # trick to prevent tight_layout from changing ticks\n",
    "# yticklabels = [f'{y:g}' for y in ax.get_yticks()]\n",
    "# yticklabels[-1] += ' mN'\n",
    "# ax.set_yticklabels(yticklabels)\n",
    "       \n",
    "# plot force phase boundaries in normalized time\n",
    "for t in trimmed_median_phase_boundaries:\n",
    "    ax.add_artist(patches.ConnectionPatch(\n",
    "        xyA=(t, 0), xyB=(t, 1),\n",
    "        coordsA=ax.get_xaxis_transform(), coordsB=axes[0].get_xaxis_transform(),\n",
    "        axesA=ax, axesB=axes[0],\n",
    "        color='gray', lw=1, ls=':', zorder=0))\n",
    "\n",
    "# add time scale bar\n",
    "ax.add_artist(AnchoredScaleBar(\n",
    "    ax.transData,\n",
    "    sizex=1,\n",
    "    labelx='1 s',\n",
    "\n",
    "    loc='upper right',\n",
    "    bbox_to_anchor=(0.98, 1),\n",
    "    bbox_transform=ax.transAxes,\n",
    "\n",
    "    pad=0,\n",
    "    borderpad=1,\n",
    "    sep=5,\n",
    "    barwidth=2,\n",
    "))\n",
    "\n",
    "fig.tight_layout(h_pad=0, pad=0) # first tight_layout removes excess margins and sets reasonable ylims\n",
    "# fig.tight_layout(pad=0)\n",
    "\n",
    "# ylims = [\n",
    "#     [0, 20], # I2\n",
    "#     [0, 40], # B8a/b\n",
    "#     [0, 50], # B6/B9\n",
    "#     [0, 10], # B3\n",
    "#     [0, 15], # B38\n",
    "#     [0, 20], # B4/B5\n",
    "#     [0, 300], # Force\n",
    "# ]\n",
    "# for i, ax in enumerate(axes):\n",
    "#     ax.set_ylim(ylims[i])\n",
    "\n",
    "for i, unit in enumerate(units):\n",
    "    ax = axes[i]\n",
    "    ax.grid(axis='y', clip_on=False)\n",
    "    ax.set_yticks(ax.get_yticks()) # trick to prevent tight_layout from changing ticks\n",
    "    yticklabels = [f'{y:g}' for y in ax.get_yticks()]\n",
    "    yticklabels[-1] += ' Hz'\n",
    "    ax.set_yticklabels(yticklabels)\n",
    "ax = axes[-1]\n",
    "ax.grid(axis='y', clip_on=False)\n",
    "ax.set_yticks(ax.get_yticks()) # trick to prevent tight_layout from changing ticks\n",
    "yticklabels = [f'{y:g}' for y in ax.get_yticks()]\n",
    "yticklabels[-1] += ' mN'\n",
    "ax.set_yticklabels(yticklabels)\n",
    "\n",
    "fig.tight_layout(h_pad=0, pad=0) # second tight_layout makes room for units added to y tick labels\n",
    "# fig.tight_layout(pad=0)\n",
    "\n",
    "fig.savefig(os.path.join(export_dir, 'figure-5B.png'), dpi=600)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## [FIGURE 6]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(5, 5))\n",
    "ax = plt.gca()\n",
    "\n",
    "data_subsets = [\n",
    "    'JG07 Tape nori',\n",
    "    'JG08 Tape nori',\n",
    "    'JG11 Tape nori',\n",
    "    'JG12 Tape nori',\n",
    "    'JG14 Tape nori',\n",
    "]\n",
    "data_subsets = {label:label2query(label) for label in data_subsets}\n",
    "\n",
    "# xlabel, xlim = 'B3 all bursts duration (s)', [0, 5]\n",
    "xlabel, xlim = 'B6/B9 all bursts duration (s)', [0, 6]\n",
    "# xlabel, xlim = 'B3/B6/B9 burst duration (s)', [0, 5]\n",
    "ylabel, ylim = 'Force plateau duration (s)', [0, 6]\n",
    "ylabel_alt = 'Force maintenance duration (s)'\n",
    "\n",
    "scatter2d(ax, data_subsets, xlabel, xlim, ylabel, ylim, trend=True, trend_separately=True, tooltips=False)\n",
    "plt.plot([0, 999], [0, 999], ls=':', c='gray', zorder=0)\n",
    "plt.ylabel(ylabel_alt)\n",
    "ax.legend()\n",
    "sns.despine(ax=ax, offset=20, trim=True)\n",
    "plt.tight_layout()\n",
    "\n",
    "plt.gcf().savefig(os.path.join(export_dir, 'figure-6.png'), dpi=300)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "-"
    }
   },
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Random old figures"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(5, 5))\n",
    "ax = plt.gca()\n",
    "\n",
    "df = df_all.reset_index()\n",
    "# column = 'Delay from I2 end to force min (s)'\n",
    "column = 'Delay from I2 end to force rise start (s)'\n",
    "\n",
    "sns.boxplot(y='Animal', x=column, data=df, fliersize=0, whis=999) # whis=999 ensures whiskers go to min and max\n",
    "# sns.swarmplot(y='Animal', x=column, data=df, color='0.25')\n",
    "\n",
    "# sns.boxplot(x=column, data=df, fliersize=0, whis=999) # whis=999 ensures whiskers go to min and max\n",
    "# sns.swarmplot(x=column, data=df, color='0.25')\n",
    "\n",
    "# plot zero line\n",
    "plt.axvline(x=0, ls=':', c='gray', zorder=-1)\n",
    "\n",
    "plt.tight_layout()\n",
    "\n",
    "# plt.gcf().savefig(os.path.join(export_dir, 'figure-X.png'), dpi=300)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(5, 5))\n",
    "ax = plt.gca()\n",
    "\n",
    "df = df_all.reset_index()\n",
    "# column = 'Delay from B3/B6/B9 start to force start (s)'\n",
    "column = 'Delay from B3/B6/B9 start to force rise start (s)'\n",
    "\n",
    "sns.boxplot(y='Animal', x=column, data=df, fliersize=0, whis=999) # whis=999 ensures whiskers go to min and max\n",
    "sns.swarmplot(y='Animal', x=column, data=df, color='0.25')\n",
    "\n",
    "# sns.boxplot(x=column, data=df, fliersize=0, whis=999) # whis=999 ensures whiskers go to min and max\n",
    "# sns.swarmplot(x=column, data=df, color='0.25')\n",
    "\n",
    "# plot zero line\n",
    "plt.axvline(x=0, ls=':', c='gray', zorder=-1)\n",
    "\n",
    "plt.tight_layout()\n",
    "\n",
    "# plt.gcf().savefig(os.path.join(export_dir, 'figure-X.png'), dpi=300)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(5, 5))\n",
    "ax = plt.gca()\n",
    "\n",
    "df = df_all.reset_index()\n",
    "# column = 'Delay from B8a/b start to force start (s)'\n",
    "column = 'Delay from B8a/b start to force rise start (s)'\n",
    "\n",
    "sns.boxplot(y='Animal', x=column, data=df, fliersize=0, whis=999) # whis=999 ensures whiskers go to min and max\n",
    "sns.swarmplot(y='Animal', x=column, data=df, color='0.25')\n",
    "\n",
    "# sns.boxplot(x=column, data=df, fliersize=0, whis=999) # whis=999 ensures whiskers go to min and max\n",
    "# sns.swarmplot(x=column, data=df, color='0.25')\n",
    "\n",
    "# plot zero line\n",
    "plt.axvline(x=0, ls=':', c='gray', zorder=-1)\n",
    "\n",
    "plt.tight_layout()\n",
    "\n",
    "# plt.gcf().savefig(os.path.join(export_dir, 'figure-X.png'), dpi=300)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(5, 5))\n",
    "ax = plt.gca()\n",
    "\n",
    "data_subsets = [\n",
    "    'JG07 Tape nori',\n",
    "    'JG08 Tape nori',\n",
    "    'JG11 Tape nori',\n",
    "    'JG12 Tape nori',\n",
    "    'JG14 Tape nori',\n",
    "]\n",
    "data_subsets = {label:label2query(label) for label in data_subsets}\n",
    "\n",
    "# xlabel, xlim = 'B8 activity mean rectified voltage (μV)', [0, None]\n",
    "# xlabel, xlim = 'B8a/b first burst mean rectified voltage (μV)', [0, None]\n",
    "xlabel, xlim = 'B8a/b pre-B3/B6/B9 burst mean rectified voltage (μV)', [0, None]\n",
    "# xlabel, xlim = 'B8a/b pre-B3/B6/B9 burst mean frequency (Hz)', [0, None]\n",
    "# ylabel, ylim = 'Force slope (mN/s)', [0, None]\n",
    "ylabel, ylim = 'Force initial slope (mN/s)', [0, None]\n",
    "# ylabel, ylim = 'Force initial increase (mN)', [0, None]\n",
    "\n",
    "scatter2d(ax, data_subsets, xlabel, xlim, ylabel, ylim, trend=True, trend_separately=True, tooltips=True)\n",
    "ax.legend()\n",
    "sns.despine(ax=ax, offset=20, trim=True)\n",
    "plt.tight_layout()\n",
    "\n",
    "# plt.gcf().savefig(os.path.join(export_dir, 'figure-X.png'), dpi=300)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [],
   "source": [
    "plt.figure(figsize=(5, 5))\n",
    "ax = plt.gca()\n",
    "\n",
    "data_subsets = [\n",
    "    'JG07 Tape nori',\n",
    "    'JG08 Tape nori',\n",
    "    'JG11 Tape nori',\n",
    "    'JG12 Tape nori',\n",
    "    'JG14 Tape nori',\n",
    "]\n",
    "data_subsets = {label:label2query(label) for label in data_subsets}\n",
    "\n",
    "# xlabel, xlim = 'B8 activity mean rectified voltage (μV)', [0, None]\n",
    "# xlabel, xlim = 'B8a/b first burst mean rectified voltage (μV)', [0, None]\n",
    "# xlabel, xlim = 'B8a/b pre-B3/B6/B9 burst mean rectified voltage (μV)', [0, None]\n",
    "xlabel, xlim = 'B8a/b pre-B3/B6/B9 burst mean frequency (Hz)', [0, None]\n",
    "# ylabel, ylim = 'Force slope (mN/s)', [0, None]\n",
    "ylabel, ylim = 'Force initial slope (mN/s)', [0, None]\n",
    "# ylabel, ylim = 'Force initial increase (mN)', [0, None]\n",
    "\n",
    "scatter2d(ax, data_subsets, xlabel, xlim, ylabel, ylim, trend=True, trend_separately=True, tooltips=True)\n",
    "ax.legend()\n",
    "sns.despine(ax=ax, offset=20, trim=True)\n",
    "plt.tight_layout()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(5, 5))\n",
    "ax = plt.gca()\n",
    "\n",
    "data_subsets = [\n",
    "    'JG07 Tape nori',\n",
    "    'JG08 Tape nori',\n",
    "    'JG11 Tape nori',\n",
    "    'JG12 Tape nori',\n",
    "    'JG14 Tape nori',\n",
    "]\n",
    "data_subsets = {label:label2query(label) for label in data_subsets}\n",
    "\n",
    "# xlabel, xlim = 'B8 activity mean rectified voltage (μV)', [0, None]\n",
    "# xlabel, xlim = 'B8a/b first burst mean rectified voltage (μV)', [0, None]\n",
    "xlabel, xlim = 'B8a/b pre-B3/B6/B9 burst mean rectified voltage (μV)', [0, None]\n",
    "# xlabel, xlim = 'B8a/b pre-B3/B6/B9 burst mean frequency (Hz)', [0, None]\n",
    "# ylabel, ylim = 'Force slope (mN/s)', [0, None]\n",
    "# ylabel, ylim = 'Force initial slope (mN/s)', [0, None]\n",
    "ylabel, ylim = 'Force initial increase (mN)', [0, None]\n",
    "\n",
    "scatter2d(ax, data_subsets, xlabel, xlim, ylabel, ylim, trend=True, trend_separately=True, tooltips=True)\n",
    "ax.legend()\n",
    "sns.despine(ax=ax, offset=20, trim=True)\n",
    "plt.tight_layout()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(5, 5))\n",
    "ax = plt.gca()\n",
    "\n",
    "data_subsets = [\n",
    "    'JG07 Tape nori',\n",
    "    'JG08 Tape nori',\n",
    "    'JG11 Tape nori',\n",
    "    'JG12 Tape nori',\n",
    "    'JG14 Tape nori',\n",
    "]\n",
    "data_subsets = {label:label2query(label) for label in data_subsets}\n",
    "\n",
    "# xlabel, xlim = 'B8 activity mean rectified voltage (μV)', [0, None]\n",
    "# xlabel, xlim = 'B8a/b first burst mean rectified voltage (μV)', [0, None]\n",
    "# xlabel, xlim = 'B8a/b pre-B3/B6/B9 burst mean rectified voltage (μV)', [0, None]\n",
    "xlabel, xlim = 'B8a/b pre-B3/B6/B9 burst mean frequency (Hz)', [0, None]\n",
    "# ylabel, ylim = 'Force slope (mN/s)', [0, None]\n",
    "ylabel, ylim = 'Force increase (mN)', [0, None]\n",
    "# ylabel, ylim = 'Force initial slope (mN/s)', [0, None]\n",
    "# ylabel, ylim = 'Force initial increase (mN)', [0, None]\n",
    "\n",
    "scatter2d(ax, data_subsets, xlabel, xlim, ylabel, ylim, trend=True, trend_separately=True, tooltips=True)\n",
    "ax.legend()\n",
    "sns.despine(ax=ax, offset=20, trim=True)\n",
    "plt.tight_layout()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [],
   "source": [
    "plt.figure(figsize=(5, 5))\n",
    "ax = plt.gca()\n",
    "\n",
    "data_subsets = [\n",
    "    'JG07 Tape nori',\n",
    "    'JG08 Tape nori',\n",
    "    'JG11 Tape nori',\n",
    "    'JG12 Tape nori',\n",
    "    'JG14 Tape nori',\n",
    "]\n",
    "data_subsets = {label:label2query(label) for label in data_subsets}\n",
    "\n",
    "# xlabel, xlim = 'B8 activity duration (s)', [0, 8]\n",
    "xlabel, xlim = 'B8a/b first burst duration (s)', [0, 8]\n",
    "ylabel, ylim = 'Force rise and plateau duration (s)', [0, 8]\n",
    "\n",
    "scatter2d(ax, data_subsets, xlabel, xlim, ylabel, ylim, trend=True, trend_separately=True, tooltips=False)\n",
    "plt.plot([0, 999], [0, 999], ls=':', c='gray', zorder=0)\n",
    "ax.legend()\n",
    "sns.despine(ax=ax, offset=20, trim=True)\n",
    "plt.tight_layout()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(5, 5))\n",
    "ax = plt.gca()\n",
    "\n",
    "df = df_all.reset_index()\n",
    "# column = 'Delay from B3/B6/B9 start to force 50%-height (s)'\n",
    "column = 'Delay from B3/B6/B9 start to force plateau start (s)'\n",
    "\n",
    "sns.boxplot(y='Animal', x=column, data=df, fliersize=0, whis=999) # whis=999 ensures whiskers go to min and max\n",
    "# sns.swarmplot(y='Animal', x=column, data=df, color='0.25')\n",
    "\n",
    "# sns.boxplot(x=column, data=df, fliersize=0, whis=999) # whis=999 ensures whiskers go to min and max\n",
    "# sns.swarmplot(x=column, data=df, color='0.25')\n",
    "\n",
    "# plot zero line\n",
    "plt.axvline(x=0, ls=':', c='gray', zorder=-1)\n",
    "\n",
    "plt.tight_layout()\n",
    "\n",
    "# plt.gcf().savefig(os.path.join(export_dir, 'figure-X.png'), dpi=300)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(5, 5))\n",
    "ax = plt.gca()\n",
    "\n",
    "df = df_all.reset_index()\n",
    "# column = 'Delay from either B8a/b or B3/B6/B9 end to force 80%-height end (s)'\n",
    "column = 'Delay from either B8a/b or B3/B6/B9 end to force plateau end (s)'\n",
    "\n",
    "sns.boxplot(y='Animal', x=column, data=df, fliersize=0, whis=999) # whis=999 ensures whiskers go to min and max\n",
    "sns.swarmplot(y='Animal', x=column, data=df, color='0.25')\n",
    "\n",
    "# sns.boxplot(x=column, data=df, fliersize=0, whis=999) # whis=999 ensures whiskers go to min and max\n",
    "# sns.swarmplot(x=column, data=df, color='0.25')\n",
    "\n",
    "# plot zero line\n",
    "plt.axvline(x=0, ls=':', c='gray', zorder=-1)\n",
    "\n",
    "plt.tight_layout()\n",
    "\n",
    "# plt.gcf().savefig(os.path.join(export_dir, 'figure-X.png'), dpi=300)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [],
   "source": [
    "plt.figure(figsize=(5, 5))\n",
    "ax = plt.gca()\n",
    "\n",
    "data_subsets = [\n",
    "    'JG07 Tape nori',\n",
    "    'JG08 Tape nori',\n",
    "    'JG11 Tape nori',\n",
    "    'JG12 Tape nori',\n",
    "    'JG14 Tape nori',\n",
    "]\n",
    "data_subsets = {label:label2query(label) for label in data_subsets}\n",
    "\n",
    "# xlabel, xlim = 'B3/6/9/10 activity duration (s)', [0, 8]\n",
    "# xlabel, xlim = 'B6/B9 first burst duration (s)', [0, 8]\n",
    "xlabel, xlim = 'B6/B9 all bursts duration (s)', [0, 8]\n",
    "ylabel, ylim = 'Force rise and plateau duration (s)', [0, 8]\n",
    "\n",
    "scatter2d(ax, data_subsets, xlabel, xlim, ylabel, ylim, trend=True, trend_separately=True, tooltips=False)\n",
    "plt.plot([0, 999], [0, 999], ls=':', c='gray', zorder=0)\n",
    "ax.legend()\n",
    "sns.despine(ax=ax, offset=20, trim=True)\n",
    "plt.tight_layout()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(5, 5))\n",
    "ax = plt.gca()\n",
    "\n",
    "df = df_all.reset_index()\n",
    "df = df.rename(columns={\n",
    "#     'Delay from B3 start to force 80%-height start (s)': 'Start of burst',\n",
    "#     'Delay from B3 end to force 80%-height end (s)':     'End of burst'})\n",
    "    'Delay from B3 start to force plateau start (s)': 'Start of burst',\n",
    "    'Delay from B3 end to force plateau end (s)':     'End of burst'})\n",
    "df = pd.melt(df,\n",
    "             id_vars=['Animal', 'Food', 'Bout_index', 'Behavior_index'],\n",
    "             value_vars=['Start of burst', 'End of burst'],\n",
    "             var_name='When?',\n",
    "             value_name='Delay from B3 to plateau (s)')\n",
    "sns.boxplot(hue='Animal', x='Delay from B3 to plateau (s)', y='When?', data=df, fliersize=0, whis=999) # whis=999 ensures whiskers go to min and max\n",
    "# sns.swarmplot(hue='Animal', x='Delay from B3 to plateau (s)', y='When?', data=df)\n",
    "\n",
    "# plot zero line\n",
    "plt.axvline(x=0, ls=':', c='gray', zorder=-1)\n",
    "\n",
    "plt.tight_layout()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [],
   "source": [
    "plt.figure(figsize=(5, 5))\n",
    "ax = plt.gca()\n",
    "\n",
    "data_subsets = [\n",
    "    'JG07 Tape nori',\n",
    "    'JG08 Tape nori',\n",
    "    'JG11 Tape nori',\n",
    "    'JG12 Tape nori',\n",
    "    'JG14 Tape nori',\n",
    "]\n",
    "data_subsets = {label:label2query(label) for label in data_subsets}\n",
    "\n",
    "# xlabel, xlim = 'B3/6/9/10 activity mean rectified voltage (μV)', [0, None]\n",
    "xlabel, xlim = 'B6/B9 first burst mean rectified voltage (μV)', [0, None]\n",
    "# ylabel, ylim = 'Force slope (mN/s)', [0, None]\n",
    "# ylabel, ylim = 'Force 80%-height (mN)', [0, None]\n",
    "ylabel, ylim = 'Force increase (mN)', [0, None]\n",
    "\n",
    "scatter2d(ax, data_subsets, xlabel, xlim, ylabel, ylim, trend=True, trend_separately=True, tooltips=True)\n",
    "ax.legend()\n",
    "sns.despine(ax=ax, offset=20, trim=True)\n",
    "plt.tight_layout()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(5, 5))\n",
    "ax = plt.gca()\n",
    "\n",
    "data_subsets = [\n",
    "    'JG07 Tape nori',\n",
    "    'JG08 Tape nori',\n",
    "    'JG11 Tape nori',\n",
    "    'JG12 Tape nori',\n",
    "    'JG14 Tape nori',\n",
    "]\n",
    "data_subsets = {label:label2query(label) for label in data_subsets}\n",
    "\n",
    "# xlabel, xlim = 'B3/6/9/10 activity mean rectified voltage (μV)', [0, None]\n",
    "xlabel, xlim = 'B6/B9 first burst mean frequency (Hz)', [0, None]\n",
    "# ylabel, ylim = 'Force slope (mN/s)', [0, None]\n",
    "ylabel, ylim = 'Force plateau start value (mN)', [0, None]\n",
    "# ylabel, ylim = 'Force increase (mN)', [0, None]\n",
    "# ylabel, ylim = 'Force rise increase (mN)', [0, None]\n",
    "\n",
    "scatter2d(ax, data_subsets, xlabel, xlim, ylabel, ylim, trend=True, trend_separately=True, tooltips=True)\n",
    "ax.legend()\n",
    "sns.despine(ax=ax, offset=20, trim=True)\n",
    "plt.tight_layout()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(5, 5))\n",
    "ax = plt.gca()\n",
    "\n",
    "df = df_all.reset_index()\n",
    "# column = 'Delay from B38 end to shoulder end (s)'\n",
    "column = 'Delay from B38 end to force shoulder end (s)'\n",
    "\n",
    "sns.boxplot(y='Animal', x=column, data=df, fliersize=0, whis=999) # whis=999 ensures whiskers go to min and max\n",
    "sns.swarmplot(y='Animal', x=column, data=df, color='0.25')\n",
    "\n",
    "# sns.boxplot(x=column, data=df, fliersize=0, whis=999) # whis=999 ensures whiskers go to min and max\n",
    "# sns.swarmplot(x=column, data=df, color='0.25')\n",
    "\n",
    "# plot zero line\n",
    "plt.axvline(x=0, ls=':', c='gray', zorder=-1)\n",
    "\n",
    "plt.tight_layout()\n",
    "\n",
    "# plt.gcf().savefig(os.path.join(export_dir, 'figure-X.png'), dpi=300)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(5, 5))\n",
    "ax = plt.gca()\n",
    "\n",
    "data_subsets = [\n",
    "    'JG07 Tape nori',\n",
    "    'JG08 Tape nori',\n",
    "    'JG11 Tape nori',\n",
    "    'JG12 Tape nori',\n",
    "    'JG14 Tape nori',\n",
    "]\n",
    "data_subsets = {label:label2query(label) for label in data_subsets}\n",
    "\n",
    "xlabel, xlim = 'B8a/b pre-B3/B6/B9 burst peak smoothed frequency (Hz)', [0, None]\n",
    "ylabel, ylim = 'Force slope (mN/s)', [0, None]\n",
    "\n",
    "scatter2d(ax, data_subsets, xlabel, xlim, ylabel, ylim, trend=True, trend_separately=True, tooltips=True)\n",
    "ax.legend()\n",
    "sns.despine(ax=ax, offset=20, trim=True)\n",
    "plt.tight_layout()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(5, 5))\n",
    "ax = plt.gca()\n",
    "\n",
    "data_subsets = [\n",
    "    'JG07 Tape nori',\n",
    "    'JG08 Tape nori',\n",
    "    'JG11 Tape nori',\n",
    "    'JG12 Tape nori',\n",
    "    'JG14 Tape nori',\n",
    "]\n",
    "data_subsets = {label:label2query(label) for label in data_subsets}\n",
    "\n",
    "xlabel, xlim = 'Force rise duration (s)', [0, None]\n",
    "ylabel, ylim = 'Force rise increase (mN)', [0, None]\n",
    "\n",
    "scatter2d(ax, data_subsets, xlabel, xlim, ylabel, ylim, trend=True, trend_separately=True, tooltips=True)\n",
    "ax.legend()\n",
    "sns.despine(ax=ax, offset=20, trim=True)\n",
    "plt.tight_layout()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "start = datetime.datetime.now()\n",
    "\n",
    "df = df_exemplary_bout\n",
    "(data_set_name, channel_names, time_window, epoch_types_to_keep, burst_thresholds) = feeding_bouts[exemplary_bout]\n",
    "\n",
    "t_start, t_stop = time_window*pq.s\n",
    "plots = [\n",
    "    {'channel': 'I2',       'units': 'uV', 'ylim': [ -60,  60], 'scalebar': 50}, #, 'decimation_factor': 100},\n",
    "    {'channel': 'RN',       'units': 'uV', 'ylim': [ -25,  25], 'scalebar': 25}, #, 'decimation_factor': 100},\n",
    "    {'channel': 'BN2',      'units': 'uV', 'ylim': [ -45,  45], 'scalebar': 50}, #, 'decimation_factor': 100},\n",
    "    {'channel': 'BN3-DIST', 'units': 'uV', 'ylim': [ -60,  60], 'scalebar': 50, 'ylabel': 'BN3'}, #, 'decimation_factor': 100},\n",
    "    {'channel': 'Force',    'units': 'mN', 'ylim': [ -50, 450], 'scalebar': 300, 'decimation_factor': 100},\n",
    "]\n",
    "channel_names = [p['channel'] for p in plots]\n",
    "channel_units = [p['units'] for p in plots]\n",
    "\n",
    "kwargs = dict(\n",
    "    figsize = (12, 6),\n",
    "    linewidth = 0.5,\n",
    "    x_scalebar = 10*pq.s,\n",
    ")\n",
    "\n",
    "# load the data\n",
    "metadata = neurotic.MetadataSelector('../../data/metadata.yml')\n",
    "metadata.select(data_set_name)\n",
    "blk = neurotic.load_dataset(metadata) # not lazy so that I2 filter is applied\n",
    "\n",
    "# plot the signal\n",
    "fig, axes = prettyplot_with_scalebars(blk, t_start, t_stop, plots, **kwargs)\n",
    "\n",
    "units = [\n",
    "    'I2 spikes',\n",
    "    'B8a/b',\n",
    "    'B6/B9',\n",
    "    'B3',\n",
    "    'B38',\n",
    "]\n",
    "unit_burst_boxes = {\n",
    "    'I2 spikes': [-35, 30],\n",
    "    'B8a/b':     [-20, 12],\n",
    "    'B6/B9':     [-15, 12],\n",
    "    'B3':        [-45, 35],\n",
    "    'B38':       [-12, 12],\n",
    "}\n",
    "\n",
    "# plot a zero baseline for force\n",
    "ax = axes[channel_names.index('Force')]\n",
    "force_zero = -11.5 # mN, average before animal began swallowing, not zero because of DC offset\n",
    "ax.axhline(force_zero, color='0.75', lw=1, ls='--', zorder=-1)\n",
    "\n",
    "for j, i in enumerate(df.index):\n",
    "    for k, unit in enumerate(units):\n",
    "        st = df.loc[i, unit+' spike train']\n",
    "        if st is not None and st.size > 0:\n",
    "                \n",
    "            # get the neural channel\n",
    "            channel = st.annotations['channels'][0]\n",
    "            sig = get_sig(blk, channel)\n",
    "\n",
    "            # get the signal for the entire bout\n",
    "            sig = sig.time_slice(t_start, t_stop)\n",
    "            sig = sig.rescale(channel_units[channel_names.index(channel)])\n",
    "\n",
    "            # plot spikes\n",
    "            ax = axes[channel_names.index(channel)]\n",
    "            spike_amplitudes = np.array([sig[sig.time_index(t)] for t in st]) * pq.Quantity(sig.units)\n",
    "            ax.scatter(st.times.rescale('s'), spike_amplitudes, marker='.', s=4, c=unit_colors[unit], zorder=3)\n",
    "\n",
    "            # plot burst windows\n",
    "            bursts = df.at[i, unit+' all bursts (s)']\n",
    "            bottom, top = unit_burst_boxes[unit]\n",
    "            height = top-bottom\n",
    "            for burst in bursts:\n",
    "                if is_good_burst(burst):\n",
    "                    left = burst['Start (s)']\n",
    "                    right = burst['End (s)']\n",
    "                    width = right-left\n",
    "                    rect = patches.Rectangle((left, bottom), width, height, linewidth=2, ls='-', edgecolor=unit_colors[unit], fill=False, zorder=3, clip_on=False)\n",
    "                    ax.add_patch(rect)\n",
    "\n",
    "# fig.savefig(os.path.join(export_dir, 'figure-exemplary-bout-export.png'), dpi=600)\n",
    "\n",
    "end = datetime.datetime.now()\n",
    "print('render time:', end-start)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model stuff"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "swallow_id = ('JG07', 'Tape nori', 0, 0)\n",
    "\n",
    "(data_set_name, channel_names, time_window, _, _) = feeding_bouts[swallow_id[:3]]\n",
    "\n",
    "# load the data\n",
    "metadata = neurotic.MetadataSelector('../../data/metadata.yml')\n",
    "metadata.select(data_set_name)\n",
    "blk = neurotic.load_dataset(metadata, lazy=True)\n",
    "sig = get_sig(blk, 'Force')\n",
    "sig = sig.time_slice(time_window[0]*pq.s, time_window[1]*pq.s)\n",
    "sig = sig.rescale('mN')\n",
    "sig = elephant.signal_processing.butter(sig, lowpass_freq = 10*pq.Hz)\n",
    "\n",
    "st_b6b9 = df_all.loc[swallow_id]['B6/B9 spike train']\n",
    "st_b3 = df_all.loc[swallow_id]['B3 spike train']\n",
    "\n",
    "weight_b6b9, tau_b6b9 = 1.75, 1\n",
    "weight_b3,   tau_b3   = 1.75, 0.2\n",
    "model_scale           = 100\n",
    "model_baseline        = 85\n",
    "u_to_y_constant       = 0.005\n",
    "\n",
    "rate_b6b9 = elephant.statistics.instantaneous_rate(\n",
    "    spiketrain=st_b6b9,\n",
    "    sampling_period=0.0002*pq.s,\n",
    "    kernel=CausalAlphaKernel(tau_b6b9*pq.s),\n",
    ")\n",
    "\n",
    "rate_b3 = elephant.statistics.instantaneous_rate(\n",
    "    spiketrain=st_b3,\n",
    "    sampling_period=0.0002*pq.s,\n",
    "    kernel=CausalAlphaKernel(tau_b3*pq.s),\n",
    ")\n",
    "\n",
    "rate_total = rate_b6b9 * weight_b6b9 + rate_b3 * weight_b3\n",
    "# y = np.exp(-u_to_y_constant*rate_total.magnitude)\n",
    "y = 1 - u_to_y_constant * rate_total.magnitude\n",
    "y = np.max([y.flatten(), np.zeros(y.size)], axis=0)\n",
    "y = np.min([y.flatten(), np.ones(y.size)], axis=0)\n",
    "x = np.sqrt(1-y**2)\n",
    "x = x * model_scale + model_baseline\n",
    "\n",
    "\n",
    "plt.figure(figsize=(8,4))\n",
    "plt.plot(rate_total.times.rescale('s'), rate_total)\n",
    "plt.plot(rate_total.times.rescale('s'), x)\n",
    "plt.plot(sig.times.rescale('s'), sig.magnitude, color='0.75', zorder=-1)\n",
    "plt.xlim([df_all.loc[swallow_id]['Start (s)'], df_all.loc[swallow_id]['End (s)']])\n",
    "\n",
    "plt.title(f'Scale: {model_scale} | Baseline: {model_baseline} | B6/B9: ({weight_b6b9}, {tau_b6b9}) | B3: ({weight_b3}, {tau_b3})')\n",
    "\n",
    "export_dir4 = os.path.join(export_dir, 'firing-rate-models')\n",
    "plt.gcf().savefig(os.path.join(export_dir4, f'S {model_scale} BL {model_baseline} B6B9 {weight_b6b9} {tau_b6b9} B3 {weight_b3} {tau_b3}.png'), dpi=300)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
