{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\\>\\>\\> CLICK [HERE](#Figures) TO JUMP DOWN TO MANUSCRIPT FIGURES <<<"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Preamble"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "source": [
    "## Import Packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import datetime\n",
    "import numpy as np\n",
    "import quantities as pq\n",
    "import elephant\n",
    "import pandas as pd\n",
    "import statsmodels.api as sm\n",
    "import neurotic\n",
    "from neurotic.datasets.data import _detect_spikes\n",
    "from utils import BehaviorsDataFrame, DownsampleNeoSignal\n",
    "\n",
    "pq.markup.config.use_unicode = True  # allow symbols like mu for micro in output\n",
    "pq.mN = pq.UnitQuantity('millinewton', pq.N/1e3, symbol = 'mN');  # define millinewton\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.patches as patches\n",
    "import matplotlib.lines as mlines\n",
    "from matplotlib.ticker import MultipleLocator\n",
    "import seaborn as sns\n",
    "\n",
    "import warnings\n",
    "plt.rcParams.update({'figure.max_open_warning': 0})\n",
    "warnings.filterwarnings('ignore', message='Instantaneous firing rate approximation contains negative values, ' \\\n",
    "                                          'possibly caused due to machine precision errors.')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "source": [
    "## IPython Magics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "outputs": [],
   "source": [
    "# make figures interactive and open in a separate window\n",
    "# %matplotlib qt\n",
    "\n",
    "# make figures interactive and inline\n",
    "%matplotlib notebook\n",
    "\n",
    "# make figures non-interactive and inline\n",
    "# %matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "source": [
    "## Plot Settings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "export_dir = 'manuscript-figures'\n",
    "if not os.path.exists(export_dir):\n",
    "    os.mkdir(export_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "outputs": [],
   "source": [
    "# general plot settings\n",
    "sns.set(\n",
    "#     context = 'poster',\n",
    "    style = 'ticks',\n",
    "    font_scale = 1,\n",
    "    font = 'Palatino Linotype',\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# display current color palette\n",
    "with sns.axes_style(\"darkgrid\"):\n",
    "    sns.palplot(sns.color_palette(None), size=0.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "outputs": [],
   "source": [
    "markers = ['.', '+', 'x', '1', '4', 'o', 'D']\n",
    "colors = ['C0', 'C1', 'C2', 'C3', 'C4', 'C5', 'C6']\n",
    "\n",
    "unit_colors = {\n",
    "    'I2 spikes': 'C9', # light blue\n",
    "    'B8a/b':     'C6', # pink\n",
    "    'B3':        'C3', # red\n",
    "    'B6/B9':     'C2', # green\n",
    "    'B38':       'C1', # orange\n",
    "}\n",
    "force_colors = {\n",
    "    'dip':          unit_colors['I2 spikes'],\n",
    "    'initial rise': unit_colors['B8a/b'],\n",
    "    'rise':         unit_colors['B8a/b'], #unit_colors['B6/B9'],\n",
    "    'plateau':      unit_colors['B6/B9'], #unit_colors['B3'],\n",
    "    'drop':         'gray',\n",
    "    'shoulder':     unit_colors['B38'],\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "source": [
    "## Data Parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "outputs": [],
   "source": [
    "feeding_bouts = {\n",
    "    # (animal, food, bout_index): (\n",
    "    #     data_set_name,\n",
    "    #     channel_names,\n",
    "    #     time_window,\n",
    "    #     epoch_types_to_keep,\n",
    "    #     burst_thresholds,\n",
    "    # )\n",
    "\n",
    "#     ('JG07', 'Tape nori', 0): (\n",
    "#         'IN VIVO / JG07 / 2018-05-20 / 002',\n",
    "#         ['I2-L', 'RN-L', 'BN2-L', 'BN3-L', 'Force'],\n",
    "#         [2718, 2755], # 5 swallows\n",
    "#         ['Swallow (tape nori)'],\n",
    "#         {\n",
    "#             'I2 spikes': (10,  5)*pq.Hz, # same as Cullins et al. 2015a (based on Hurwitz et al. 1996)\n",
    "#             'B8a/b':     ( 3,  3)*pq.Hz, # same as Cullins et al. 2015a (based on Morton and Chiel 1993a)\n",
    "#             'B3':        ( 8,  2)*pq.Hz, # based on Lu et al. 2015\n",
    "#             'B6/B9':     (10,  5)*pq.Hz, # based on Lu et al. 2015\n",
    "#             'B38':       ( 8,  5)*pq.Hz, # based on McManus et al. 2014\n",
    "#         },\n",
    "#     ),\n",
    "    \n",
    "#     ('JG08', 'Tape nori', 0): (\n",
    "#         'IN VIVO / JG08 / 2018-06-21 / 002',\n",
    "#         ['I2', 'RN', 'BN2', 'BN3', 'Force'],\n",
    "#         [148, 208], # 7 swallows, some bucket and head movement\n",
    "#         ['Swallow (tape nori)'],\n",
    "#         {\n",
    "#             'I2 spikes': (10,  5)*pq.Hz, # same as Cullins et al. 2015a (based on Hurwitz et al. 1996)\n",
    "#             'B8a/b':     ( 3,  3)*pq.Hz, # same as Cullins et al. 2015a (based on Morton and Chiel 1993a)\n",
    "#             'B3':        ( 8,  2)*pq.Hz, # based on Lu et al. 2015\n",
    "# #             'B6/B9':     (10,  5)*pq.Hz, # based on Lu et al. 2015\n",
    "#             'B6/B9':     (10,  3)*pq.Hz, # based on Lu et al. 2015 (end threshold reduced for this animal)\n",
    "#             'B38':       ( 8,  5)*pq.Hz, # based on McManus et al. 2014\n",
    "#         },\n",
    "#     ),\n",
    "\n",
    "#     ('JG08', 'Tape nori', 1): (\n",
    "#         'IN VIVO / JG08 / 2018-06-21 / 002',\n",
    "#         ['I2', 'RN', 'BN2', 'BN3', 'Force'],\n",
    "#         [664, 701], # 5 swallows, large bucket movement\n",
    "#         ['Swallow (tape nori)'],\n",
    "#         {\n",
    "#             'I2 spikes': (10,  5)*pq.Hz, # same as Cullins et al. 2015a (based on Hurwitz et al. 1996)\n",
    "#             'B8a/b':     ( 3,  3)*pq.Hz, # same as Cullins et al. 2015a (based on Morton and Chiel 1993a)\n",
    "#             'B3':        ( 8,  2)*pq.Hz, # based on Lu et al. 2015\n",
    "# #             'B6/B9':     (10,  5)*pq.Hz, # based on Lu et al. 2015\n",
    "#             'B6/B9':     (10,  3)*pq.Hz, # based on Lu et al. 2015 (end threshold reduced for this animal)\n",
    "#             'B38':       ( 8,  5)*pq.Hz, # based on McManus et al. 2014\n",
    "#         },\n",
    "#     ),\n",
    "\n",
    "#     ('JG08', 'Tape nori', 2): (\n",
    "#         'IN VIVO / JG08 / 2018-06-21 / 002',\n",
    "#         ['I2', 'RN', 'BN2', 'BN3', 'Force'],\n",
    "#         [1452, 1477], # 3 swallows, some bucket movement\n",
    "#         ['Swallow (tape nori)'],\n",
    "#         {\n",
    "#             'I2 spikes': (10,  5)*pq.Hz, # same as Cullins et al. 2015a (based on Hurwitz et al. 1996)\n",
    "#             'B8a/b':     ( 3,  3)*pq.Hz, # same as Cullins et al. 2015a (based on Morton and Chiel 1993a)\n",
    "#             'B3':        ( 8,  2)*pq.Hz, # based on Lu et al. 2015\n",
    "# #             'B6/B9':     (10,  5)*pq.Hz, # based on Lu et al. 2015\n",
    "#             'B6/B9':     (10,  3)*pq.Hz, # based on Lu et al. 2015 (end threshold reduced for this animal)\n",
    "#             'B38':       ( 8,  5)*pq.Hz, # based on McManus et al. 2014\n",
    "#         },\n",
    "#     ),\n",
    "\n",
    "#     ('JG11', 'Tape nori', 0): (\n",
    "#         'IN VIVO / JG11 / 2019-04-03 / 004',\n",
    "#         ['I2', 'RN', 'BN2', 'BN3-PROX', 'Force'],\n",
    "#         [1233, 1280], # 5 swallows\n",
    "#         ['Swallow (tape nori)'],\n",
    "#         {\n",
    "#             'I2 spikes': (10,  5)*pq.Hz, # same as Cullins et al. 2015a (based on Hurwitz et al. 1996)\n",
    "#             'B8a/b':     ( 3,  3)*pq.Hz, # same as Cullins et al. 2015a (based on Morton and Chiel 1993a)\n",
    "#             'B3':        ( 8,  2)*pq.Hz, # based on Lu et al. 2015\n",
    "#             'B6/B9':     (10,  5)*pq.Hz, # based on Lu et al. 2015\n",
    "#             'B38':       ( 8,  5)*pq.Hz, # based on McManus et al. 2014\n",
    "#         },\n",
    "#     ),\n",
    "\n",
    "#     ('JG12', 'Tape nori', 0): (\n",
    "#         'IN VIVO / JG12 / 2019-05-10 / 002',\n",
    "#         ['I2', 'RN', 'BN2', 'BN3-DIST', 'Force'],\n",
    "#         [437, 465], # 4 swallows\n",
    "#         ['Swallow (tape nori)'],\n",
    "#         {\n",
    "#             'I2 spikes': (10,  5)*pq.Hz, # same as Cullins et al. 2015a (based on Hurwitz et al. 1996)\n",
    "#             'B8a/b':     ( 3,  3)*pq.Hz, # same as Cullins et al. 2015a (based on Morton and Chiel 1993a)\n",
    "#             'B3':        ( 8,  2)*pq.Hz, # based on Lu et al. 2015\n",
    "#             'B6/B9':     (10,  5)*pq.Hz, # based on Lu et al. 2015\n",
    "#             'B38':       ( 8,  5)*pq.Hz, # based on McManus et al. 2014\n",
    "#         },\n",
    "#     ),\n",
    "    \n",
    "#     ('JG12', 'Tape nori', 1): (\n",
    "#         'IN VIVO / JG12 / 2019-05-10 / 002',\n",
    "#         ['I2', 'RN', 'BN2', 'BN3-DIST', 'Force'],\n",
    "#         [2901, 2937], # 5 swallows\n",
    "#         ['Swallow (tape nori)'],\n",
    "#         {\n",
    "#             'I2 spikes': (10,  5)*pq.Hz, # same as Cullins et al. 2015a (based on Hurwitz et al. 1996)\n",
    "#             'B8a/b':     ( 3,  3)*pq.Hz, # same as Cullins et al. 2015a (based on Morton and Chiel 1993a)\n",
    "#             'B3':        ( 8,  2)*pq.Hz, # based on Lu et al. 2015\n",
    "#             'B6/B9':     (10,  5)*pq.Hz, # based on Lu et al. 2015\n",
    "#             'B38':       ( 8,  5)*pq.Hz, # based on McManus et al. 2014\n",
    "#         },\n",
    "#     ),\n",
    "\n",
    "#     ('JG14', 'Tape nori', 0): (\n",
    "#         'IN VIVO / JG14 / 2019-07-29 / 004',\n",
    "#         ['I2', 'RN', 'BN2', 'BN3-PROX', 'Force'],\n",
    "#         [831, 870], # 5 swallows\n",
    "#         ['Swallow (tape nori)'],\n",
    "#         {\n",
    "#             'I2 spikes': (10,  5)*pq.Hz, # same as Cullins et al. 2015a (based on Hurwitz et al. 1996)\n",
    "#             'B8a/b':     ( 3,  3)*pq.Hz, # same as Cullins et al. 2015a (based on Morton and Chiel 1993a)\n",
    "#             'B3':        ( 8,  2)*pq.Hz, # based on Lu et al. 2015\n",
    "#             'B6/B9':     (10,  5)*pq.Hz, # based on Lu et al. 2015\n",
    "#             'B38':       ( 8,  5)*pq.Hz, # based on McManus et al. 2014\n",
    "#         },\n",
    "#     ),\n",
    "\n",
    "\n",
    "    \n",
    "    # for example figures only -- not used in majority of analysis because of long inter-swallow intervals\n",
    "    ('JG12', 'Tape nori', 101): (\n",
    "        'IN VIVO / JG12 / 2019-05-10 / 002',\n",
    "        ['I2', 'RN', 'BN2', 'BN3-DIST', 'Force'],\n",
    "        [2944.5, 3002.5], # 6 swallows\n",
    "        ['Swallow (tape nori)'],\n",
    "        {\n",
    "            'I2 spikes': (10,  5)*pq.Hz, # same as Cullins et al. 2015a (based on Hurwitz et al. 1996)\n",
    "            'B8a/b':     ( 3,  3)*pq.Hz, # same as Cullins et al. 2015a (based on Morton and Chiel 1993a)\n",
    "            'B3':        ( 8,  2)*pq.Hz, # based on Lu et al. 2015\n",
    "            'B6/B9':     (10,  5)*pq.Hz, # based on Lu et al. 2015\n",
    "            'B38':       ( 8,  5)*pq.Hz, # based on McManus et al. 2014\n",
    "        },\n",
    "    ),\n",
    "    \n",
    "    # for example figures only -- not used in majority of analysis because of long inter-swallow intervals\n",
    "    ('JG12', 'Tape nori', 102): (\n",
    "        'IN VIVO / JG12 / 2019-05-10 / 002',\n",
    "        ['I2', 'RN', 'BN2', 'BN3-DIST', 'Force'],\n",
    "        [2999.3, 3010], # 1 swallow\n",
    "        ['Swallow (tape nori)'],\n",
    "        {\n",
    "            'I2 spikes': (10,  5)*pq.Hz, # same as Cullins et al. 2015a (based on Hurwitz et al. 1996)\n",
    "            'B8a/b':     ( 3,  3)*pq.Hz, # same as Cullins et al. 2015a (based on Morton and Chiel 1993a)\n",
    "            'B3':        ( 8,  2)*pq.Hz, # based on Lu et al. 2015\n",
    "            'B6/B9':     (10,  5)*pq.Hz, # based on Lu et al. 2015\n",
    "            'B38':       ( 8,  5)*pq.Hz, # based on McManus et al. 2014\n",
    "        },\n",
    "    ),\n",
    "}\n",
    "\n",
    "\n",
    "exemplary_bout = ('JG12', 'Tape nori', 101)\n",
    "exemplary_swallow = ('JG12', 'Tape nori', 102)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "source": [
    "## Helper Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "outputs": [],
   "source": [
    "def query_union(queries):\n",
    "    return '|'.join([f'({q})' for q in queries if q is not None])\n",
    "\n",
    "def label2query(label):\n",
    "    animal, food = label[:4], label[5:]\n",
    "    query = f'(Animal == \"{animal}\") & (Food == \"{food}\")'\n",
    "    return query\n",
    "\n",
    "def contains(series, string):\n",
    "#     return np.array([string in x for x in series])\n",
    "    return series.map(lambda x: string in x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def update_filter(metadata, new_filter):\n",
    "    i = next((i for i, f in enumerate(metadata['filters']) if f['channel'] == new_filter['channel']), None)\n",
    "    if i is not None:\n",
    "        metadata['filters'][i] = new_filter\n",
    "    else:\n",
    "        metadata['filters'].append(new_filter)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "outputs": [],
   "source": [
    "def get_sig(blk, channel):\n",
    "    sig = next((sig for sig in blk.segments[0].analogsignals if sig.name == channel), None)\n",
    "    if sig is None:\n",
    "        raise Exception(f'Channel \"{channel}\" could not be found')\n",
    "    else:\n",
    "        return sig"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "outputs": [],
   "source": [
    "def finite_min(x, y):\n",
    "    '''Workaround for Quantities warning about comparison to NaN'''\n",
    "    if np.isfinite(x) and np.isfinite(y):\n",
    "        return min(x, y)\n",
    "    elif np.isfinite(x):\n",
    "        return x\n",
    "    elif np.isfinite(y):\n",
    "        return y\n",
    "    else:\n",
    "        return np.nan\n",
    "\n",
    "def finite_max(x, y):\n",
    "    '''Workaround for Quantities warning about comparison to NaN'''\n",
    "    if np.isfinite(x) and np.isfinite(y):\n",
    "        return max(x, y)\n",
    "    elif np.isfinite(x):\n",
    "        return x\n",
    "    elif np.isfinite(y):\n",
    "        return y\n",
    "    else:\n",
    "        return np.nan"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "outputs": [],
   "source": [
    "def find_bursts(st, burst_thresholds):\n",
    "    '''Find every sequence of spikes that qualifies as a burst'''\n",
    "    \n",
    "    isi = elephant.statistics.isi(st).rescale('s')\n",
    "    iff = 1/isi\n",
    "\n",
    "    start_freq, end_freq = burst_thresholds\n",
    "    start_mask = iff > start_freq\n",
    "    end_mask = iff < end_freq\n",
    "\n",
    "    bursts = []\n",
    "    scan_index = -1\n",
    "    while scan_index < iff.size:\n",
    "        start_index = None\n",
    "        end_index = None\n",
    "\n",
    "        start_mask_indexes = np.where(start_mask)[0]\n",
    "        start_mask_indexes = start_mask_indexes[start_mask_indexes > scan_index]\n",
    "        if start_mask_indexes.size == 0:\n",
    "            break\n",
    "\n",
    "        start_index = start_mask_indexes[0] # first time that iff rises above start threshold\n",
    "\n",
    "        end_mask_indexes = np.where(end_mask)[0]\n",
    "        end_mask_indexes = end_mask_indexes[end_mask_indexes > start_index]\n",
    "        if end_mask_indexes.size > 0:\n",
    "            end_index = end_mask_indexes[0] # first time after start that iff drops below end theshold\n",
    "        else:\n",
    "            end_index = -1 # end of spike train (include all spikes after start)\n",
    "\n",
    "        burst = {\n",
    "            'Start (s)': st[start_index].rescale('s'),\n",
    "            'End (s)': st[end_index].rescale('s'),\n",
    "            'Duration (s)': (st[end_index] - st[start_index]).rescale('s'),\n",
    "            'Number of spikes': end_index-start_index+1 if end_index > 0 else st.size-start_index\n",
    "        }\n",
    "        bursts.append(burst)\n",
    "        if end_index == -1:\n",
    "            break\n",
    "        else:\n",
    "            scan_index = end_index\n",
    "    \n",
    "    return bursts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "outputs": [],
   "source": [
    "def is_good_burst(burst):\n",
    "    return burst['Duration (s)'] >= 0.5*pq.s and burst['Number of spikes'] > 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def normalize_time(fixed_times, t):\n",
    "    \n",
    "    if np.isnan(t):\n",
    "        return np.nan\n",
    "    \n",
    "    assert np.all(np.diff(fixed_times[~np.isnan(fixed_times)])>=0), f'fixed_times must be sorted: {fixed_times}'\n",
    "    \n",
    "    t_min = fixed_times[~np.isnan(fixed_times)].min()\n",
    "    t_max = fixed_times[~np.isnan(fixed_times)].max()\n",
    "    if t < t_min or t_max < t:\n",
    "#         print(f'time {t:.3f} was out of bounds for normalization, returning NaN')\n",
    "        return np.nan\n",
    "    \n",
    "    for i in range(len(fixed_times)-1):\n",
    "        before = fixed_times[i]\n",
    "        after = fixed_times[i+1]\n",
    "        if np.isfinite(before) and np.isfinite(after):\n",
    "            if before <= t <= after:\n",
    "                return (t-before)/(after-before) + i\n",
    "    \n",
    "    # if we haven't returned already, then there must be a NaN bordering where t would go\n",
    "#     print(f'time {t:.3f} would fall next to an undefined boundary, returning NaN')\n",
    "    return np.nan"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def unnormalize_time(fixed_times, t_normalized):\n",
    "    \n",
    "    if np.isnan(t_normalized):\n",
    "        return np.nan\n",
    "    \n",
    "    assert np.all(np.diff(fixed_times[~np.isnan(fixed_times)])>=0), f'fixed_times must be sorted: {fixed_times}'\n",
    "    \n",
    "    t_normalized_min = np.where(~np.isnan(fixed_times))[0].min()\n",
    "    t_normalized_max = np.where(~np.isnan(fixed_times))[0].max()\n",
    "    if t_normalized < t_normalized_min or t_normalized_max < t_normalized:\n",
    "#         print(f'normalized time {t_normalized:.3f} was out of bounds for un-normalization, returning NaN')\n",
    "        return np.nan\n",
    "    \n",
    "    if np.isclose(t_normalized, t_normalized_max):\n",
    "        # workaround for numerical imprecision issue\n",
    "        t_normalized -= 0.000001\n",
    "    \n",
    "    i = int(np.floor(t_normalized))\n",
    "    before = fixed_times[i]\n",
    "    after = fixed_times[i+1]\n",
    "    if np.isfinite(before) and np.isfinite(after):\n",
    "        return (t_normalized - i)*(after-before) + before\n",
    "    else:\n",
    "        # there is a NaN bordering where t would go\n",
    "#         print(f'normalized time {t_normalized:.3f} would fall next to an undefined boundary, returning NaN')\n",
    "        return np.nan"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def print_column_analysis(column):\n",
    "    unit = column.split('(')[-1].split(')')[0]\n",
    "    mean = df_all[column].mean()\n",
    "    std = df_all[column].std()\n",
    "    cv = std/abs(mean)\n",
    "    print(f'Overall mean +/- std: {mean:.2f} +/- {std:.2f} {unit}')\n",
    "    print(f'Overall coefficient of variation CV: {cv:.2f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_vertical_lines_with_delay(axes, t, delay, force_y, color):\n",
    "\n",
    "    # plot vertical line in force plot at time t\n",
    "    axes[-1].add_artist(patches.ConnectionPatch(\n",
    "        xyA=(t, force_y), xyB=(t, 1),\n",
    "        coordsA='data', coordsB=axes[-1].get_xaxis_transform(),\n",
    "        axesA=axes[-1], axesB=axes[-1],\n",
    "        color=color, lw=1, ls=':'))\n",
    "    \n",
    "    # plot vertical line through all neural plots at time t-delay\n",
    "    axes[-1].add_artist(patches.ConnectionPatch(\n",
    "        xyA=(t-delay, 0), xyB=(t-delay, 1),\n",
    "        coordsA=axes[-2].get_xaxis_transform(), coordsB=axes[0].get_xaxis_transform(),\n",
    "        axesA=axes[-2], axesB=axes[0],\n",
    "        color=color, lw=1, ls=':'))\n",
    "    \n",
    "    # connect the two lines\n",
    "    axes[-1].add_artist(patches.ConnectionPatch(\n",
    "        xyA=(t-delay, 0), xyB=(t, 1),\n",
    "        coordsA=axes[-2].get_xaxis_transform(), coordsB=axes[-1].get_xaxis_transform(),\n",
    "        axesA=axes[-2], axesB=axes[-1],\n",
    "        color=color, lw=1, ls=':'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def lighten_color(color, amount=0.5):\n",
    "    '''\n",
    "    Lightens the given color by multiplying (1-luminosity) by the given amount.\n",
    "    Input can be matplotlib color string, hex string, or RGB tuple.\n",
    "\n",
    "    Examples:\n",
    "    >> lighten_color('g', 0.3)\n",
    "    >> lighten_color('#F034A3', 0.6)\n",
    "    >> lighten_color((.3,.55,.1), 0.5)\n",
    "    \n",
    "    https://stackoverflow.com/a/49601444/3314376\n",
    "    '''\n",
    "    import matplotlib.colors as mc\n",
    "    import colorsys\n",
    "    try:\n",
    "        c = mc.cnames[color]\n",
    "    except:\n",
    "        c = color\n",
    "    c = colorsys.rgb_to_hls(*mc.to_rgb(c))\n",
    "    return colorsys.hls_to_rgb(c[0], 1 - amount * (1 - c[1]), c[2])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import and Process the Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Main dataframe used for most figures"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "start = datetime.datetime.now()\n",
    "\n",
    "# use Neo RawIO lazy loading to load much faster and using less memory\n",
    "# - with lazy=True, filtering parameters specified in metadata are ignored\n",
    "# - with lazy=True, loading via time_slice requires neo>=0.8.0.dev\n",
    "# - IMPORTANT: force and I2 filters affect smoothness and possibly threshold crossings and spike detection\n",
    "lazy = False\n",
    "\n",
    "# load the metadata containing file paths\n",
    "metadata = neurotic.MetadataSelector(file='../../data/metadata.yml')\n",
    "\n",
    "# filter epochs for each bout and perform calculations\n",
    "df_list = []\n",
    "last_data_set_name = None\n",
    "for (animal, food, bout_index), (data_set_name, channel_names, time_window, epoch_types_to_keep, burst_thresholds) in feeding_bouts.items():\n",
    "    \n",
    "    ###\n",
    "    ### LOCATE BEHAVIOR EPOCHS AND SUBEPOCHS\n",
    "    ###\n",
    "    \n",
    "    metadata.select(data_set_name)\n",
    "    if data_set_name is last_data_set_name:\n",
    "        # skip reloading the data if it's already in memory\n",
    "        pass\n",
    "    else:\n",
    "        blk = neurotic.load_dataset(metadata, lazy=lazy)\n",
    "    last_data_set_name = data_set_name\n",
    "    \n",
    "    # construct a query for locating behaviors\n",
    "    behavior_query = f'(Type in {epoch_types_to_keep}) & ({time_window[0]} <= Start) & (End <= {time_window[1]})'\n",
    "    \n",
    "    # construct queries for locating epochs associated with each behavior\n",
    "    # - each query should match at most one epoch\n",
    "    # - dictionary keys are used as prefixes for the names of new columns\n",
    "    subepoch_queries = {}\n",
    "    \n",
    "    subepoch_queries['I2 protraction activity'] = f'(Type == \"I2 protraction activity\") & ' \\\n",
    "                                                  f'(@behavior_start-1 <= Start) & (End <= @behavior_end)'\n",
    "                                                  # must start no earlier than 1 second before behavior and end within it\n",
    "    \n",
    "    subepoch_queries['B8 activity']             = f'(Type == \"B8 activity\") & ' \\\n",
    "                                                  f'(@behavior_start <= Start) & (End <= @behavior_end)'\n",
    "                                                  # must be fully contained within behavior\n",
    "    \n",
    "    subepoch_queries['B3/6/9/10 activity']      = f'(Type == \"B3/6/9/10 activity\") & ' \\\n",
    "                                                  f'(@behavior_start <= Start) & (End <= @behavior_end)'\n",
    "                                                  # must be fully contained within behavior\n",
    "\n",
    "    subepoch_queries['B38 activity']            = f'(Type == \"B38 activity\") & ' \\\n",
    "                                                  f'(@behavior_end-2 <= Start) & (Start <= @behavior_end+2)'\n",
    "                                                  # must start within 2 seconds of behavior end\n",
    "\n",
    "    subepoch_queries['Force rise start']        = f'(Type == \"Force rise start\") & ' \\\n",
    "                                                  f'(@behavior_start <= Start) & (Start <= @behavior_end)'\n",
    "                                                  # must start within behavior\n",
    "    \n",
    "    subepoch_queries['Force plateau start']     = f'(Type == \"Force plateau start\") & ' \\\n",
    "                                                  f'(@behavior_start <= Start) & (Start <= @behavior_end)'\n",
    "                                                  # must start within behavior\n",
    "    \n",
    "    subepoch_queries['Force plateau end']       = f'(Type == \"Force plateau end\") & ' \\\n",
    "                                                  f'(@behavior_end-2 <= Start) & (Start <= @behavior_end+2)'\n",
    "                                                  # must start within 2 seconds of behavior end\n",
    "    \n",
    "    subepoch_queries['Force drop end']          = f'(Type == \"Force drop end\") & ' \\\n",
    "                                                  f'(@behavior_end-2 <= Start) & (Start <= @behavior_end+2)'\n",
    "                                                  # must start within 2 seconds of behavior end\n",
    "    \n",
    "    subepoch_queries['Force shoulder end']      = f'(Type == \"Force shoulder end\") & ' \\\n",
    "                                                  f'(@behavior_end <= Start) & (Start <= @behavior_end+4)'\n",
    "                                                  # must start less than 4 seconds after behavior end\n",
    "    \n",
    "    # construct a table in which each row is a behavior and subepoch data\n",
    "    # is added as columns, e.g. df['B38 activity start (s)']\n",
    "    df = BehaviorsDataFrame(blk.segments[0].epochs, behavior_query, subepoch_queries)\n",
    "\n",
    "    # renumber behaviors assuming all behaviors are from a single contiguous sequence\n",
    "    df = df.sort_values('Start (s)').reset_index(drop=True).rename_axis('Behavior_index')\n",
    "\n",
    "    \n",
    "    \n",
    "    ###\n",
    "    ### START CALCULATIONS\n",
    "    ###\n",
    "\n",
    "    # some columns must have type 'object', which\n",
    "    # can be accomplished by initializing with None or np.nan\n",
    "    df['Normalization fixed times (s)'] = None\n",
    "    units = [\n",
    "        'I2 spikes',\n",
    "        'B8a/b',\n",
    "        'B3',\n",
    "        'B6/B9',\n",
    "        'B38',\n",
    "    ]\n",
    "    for unit in units:\n",
    "        df[unit+' spike train'] = None\n",
    "        df[unit+' inter-spike intervals (s)'] = None\n",
    "        df[unit+' all bursts (s)'] = None\n",
    "\n",
    "        # while we're at it, initialize some other things that might otherwise never be given values\n",
    "        df[unit+' first burst start (s)'] = np.nan\n",
    "        df[unit+' first burst end (s)'] = np.nan\n",
    "        df[unit+' first burst duration (s)'] = 0\n",
    "        df[unit+' first burst spike count'] = 0\n",
    "        df[unit+' first burst mean frequency (Hz)'] = np.nan\n",
    "        df[unit+' last burst start (s)'] = np.nan\n",
    "        df[unit+' last burst end (s)'] = np.nan\n",
    "        df[unit+' last burst duration (s)'] = 0\n",
    "        df[unit+' last burst spike count'] = 0\n",
    "        df[unit+' last burst mean frequency (Hz)'] = np.nan\n",
    "\n",
    "\n",
    "    ### SANITY CHECK: plot all channels for entire time window\n",
    "    figsize = (9.5, 10) # dimensions for notebook\n",
    "#     figsize = (11, 8.5) # dimensions for printing\n",
    "    fig, axes = plt.subplots(len(channel_names), 1, sharex=True, figsize=figsize)\n",
    "    channel_units = ['uV', 'uV', 'uV', 'uV', 'mN']\n",
    "    for i, channel in enumerate(channel_names):\n",
    "        plt.sca(axes[i])\n",
    "        sig = get_sig(blk, channel)\n",
    "        sig = sig.time_slice(time_window[0]*pq.s, time_window[1]*pq.s)\n",
    "        sig = sig.rescale(channel_units[i])\n",
    "        plt.plot(sig.times, sig.magnitude, c='0.8', lw=1, zorder=-1)\n",
    "        \n",
    "        if i == 0:\n",
    "            plt.title(f'({animal}, {food}, {bout_index}): {data_set_name}')\n",
    "            \n",
    "        plt.ylabel(sig.name + ' (' + sig.units.dimensionality.string + ')')\n",
    "        axes[i].yaxis.set_label_coords(-0.06, 0.5)\n",
    "        \n",
    "        if i < len(channel_names)-1:\n",
    "            # remove right, top, and bottom plot borders, and remove x-axis\n",
    "            sns.despine(ax=plt.gca(), bottom=True)\n",
    "            plt.gca().xaxis.set_visible(False)\n",
    "        else:\n",
    "            # remove right and top plot borders, and set x-label\n",
    "            sns.despine(ax=plt.gca())\n",
    "            plt.xlabel('Time (s)')\n",
    "                \n",
    "\n",
    "    \n",
    "    ### SANITY CHECK: plot smoothed force for entire time window\n",
    "    channel = 'Force'\n",
    "    sig = get_sig(blk, channel)\n",
    "    if lazy:\n",
    "        sig = sig.time_slice(None, None)\n",
    "    sig = elephant.signal_processing.butter(sig, lowpass_freq = 5*pq.Hz)\n",
    "    sig = sig.time_slice(time_window[0]*pq.s, time_window[1]*pq.s)\n",
    "    sig = sig.rescale('mN')\n",
    "    plt.plot(sig.times, sig.magnitude, c='k', lw=1, zorder=0)\n",
    "    force_smoothed_sig = sig\n",
    "    \n",
    "    \n",
    "    \n",
    "    # iterate over all swallows\n",
    "    for j, i in enumerate(df.index):\n",
    "        \n",
    "        behavior_start = df.loc[i, 'Start (s)']*pq.s\n",
    "        behavior_end = df.loc[i, 'End (s)']*pq.s\n",
    "        \n",
    "        ###\n",
    "        ### FORCE\n",
    "        ###\n",
    "        \n",
    "        # quantify force in each behavior\n",
    "        \n",
    "        force_rise_start = df.loc[i, 'Force rise start start (s)']*pq.s # start of \"Force rise start\" epoch\n",
    "        force_plateau_start = df.loc[i, 'Force plateau start start (s)']*pq.s # start of \"Force plateau start\" epoch\n",
    "        force_plateau_end = df.loc[i, 'Force plateau end start (s)']*pq.s # start of \"Force plateau end\" epoch\n",
    "        force_drop_end = df.loc[i, 'Force drop end start (s)']*pq.s # start of \"Force drop end\" epoch\n",
    "        force_shoulder_end = df.loc[i, 'Force shoulder end start (s)']*pq.s # start of \"Force shoulder end\" epoch\n",
    "        \n",
    "        # get the drop time for the previous swallow and the rise time for the next swallow\n",
    "        epochs_force_rise_start = next((ep for ep in blk.segments[0].epochs if ep.name == 'Force rise start'), None)\n",
    "        epochs_force_plateau_end = next((ep for ep in blk.segments[0].epochs if ep.name == 'Force plateau end'), None)\n",
    "        epochs_force_drop_end = next((ep for ep in blk.segments[0].epochs if ep.name == 'Force drop end'), None)\n",
    "        epochs_force_shoulder_end = next((ep for ep in blk.segments[0].epochs if ep.name == 'Force shoulder end'), None)\n",
    "        assert epochs_force_rise_start is not None, 'failed to find \"Force rise start\" epochs'\n",
    "        assert epochs_force_plateau_end is not None, 'failed to find \"Force plateau end\" epochs'\n",
    "        assert epochs_force_drop_end is not None, 'failed to find \"Force drop end\" epochs'\n",
    "        assert epochs_force_shoulder_end is not None, 'failed to find \"Force shoulder end\" epochs'\n",
    "        \n",
    "        try:\n",
    "            prev_force_plateau_end = df.loc[i, 'Previous force plateau end (s)'] = epochs_force_plateau_end.time_slice(None, force_rise_start)[-1]\n",
    "            assert force_rise_start-prev_force_plateau_end < 12*pq.s, f'for swallow {i}, previous force plateau end is too far away'\n",
    "        except IndexError:\n",
    "            prev_force_plateau_end = df.loc[i, 'Previous force plateau end (s)'] = np.nan\n",
    "        \n",
    "        try:\n",
    "            prev_force_drop_end = df.loc[i, 'Previous force drop end (s)'] = epochs_force_drop_end.time_slice(None, force_rise_start)[-1]\n",
    "            assert force_rise_start-prev_force_drop_end < 12*pq.s, f'for swallow {i}, previous force drop end is too far away'\n",
    "        except IndexError:\n",
    "            prev_force_drop_end = df.loc[i, 'Previous force drop end (s)'] = np.nan\n",
    "        \n",
    "        try:\n",
    "            prev_force_shoulder_end = df.loc[i, 'Previous force shoulder end (s)'] = epochs_force_shoulder_end.time_slice(None, force_rise_start)[-1]\n",
    "            if prev_force_shoulder_end < prev_force_drop_end:\n",
    "                # previous swallow did not have a shoulder and we instead grabbed an earlier shoulder\n",
    "                prev_force_shoulder_end = df.loc[i, 'Previous force shoulder end (s)'] = np.nan\n",
    "        except IndexError:\n",
    "            prev_force_shoulder_end = df.loc[i, 'Previous force shoulder end (s)'] = np.nan\n",
    "        \n",
    "        try:\n",
    "            next_force_rise_start = df.loc[i, 'Next force rise start (s)'] = epochs_force_rise_start.time_slice(force_drop_end, None)[0]\n",
    "            assert next_force_rise_start-force_drop_end < 12*pq.s, f'for swallow {i}, next force rise start is too far away'\n",
    "        except IndexError:\n",
    "            next_force_rise_start = df.loc[i, 'Next force rise start (s)'] = np.nan\n",
    "        \n",
    "        # get the list of fixed times for normalization\n",
    "        normalization_fixed_times = df.at[i, 'Normalization fixed times (s)'] = np.array([\n",
    "            prev_force_plateau_end,\n",
    "            prev_force_drop_end,\n",
    "            prev_force_shoulder_end,\n",
    "            force_rise_start,\n",
    "            force_plateau_start,\n",
    "            force_plateau_end,\n",
    "            force_drop_end,\n",
    "            force_shoulder_end,\n",
    "            next_force_rise_start,\n",
    "        ])*pq.s # 'at', not 'loc', is important for inserting list into cell\n",
    "\n",
    "        # get smoothed force for whole behavior for remaining force calculations\n",
    "        sig = force_smoothed_sig\n",
    "        if np.isfinite(force_shoulder_end):\n",
    "            sig = sig.time_slice(force_rise_start - 0.01*pq.s, force_shoulder_end + 0.01*pq.s)\n",
    "        else:\n",
    "            sig = sig.time_slice(force_rise_start - 0.01*pq.s, force_drop_end + 0.01*pq.s)\n",
    "        sig = sig.rescale('mN')\n",
    "\n",
    "        # find force peak, baseline, and the increase\n",
    "        force_peak_time = elephant.spike_train_generation.peak_detection(sig, 0*pq.mN)[0]\n",
    "        force_peak = df.loc[i, 'Force peak (mN)'] = sig[sig.time_index(force_peak_time)][0]\n",
    "        force_baseline = df.loc[i, 'Force baseline (mN)'] = sig[sig.time_index(force_rise_start)][0]\n",
    "        force_increase = df.loc[i, 'Force increase (mN)'] = force_peak-force_baseline\n",
    "        \n",
    "        # find force plateau, drop, and shoulder values\n",
    "        force_plateau_start_value = df.loc[i, 'Force plateau start value (mN)'] = sig[sig.time_index(force_plateau_start)][0]\n",
    "        force_plateau_end_value = df.loc[i, 'Force plateau end value (mN)'] = sig[sig.time_index(force_plateau_end)][0]\n",
    "        force_drop_end_value = df.loc[i, 'Force drop end value (mN)'] = sig[sig.time_index(force_drop_end)][0]\n",
    "        if np.isfinite(force_shoulder_end):\n",
    "            force_shoulder_end_value = df.loc[i, 'Force shoulder end value (mN)'] = sig[sig.time_index(force_shoulder_end)][0]\n",
    "        else:\n",
    "            force_shoulder_end_value = np.nan\n",
    "\n",
    "        # find force rise and plateau durations\n",
    "        force_rise_duration = df.loc[i, 'Force rise duration (s)'] = force_plateau_start - force_rise_start\n",
    "        force_plateau_duration = df.loc[i, 'Force plateau duration (s)'] = force_plateau_end - force_plateau_start\n",
    "        force_rise_plateau_duration = df.loc[i, 'Force rise and plateau duration (s)'] = force_plateau_end - force_rise_start\n",
    "        \n",
    "        # find average slope during rising phase\n",
    "        force_rise_increase = df.loc[i, 'Force rise increase (mN)'] = force_plateau_start_value - force_baseline\n",
    "        force_slope = df.loc[i, 'Force slope (mN/s)'] = (force_rise_increase/force_rise_duration).rescale('mN/s')\n",
    "\n",
    "        \n",
    "        ### SANITY CHECK: plot force rise\n",
    "        plt.sca(axes[channel_names.index('Force')])\n",
    "        sig2 = sig.time_slice(force_rise_start, force_plateau_start)\n",
    "        plt.plot(sig2.times, sig2.magnitude, c=force_colors['rise'], lw=2, zorder=1)\n",
    "        \n",
    "        ### SANITY CHECK: plot force plateau\n",
    "        sig2 = sig.time_slice(force_plateau_start, force_plateau_end)\n",
    "        plt.plot(sig2.times, sig2.magnitude, c=force_colors['plateau'], lw=2, zorder=1)\n",
    "        \n",
    "        ### SANITY CHECK: plot force shoulder\n",
    "        if np.isfinite(force_shoulder_end):\n",
    "            sig2 = sig.time_slice(force_drop_end, force_shoulder_end)\n",
    "            plt.plot(sig2.times, sig2.magnitude, c=force_colors['shoulder'], lw=2, zorder=1)\n",
    "\n",
    "        ### SANITY CHECK: plot force peak, baseline, and plateau values\n",
    "        plt.plot([force_peak_time],     [force_peak],                marker=7, markersize=5, color='k')\n",
    "        plt.plot([force_rise_start],    [force_baseline],            marker=6, markersize=5, color='k')\n",
    "        plt.plot([force_plateau_start], [force_plateau_start_value], marker=5, markersize=5, color='k')\n",
    "        plt.plot([force_plateau_end],   [force_plateau_end_value],   marker=4, markersize=5, color='k')\n",
    "\n",
    "        \n",
    "        \n",
    "        ###\n",
    "        ### FIND SPIKE TRAINS\n",
    "        ###\n",
    "        \n",
    "        if lazy:\n",
    "            if metadata['amplitude_discriminators'] is not None:\n",
    "                for discriminator in metadata['amplitude_discriminators']:\n",
    "                    sig = get_sig(blk, discriminator['channel'])\n",
    "                    if sig is not None:\n",
    "                        sig = sig.time_slice(behavior_start - 5*pq.s, behavior_end + 5*pq.s)\n",
    "                        st = _detect_spikes(sig, discriminator, blk.segments[0].epochs)\n",
    "                        st_epoch_start = df.loc[i, discriminator['epoch']+' start (s)']*pq.s\n",
    "                        st_epoch_end = df.loc[i, discriminator['epoch']+' end (s)']*pq.s\n",
    "                        st = st.time_slice(st_epoch_start, st_epoch_end)\n",
    "                        df.at[i, st.name+' spike train'] = st # 'at', not 'loc', is important for inserting list into cell\n",
    "        else:\n",
    "            for spiketrain in blk.segments[0].spiketrains:\n",
    "                discriminator = next((d for d in metadata['amplitude_discriminators'] if d['name'] == spiketrain.name), None)\n",
    "                if discriminator is None:\n",
    "                    raise Exception(f'For data set \"{data_set_name}\", discriminator \"{spiketrain.name}\" could not be found')\n",
    "                st_epoch_start = df.loc[i, discriminator['epoch']+' start (s)']*pq.s\n",
    "                st_epoch_end = df.loc[i, discriminator['epoch']+' end (s)']*pq.s\n",
    "                st = spiketrain.time_slice(st_epoch_start, st_epoch_end)\n",
    "                df.at[i, st.name+' spike train'] = st # 'at', not 'loc', is important for inserting list into cell\n",
    "    \n",
    "    \n",
    "            \n",
    "        ###\n",
    "        ### QUANTIFY SPIKE TRAINS AND BURSTS\n",
    "        ###\n",
    "        \n",
    "        for k, unit in enumerate(units):\n",
    "            st = df.loc[i, unit+' spike train']\n",
    "            if st is not None:\n",
    "                df.loc[i, unit+' spike count'] = st.size\n",
    "                if st.size > 0:\n",
    "                    \n",
    "                    # get the neural channel\n",
    "                    channel = st.annotations['channels'][0]\n",
    "                    sig = get_sig(blk, channel)\n",
    "\n",
    "                    # get the signal for the behavior with 10 seconds cushion before and after (for better baseline estimation)\n",
    "                    sig = sig.time_slice(behavior_start - 10*pq.s, behavior_end + 10*pq.s)\n",
    "                    sig = sig.rescale(channel_units[channel_names.index(channel)])\n",
    "                    \n",
    "                    # find every sequence of spikes that qualifies as a burst\n",
    "                    bursts = df.at[i, unit+' all bursts (s)'] = find_bursts(st, burst_thresholds[unit]) # 'at', not 'loc', is important for inserting list into cell\n",
    "                    \n",
    "                    first_burst_start = np.nan\n",
    "                    first_burst_end = np.nan\n",
    "                    first_burst_spike_count = 0\n",
    "                    first_burst_mean_freq = 0*pq.Hz\n",
    "                    last_burst_start = np.nan\n",
    "                    last_burst_end = np.nan\n",
    "                    last_burst_spike_count = 0\n",
    "                    last_burst_mean_freq = 0*pq.Hz\n",
    "                    if len(bursts) > 0:\n",
    "\n",
    "                        for burst in bursts:\n",
    "                            if is_good_burst(burst):\n",
    "                                first_burst_start, first_burst_end = burst['Start (s)'], burst['End (s)']\n",
    "                                first_burst_duration = first_burst_end-first_burst_start\n",
    "                                df.loc[i, unit+' first burst start (s)'] = first_burst_start.rescale('s')\n",
    "                                df.loc[i, unit+' first burst end (s)'] = first_burst_end.rescale('s')\n",
    "                                first_burst_duration = df.loc[i, unit+' first burst duration (s)'] = first_burst_duration.rescale('s')\n",
    "                                first_burst_spike_count = df.loc[i, unit+' first burst spike count'] = st.time_slice(first_burst_start, first_burst_end).size\n",
    "                                first_burst_mean_freq = df.loc[i, unit+' first burst mean frequency (Hz)'] = ((first_burst_spike_count-1)/first_burst_duration).rescale('Hz')\n",
    "                                \n",
    "                                # find burst RAUC and mean voltage\n",
    "                                first_burst_rauc = df.loc[i, unit+' first burst RAUC (μV·s)'] = elephant.signal_processing.rauc(sig, baseline='mean', t_start=first_burst_start, t_stop=first_burst_end).rescale('uV*s')\n",
    "                                first_burst_mean_rect_voltage = df.loc[i, unit+' first burst mean rectified voltage (μV)'] = first_burst_rauc/first_burst_duration\n",
    "\n",
    "                                break # quit after finding first good burst\n",
    "\n",
    "                        for burst in reversed(bursts):\n",
    "                            if is_good_burst(burst):\n",
    "                                last_burst_start, last_burst_end = burst['Start (s)'], burst['End (s)']\n",
    "                                last_burst_duration = last_burst_end-last_burst_start\n",
    "                                df.loc[i, unit+' last burst start (s)'] = last_burst_start.rescale('s')\n",
    "                                df.loc[i, unit+' last burst end (s)'] = last_burst_end.rescale('s')\n",
    "                                last_burst_duration = df.loc[i, unit+' last burst duration (s)'] = last_burst_duration.rescale('s')\n",
    "                                last_burst_spike_count = df.loc[i, unit+' last burst spike count'] = st.time_slice(last_burst_start, last_burst_end).size\n",
    "                                last_burst_mean_freq = df.loc[i, unit+' last burst mean frequency (Hz)'] = ((last_burst_spike_count-1)/last_burst_duration).rescale('Hz')\n",
    "\n",
    "                                # find burst RAUC and mean voltage\n",
    "                                last_burst_rauc = df.loc[i, unit+' last burst RAUC (μV·s)'] = elephant.signal_processing.rauc(sig, baseline='mean', t_start=last_burst_start, t_stop=last_burst_end).rescale('uV*s')\n",
    "                                last_burst_mean_rect_voltage = df.loc[i, unit+' last burst mean rectified voltage (μV)'] = last_burst_rauc/last_burst_duration\n",
    "    \n",
    "                                break # quit after finding first (actually, last) good burst\n",
    "\n",
    "                                    \n",
    "                    ### SANITY CHECK: plot spikes\n",
    "                    plt.sca(axes[channel_names.index(channel)])\n",
    "                    marker = ['.', 'x'][j%2] # alternate markers between behaviors\n",
    "                    \n",
    "                    spike_amplitudes = np.array([sig[sig.time_index(t)] for t in st]) * pq.Quantity(sig.units)\n",
    "                    plt.scatter(st.times.rescale('s'), spike_amplitudes, marker=marker, c=unit_colors[unit])\n",
    "\n",
    "                    ### SANITY CHECK: plot burst windows\n",
    "                    discriminator = next((d for d in metadata['amplitude_discriminators'] if d['name'] == st.name), None)\n",
    "                    if discriminator is None:\n",
    "                        raise Exception(f'For data set \"{data_set_name}\", discriminator \"{st.name}\" could not be found')\n",
    "                    bottom = pq.Quantity(discriminator['amplitude'][0], discriminator['units']).rescale(sig.units)\n",
    "                    top = pq.Quantity(discriminator['amplitude'][1], discriminator['units']).rescale(sig.units)\n",
    "                    height = top-bottom\n",
    "                    for burst in bursts:\n",
    "                        left = burst['Start (s)']\n",
    "                        right = burst['End (s)']\n",
    "                        width = right-left\n",
    "                        linestyle = '-' if is_good_burst(burst) else '--'\n",
    "                        rect = patches.Rectangle((left, bottom), width, height, ls=linestyle, edgecolor=unit_colors[unit], fill=False)\n",
    "                        plt.gca().add_patch(rect)\n",
    "\n",
    "                    ### SANITY CHECK: plot markers for edges of bursts\n",
    "                    if top > 0:\n",
    "                        plt.plot([first_burst_start], [top], marker=7, markersize=5, color='k')\n",
    "                        plt.plot([last_burst_end], [top], marker=7, markersize=5, color='k')\n",
    "                    else:\n",
    "                        plt.plot([first_burst_start], [bottom], marker=6, markersize=5, color='k')\n",
    "                        plt.plot([last_burst_end], [bottom], marker=6, markersize=5, color='k')\n",
    "\n",
    "\n",
    "\n",
    "        ###\n",
    "        ### INSTANTANEOUS FIRING FREQUENCIES\n",
    "        ###\n",
    "        \n",
    "        smoothing_kernel = elephant.kernels.RectangularKernel(0.2*pq.s)\n",
    "        \n",
    "        for unit in ['B8a/b', 'B6/B9']:\n",
    "            st = df.loc[i, unit+' spike train']\n",
    "            if st is not None and st.size > 0:\n",
    "                channel = st.annotations['channels'][0]\n",
    "                plt.sca(axes[channel_names.index(channel)])\n",
    "\n",
    "                \n",
    "                \n",
    "#                 times = st.times.rescale('s')\n",
    "#                 times = np.concatenate([[behavior_start], times, [behavior_end]])*pq.s\n",
    "#                 iff = 1/elephant.statistics.isi(st)\n",
    "#                 iff = np.concatenate([[0], iff.rescale('1/s'), [0, 0]])/pq.s\n",
    "\n",
    "#                 # arbitrary rescaling to fit in plot\n",
    "#                 shift = -6 * np.abs(discriminator['amplitude']).max()\n",
    "#                 iff = iff.magnitude/5+shift\n",
    "\n",
    "#                 plt.plot(times, iff, drawstyle='steps-post', c=lighten_color(unit_colors[unit], amount=0.7), zorder=0)\n",
    "\n",
    "\n",
    "\n",
    "                sig = get_sig(blk, channel)\n",
    "                rate_model = elephant.statistics.instantaneous_rate(\n",
    "                    spiketrain=st,\n",
    "                    t_start=st.t_start,\n",
    "                    sampling_period=sig.sampling_period,\n",
    "                    kernel=smoothing_kernel,\n",
    "                )\n",
    "                times = rate_model.times.rescale('s')\n",
    "            \n",
    "                # arbitrary rescaling to fit in plot\n",
    "                shift = -6 * np.abs(discriminator['amplitude']).max()\n",
    "                iff = rate_model.magnitude/1+shift\n",
    "                plt.plot(times, iff, c=lighten_color(unit_colors[unit], amount=0.7), zorder=0)\n",
    "        \n",
    "        \n",
    "        \n",
    "        ###\n",
    "        ### TIMING DELAYS\n",
    "        ###\n",
    "        \n",
    "        i2_burst_start   = df.loc[i, 'I2 spikes first burst start (s)']*pq.s\n",
    "        i2_burst_end     = df.loc[i, 'I2 spikes last burst end (s)']*pq.s\n",
    "        b8_burst_start   = df.loc[i, 'B8a/b first burst start (s)']*pq.s\n",
    "        b8_burst_end     = df.loc[i, 'B8a/b last burst end (s)']*pq.s\n",
    "        b6b9_burst_start = df.loc[i, 'B6/B9 first burst start (s)']*pq.s\n",
    "        b6b9_burst_end   = df.loc[i, 'B6/B9 last burst end (s)']*pq.s\n",
    "        b3_burst_start   = df.loc[i, 'B3 first burst start (s)']*pq.s\n",
    "        b3_burst_end     = df.loc[i, 'B3 last burst end (s)']*pq.s\n",
    "        b38_burst_start  = df.loc[i, 'B38 first burst start (s)']*pq.s\n",
    "        b38_burst_end    = df.loc[i, 'B38 last burst end (s)']*pq.s\n",
    "        \n",
    "        df.loc[i, 'Next I2 spikes first burst start (s)'] = np.nan # will be set on next iteration\n",
    "        df.loc[i, 'Next I2 spikes last burst end (s)'] = np.nan # will be set on next iteration\n",
    "        if j != 0:\n",
    "            df.loc[df.index[j-1], 'Next I2 spikes first burst start (s)'] = i2_burst_start\n",
    "            df.loc[df.index[j-1], 'Next I2 spikes last burst end (s)'] = i2_burst_end\n",
    "        \n",
    "        # consider B3/B6/B9 bursting if either B3 or B6/B9 is bursting\n",
    "        b3b6b9_burst_start    = df.loc[i, 'B3/B6/B9 burst start (s)']    = finite_min(b6b9_burst_start, b3_burst_start)\n",
    "        b3b6b9_burst_end      = df.loc[i, 'B3/B6/B9 burst end (s)']      = finite_max(b6b9_burst_end,   b3_burst_end)\n",
    "        b3b6b9_burst_duration = df.loc[i, 'B3/B6/B9 burst duration (s)'] = b3b6b9_burst_end - b3b6b9_burst_start\n",
    "        \n",
    "        # consider bursting only if B8a/b and B3/B6/B9 are both bursting\n",
    "        b8_or_b3b6b9_burst_end = df.loc[i, 'B8a/b and B3/B6/B9 conjunction end (s)'] = \\\n",
    "                                           finite_min(b8_burst_end, b3b6b9_burst_end)\n",
    "        \n",
    "        # delays from neural to force\n",
    "        i2_force_rise_start_delay        = df.loc[i, 'Delay from I2 end to force rise start (s)'] = \\\n",
    "                                                     force_rise_start - i2_burst_end\n",
    "\n",
    "        b8_force_rise_start_delay        = df.loc[i, 'Delay from B8a/b start to force rise start (s)'] = \\\n",
    "                                                     force_rise_start - b8_burst_start\n",
    "        b8_force_plateau_start_delay     = df.loc[i, 'Delay from B8a/b start to force plateau start (s)'] = \\\n",
    "                                                     force_plateau_start - b8_burst_start\n",
    "        b8_force_plateau_end_delay       = df.loc[i, 'Delay from B8a/b end to force plateau end (s)'] = \\\n",
    "                                                     force_plateau_end - b8_burst_end\n",
    "        \n",
    "        b6b9_force_rise_start_delay      = df.loc[i, 'Delay from B6/B9 start to force rise start (s)'] = \\\n",
    "                                                     force_rise_start - b6b9_burst_start\n",
    "        b6b9_force_plateau_start_delay   = df.loc[i, 'Delay from B6/B9 start to force plateau start (s)'] = \\\n",
    "                                                     force_plateau_start - b6b9_burst_start\n",
    "        b6b9_force_plateau_end_delay     = df.loc[i, 'Delay from B6/B9 end to force plateau end (s)'] = \\\n",
    "                                                     force_plateau_end - b6b9_burst_end\n",
    "\n",
    "        b3b6b9_force_rise_start_delay    = df.loc[i, 'Delay from B3/B6/B9 start to force rise start (s)'] = \\\n",
    "                                                     force_rise_start - b3b6b9_burst_start\n",
    "        b3b6b9_force_plateau_start_delay = df.loc[i, 'Delay from B3/B6/B9 start to force plateau start (s)'] = \\\n",
    "                                                     force_plateau_start - b3b6b9_burst_start\n",
    "        b3b6b9_force_plateau_end_delay   = df.loc[i, 'Delay from B3/B6/B9 end to force plateau end (s)'] = \\\n",
    "                                                     force_plateau_end - b3b6b9_burst_end\n",
    "        \n",
    "        b3_force_plateau_start_delay     = df.loc[i, 'Delay from B3 start to force plateau start (s)'] = \\\n",
    "                                                     force_plateau_start - b3_burst_start\n",
    "        b3_force_plateau_end_delay       = df.loc[i, 'Delay from B3 end to force plateau end (s)'] = \\\n",
    "                                                     force_plateau_end - b3_burst_end\n",
    "        b8_or_b3b6b9_force_plateau_end_delay = \\\n",
    "                                           df.loc[i, 'Delay from either B8a/b or B3/B6/B9 end to force plateau end (s)'] = \\\n",
    "                                                     force_plateau_end - b8_or_b3b6b9_burst_end\n",
    "        \n",
    "        b38_force_shoulder_end_delay     = df.loc[i, 'Delay from B38 end to force shoulder end (s)'] = \\\n",
    "                                                     force_shoulder_end - b38_burst_end\n",
    "\n",
    "        \n",
    "        \n",
    "        ###\n",
    "        ### B8 ACTIVITY BEFORE B3/B6/B9\n",
    "        ###\n",
    "        \n",
    "        st = df.loc[i, 'B8a/b spike train']\n",
    "        b8_preb3b6b9_burst_duration    = df.loc[i, 'B8a/b pre-B3/B6/B9 burst duration (s)'] = \\\n",
    "                                                   b3b6b9_burst_start - b8_burst_start\n",
    "        b8_preb3b6b9_burst_spike_count = df.loc[i, 'B8a/b pre-B3/B6/B9 burst spike count'] = \\\n",
    "                                                   st.time_slice(b8_burst_start, b3b6b9_burst_start).size\n",
    "        b8_preb3b6b9_burst_mean_freq   = df.loc[i, 'B8a/b pre-B3/B6/B9 burst mean frequency (Hz)'] = \\\n",
    "                                                   ((b8_preb3b6b9_burst_spike_count-1)/b8_preb3b6b9_burst_duration).rescale('Hz')\n",
    "        \n",
    "        # get the neural channel\n",
    "        channel = st.annotations['channels'][0]\n",
    "        sig = get_sig(blk, channel)\n",
    "        \n",
    "        # get the signal for the behavior with 5 seconds cushion before and after (for better baseline estimation)\n",
    "        sig = sig.time_slice(behavior_start - 5*pq.s, behavior_end + 5*pq.s)\n",
    "        sig = sig.rescale('uV')\n",
    "\n",
    "        # find RAUC and mean voltage for B8a/b before B3/B6/B9 start in each behavior\n",
    "        if np.isfinite(b8_burst_start) and np.isfinite(b3b6b9_burst_start):\n",
    "            b8_preb3b6b9_rauc = df.loc[i, 'B8a/b pre-B3/B6/B9 burst RAUC (μV·s)'] = elephant.signal_processing.rauc(sig, baseline='mean', t_start=b8_burst_start, t_stop=b3b6b9_burst_start).rescale('uV*s')\n",
    "            b8_preb3b6b9_mean_rect_voltage = df.loc[i, 'B8a/b pre-B3/B6/B9 burst mean rectified voltage (μV)'] = b8_preb3b6b9_rauc/b8_preb3b6b9_burst_duration\n",
    "        else:\n",
    "            print(f'Missing either B8a/b burst and/or B3/B6/B9 burst in data set \"{data_set_name}\" for swallow spanning times ({behavior_start}, {behavior_end})')\n",
    "\n",
    "        # get the peak smoothed frequency\n",
    "        rate_model = elephant.statistics.instantaneous_rate(\n",
    "            spiketrain=st,\n",
    "            t_start=st.t_start,\n",
    "            sampling_period=sig.sampling_period,\n",
    "            kernel=smoothing_kernel,\n",
    "        )\n",
    "        b8_preb3b6b9_burst_peak_smoothed_freq = df.loc[i, 'B8a/b pre-B3/B6/B9 burst peak smoothed frequency (Hz)'] = \\\n",
    "                                                          rate_model.time_slice(b8_burst_start, b3b6b9_burst_start).max().rescale('Hz')\n",
    "\n",
    "            \n",
    "        # get force during rise and plateau\n",
    "        sig = get_sig(blk, 'Force')\n",
    "        sig = sig.time_slice(force_rise_start, force_plateau_end)\n",
    "        sig = sig.rescale('mN')\n",
    "        \n",
    "        # get force at end of B8-only burst, offset by delay\n",
    "        force_b8_only_rise_end = df.loc[i, 'Force delayed B8-only rise end (s)'] = force_rise_start + b8_preb3b6b9_burst_duration\n",
    "        force_b8_only_rise_height = df.loc[i, 'Force at delayed B8-only rise end (mN)'] = sig[sig.time_index(force_b8_only_rise_end)][0]\n",
    "\n",
    "        # find average slope during initial rising phase (before B3/B6/B9 begin, offset by delay)\n",
    "        force_initial_increase = df.loc[i, 'Force initial increase (mN)'] = (force_b8_only_rise_height-force_baseline).rescale('mN')\n",
    "        force_initial_slope = df.loc[i, 'Force initial slope (mN/s)'] = (force_initial_increase/b8_preb3b6b9_burst_duration).rescale('mN/s')\n",
    "        \n",
    "        \n",
    "        \n",
    "        ### SANITY CHECK: plot important times across all subplots, with delays set by I2 end and force min\n",
    "        if j == 0:\n",
    "            # use first swallow's delay from peak protraction to force start for all units in all swallows\n",
    "            muscle_delay = i2_force_rise_start_delay\n",
    "#             muscle_delay = b8_force_rise_start_delay\n",
    "            axes[-1].text(\n",
    "                force_rise_start, 1.05, f\"{muscle_delay.rescale('ms'):.0f} ms delay\",\n",
    "                horizontalalignment='right', verticalalignment='center', transform=axes[-1].get_xaxis_transform(),\n",
    "                fontsize=8)\n",
    "        plot_vertical_lines_with_delay(axes, force_rise_start,    muscle_delay, force_baseline,            force_colors['dip'])\n",
    "        plot_vertical_lines_with_delay(axes, force_plateau_start, muscle_delay, force_plateau_start_value, force_colors['plateau'])\n",
    "        plot_vertical_lines_with_delay(axes, force_plateau_end,   muscle_delay, force_plateau_end_value,   force_colors['plateau'])\n",
    "        plot_vertical_lines_with_delay(axes, force_drop_end,      muscle_delay, force_drop_end_value,      force_colors['drop'])\n",
    "        if np.isfinite(force_shoulder_end_value):\n",
    "            plot_vertical_lines_with_delay(axes, force_shoulder_end, muscle_delay, force_shoulder_end_value, force_colors['shoulder'])\n",
    "\n",
    "            \n",
    "    \n",
    "    # perform the following after having gone through all behaviors once\n",
    "    for j, i in enumerate(df.index):\n",
    "        \n",
    "        ###\n",
    "        ### NORMALIZED TIMES\n",
    "        ###\n",
    "        \n",
    "        normalization_fixed_times = df.loc[i, 'Normalization fixed times (s)']\n",
    "        \n",
    "        i2_burst_start   = df.loc[i, 'I2 spikes first burst start (s)']*pq.s\n",
    "        i2_burst_end     = df.loc[i, 'I2 spikes last burst end (s)']*pq.s\n",
    "        b8_burst_start   = df.loc[i, 'B8a/b first burst start (s)']*pq.s\n",
    "        b8_burst_end     = df.loc[i, 'B8a/b last burst end (s)']*pq.s\n",
    "        b6b9_burst_start = df.loc[i, 'B6/B9 first burst start (s)']*pq.s\n",
    "        b6b9_burst_end   = df.loc[i, 'B6/B9 last burst end (s)']*pq.s\n",
    "        b3_burst_start   = df.loc[i, 'B3 first burst start (s)']*pq.s\n",
    "        b3_burst_end     = df.loc[i, 'B3 last burst end (s)']*pq.s\n",
    "        b38_burst_start  = df.loc[i, 'B38 first burst start (s)']*pq.s\n",
    "        b38_burst_end    = df.loc[i, 'B38 last burst end (s)']*pq.s\n",
    "        next_i2_burst_start = df.loc[i, 'Next I2 spikes first burst start (s)']*pq.s\n",
    "        next_i2_burst_end   = df.loc[i, 'Next I2 spikes last burst end (s)']*pq.s\n",
    "        \n",
    "        if j == 0:\n",
    "            # use first swallow's delay from peak protraction to force start for all units in all swallows\n",
    "            muscle_delay = df.loc[i, 'Delay from I2 end to force rise start (s)']*pq.s\n",
    "#             muscle_delay = df.loc[i, 'Delay from B8a/b start to force rise start (s)']*pq.s\n",
    "\n",
    "        i2_burst_start_normalized      = df.loc[i, 'I2 first burst start (delayed normalized)']      = normalize_time(normalization_fixed_times,\n",
    "                                                   i2_burst_start      + muscle_delay)\n",
    "        i2_burst_end_normalized        = df.loc[i, 'I2 last burst end (delayed normalized)']         = normalize_time(normalization_fixed_times,\n",
    "                                                   i2_burst_end        + muscle_delay)\n",
    "        \n",
    "        b8_burst_start_normalized      = df.loc[i, 'B8a/b first burst start (delayed normalized)']   = normalize_time(normalization_fixed_times,\n",
    "                                                   b8_burst_start      + muscle_delay)\n",
    "        b8_burst_end_normalized        = df.loc[i, 'B8a/b last burst end (delayed normalized)']      = normalize_time(normalization_fixed_times,\n",
    "                                                   b8_burst_end        + muscle_delay)\n",
    "        \n",
    "        b6b9_burst_start_normalized    = df.loc[i, 'B6/B9 first burst start (delayed normalized)']   = normalize_time(normalization_fixed_times,\n",
    "                                                   b6b9_burst_start    + muscle_delay)\n",
    "        b6b9_burst_end_normalized      = df.loc[i, 'B6/B9 last burst end (delayed normalized)']      = normalize_time(normalization_fixed_times,\n",
    "                                                   b6b9_burst_end      + muscle_delay)\n",
    "        \n",
    "        b3_burst_start_normalized      = df.loc[i, 'B3 first burst start (delayed normalized)']      = normalize_time(normalization_fixed_times,\n",
    "                                                   b3_burst_start      + muscle_delay)\n",
    "        b3_burst_end_normalized        = df.loc[i, 'B3 last burst end (delayed normalized)']         = normalize_time(normalization_fixed_times,\n",
    "                                                   b3_burst_end        + muscle_delay)\n",
    "\n",
    "        b38_burst_start_normalized     = df.loc[i, 'B38 first burst start (delayed normalized)']     = normalize_time(normalization_fixed_times,\n",
    "                                                   b38_burst_start     + muscle_delay)\n",
    "        b38_burst_end_normalized       = df.loc[i, 'B38 last burst end (delayed normalized)']        = normalize_time(normalization_fixed_times,\n",
    "                                                   b38_burst_end       + muscle_delay)\n",
    "        \n",
    "        next_i2_burst_start_normalized = df.loc[i, 'Next I2 first burst start (delayed normalized)'] = normalize_time(normalization_fixed_times,\n",
    "                                                   next_i2_burst_start + muscle_delay)\n",
    "        \n",
    "        next_i2_burst_end_normalized   = df.loc[i, 'Next I2 last burst end (delayed normalized)']    = normalize_time(normalization_fixed_times,\n",
    "                                                   next_i2_burst_end + muscle_delay)\n",
    "\n",
    "\n",
    "\n",
    "        # EXPERIMENTAL: NORMALIZATION WITHOUT DELAY\n",
    "\n",
    "        i2_burst_start_normalized      = df.loc[i, 'I2 first burst start (normalized)']      = normalize_time(normalization_fixed_times,\n",
    "                                                   i2_burst_start)\n",
    "        i2_burst_end_normalized        = df.loc[i, 'I2 last burst end (normalized)']         = normalize_time(normalization_fixed_times,\n",
    "                                                   i2_burst_end)\n",
    "        \n",
    "        b8_burst_start_normalized      = df.loc[i, 'B8a/b first burst start (normalized)']   = normalize_time(normalization_fixed_times,\n",
    "                                                   b8_burst_start)\n",
    "        b8_burst_end_normalized        = df.loc[i, 'B8a/b last burst end (normalized)']      = normalize_time(normalization_fixed_times,\n",
    "                                                   b8_burst_end)\n",
    "        \n",
    "        b6b9_burst_start_normalized    = df.loc[i, 'B6/B9 first burst start (normalized)']   = normalize_time(normalization_fixed_times,\n",
    "                                                   b6b9_burst_start)\n",
    "        b6b9_burst_end_normalized      = df.loc[i, 'B6/B9 last burst end (normalized)']      = normalize_time(normalization_fixed_times,\n",
    "                                                   b6b9_burst_end)\n",
    "        \n",
    "        b3_burst_start_normalized      = df.loc[i, 'B3 first burst start (normalized)']      = normalize_time(normalization_fixed_times,\n",
    "                                                   b3_burst_start)\n",
    "        b3_burst_end_normalized        = df.loc[i, 'B3 last burst end (normalized)']         = normalize_time(normalization_fixed_times,\n",
    "                                                   b3_burst_end)\n",
    "\n",
    "        b38_burst_start_normalized     = df.loc[i, 'B38 first burst start (normalized)']     = normalize_time(normalization_fixed_times,\n",
    "                                                   b38_burst_start)\n",
    "        b38_burst_end_normalized       = df.loc[i, 'B38 last burst end (normalized)']        = normalize_time(normalization_fixed_times,\n",
    "                                                   b38_burst_end)\n",
    "        \n",
    "        next_i2_burst_start_normalized = df.loc[i, 'Next I2 first burst start (normalized)'] = normalize_time(normalization_fixed_times,\n",
    "                                                   next_i2_burst_start)\n",
    "        \n",
    "        next_i2_burst_end_normalized   = df.loc[i, 'Next I2 last burst end (normalized)']    = normalize_time(normalization_fixed_times,\n",
    "                                                   next_i2_burst_end)\n",
    "\n",
    "        \n",
    "        \n",
    "    ###\n",
    "    ### FINISH\n",
    "    ###\n",
    "    \n",
    "    # optimize plot margins\n",
    "    plt.subplots_adjust(\n",
    "        left   = 0.1,\n",
    "        right  = 0.99,\n",
    "        top    = 0.96,\n",
    "        bottom = 0.06,\n",
    "        hspace = 0.15,\n",
    "    )\n",
    "    \n",
    "    # export figure\n",
    "    export_dir2 = os.path.join(export_dir, 'sanity-checks')\n",
    "    if not os.path.exists(export_dir2):\n",
    "        os.mkdir(export_dir2)\n",
    "    plt.gcf().savefig(os.path.join(export_dir2, f'{animal} {food} {bout_index}.png'), dpi=300)\n",
    "    \n",
    "    # index the table on 4 variables so that this dataframe can later be merged with others\n",
    "    df['Animal'] = animal\n",
    "    df['Food'] = food\n",
    "    df['Bout_index'] = bout_index\n",
    "    df = df.reset_index().set_index(['Animal', 'Food', 'Bout_index', 'Behavior_index'])\n",
    "    \n",
    "    df_list += [df]\n",
    "    \n",
    "df_all = pd.concat(df_list, sort=False).sort_index()\n",
    "\n",
    "# move exemplary behaviors to separate dataframes\n",
    "df_exemplary_swallow = df_all.loc[exemplary_swallow].copy()\n",
    "df_exemplary_bout = df_all.loc[exemplary_bout].copy()\n",
    "df_all = df_all.drop(exemplary_swallow)\n",
    "df_all = df_all.drop(exemplary_bout)\n",
    "\n",
    "end = datetime.datetime.now()\n",
    "print('elapsed time:', end-start)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Special dataframe used for Fig 2C only"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "feeding_bouts_multiple_foods = {\n",
    "    # (animal, food, bout_index): (data_set_name, time_window, epoch_types_to_keep)\n",
    "        \n",
    "    ('JG12', 'Regular nori', 0): ('IN VIVO / JG12 / 2019-05-10 / 002', [ 147,  165], ['Swallow (regular 5-cm nori strip)']),\n",
    "    ('JG12', 'Regular nori', 1): ('IN VIVO / JG12 / 2019-05-10 / 002', [ 229,  245], ['Swallow (regular 5-cm nori strip)']),\n",
    "    ('JG12', 'Regular nori', 2): ('IN VIVO / JG12 / 2019-05-10 / 002', [ 277,  291], ['Swallow (regular 5-cm nori strip)']),\n",
    "\n",
    "    ('JG12', 'Tape nori',  103): ('IN VIVO / JG12 / 2019-05-10 / 002', [2890, 3080], ['Swallow (tape nori)']),\n",
    "}\n",
    "\n",
    "# filter epochs for each feeding condition and perform calculations\n",
    "df_list = []\n",
    "last_data_set_name = None\n",
    "for (animal, food, bout_index), (data_set_name, time_window, epoch_types_to_keep) in feeding_bouts_multiple_foods.items():\n",
    "    \n",
    "    metadata.select(data_set_name)\n",
    "    if data_set_name is last_data_set_name:\n",
    "        # skip reloading the data if it's already in memory\n",
    "        pass\n",
    "    else:\n",
    "        blk = neurotic.load_dataset(metadata, lazy=True)\n",
    "    last_data_set_name = data_set_name\n",
    "    \n",
    "    # construct a query for locating behaviors\n",
    "    behavior_query = f'(Type in {epoch_types_to_keep}) & ({time_window[0]} <= Start) & (End <= {time_window[1]})'\n",
    "    \n",
    "    # construct queries for locating epochs associated with each behavior\n",
    "    # - each query should match at most one epoch\n",
    "    # - dictionary keys are used as prefixes for the names of new columns\n",
    "    subepoch_queries = {}\n",
    "    \n",
    "    # construct a table in which each row is a behavior and subepoch data\n",
    "    # is added as columns, e.g. df['Force start (s)']\n",
    "    df = BehaviorsDataFrame(blk.segments[0].epochs, behavior_query, subepoch_queries)\n",
    "\n",
    "    # calculate interbehavior interval assuming all behaviors are from a single contiguous sequence\n",
    "    df['Interval after (s)'] = np.nan\n",
    "    previous_i = None\n",
    "    for i in df.index:\n",
    "        if previous_i is not None:\n",
    "            df.loc[previous_i, 'Interval after (s)']  = df.loc[i, 'Start (s)'] - df.loc[previous_i, 'End (s)']\n",
    "        previous_i = i\n",
    "\n",
    "    # renumber behaviors assuming all behaviors are from a single contiguous sequence\n",
    "    df = df.sort_values('Start (s)').reset_index(drop=True).rename_axis('Behavior_index')\n",
    "    \n",
    "    # index the table on 4 variables\n",
    "    df['Animal'] = animal\n",
    "    df['Food'] = food\n",
    "    df['Bout_index'] = bout_index\n",
    "    df = df.reset_index().set_index(['Animal', 'Food', 'Bout_index', 'Behavior_index'])\n",
    "    \n",
    "    df_list += [df]\n",
    "    \n",
    "df_durations_intervals = pd.concat(df_list, sort=False).sort_index()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "source": [
    "## Plotting Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "outputs": [],
   "source": [
    "def scatter2d(ax, data_subsets, xlabel, xlim, ylabel, ylim, trend=False, trend_separately=False, tooltips=False, padding=0.05):\n",
    "    \n",
    "    for j, (label, query) in enumerate(data_subsets.items()):\n",
    "        if query is not None:\n",
    "            df = df_all.query(query)\n",
    "            ax.scatter(df[xlabel], df[ylabel],\n",
    "                       label=label, marker=markers[j], c=colors[j], clip_on=False)\n",
    "            \n",
    "    all_points = df_all.query(query_union(data_subsets.values()))[[xlabel, ylabel]].dropna()\n",
    "    \n",
    "    if len(all_points) > 0:\n",
    "\n",
    "        xrange = np.ptp(all_points.iloc[:, 0])\n",
    "        xmin = min(all_points.iloc[:, 0]) - xrange * padding\n",
    "        xmax = max(all_points.iloc[:, 0]) + xrange * padding\n",
    "        if xlim is None:\n",
    "            xlim = [xmin, xmax]\n",
    "        if xlim[0] is None:\n",
    "            xlim[0] = xmin\n",
    "        if xlim[1] is None:\n",
    "            xlim[1] = xmax\n",
    "\n",
    "        yrange = np.ptp(all_points.iloc[:, 1])\n",
    "        ymin = min(all_points.iloc[:, 1]) - yrange * padding\n",
    "        ymax = max(all_points.iloc[:, 1]) + yrange * padding\n",
    "        if ylim is None:\n",
    "            ylim = [ymin, ymax]\n",
    "        if ylim[0] is None:\n",
    "            ylim[0] = ymin\n",
    "        if ylim[1] is None:\n",
    "            ylim[1] = ymax\n",
    "    \n",
    "    if trend_separately:\n",
    "        for j, (label, query) in enumerate(data_subsets.items()):\n",
    "            if query is not None:\n",
    "                df = df_all.query(query)[[xlabel, ylabel]].dropna()\n",
    "                model = sm.OLS(df.iloc[:,1], sm.add_constant(df.iloc[:,0])).fit()\n",
    "                model_stats = 'R$^2$ = {:.2f}, p = {:.3f}, n = {}'.format(model.rsquared, model.pvalues[1], len(df))\n",
    "                print(label+':', model_stats)\n",
    "                model_x = np.linspace(xlim[0], xlim[1], 100)\n",
    "                model_y = model.params[0] + model.params[1] * model_x\n",
    "                ax.plot(model_x, model_y, color=colors[j])#, label=model_stats)\n",
    "                \n",
    "    if trend:\n",
    "        model = sm.OLS(all_points.iloc[:,1], sm.add_constant(all_points.iloc[:,0])).fit()\n",
    "        model_stats = 'R$^2$ = {:.2f}, p = {:.3f}, n = {}'.format(model.rsquared, model.pvalues[1], len(all_points))\n",
    "        print('All points:', model_stats)\n",
    "        model_x = np.linspace(xlim[0], xlim[1], 100)\n",
    "        model_y = model.params[0] + model.params[1] * model_x\n",
    "        ax.plot(model_x, model_y, color='gray')#, label=model_stats)\n",
    "    \n",
    "    if tooltips:\n",
    "        # create a transparent layer containing all points for detecting mouse events\n",
    "        sc = ax.scatter(all_points.iloc[:, 0], all_points.iloc[:, 1], label=None,\n",
    "                        alpha=0, # transparent points\n",
    "                        s=0.001, # small radius of tooltip activation\n",
    "                       )\n",
    "        \n",
    "        # initialize a hidden empty tooltip\n",
    "        annot = ax.annotate(\n",
    "            '', xy=(0, 0),                              # initialize empty at origin\n",
    "            xytext=(0, 15), textcoords='offset points', # position text above point\n",
    "            color='k', size=10, ha='center',            # small black centered text\n",
    "            bbox=dict(fc='w', lw=0, alpha=0.6),         # transparent white background\n",
    "            arrowprops=dict(shrink=0, headlength=7, headwidth=7, width=0, lw=0, color='k'), # small black arrow\n",
    "        )\n",
    "        annot.set_visible(False)\n",
    "        \n",
    "        # prepare tooltip contents\n",
    "        tooltip_text = [' '.join([str(x) for x in index]) for index in list(all_points.index)]\n",
    "        \n",
    "        # bind the animation of tooltips to a hover event\n",
    "        def hover(event):\n",
    "            if event.inaxes == ax:\n",
    "                cont, ind = sc.contains(event)\n",
    "                if cont:\n",
    "                    point_index = ind['ind'][0]\n",
    "                    pos = sc.get_offsets()[point_index]\n",
    "                    annot.xy = pos\n",
    "                    annot.set_text(tooltip_text[point_index])\n",
    "                    annot.set_visible(True)\n",
    "                    ax.figure.canvas.draw_idle()\n",
    "                else:\n",
    "                    if annot.get_visible():\n",
    "                        annot.set_visible(False)\n",
    "                        ax.figure.canvas.draw_idle()\n",
    "        ax.figure.canvas.mpl_connect('motion_notify_event', hover)\n",
    "        \n",
    "    ax.set_xlabel(xlabel)\n",
    "    ax.set_xlim(xlim)\n",
    "    ax.set_ylabel(ylabel)#.replace('rectified ',''))\n",
    "    ax.set_ylim(ylim)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from matplotlib.offsetbox import AnchoredOffsetbox\n",
    "class AnchoredScaleBar(AnchoredOffsetbox):\n",
    "    def __init__(self, transform, sizex=0, sizey=0, labelx=None, labely=None, loc=4,\n",
    "                 pad=0.1, borderpad=0.1, sep=2, prop=None, barcolor=\"black\", barwidth=None, \n",
    "                 **kwargs):\n",
    "        \"\"\"\n",
    "        Draw a horizontal and/or vertical  bar with the size in data coordinate\n",
    "        of the give axes. A label will be drawn underneath (center-aligned).\n",
    "        - transform : the coordinate frame (typically axes.transData)\n",
    "        - sizex,sizey : width of x,y bar, in data units. 0 to omit\n",
    "        - labelx,labely : labels for x,y bars; None to omit\n",
    "        - loc : position in containing axes\n",
    "        - pad, borderpad : padding, in fraction of the legend font size (or prop)\n",
    "        - sep : separation between labels and bars in points.\n",
    "        - **kwargs : additional arguments passed to base class constructor\n",
    "        \"\"\"\n",
    "        from matplotlib.patches import Rectangle\n",
    "        from matplotlib.offsetbox import AuxTransformBox, VPacker, HPacker, TextArea, DrawingArea\n",
    "        bars = AuxTransformBox(transform)\n",
    "        if sizex:\n",
    "#             bars.add_artist(Rectangle((0,0), sizex, 0, ec=barcolor, lw=barwidth, fc=\"none\"))\n",
    "            bars.add_artist(Rectangle((0,0), -sizex, 0, ec=barcolor, lw=barwidth, fc=\"none\"))\n",
    "        if sizey:\n",
    "            bars.add_artist(Rectangle((0,0), 0, sizey, ec=barcolor, lw=barwidth, fc=\"none\"))\n",
    "\n",
    "        if sizex and labelx:\n",
    "            self.xlabel = TextArea(labelx, minimumdescent=False)\n",
    "            bars = VPacker(children=[bars, self.xlabel], align=\"center\", pad=0, sep=sep)\n",
    "        if sizey and labely:\n",
    "            self.ylabel = TextArea(labely)\n",
    "#             bars = HPacker(children=[self.ylabel, bars], align=\"center\", pad=0, sep=sep)\n",
    "            bars = HPacker(children=[bars, self.ylabel], align=\"center\", pad=0, sep=sep)\n",
    "\n",
    "        AnchoredOffsetbox.__init__(self, loc, pad=pad, borderpad=borderpad,\n",
    "                                   child=bars, prop=prop, frameon=False, **kwargs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def prettyplot_with_scalebars(\n",
    "    blk,\n",
    "    t_start,\n",
    "    t_stop,\n",
    "    plots,\n",
    "    \n",
    "    outfile_basename=None, # base name of output files\n",
    "    export_only=False,     # if True, will not render in notebook\n",
    "    formats=['pdf', 'svg', 'png'], # extensions of output files\n",
    "    dpi=300,               # resolution (applicable only for PNG)\n",
    "    \n",
    "    figsize=(14, 7),       # figure size in inches\n",
    "    linewidth=1,           # thickness of lines in points\n",
    "    layout_settings=None,  # positioning of plot edges and the space between plots\n",
    "    \n",
    "    x_scalebar=1*pq.s,     # size of the time scale bar in seconds\n",
    "    ylabel_padding=10,     # space between trace labels and plots\n",
    "    scalebar_padding=1,    # space between scale bars and plots\n",
    "    scalebar_sep=5,        # space between scale bars and scale labels\n",
    "    barwidth=2,            # thickness of scale bars\n",
    "):\n",
    "    \n",
    "    if export_only:\n",
    "        plt.ioff()\n",
    "        \n",
    "    fig, axes = plt.subplots(len(plots), 1, sharex=True, figsize=figsize, squeeze=False)\n",
    "    axes = axes.flatten()\n",
    "\n",
    "    for i, p in enumerate(plots):\n",
    "\n",
    "        # get the subplot axes handle\n",
    "        ax = axes[i]\n",
    "\n",
    "        # select and rescale a channel for the subplot\n",
    "        sig = next((sig for sig in blk.segments[0].analogsignals if sig.name == p['channel']), None)\n",
    "        assert sig is not None, f\"Signal with name {p['channel']} not found\"\n",
    "        sig = sig.time_slice(t_start, t_stop)\n",
    "        sig = sig.rescale(p['units'])\n",
    "\n",
    "        # downsample the data\n",
    "        sig_downsampled = DownsampleNeoSignal(sig, p.get('decimation_factor', 1))\n",
    "\n",
    "        # specify the x- and y-data for the subplot\n",
    "        ax.plot(\n",
    "            sig_downsampled.times,\n",
    "            sig_downsampled.as_quantity(),\n",
    "            linewidth=linewidth,\n",
    "            color=p.get('color', 'k'),\n",
    "        )\n",
    "        \n",
    "        # hide the box around the subplot\n",
    "        ax.set_frame_on(False)\n",
    "\n",
    "        # specify the y-axis label\n",
    "        ylabel = p.get('ylabel', sig.name)\n",
    "        if ylabel is not None:\n",
    "            ax.set_ylabel(ylabel, rotation='horizontal', ha='right', va='center', labelpad=ylabel_padding)\n",
    "\n",
    "        # specify the plot range\n",
    "        ax.set_xlim([t_start, t_stop])\n",
    "        ax.set_ylim(p['ylim'])\n",
    "\n",
    "        # disable tick marks\n",
    "        ax.tick_params(\n",
    "            bottom=False,\n",
    "            left=False,\n",
    "            labelbottom=False,\n",
    "            labelleft=False)\n",
    "\n",
    "        # add y-axis scale bar\n",
    "        if p['scalebar'] is not None:\n",
    "            ax.add_artist(AnchoredScaleBar(\n",
    "                ax.transData,\n",
    "                sizey=p['scalebar'],\n",
    "                labely=f'{p[\"scalebar\"]} {sig.units.dimensionality.string}',\n",
    "\n",
    "                loc='center left',\n",
    "                bbox_to_anchor=(1, 0.5),\n",
    "                bbox_transform=ax.transAxes,\n",
    "\n",
    "                pad=0,\n",
    "                borderpad=scalebar_padding,\n",
    "                sep=scalebar_sep,\n",
    "                barwidth=barwidth,\n",
    "            ))\n",
    "        \n",
    "    # add time scale bar below final plot\n",
    "    if x_scalebar is not None:\n",
    "        axes[-1].add_artist(AnchoredScaleBar(\n",
    "            axes[-1].transData,\n",
    "            sizex=x_scalebar.rescale(sig.times.units).magnitude,\n",
    "            labelx=f'{x_scalebar.magnitude:g} {x_scalebar.units.dimensionality.string}',\n",
    "\n",
    "            loc='upper right',\n",
    "            bbox_to_anchor=(1, 0),\n",
    "            bbox_transform=axes[-1].transAxes,\n",
    "\n",
    "            pad=0,\n",
    "            borderpad=scalebar_padding,\n",
    "            sep=scalebar_sep,\n",
    "            barwidth=barwidth,\n",
    "        ))\n",
    "\n",
    "    # adjust the white space around and between the subplots\n",
    "    if layout_settings is None:\n",
    "        fig.tight_layout(h_pad=0, w_pad=0, pad=0)\n",
    "    else:\n",
    "        plt.subplots_adjust(**layout_settings)\n",
    "\n",
    "    if outfile_basename is not None:\n",
    "        # specify file metadata (applicable only for PDF)\n",
    "        metadata = dict(\n",
    "            Subject = 'Data file: '  + blk.file_origin + '\\n' +\n",
    "                      'Start time: ' + str(t_start)    + '\\n' +\n",
    "                      'End time: '   + str(t_stop),\n",
    "        )\n",
    "\n",
    "        # write the figure to files\n",
    "        for ext in formats:\n",
    "            fig.savefig(outfile_basename+'.'+ext, metadata=metadata, dpi=dpi)\n",
    "\n",
    "    if export_only:\n",
    "        plt.ion()\n",
    "    \n",
    "    return fig, axes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Figures"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## [FIGURE 1] Biomechanics schematic ❌"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "-"
    }
   },
   "source": [
    "Schematic illustration of biomechanics of _Aplysia_ swallowing\n",
    "- Synthesis of Cullins et al. 2015a, Fig. 6, and McManus et al. 2014, Fig. 10.\n",
    "- Show grasper protraction/retraction, grasper closing/opening, anterior jaws closing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "-"
    }
   },
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## [FIGURE 2] Motor pattern and force examples"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "### Fig 2A ✅"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "-"
    }
   },
   "source": [
    "Short sequence of swallows on regular nori, 4 channels\n",
    "\n",
    "- TODO: Annotations? (e.g., \"Bite/swallow\", \"Swallow\", \"Swallow\", \"Bite\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The plot output by this code is much longer than it will be in the final figure and must be cropped manually. It is rendered with the same amount of time showing as Fig 2B so that time scales are identical."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "start = datetime.datetime.now()\n",
    "\n",
    "data_set_name = 'IN VIVO / JG12 / 2019-05-10 / 002'\n",
    "t_start, t_stop = [228.8, 392.8] * pq.s # t=278, twidth=164, first few are regular nori strip swallows\n",
    "plots = [\n",
    "    {'channel': 'I2',       'units': 'uV', 'ylim': [ -60,  60], 'scalebar': 50}, #, 'decimation_factor': 400},\n",
    "    {'channel': 'RN',       'units': 'uV', 'ylim': [ -25,  25], 'scalebar': 25}, #, 'decimation_factor': 400},\n",
    "    {'channel': 'BN2',      'units': 'uV', 'ylim': [ -45,  45], 'scalebar': 50}, #, 'decimation_factor': 400},\n",
    "    {'channel': 'BN3-DIST', 'units': 'uV', 'ylim': [ -60,  60], 'scalebar': 50, 'ylabel': 'BN3'}, #, 'decimation_factor': 400},\n",
    "    {'channel': 'Force',    'units': 'mN', 'ylim': [ -50, 450], 'scalebar': 300, 'decimation_factor': 100},\n",
    "]\n",
    "channel_names = [p['channel'] for p in plots]\n",
    "channel_units = [p['units'] for p in plots]\n",
    "\n",
    "kwargs = dict(\n",
    "    formats = ['png'],\n",
    "    dpi = 600,\n",
    "    figsize = (14, 5),\n",
    "    linewidth = 0.5,\n",
    "    x_scalebar = 10*pq.s,\n",
    ")\n",
    "\n",
    "# load the data\n",
    "metadata = neurotic.MetadataSelector('../../data/metadata.yml')\n",
    "metadata.select(data_set_name)\n",
    "blk = neurotic.load_dataset(metadata) # not lazy so that I2 filter is applied\n",
    "\n",
    "# plot the data\n",
    "fig, axes = prettyplot_with_scalebars(blk, t_start, t_stop, plots, **kwargs)\n",
    "\n",
    "fig.savefig(os.path.join(export_dir, 'figure-2A.png'), dpi=600)\n",
    "\n",
    "end = datetime.datetime.now()\n",
    "print('render time:', end-start)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "-"
    }
   },
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "### Fig 2B ✅"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "-"
    }
   },
   "source": [
    "Long sequence of swallows on tape nori exemplar\n",
    "\n",
    "- TODO: Mark which swallows are used in later analysis?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "start = datetime.datetime.now()\n",
    "\n",
    "data_set_name = 'IN VIVO / JG12 / 2019-05-10 / 002'\n",
    "t_start, t_stop = [2879, 3043] * pq.s # t=2928.2, twidth=164, 19 tape nori swallows\n",
    "plots = [\n",
    "    {'channel': 'I2',       'units': 'uV', 'ylim': [ -60,  60], 'scalebar': 50}, #, 'decimation_factor': 400},\n",
    "    {'channel': 'RN',       'units': 'uV', 'ylim': [ -25,  25], 'scalebar': 25}, #, 'decimation_factor': 400},\n",
    "    {'channel': 'BN2',      'units': 'uV', 'ylim': [ -45,  45], 'scalebar': 50}, #, 'decimation_factor': 400},\n",
    "    {'channel': 'BN3-DIST', 'units': 'uV', 'ylim': [ -60,  60], 'scalebar': 50, 'ylabel': 'BN3'}, #, 'decimation_factor': 400},\n",
    "    {'channel': 'Force',    'units': 'mN', 'ylim': [ -50, 450], 'scalebar': 300, 'decimation_factor': 100},\n",
    "]\n",
    "channel_names = [p['channel'] for p in plots]\n",
    "channel_units = [p['units'] for p in plots]\n",
    "\n",
    "kwargs = dict(\n",
    "    formats = ['png'],\n",
    "    dpi = 600,\n",
    "    figsize = (14, 5),\n",
    "    linewidth = 0.5,\n",
    "    x_scalebar = 10*pq.s,\n",
    ")\n",
    "\n",
    "# load the data\n",
    "metadata = neurotic.MetadataSelector('../../data/metadata.yml')\n",
    "metadata.select(data_set_name)\n",
    "blk = neurotic.load_dataset(metadata) # not lazy so that I2 filter is applied\n",
    "\n",
    "# plot the data\n",
    "fig, axes = prettyplot_with_scalebars(blk, t_start, t_stop, plots, **kwargs)\n",
    "\n",
    "# plot a zero baseline for force\n",
    "ax = axes[channel_names.index('Force')]\n",
    "force_zero = -11.5 # mN, average before animal began swallowing, not zero because of DC offset\n",
    "ax.axhline(force_zero, color='0.75', lw=1, ls='--')\n",
    "\n",
    "fig.savefig(os.path.join(export_dir, 'figure-2B.png'), dpi=600)\n",
    "\n",
    "end = datetime.datetime.now()\n",
    "print('render time:', end-start)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "-"
    }
   },
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "### Fig 2C ✅"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "-"
    }
   },
   "source": [
    "Plot swallow duration and inter-swallow interval differences between tape nori and reg nori"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(5, 5))\n",
    "ax = plt.gca()\n",
    "\n",
    "df = df_durations_intervals.reset_index()\n",
    "df = df.rename(columns={\n",
    "    'Duration (s)':       'Swallow duration',\n",
    "    'Interval after (s)': 'Inter-swallow interval'})\n",
    "df = pd.melt(df,\n",
    "             id_vars=['Animal', 'Food', 'Bout_index', 'Behavior_index'],\n",
    "             value_vars=['Swallow duration', 'Inter-swallow interval'],\n",
    "             var_name='',\n",
    "             value_name='Duration/interval (s)')\n",
    "sns.boxplot(hue='Food', y='Duration/interval (s)', x='', data=df, fliersize=0, whis=999) # whis=999 ensures whiskers go to min and max\n",
    "# sns.swarmplot(hue='Food', y='Duration/interval (s)', x='', data=df)\n",
    "\n",
    "plt.tight_layout()\n",
    "\n",
    "plt.gcf().savefig(os.path.join(export_dir, 'figure-2C.png'), dpi=300)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "-"
    }
   },
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "### Fig 2D ✅"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "-"
    }
   },
   "source": [
    "Exemplar force plot for one swallow with labeled features (rise, plateau, shoulder, etc.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "start = datetime.datetime.now()\n",
    "\n",
    "data_set_name = 'IN VIVO / JG12 / 2019-05-10 / 002'\n",
    "t_start, t_stop = [3001.3, 3009.75] * pq.s # t=3003.835, twidth=8.45\n",
    "plots = [\n",
    "    {'channel': 'Force', 'units': 'mN', 'ylim': [-20, 250], 'scalebar': None, 'ylabel': None, 'decimation_factor': 100},\n",
    "]\n",
    "channel_names = [p['channel'] for p in plots]\n",
    "channel_units = [p['units'] for p in plots]\n",
    "\n",
    "kwargs = dict(\n",
    "    formats = ['png'],\n",
    "    dpi = 600,\n",
    "    figsize = (7, 5),\n",
    "    linewidth = 2,\n",
    "    x_scalebar = None,\n",
    ")\n",
    "\n",
    "# load the metadata\n",
    "metadata = neurotic.MetadataSelector('../../data/metadata.yml')\n",
    "metadata.select(data_set_name)\n",
    "\n",
    "# add/update the force filter\n",
    "new_force_filter = {'channel': 'Force', 'lowpass': 10}\n",
    "update_filter(metadata, new_force_filter)\n",
    "\n",
    "# load the data\n",
    "blk = neurotic.load_dataset(metadata) # not lazy so that force filter is applied\n",
    "\n",
    "# plot the data\n",
    "fig, axes = prettyplot_with_scalebars(blk, t_start, t_stop, plots, **kwargs)\n",
    "\n",
    "# # plot a zero baseline for force\n",
    "# ax = axes[channel_names.index('Force')]\n",
    "# force_zero = -11.5 # mN, average before animal began swallowing, not zero because of DC offset\n",
    "# ax.axhline(force_zero, color='0.75', lw=1, ls='--')\n",
    "\n",
    "fig.savefig(os.path.join(export_dir, 'figure-2D.png'), dpi=600)\n",
    "    \n",
    "end = datetime.datetime.now()\n",
    "print('render time:', end-start)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "-"
    }
   },
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## [FIGURE 3] First phase of swallowing: peak of protraction and min force"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "### Fig 3A ✅"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "-"
    }
   },
   "source": [
    "Example motor patterns, lines connecting I2 muscle activity ending and force minimum\n",
    "\n",
    "* TODO: Place event markers programattically so they are completely accurate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "start = datetime.datetime.now()\n",
    "\n",
    "data_set_name = 'IN VIVO / JG12 / 2019-05-10 / 002'\n",
    "t_start, t_stop = [2944.5, 3002.5] * pq.s # t=2961.9, twidth=58, 6 tape nori swallows\n",
    "plots = [\n",
    "    {'channel': 'I2',       'units': 'uV', 'ylim': [ -35,  35], 'scalebar': 50},#, 'decimation_factor': 400},\n",
    "#     {'channel': 'RN',       'units': 'uV', 'ylim': [ -25,  25], 'scalebar': 25},#, 'decimation_factor': 400},\n",
    "#     {'channel': 'BN2',      'units': 'uV', 'ylim': [ -45,  45], 'scalebar': 50},#, 'decimation_factor': 400},\n",
    "#     {'channel': 'BN3-DIST', 'units': 'uV', 'ylim': [ -60,  60], 'scalebar': 50, 'ylabel': 'BN3'},#, 'decimation_factor': 400},\n",
    "    {'channel': 'Force',    'units': 'mN', 'ylim': [ -50, 450], 'scalebar': 300, 'decimation_factor': 100},\n",
    "]\n",
    "channel_names = [p['channel'] for p in plots]\n",
    "channel_units = [p['units'] for p in plots]\n",
    "\n",
    "kwargs = dict(\n",
    "    formats = ['png'],\n",
    "    dpi = 600,\n",
    "    figsize = (12, 4),\n",
    "    linewidth = 0.5,\n",
    "    x_scalebar = 10*pq.s,\n",
    ")\n",
    "\n",
    "# load the data\n",
    "metadata = neurotic.MetadataSelector('../../data/metadata.yml')\n",
    "metadata.select(data_set_name)\n",
    "blk = neurotic.load_dataset(metadata) # not lazy so that I2 filter is applied\n",
    "\n",
    "# plot the data\n",
    "fig, axes = prettyplot_with_scalebars(blk, t_start, t_stop, plots, **kwargs)\n",
    "\n",
    "# plot a zero baseline for force\n",
    "ax = axes[channel_names.index('Force')]\n",
    "force_zero = -11.5 # mN, average before animal began swallowing, not zero because of DC offset\n",
    "ax.axhline(force_zero, color='0.75', lw=1, ls='--')\n",
    "\n",
    "fig.savefig(os.path.join(export_dir, 'figure-3A.png'), dpi=600)\n",
    "\n",
    "end = datetime.datetime.now()\n",
    "print('render time:', end-start)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "-"
    }
   },
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "### Fig 3B ✅"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "-"
    }
   },
   "source": [
    "Plot delay between I2 muscle activity ending and force drop"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- **The Good**: Almost all points are to the right, consistent with peak protraction causing force drop\n",
    "\n",
    "- **The Bad**: Within-animal variability is high, and some extreme delays are too long\n",
    "\n",
    "- **Verdict**: Very good for showing I2 protraction idea is plausible. Data from different animals can probably be lumped together without issue."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(5, 5))\n",
    "ax = plt.gca()\n",
    "\n",
    "df = df_all.reset_index()\n",
    "# column = 'Delay from I2 end to force min (s)'\n",
    "column = 'Delay from I2 end to force rise start (s)'\n",
    "\n",
    "sns.boxplot(y='Animal', x=column, data=df, fliersize=0, whis=999) # whis=999 ensures whiskers go to min and max\n",
    "# sns.swarmplot(y='Animal', x=column, data=df, color='0.25')\n",
    "\n",
    "# sns.boxplot(x=column, data=df, fliersize=0, whis=999) # whis=999 ensures whiskers go to min and max\n",
    "# sns.swarmplot(x=column, data=df, color='0.25')\n",
    "\n",
    "plt.axvline(x=0, ls=':', c='gray', zorder=-1)\n",
    "\n",
    "plt.tight_layout()\n",
    "\n",
    "plt.gcf().savefig(os.path.join(export_dir, 'figure-3B.png'), dpi=300)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# column = 'Delay from I2 end to force min (s)'\n",
    "column = 'Delay from I2 end to force rise start (s)'\n",
    "print_column_analysis(column)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [],
   "source": [
    "# points that aren't where we expected\n",
    "# column = 'Delay from I2 end to force min (s)'\n",
    "column = 'Delay from I2 end to force rise start (s)'\n",
    "df_all[df_all[column] < 0][[column]]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "-"
    }
   },
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## [FIGURE 4] Second phase of swallowing: grasper closing and initial force rise"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "### Fig 4A ❌"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "-"
    }
   },
   "source": [
    "Example motor patterns, lines connecting B8a/b motor neuron activity starting and force beginning to rise"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "-"
    }
   },
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "### Fig 4B ❗"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "-"
    }
   },
   "source": [
    "Plot delay between B3/B6/B9 motor neuron activity starting and force beginning to rise. Takeaway: Force occurs first, evidence that these motor neurons don't start the rise"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- **The Good**: In most swallows, force starts before B3/B6/B9\n",
    "\n",
    "- **The Bad**: However, this is not true in about 1/3 of swallows. Variability is high, so this timing relationship is not reliable.\n",
    "\n",
    "- This suggests that although there are swallows where B3/B6/B9 might have initialiated force rise, there are even more swallows where it couldn't have because force rose first.\n",
    "\n",
    "- **Verdict**: Because the plot isn't compelling, instead of showing it we could just cite the statistic (\"In X% of swallows, B3/B6/B9 bursts started after force generation had already begun\") to motivate the B8a/b analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(5, 5))\n",
    "ax = plt.gca()\n",
    "\n",
    "df = df_all.reset_index()\n",
    "# column = 'Delay from B3/B6/B9 start to force start (s)'\n",
    "column = 'Delay from B3/B6/B9 start to force rise start (s)'\n",
    "\n",
    "sns.boxplot(y='Animal', x=column, data=df, fliersize=0, whis=999) # whis=999 ensures whiskers go to min and max\n",
    "sns.swarmplot(y='Animal', x=column, data=df, color='0.25')\n",
    "\n",
    "# sns.boxplot(x=column, data=df, fliersize=0, whis=999) # whis=999 ensures whiskers go to min and max\n",
    "# sns.swarmplot(x=column, data=df, color='0.25')\n",
    "\n",
    "plt.axvline(x=0, ls=':', c='gray', zorder=-1)\n",
    "\n",
    "plt.tight_layout()\n",
    "\n",
    "plt.gcf().savefig(os.path.join(export_dir, 'figure-4B.png'), dpi=300)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# column = 'Delay from B3/B6/B9 start to force start (s)'\n",
    "column = 'Delay from B3/B6/B9 start to force rise start (s)'\n",
    "print_column_analysis(column)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [],
   "source": [
    "# points that aren't where we expected\n",
    "# column = 'Delay from B3/B6/B9 start to force start (s)'\n",
    "column = 'Delay from B3/B6/B9 start to force rise start (s)'\n",
    "df_all[df_all[column] > 0][[column]]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "-"
    }
   },
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "### Fig 4C ✅"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "-"
    }
   },
   "source": [
    "Plot delay between B8a/b motor neuron activity starting and force beginning to rise. Takeaway: B8a/b have the right timing for being the cause of initial force rise (by closing the grasper)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- **The Good**: B8a/b always precedes force start. With the exception of JG11, variability is low. Means are similar enough that we might be able to propose a \"typical\" delay.\n",
    "\n",
    "- **The Bad**: JG11's variability\n",
    "\n",
    "- **Verdict**: Very supportive of the argument. Check JG11's outliers for errors. This figure is clean enough that swallows from multiple animals could probably be lumped together without issue."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(5, 5))\n",
    "ax = plt.gca()\n",
    "\n",
    "df = df_all.reset_index()\n",
    "# column = 'Delay from B8a/b start to force start (s)'\n",
    "column = 'Delay from B8a/b start to force rise start (s)'\n",
    "\n",
    "sns.boxplot(y='Animal', x=column, data=df, fliersize=0, whis=999) # whis=999 ensures whiskers go to min and max\n",
    "sns.swarmplot(y='Animal', x=column, data=df, color='0.25')\n",
    "\n",
    "# sns.boxplot(x=column, data=df, fliersize=0, whis=999) # whis=999 ensures whiskers go to min and max\n",
    "# sns.swarmplot(x=column, data=df, color='0.25')\n",
    "\n",
    "plt.axvline(x=0, ls=':', c='gray', zorder=-1)\n",
    "\n",
    "plt.tight_layout()\n",
    "\n",
    "plt.gcf().savefig(os.path.join(export_dir, 'figure-4C.png'), dpi=300)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# column = 'Delay from B8a/b start to force start (s)'\n",
    "column = 'Delay from B8a/b start to force rise start (s)'\n",
    "print_column_analysis(column)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [],
   "source": [
    "# points that aren't where we expected\n",
    "# column = 'Delay from B8a/b start to force start (s)'\n",
    "column = 'Delay from B8a/b start to force rise start (s)'\n",
    "df_all[df_all[column] < 0][[column]]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "-"
    }
   },
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "### Fig 4D ❌"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "-"
    }
   },
   "source": [
    "Plot mean rectified voltage on radula nerve (B8a/b burst) preceding the start of B3/B6/B9 activity against initial force slope or delta force. Takeaway: Show that intensity of B8a/b activity correlates with intensity of force rise"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- **The Good**: 4 of 5 animals have positive slopes\n",
    "\n",
    "- **The Bad**: Highly variable. No significant correlations.\n",
    "\n",
    "- The boundaries of the \"B8a/b pre-B3/B6/B9\" period are hightly sensitive to several threshold parameters, so it may not be possible to locate it reliably.\n",
    "\n",
    "- Measurements based on mean rectified voltage probably should not be lumped together from different animals without normalization.\n",
    "\n",
    "- **Verdict**: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(5, 5))\n",
    "ax = plt.gca()\n",
    "\n",
    "data_subsets = [\n",
    "    'JG07 Tape nori',\n",
    "    'JG08 Tape nori',\n",
    "    'JG11 Tape nori',\n",
    "    'JG12 Tape nori',\n",
    "    'JG14 Tape nori',\n",
    "]\n",
    "data_subsets = {label:label2query(label) for label in data_subsets}\n",
    "\n",
    "# xlabel, xlim = 'B8 activity mean rectified voltage (μV)', [0, None]\n",
    "# xlabel, xlim = 'B8a/b first burst mean rectified voltage (μV)', [0, None]\n",
    "xlabel, xlim = 'B8a/b pre-B3/B6/B9 burst mean rectified voltage (μV)', [0, None]\n",
    "# xlabel, xlim = 'B8a/b pre-B3/B6/B9 burst mean frequency (Hz)', [0, None]\n",
    "# ylabel, ylim = 'Force slope (mN/s)', [0, None]\n",
    "ylabel, ylim = 'Force initial slope (mN/s)', [0, None]\n",
    "# ylabel, ylim = 'Force initial increase (mN)', [0, None]\n",
    "\n",
    "scatter2d(ax, data_subsets, xlabel, xlim, ylabel, ylim, trend=True, trend_separately=True, tooltips=True)\n",
    "ax.legend()\n",
    "sns.despine(ax=ax, offset=20, trim=True)\n",
    "plt.tight_layout()\n",
    "\n",
    "plt.gcf().savefig(os.path.join(export_dir, 'figure-4D.png'), dpi=300)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "-"
    }
   },
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "### Fig 4 Alternatives ❓"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [],
   "source": [
    "plt.figure(figsize=(5, 5))\n",
    "ax = plt.gca()\n",
    "\n",
    "data_subsets = [\n",
    "    'JG07 Tape nori',\n",
    "    'JG08 Tape nori',\n",
    "    'JG11 Tape nori',\n",
    "    'JG12 Tape nori',\n",
    "    'JG14 Tape nori',\n",
    "]\n",
    "data_subsets = {label:label2query(label) for label in data_subsets}\n",
    "\n",
    "# xlabel, xlim = 'B8 activity mean rectified voltage (μV)', [0, None]\n",
    "# xlabel, xlim = 'B8a/b first burst mean rectified voltage (μV)', [0, None]\n",
    "# xlabel, xlim = 'B8a/b pre-B3/B6/B9 burst mean rectified voltage (μV)', [0, None]\n",
    "xlabel, xlim = 'B8a/b pre-B3/B6/B9 burst mean frequency (Hz)', [0, None]\n",
    "# ylabel, ylim = 'Force slope (mN/s)', [0, None]\n",
    "ylabel, ylim = 'Force initial slope (mN/s)', [0, None]\n",
    "# ylabel, ylim = 'Force initial increase (mN)', [0, None]\n",
    "\n",
    "scatter2d(ax, data_subsets, xlabel, xlim, ylabel, ylim, trend=True, trend_separately=True, tooltips=True)\n",
    "ax.legend()\n",
    "sns.despine(ax=ax, offset=20, trim=True)\n",
    "plt.tight_layout()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(5, 5))\n",
    "ax = plt.gca()\n",
    "\n",
    "data_subsets = [\n",
    "    'JG07 Tape nori',\n",
    "    'JG08 Tape nori',\n",
    "    'JG11 Tape nori',\n",
    "    'JG12 Tape nori',\n",
    "    'JG14 Tape nori',\n",
    "]\n",
    "data_subsets = {label:label2query(label) for label in data_subsets}\n",
    "\n",
    "# xlabel, xlim = 'B8 activity mean rectified voltage (μV)', [0, None]\n",
    "# xlabel, xlim = 'B8a/b first burst mean rectified voltage (μV)', [0, None]\n",
    "xlabel, xlim = 'B8a/b pre-B3/B6/B9 burst mean rectified voltage (μV)', [0, None]\n",
    "# xlabel, xlim = 'B8a/b pre-B3/B6/B9 burst mean frequency (Hz)', [0, None]\n",
    "# ylabel, ylim = 'Force slope (mN/s)', [0, None]\n",
    "# ylabel, ylim = 'Force initial slope (mN/s)', [0, None]\n",
    "ylabel, ylim = 'Force initial increase (mN)', [0, None]\n",
    "\n",
    "scatter2d(ax, data_subsets, xlabel, xlim, ylabel, ylim, trend=True, trend_separately=True, tooltips=True)\n",
    "ax.legend()\n",
    "sns.despine(ax=ax, offset=20, trim=True)\n",
    "plt.tight_layout()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(5, 5))\n",
    "ax = plt.gca()\n",
    "\n",
    "data_subsets = [\n",
    "    'JG07 Tape nori',\n",
    "    'JG08 Tape nori',\n",
    "    'JG11 Tape nori',\n",
    "    'JG12 Tape nori',\n",
    "    'JG14 Tape nori',\n",
    "]\n",
    "data_subsets = {label:label2query(label) for label in data_subsets}\n",
    "\n",
    "# xlabel, xlim = 'B8 activity mean rectified voltage (μV)', [0, None]\n",
    "# xlabel, xlim = 'B8a/b first burst mean rectified voltage (μV)', [0, None]\n",
    "# xlabel, xlim = 'B8a/b pre-B3/B6/B9 burst mean rectified voltage (μV)', [0, None]\n",
    "xlabel, xlim = 'B8a/b pre-B3/B6/B9 burst mean frequency (Hz)', [0, None]\n",
    "# ylabel, ylim = 'Force slope (mN/s)', [0, None]\n",
    "ylabel, ylim = 'Force increase (mN)', [0, None]\n",
    "# ylabel, ylim = 'Force initial slope (mN/s)', [0, None]\n",
    "# ylabel, ylim = 'Force initial increase (mN)', [0, None]\n",
    "\n",
    "scatter2d(ax, data_subsets, xlabel, xlim, ylabel, ylim, trend=True, trend_separately=True, tooltips=True)\n",
    "ax.legend()\n",
    "sns.despine(ax=ax, offset=20, trim=True)\n",
    "plt.tight_layout()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [],
   "source": [
    "plt.figure(figsize=(5, 5))\n",
    "ax = plt.gca()\n",
    "\n",
    "data_subsets = [\n",
    "    'JG07 Tape nori',\n",
    "    'JG08 Tape nori',\n",
    "    'JG11 Tape nori',\n",
    "    'JG12 Tape nori',\n",
    "    'JG14 Tape nori',\n",
    "]\n",
    "data_subsets = {label:label2query(label) for label in data_subsets}\n",
    "\n",
    "# xlabel, xlim = 'B8 activity duration (s)', [0, 8]\n",
    "xlabel, xlim = 'B8a/b first burst duration (s)', [0, 8]\n",
    "ylabel, ylim = 'Force rise and plateau duration (s)', [0, 8]\n",
    "\n",
    "scatter2d(ax, data_subsets, xlabel, xlim, ylabel, ylim, trend=True, trend_separately=True, tooltips=False)\n",
    "plt.plot([0, 999], [0, 999], ls=':', c='gray', zorder=0)\n",
    "ax.legend()\n",
    "sns.despine(ax=ax, offset=20, trim=True)\n",
    "plt.tight_layout()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "-"
    }
   },
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## [FIGURE 5] Third phase of swallowing: maintaining high force"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "### Fig 5A ✅"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Example motor patterns, lines connecting B3/B6/B9 motor neuron activity to force plateau\n",
    "\n",
    "* TODO: Place event markers programmatically"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "start = datetime.datetime.now()\n",
    "\n",
    "data_set_name = 'IN VIVO / JG12 / 2019-05-10 / 002'\n",
    "t_start, t_stop = [2944.5, 3002.5] * pq.s # t=2961.9, twidth=58, 6 tape nori swallows\n",
    "plots = [\n",
    "#     {'channel': 'I2',       'units': 'uV', 'ylim': [ -35,  35], 'scalebar': 50},#, 'decimation_factor': 400},\n",
    "#     {'channel': 'RN',       'units': 'uV', 'ylim': [ -25,  25], 'scalebar': 25},#, 'decimation_factor': 400},\n",
    "    {'channel': 'BN2',      'units': 'uV', 'ylim': [ -45,  45], 'scalebar': 50},#, 'decimation_factor': 400},\n",
    "#     {'channel': 'BN3-DIST', 'units': 'uV', 'ylim': [ -60,  60], 'scalebar': 50, 'ylabel': 'BN3'},#, 'decimation_factor': 400},\n",
    "    {'channel': 'Force',    'units': 'mN', 'ylim': [ -50, 450], 'scalebar': 300, 'decimation_factor': 100},\n",
    "]\n",
    "channel_names = [p['channel'] for p in plots]\n",
    "channel_units = [p['units'] for p in plots]\n",
    "\n",
    "kwargs = dict(\n",
    "    formats = ['png'],\n",
    "    dpi = 600,\n",
    "    figsize = (12, 4),\n",
    "    linewidth = 0.5,\n",
    "    x_scalebar = 10*pq.s,\n",
    ")\n",
    "\n",
    "# load the data\n",
    "metadata = neurotic.MetadataSelector('../../data/metadata.yml')\n",
    "metadata.select(data_set_name)\n",
    "blk = neurotic.load_dataset(metadata, lazy=True)\n",
    "\n",
    "# plot the data\n",
    "fig, axes = prettyplot_with_scalebars(blk, t_start, t_stop, plots, **kwargs)\n",
    "\n",
    "# plot a zero baseline for force\n",
    "ax = axes[channel_names.index('Force')]\n",
    "force_zero = -11.5 # mN, average before animal began swallowing, not zero because of DC offset\n",
    "ax.axhline(force_zero, color='0.75', lw=1, ls='--')\n",
    "\n",
    "fig.savefig(os.path.join(export_dir, 'figure-5A.png'), dpi=600)\n",
    "\n",
    "end = datetime.datetime.now()\n",
    "print('render time:', end-start)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "### Fig 5B ✅"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Plot delay between B3/B6/B9 motor neuron activity starting and force reaching 50% max height. Takeaway: B3/B6/B9 have the right timing for keeping force high"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- **The Good**: All delays are positive.\n",
    "\n",
    "- **The Bad**: Delays are highly variable.\n",
    "\n",
    "- Perhaps 50%-height isn't the right comparison point. Maybe B3/B6/B9 have effects earlier at 20%-height, or maybe later.\n",
    "\n",
    "- **Verdict**: Not bad, but perhaps could be better. Delay might be more consistent with a better comparison point."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(5, 5))\n",
    "ax = plt.gca()\n",
    "\n",
    "df = df_all.reset_index()\n",
    "# column = 'Delay from B3/B6/B9 start to force 50%-height (s)'\n",
    "column = 'Delay from B3/B6/B9 start to force plateau start (s)'\n",
    "\n",
    "sns.boxplot(y='Animal', x=column, data=df, fliersize=0, whis=999) # whis=999 ensures whiskers go to min and max\n",
    "# sns.swarmplot(y='Animal', x=column, data=df, color='0.25')\n",
    "\n",
    "# sns.boxplot(x=column, data=df, fliersize=0, whis=999) # whis=999 ensures whiskers go to min and max\n",
    "# sns.swarmplot(x=column, data=df, color='0.25')\n",
    "\n",
    "plt.axvline(x=0, ls=':', c='gray', zorder=-1)\n",
    "\n",
    "plt.tight_layout()\n",
    "\n",
    "plt.gcf().savefig(os.path.join(export_dir, 'figure-5B.png'), dpi=300)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# column = 'Delay from B3/B6/B9 start to force 50%-height (s)'\n",
    "column = 'Delay from B3/B6/B9 start to force plateau start (s)'\n",
    "print_column_analysis(column)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# points that aren't where we expected\n",
    "# column = 'Delay from B3/B6/B9 start to force 50%-height (s)'\n",
    "column = 'Delay from B3/B6/B9 start to force plateau start (s)'\n",
    "df_all[df_all[column] < 0][[column]]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "### Fig 5C ✅"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Plot B3/B6/B9 burst duration against time force is above 80% max height"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- **The Good**: All same positive trends, most are significant.\n",
    "\n",
    "- **The Bad**: Would be more satisfying if the points lay on the diagonal.\n",
    "\n",
    "- **Verdict**: Good result. Might be improved by choosing a lower plateau threshold with longer duration, such as 75%."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(5, 5))\n",
    "ax = plt.gca()\n",
    "\n",
    "data_subsets = [\n",
    "    'JG07 Tape nori',\n",
    "    'JG08 Tape nori',\n",
    "    'JG11 Tape nori',\n",
    "    'JG12 Tape nori',\n",
    "    'JG14 Tape nori',\n",
    "]\n",
    "data_subsets = {label:label2query(label) for label in data_subsets}\n",
    "\n",
    "# xlabel, xlim = 'B3 first burst duration (s)', [0, 5]\n",
    "# xlabel, xlim = 'B6/B9 first burst duration (s)', [0, 5]\n",
    "xlabel, xlim = 'B3/B6/B9 burst duration (s)', [0, 5]\n",
    "# ylabel, ylim = 'Force 80%-height duration (s)', [0, 5]\n",
    "ylabel, ylim = 'Force plateau duration (s)', [0, 5]\n",
    "\n",
    "scatter2d(ax, data_subsets, xlabel, xlim, ylabel, ylim, trend=True, trend_separately=True, tooltips=False)\n",
    "plt.plot([0, 999], [0, 999], ls=':', c='gray', zorder=0)\n",
    "ax.legend()\n",
    "sns.despine(ax=ax, offset=20, trim=True)\n",
    "plt.tight_layout()\n",
    "\n",
    "plt.gcf().savefig(os.path.join(export_dir, 'figure-5C.png'), dpi=300)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "### Fig 5D ❌"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Plot delay between EITHER B8a/b OR B3/B6/B9 activity ending (whichever comes first) and end of force plateau. Takeaway: Show that simultaneous B8a/b and B3/B6/B9 activity are needed to sustain force, i.e., force drops when either grasper opens or retraction stops"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- **The Good**: There are more points on the right than on the left\n",
    "\n",
    "- **The Bad**: Very large variability, can't really determine sign of the timing delay\n",
    "\n",
    "- The end of the \"simultaneous B8a/b and B3/B6/B9\" period is sensitive to several threshold parameters, so it may not be possible to locate it reliably.\n",
    "\n",
    "- Perhaps the hard rule of using 80%-height for the end of the plateau is not generally applicable.\n",
    "\n",
    "- **Verdict**: Not usable in current form."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(5, 5))\n",
    "ax = plt.gca()\n",
    "\n",
    "df = df_all.reset_index()\n",
    "# column = 'Delay from either B8a/b or B3/B6/B9 end to force 80%-height end (s)'\n",
    "column = 'Delay from either B8a/b or B3/B6/B9 end to force plateau end (s)'\n",
    "\n",
    "sns.boxplot(y='Animal', x=column, data=df, fliersize=0, whis=999) # whis=999 ensures whiskers go to min and max\n",
    "sns.swarmplot(y='Animal', x=column, data=df, color='0.25')\n",
    "\n",
    "# sns.boxplot(x=column, data=df, fliersize=0, whis=999) # whis=999 ensures whiskers go to min and max\n",
    "# sns.swarmplot(x=column, data=df, color='0.25')\n",
    "\n",
    "plt.axvline(x=0, ls=':', c='gray', zorder=-1)\n",
    "\n",
    "plt.tight_layout()\n",
    "\n",
    "plt.gcf().savefig(os.path.join(export_dir, 'figure-5D.png'), dpi=300)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# column = 'Delay from either B8a/b or B3/B6/B9 end to force 80%-height end (s)'\n",
    "column = 'Delay from either B8a/b or B3/B6/B9 end to force plateau end (s)'\n",
    "print_column_analysis(column)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# points that aren't where we expected\n",
    "# column = 'Delay from either B8a/b or B3/B6/B9 end to force 80%-height end (s)'\n",
    "column = 'Delay from either B8a/b or B3/B6/B9 end to force plateau end (s)'\n",
    "df_all[df_all[column] < 0][[column]]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "### Fig 5 Alternatives ❓"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "-"
    }
   },
   "source": [
    "__Other ideas:__\n",
    "\n",
    "* Plot mean voltage on BN2 during B3/6/9 acitivty vs slope or relative rise in force ?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [],
   "source": [
    "plt.figure(figsize=(5, 5))\n",
    "ax = plt.gca()\n",
    "\n",
    "data_subsets = [\n",
    "    'JG07 Tape nori',\n",
    "    'JG08 Tape nori',\n",
    "    'JG11 Tape nori',\n",
    "    'JG12 Tape nori',\n",
    "    'JG14 Tape nori',\n",
    "]\n",
    "data_subsets = {label:label2query(label) for label in data_subsets}\n",
    "\n",
    "# xlabel, xlim = 'B3/6/9/10 activity duration (s)', [0, 8]\n",
    "xlabel, xlim = 'B6/B9 first burst duration (s)', [0, 8]\n",
    "ylabel, ylim = 'Force rise and plateau duration (s)', [0, 8]\n",
    "\n",
    "scatter2d(ax, data_subsets, xlabel, xlim, ylabel, ylim, trend=True, trend_separately=True, tooltips=False)\n",
    "plt.plot([0, 999], [0, 999], ls=':', c='gray', zorder=0)\n",
    "ax.legend()\n",
    "sns.despine(ax=ax, offset=20, trim=True)\n",
    "plt.tight_layout()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(5, 5))\n",
    "ax = plt.gca()\n",
    "\n",
    "df = df_all.reset_index()\n",
    "df = df.rename(columns={\n",
    "#     'Delay from B3 start to force 80%-height start (s)': 'Start of burst',\n",
    "#     'Delay from B3 end to force 80%-height end (s)':     'End of burst'})\n",
    "    'Delay from B3 start to force plateau start (s)': 'Start of burst',\n",
    "    'Delay from B3 end to force plateau end (s)':     'End of burst'})\n",
    "df = pd.melt(df,\n",
    "             id_vars=['Animal', 'Food', 'Bout_index', 'Behavior_index'],\n",
    "             value_vars=['Start of burst', 'End of burst'],\n",
    "             var_name='When?',\n",
    "             value_name='Delay from B3 to plateau (s)')\n",
    "sns.boxplot(hue='Animal', x='Delay from B3 to plateau (s)', y='When?', data=df, fliersize=0, whis=999) # whis=999 ensures whiskers go to min and max\n",
    "# sns.swarmplot(hue='Animal', x='Delay from B3 to plateau (s)', y='When?', data=df)\n",
    "\n",
    "plt.axvline(x=0, ls=':', c='gray', zorder=-1)\n",
    "\n",
    "plt.tight_layout()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [],
   "source": [
    "plt.figure(figsize=(5, 5))\n",
    "ax = plt.gca()\n",
    "\n",
    "data_subsets = [\n",
    "    'JG07 Tape nori',\n",
    "    'JG08 Tape nori',\n",
    "    'JG11 Tape nori',\n",
    "    'JG12 Tape nori',\n",
    "    'JG14 Tape nori',\n",
    "]\n",
    "data_subsets = {label:label2query(label) for label in data_subsets}\n",
    "\n",
    "# xlabel, xlim = 'B3/6/9/10 activity mean rectified voltage (μV)', [0, None]\n",
    "xlabel, xlim = 'B6/B9 first burst mean rectified voltage (μV)', [0, None]\n",
    "# ylabel, ylim = 'Force slope (mN/s)', [0, None]\n",
    "# ylabel, ylim = 'Force 80%-height (mN)', [0, None]\n",
    "ylabel, ylim = 'Force increase (mN)', [0, None]\n",
    "\n",
    "scatter2d(ax, data_subsets, xlabel, xlim, ylabel, ylim, trend=True, trend_separately=True, tooltips=True)\n",
    "ax.legend()\n",
    "sns.despine(ax=ax, offset=20, trim=True)\n",
    "plt.tight_layout()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(5, 5))\n",
    "ax = plt.gca()\n",
    "\n",
    "data_subsets = [\n",
    "    'JG07 Tape nori',\n",
    "    'JG08 Tape nori',\n",
    "    'JG11 Tape nori',\n",
    "    'JG12 Tape nori',\n",
    "    'JG14 Tape nori',\n",
    "]\n",
    "data_subsets = {label:label2query(label) for label in data_subsets}\n",
    "\n",
    "# xlabel, xlim = 'B3/6/9/10 activity mean rectified voltage (μV)', [0, None]\n",
    "xlabel, xlim = 'B6/B9 first burst mean frequency (Hz)', [0, None]\n",
    "# ylabel, ylim = 'Force slope (mN/s)', [0, None]\n",
    "ylabel, ylim = 'Force plateau start value (mN)', [0, None]\n",
    "# ylabel, ylim = 'Force increase (mN)', [0, None]\n",
    "# ylabel, ylim = 'Force rise increase (mN)', [0, None]\n",
    "\n",
    "scatter2d(ax, data_subsets, xlabel, xlim, ylabel, ylim, trend=True, trend_separately=True, tooltips=True)\n",
    "ax.legend()\n",
    "sns.despine(ax=ax, offset=20, trim=True)\n",
    "plt.tight_layout()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## [FIGURE 6] Fourth phase of swallowing: force shoulder during initial protraction"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "### Fig 6A ❌"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Example motor patterns, lines connecting B38 motor neuron activity and force shoulder"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "### Fig 6B ❌"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Plot delay between B38 motor neuron activity ending and force shoulder ending"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- **The Good**: \n",
    "\n",
    "- **The Bad**: Terrible variability. Certainly bad shoulders are contributing to this.\n",
    "\n",
    "- **Verdict**: This figure needs to use only the best hand-selected swallows with well-defined shoulders AND well-defined B38 burst"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(5, 5))\n",
    "ax = plt.gca()\n",
    "\n",
    "df = df_all.reset_index()\n",
    "# column = 'Delay from B38 end to shoulder end (s)'\n",
    "column = 'Delay from B38 end to force shoulder end (s)'\n",
    "\n",
    "sns.boxplot(y='Animal', x=column, data=df, fliersize=0, whis=999) # whis=999 ensures whiskers go to min and max\n",
    "sns.swarmplot(y='Animal', x=column, data=df, color='0.25')\n",
    "\n",
    "# sns.boxplot(x=column, data=df, fliersize=0, whis=999) # whis=999 ensures whiskers go to min and max\n",
    "# sns.swarmplot(x=column, data=df, color='0.25')\n",
    "\n",
    "plt.axvline(x=0, ls=':', c='gray', zorder=-1)\n",
    "\n",
    "plt.tight_layout()\n",
    "\n",
    "plt.gcf().savefig(os.path.join(export_dir, 'figure-6B.png'), dpi=300)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# column = 'Delay from B38 end to shoulder end (s)'\n",
    "column = 'Delay from B38 end to force shoulder end (s)'\n",
    "print_column_analysis(column)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# points that aren't where we expected\n",
    "# column = 'Delay from B38 end to shoulder end (s)'\n",
    "column = 'Delay from B38 end to force shoulder end (s)'\n",
    "df_all[df_all[column] < 0][[column]]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "### Fig 6 Alternatives ❓"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plt.figure(figsize=(5, 5))\n",
    "# ax = plt.gca()\n",
    "\n",
    "# data_subsets = [\n",
    "#     'JG07 Tape nori',\n",
    "#     'JG08 Tape nori',\n",
    "#     'JG11 Tape nori',\n",
    "#     'JG12 Tape nori',\n",
    "#     'JG14 Tape nori',\n",
    "# ]\n",
    "# data_subsets = {label:label2query(label) for label in data_subsets}\n",
    "\n",
    "# # xlabel, xlim = 'B38 activity duration (s)', [0, 6]\n",
    "# xlabel, xlim = 'B38 last burst duration (s)', [0, 6]\n",
    "# ylabel, ylim = 'Force shoulder duration (s)', [0, 6]\n",
    "\n",
    "# scatter2d(ax, data_subsets, xlabel, xlim, ylabel, ylim, trend=True, trend_separately=True, tooltips=False)\n",
    "# plt.plot([0, 999], [0, 999], ls=':', c='gray', zorder=0)\n",
    "# ax.legend()\n",
    "# sns.despine(ax=ax, offset=20, trim=True)\n",
    "# plt.tight_layout()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plt.figure(figsize=(5, 5))\n",
    "# ax = plt.gca()\n",
    "\n",
    "# data_subsets = [\n",
    "#     'JG07 Tape nori',\n",
    "#     'JG08 Tape nori',\n",
    "#     'JG11 Tape nori',\n",
    "#     'JG12 Tape nori',\n",
    "#     'JG14 Tape nori',\n",
    "# ]\n",
    "# data_subsets = {label:label2query(label) for label in data_subsets}\n",
    "\n",
    "# xlabel, xlim = 'B38 last burst mean frequency (Hz)', [0, None]\n",
    "# ylabel, ylim = 'Force shoulder duration (s)', [0, None]\n",
    "\n",
    "# scatter2d(ax, data_subsets, xlabel, xlim, ylabel, ylim, trend=True, trend_separately=True, tooltips=False)\n",
    "# ax.legend()\n",
    "# sns.despine(ax=ax, offset=20, trim=True)\n",
    "# plt.tight_layout()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## [FIGURE 7] Summary ❌"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Firing rate model (time permitting), or schematic summary of all phases (boxes for motor neuron activity, idealized force, etc.)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## [????]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(5, 5))\n",
    "ax = plt.gca()\n",
    "\n",
    "data_subsets = [\n",
    "    'JG07 Tape nori',\n",
    "    'JG08 Tape nori',\n",
    "    'JG11 Tape nori',\n",
    "    'JG12 Tape nori',\n",
    "    'JG14 Tape nori',\n",
    "]\n",
    "data_subsets = {label:label2query(label) for label in data_subsets}\n",
    "\n",
    "xlabel, xlim = 'B8a/b pre-B3/B6/B9 burst peak smoothed frequency (Hz)', [0, None]\n",
    "ylabel, ylim = 'Force slope (mN/s)', [0, None]\n",
    "\n",
    "scatter2d(ax, data_subsets, xlabel, xlim, ylabel, ylim, trend=True, trend_separately=True, tooltips=True)\n",
    "ax.legend()\n",
    "sns.despine(ax=ax, offset=20, trim=True)\n",
    "plt.tight_layout()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##  [FIGURE ??] Force rise slope"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(5, 5))\n",
    "ax = plt.gca()\n",
    "\n",
    "data_subsets = [\n",
    "    'JG07 Tape nori',\n",
    "    'JG08 Tape nori',\n",
    "    'JG11 Tape nori',\n",
    "    'JG12 Tape nori',\n",
    "    'JG14 Tape nori',\n",
    "]\n",
    "data_subsets = {label:label2query(label) for label in data_subsets}\n",
    "\n",
    "xlabel, xlim = 'Force rise duration (s)', [0, None]\n",
    "ylabel, ylim = 'Force rise increase (mN)', [0, None]\n",
    "\n",
    "scatter2d(ax, data_subsets, xlabel, xlim, ylabel, ylim, trend=True, trend_separately=True, tooltips=True)\n",
    "ax.legend()\n",
    "sns.despine(ax=ax, offset=20, trim=True)\n",
    "plt.tight_layout()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## [FIGURE ??] Normalized time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plt.figure(figsize=(9, 7))\n",
    "# ax = plt.gca()\n",
    "\n",
    "# df = df_all.reset_index()\n",
    "# df = df.rename(columns={\n",
    "#     'I2 first burst start (delayed normalized)':    'I2',\n",
    "#     'B8a/b first burst start (delayed normalized)': 'B8a/b',\n",
    "#     'B6/B9 first burst start (delayed normalized)': 'B6/B9',\n",
    "#     'B3 first burst start (delayed normalized)':    'B3',\n",
    "#     'B38 first burst start (delayed normalized)':   'B38',\n",
    "#     'Next I2 first burst start (delayed normalized)':   'Next I2'})\n",
    "# df = pd.melt(df,\n",
    "#              id_vars=['Animal', 'Food', 'Bout_index', 'Behavior_index'],\n",
    "#              value_vars=['I2', 'B8a/b', 'B6/B9', 'B3', 'B38', 'Next I2'],\n",
    "#              var_name='Unit',\n",
    "#              value_name='Burst start (delayed normalized)')\n",
    "# sns.boxplot(y='Animal', x='Burst start (delayed normalized)', hue='Unit', data=df, fliersize=0, whis=999) # whis=999 ensures whiskers go to min and max\n",
    "# # sns.swarmplot(y='Animal', x='Burst start (delayed normalized)', hue='Unit', data=df)\n",
    "\n",
    "# df = df_all.reset_index()\n",
    "# df = df.rename(columns={\n",
    "#     'I2 last burst end (delayed normalized)':    'I2',\n",
    "#     'B8a/b last burst end (delayed normalized)': 'B8a/b',\n",
    "#     'B6/B9 last burst end (delayed normalized)': 'B6/B9',\n",
    "#     'B3 last burst end (delayed normalized)':    'B3',\n",
    "#     'B38 last burst end (delayed normalized)':   'B38',\n",
    "#     'Next I2 first burst start (delayed normalized)':   'Next I2'}) # redundant, but ensures ends have same number of boxes as starts\n",
    "# df = pd.melt(df,\n",
    "#              id_vars=['Animal', 'Food', 'Bout_index', 'Behavior_index'],\n",
    "#              value_vars=['I2', 'B8a/b', 'B6/B9', 'B3', 'B38', 'Next I2'],\n",
    "#              var_name='Unit',\n",
    "#              value_name='Burst end (delayed normalized)')\n",
    "# sns.boxplot(y='Animal', x='Burst end (delayed normalized)', hue='Unit', data=df, fliersize=0, whis=999) # whis=999 ensures whiskers go to min and max\n",
    "# # sns.swarmplot(y='Animal', x='Burst start (delayed normalized)', hue='Unit', data=df)\n",
    "\n",
    "# plt.axvline(x=0, ls=':', c='gray', zorder=-1)\n",
    "# plt.axvline(x=1, ls=':', c='gray', zorder=-1)\n",
    "# plt.axvline(x=2, ls=':', c='gray', zorder=-1)\n",
    "# plt.axvline(x=3, ls=':', c='gray', zorder=-1)\n",
    "# plt.axvline(x=4, ls=':', c='gray', zorder=-1)\n",
    "# plt.axvline(x=5, ls=':', c='gray', zorder=-1)\n",
    "# plt.axvline(x=6, ls=':', c='gray', zorder=-1)\n",
    "\n",
    "# plt.gca().get_legend().remove()\n",
    "\n",
    "# plt.tight_layout()\n",
    "\n",
    "# # plt.gcf().savefig(os.path.join(export_dir, 'figure-6B.png'), dpi=300)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i, unit in enumerate(['I2', 'B8a/b', 'B6/B9', 'B3', 'B38']):\n",
    "    t0_data   = df_all[f'{unit} first burst start (delayed normalized)'].dropna()\n",
    "#     if unit == 'B8a/b':\n",
    "#         # because of the way the muscle delay is estimated, B8 start time for the first\n",
    "#         # swallow in each bout is equal to the force rise time by definition, so we\n",
    "#         # remove those data points so they don't affect the distibution\n",
    "#         t0_data = t0_data.drop(level='Behavior_index', index=0)\n",
    "    t0_median = t0_data.median()\n",
    "    t0_N      = t0_data.size\n",
    "    \n",
    "    t1_data   = df_all[f'{unit} last burst end (delayed normalized)'].dropna()\n",
    "    if unit == 'I2':\n",
    "        # because of the way the muscle delay is estimated, I2 end time for the first\n",
    "        # swallow in each bout is equal to the force rise time by definition, so we\n",
    "        # remove those data points so they don't affect the distibution\n",
    "        t1_data = t1_data.drop(level='Behavior_index', index=0)\n",
    "    t1_median = t1_data.median()\n",
    "    t1_N      = t1_data.size\n",
    "    \n",
    "    print(f'{unit}:\\t[{t0_median:.2f} (n={t0_N}), {t1_median:.2f} (n={t1_N})]')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plt.figure(figsize=(9, 5))\n",
    "# ax = plt.gca()\n",
    "\n",
    "# normalization_phases = [\n",
    "#     'Previous major\\nforce drop',\n",
    "# #     'Previous partial\\nforce maintenance\\nand final drop',\n",
    "#     'Previous\\npartial force\\nmaintenance',\n",
    "#     'Previous final\\nforce drop',\n",
    "#     'Force rise',\n",
    "#     'Force\\nmaintenance',\n",
    "#     'Major\\nforce drop',\n",
    "#     'Partial force\\nmaintenance',\n",
    "#     'Final\\nforce drop',\n",
    "# ]\n",
    "\n",
    "# units = ['I2', 'B8a/b', 'B6/B9', 'B3', 'B38']\n",
    "# colors = unit_colors\n",
    "# colors['I2'] = colors['I2 spikes']\n",
    "# colors['Next I2'] = colors['I2 spikes']\n",
    "\n",
    "\n",
    "# for i, unit in enumerate(units):\n",
    "#     t0_data   = df_all[f'{unit} first burst start (delayed normalized)'].dropna()\n",
    "# #     if unit == 'B8a/b':\n",
    "# #         # because of the way the muscle delay is estimated, B8 start time for the first\n",
    "# #         # swallow in each bout is equal to the force rise time by definition, so we\n",
    "# #         # remove those data points so they don't affect the distibution\n",
    "# #         t0_data = t0_data.drop(level='Behavior_index', index=0)\n",
    "#     t0_median = t0_data.median()\n",
    "#     t0_q1     = t0_data.quantile(0.25)\n",
    "#     t0_q3     = t0_data.quantile(0.75)\n",
    "    \n",
    "#     t1_data   = df_all[f'{unit} last burst end (delayed normalized)'].dropna()\n",
    "#     if unit == 'I2':\n",
    "#         # because of the way the muscle delay is estimated, I2 end time for the first\n",
    "#         # swallow in each bout is equal to the force rise time by definition, so we\n",
    "#         # remove those data points so they don't affect the distibution\n",
    "#         t1_data = t1_data.drop(level='Behavior_index', index=0)\n",
    "#     t1_median = t1_data.median()\n",
    "#     t1_q1     = t1_data.quantile(0.25)\n",
    "#     t1_q3     = t1_data.quantile(0.75)\n",
    "    \n",
    "#     # plot boxes using medians\n",
    "#     height = 0.8\n",
    "#     lw = 1\n",
    "#     rect = patches.Rectangle((t0_median, i-height/2), t1_median-t0_median, height, facecolor=colors[unit], edgecolor='k', lw=lw, clip_on=False)\n",
    "#     ax.add_patch(rect)\n",
    "    \n",
    "#     # plot quartiles (25% and 75% quantiles)\n",
    "#     ax.add_line(mlines.Line2D([t0_q1, t0_q1], [i-0.2, i+0.2], color='k', lw=lw, clip_on=False))\n",
    "#     ax.add_line(mlines.Line2D([t0_q3, t0_q3], [i-0.2, i+0.2], color='k', lw=lw, clip_on=False))\n",
    "#     ax.add_line(mlines.Line2D([t1_q1, t1_q1], [i-0.2, i+0.2], color='k', lw=lw, clip_on=False))\n",
    "#     ax.add_line(mlines.Line2D([t1_q3, t1_q3], [i-0.2, i+0.2], color='k', lw=lw, clip_on=False))\n",
    "#     ax.add_line(mlines.Line2D([t0_q1, t0_q3], [i, i], color='k', lw=lw, clip_on=False))\n",
    "#     ax.add_line(mlines.Line2D([t1_q1, t1_q3], [i, i], color='k', lw=lw, clip_on=False))\n",
    "    \n",
    "#     if unit == 'I2':\n",
    "#         # plot I2 again shifted one cycle (5 phases)\n",
    "#         rect = patches.Rectangle((t0_median+5, i-height/2), t1_median-t0_median, height, facecolor=colors[unit], edgecolor='k', lw=lw, clip_on=False)\n",
    "#         ax.add_patch(rect)\n",
    "#         ax.add_line(mlines.Line2D([t0_q1+5, t0_q1+5], [i-0.2, i+0.2], color='k', lw=lw, clip_on=False))\n",
    "#         ax.add_line(mlines.Line2D([t0_q3+5, t0_q3+5], [i-0.2, i+0.2], color='k', lw=lw, clip_on=False))\n",
    "#         ax.add_line(mlines.Line2D([t1_q1+5, t1_q1+5], [i-0.2, i+0.2], color='k', lw=lw, clip_on=False))\n",
    "#         ax.add_line(mlines.Line2D([t1_q3+5, t1_q3+5], [i-0.2, i+0.2], color='k', lw=lw, clip_on=False))\n",
    "#         ax.add_line(mlines.Line2D([t0_q1+5, t0_q3+5], [i, i], color='k', lw=lw, clip_on=False))\n",
    "#         ax.add_line(mlines.Line2D([t1_q1+5, t1_q3+5], [i, i], color='k', lw=lw, clip_on=False))\n",
    "\n",
    "# ###\n",
    "# ### LABELS AND ANNOTATIONS\n",
    "# ###\n",
    "\n",
    "# plt.title('WITH MUSCLE DELAY (I2 END TO FORCE RISE START)')\n",
    "# # plt.title('WITH MUSCLE DELAY (B8 START TO FORCE RISE START)')\n",
    "\n",
    "# for x in range(len(normalization_phases)+1):\n",
    "#     plt.axvline(x=x, ls=':', c='gray', zorder=-1, clip_on=False)\n",
    "\n",
    "# # plt.xlabel('Normalized time')\n",
    "# # plt.ylabel('Unit')\n",
    "# plt.xlabel(None)\n",
    "# plt.ylabel(None)\n",
    "\n",
    "# sns.despine(bottom=True, left=True)\n",
    "# plt.tick_params(bottom=False, left=False) # disable tick marks\n",
    "# plt.xticks(np.arange(len(normalization_phases))+0.5, normalization_phases)\n",
    "# plt.yticks(range(len(units)), units)\n",
    "\n",
    "# plt.xlim(0, len(normalization_phases))\n",
    "# plt.ylim(4.9, -0.5)\n",
    "# for x in range(len(normalization_phases)):\n",
    "#     plt.annotate('0%',   (x,   4.9), textcoords=\"offset points\", xytext=( 6, 4), ha='left',  size=10)\n",
    "#     plt.annotate('100%', (x+1, 4.9), textcoords=\"offset points\", xytext=(-6, 4), ha='right', size=10)\n",
    "\n",
    "# plt.tight_layout()\n",
    "\n",
    "# plt.gcf().savefig(os.path.join(export_dir, 'figure-normalized-times-animals-combined-i2-delay.png'), dpi=300)\n",
    "# # plt.gcf().savefig(os.path.join(export_dir, 'figure-normalized-times-animals-combined-b8-delay.png'), dpi=300)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### EXPERIMENTAL: NO DELAY"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i, unit in enumerate(['I2', 'B8a/b', 'B6/B9', 'B3', 'B38']):\n",
    "    t0_data   = df_all[f'{unit} first burst start (normalized)'].dropna()\n",
    "    t0_median = t0_data.median()\n",
    "    t0_N      = t0_data.size\n",
    "    \n",
    "    t1_data   = df_all[f'{unit} last burst end (normalized)'].dropna()\n",
    "    t1_median = t1_data.median()\n",
    "    t1_N      = t1_data.size\n",
    "\n",
    "    print(f'{unit}:\\t[{t0_median:.2f} (n={t0_N}), {t1_median:.2f} (n={t1_N})]')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(9, 5))\n",
    "ax = plt.gca()\n",
    "\n",
    "normalization_phases = [\n",
    "    'Previous major\\nforce drop',\n",
    "#     'Previous partial\\nforce maintenance\\nand final drop',\n",
    "    'Previous\\npartial force\\nmaintenance',\n",
    "    'Previous final\\nforce drop',\n",
    "    'Force rise',\n",
    "    'Force\\nmaintenance',\n",
    "    'Major\\nforce drop',\n",
    "    'Partial force\\nmaintenance',\n",
    "    'Final\\nforce drop',\n",
    "]\n",
    "\n",
    "units = ['I2', 'B8a/b', 'B6/B9', 'B3', 'B38']\n",
    "colors = unit_colors\n",
    "colors['I2'] = colors['I2 spikes']\n",
    "colors['Next I2'] = colors['I2 spikes']\n",
    "\n",
    "\n",
    "for i, unit in enumerate(units):\n",
    "    t0_data   = df_all[f'{unit} first burst start (normalized)'].dropna()\n",
    "    t0_median = t0_data.median()\n",
    "    t0_q1     = t0_data.quantile(0.25)\n",
    "    t0_q3     = t0_data.quantile(0.75)\n",
    "    \n",
    "    t1_data   = df_all[f'{unit} last burst end (normalized)'].dropna()\n",
    "    t1_median = t1_data.median()\n",
    "    t1_q1     = t1_data.quantile(0.25)\n",
    "    t1_q3     = t1_data.quantile(0.75)\n",
    "    \n",
    "    # plot boxes using medians\n",
    "    height = 0.8\n",
    "    lw = 1\n",
    "    rect = patches.Rectangle((t0_median, i-height/2), t1_median-t0_median, height, facecolor=colors[unit], edgecolor='k', lw=lw, clip_on=False)\n",
    "    ax.add_patch(rect)\n",
    "    \n",
    "    # plot quartiles (25% and 75% quantiles)\n",
    "    ax.add_line(mlines.Line2D([t0_q1, t0_q1], [i-0.2, i+0.2], color='k', lw=lw, clip_on=False))\n",
    "    ax.add_line(mlines.Line2D([t0_q3, t0_q3], [i-0.2, i+0.2], color='k', lw=lw, clip_on=False))\n",
    "    ax.add_line(mlines.Line2D([t1_q1, t1_q1], [i-0.2, i+0.2], color='k', lw=lw, clip_on=False))\n",
    "    ax.add_line(mlines.Line2D([t1_q3, t1_q3], [i-0.2, i+0.2], color='k', lw=lw, clip_on=False))\n",
    "    ax.add_line(mlines.Line2D([t0_q1, t0_q3], [i, i], color='k', lw=lw, clip_on=False))\n",
    "    ax.add_line(mlines.Line2D([t1_q1, t1_q3], [i, i], color='k', lw=lw, clip_on=False))\n",
    "    \n",
    "    if unit == 'I2':\n",
    "        # plot I2 again shifted one cycle (5 phases)\n",
    "        rect = patches.Rectangle((t0_median+5, i-height/2), t1_median-t0_median, height, facecolor=colors[unit], edgecolor='k', lw=lw, clip_on=False)\n",
    "        ax.add_patch(rect)\n",
    "        ax.add_line(mlines.Line2D([t0_q1+5, t0_q1+5], [i-0.2, i+0.2], color='k', lw=lw, clip_on=False))\n",
    "        ax.add_line(mlines.Line2D([t0_q3+5, t0_q3+5], [i-0.2, i+0.2], color='k', lw=lw, clip_on=False))\n",
    "        ax.add_line(mlines.Line2D([t1_q1+5, t1_q1+5], [i-0.2, i+0.2], color='k', lw=lw, clip_on=False))\n",
    "        ax.add_line(mlines.Line2D([t1_q3+5, t1_q3+5], [i-0.2, i+0.2], color='k', lw=lw, clip_on=False))\n",
    "        ax.add_line(mlines.Line2D([t0_q1+5, t0_q3+5], [i, i], color='k', lw=lw, clip_on=False))\n",
    "        ax.add_line(mlines.Line2D([t1_q1+5, t1_q3+5], [i, i], color='k', lw=lw, clip_on=False))\n",
    "\n",
    "###\n",
    "### LABELS AND ANNOTATIONS\n",
    "###\n",
    "\n",
    "plt.title('WITHOUT MUSCLE DELAY')\n",
    "\n",
    "for x in range(len(normalization_phases)+1):\n",
    "    plt.axvline(x=x, ls=':', c='gray', zorder=-1, clip_on=False)\n",
    "\n",
    "# plt.xlabel('Normalized time')\n",
    "# plt.ylabel('Unit')\n",
    "plt.xlabel(None)\n",
    "plt.ylabel(None)\n",
    "\n",
    "sns.despine(bottom=True, left=True)\n",
    "plt.tick_params(bottom=False, left=False) # disable tick marks\n",
    "plt.xticks(np.arange(len(normalization_phases))+0.5, normalization_phases)\n",
    "plt.yticks(range(len(units)), units)\n",
    "\n",
    "plt.xlim(0, len(normalization_phases))\n",
    "plt.ylim(4.9, -0.5)\n",
    "for x in range(len(normalization_phases)):\n",
    "    plt.annotate('0%',   (x,   4.9), textcoords=\"offset points\", xytext=( 6, 4), ha='left',  size=10)\n",
    "    plt.annotate('100%', (x+1, 4.9), textcoords=\"offset points\", xytext=(-6, 4), ha='right', size=10)\n",
    "\n",
    "plt.tight_layout()\n",
    "\n",
    "plt.gcf().savefig(os.path.join(export_dir, 'figure-normalized-times-animals-combined-no-delay.png'), dpi=300)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plt.figure(figsize=(9, 7))\n",
    "# ax = plt.gca()\n",
    "\n",
    "# df = df_all.reset_index()\n",
    "# df = df.rename(columns={\n",
    "#     'I2 first burst start (normalized)':    'I2',\n",
    "#     'B8a/b first burst start (normalized)': 'B8a/b',\n",
    "#     'B6/B9 first burst start (normalized)': 'B6/B9',\n",
    "#     'B3 first burst start (normalized)':    'B3',\n",
    "#     'B38 first burst start (normalized)':   'B38',\n",
    "#     'Next I2 first burst start (normalized)':   'Next I2'})\n",
    "# df = pd.melt(df,\n",
    "#              id_vars=['Animal', 'Food', 'Bout_index', 'Behavior_index'],\n",
    "#              value_vars=['I2', 'B8a/b', 'B6/B9', 'B3', 'B38', 'Next I2'],\n",
    "#              var_name='Unit',\n",
    "#              value_name='Burst start (normalized)')\n",
    "# sns.boxplot(y='Animal', x='Burst start (normalized)', hue='Unit', data=df, fliersize=0, whis=999) # whis=999 ensures whiskers go to min and max\n",
    "# # sns.swarmplot(y='Animal', x='Burst start (normalized)', hue='Unit', data=df)\n",
    "\n",
    "# df = df_all.reset_index()\n",
    "# df = df.rename(columns={\n",
    "#     'I2 last burst end (normalized)':    'I2',\n",
    "#     'B8a/b last burst end (normalized)': 'B8a/b',\n",
    "#     'B6/B9 last burst end (normalized)': 'B6/B9',\n",
    "#     'B3 last burst end (normalized)':    'B3',\n",
    "#     'B38 last burst end (normalized)':   'B38',\n",
    "#     'Next I2 first burst start (normalized)':   'Next I2'}) # redundant, but ensures ends have same number of boxes as starts\n",
    "# df = pd.melt(df,\n",
    "#              id_vars=['Animal', 'Food', 'Bout_index', 'Behavior_index'],\n",
    "#              value_vars=['I2', 'B8a/b', 'B6/B9', 'B3', 'B38', 'Next I2'],\n",
    "#              var_name='Unit',\n",
    "#              value_name='Burst end (normalized)')\n",
    "# sns.boxplot(y='Animal', x='Burst end (normalized)', hue='Unit', data=df, fliersize=0, whis=999) # whis=999 ensures whiskers go to min and max\n",
    "# # sns.swarmplot(y='Animal', x='Burst start (normalized)', hue='Unit', data=df)\n",
    "\n",
    "# plt.axvline(x=0, ls=':', c='gray', zorder=-1)\n",
    "# plt.axvline(x=1, ls=':', c='gray', zorder=-1)\n",
    "# plt.axvline(x=2, ls=':', c='gray', zorder=-1)\n",
    "# plt.axvline(x=3, ls=':', c='gray', zorder=-1)\n",
    "# plt.axvline(x=4, ls=':', c='gray', zorder=-1)\n",
    "# plt.axvline(x=5, ls=':', c='gray', zorder=-1)\n",
    "# plt.axvline(x=6, ls=':', c='gray', zorder=-1)\n",
    "\n",
    "# plt.gca().get_legend().remove()\n",
    "\n",
    "# plt.tight_layout()\n",
    "\n",
    "# # plt.gcf().savefig(os.path.join(export_dir, 'figure-6B.png'), dpi=300)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Un-normalized"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(9, 5))\n",
    "ax = plt.gca()\n",
    "\n",
    "# use times from an exemplary force record\n",
    "normalization_fixed_times = df_exemplary_swallow.loc[0, 'Normalization fixed times (s)'].copy()\n",
    "normalization_fixed_times -= normalization_fixed_times[3]\n",
    "normalization_fixed_times\n",
    "\n",
    "normalization_phases = [\n",
    "    'Previous major\\nforce drop',\n",
    "#     'Previous partial\\nforce maintenance\\nand final drop',\n",
    "    'Previous\\npartial force\\nmaintenance',\n",
    "    'Previous final\\nforce drop',\n",
    "    'Force rise',\n",
    "    'Force\\nmaintenance',\n",
    "    'Major\\nforce drop',\n",
    "    'Partial force\\nmaintenance',\n",
    "    'Final\\nforce drop',\n",
    "]\n",
    "\n",
    "units = ['I2', 'B8a/b', 'B6/B9', 'B3', 'B38']\n",
    "colors = unit_colors\n",
    "colors['I2'] = colors['I2 spikes']\n",
    "colors['Next I2'] = colors['I2 spikes']\n",
    "\n",
    "\n",
    "for i, unit in enumerate(units):\n",
    "    t0_data   = df_all[f'{unit} first burst start (normalized)'].dropna()\n",
    "    t0_data[:] = [unnormalize_time(normalization_fixed_times, t) for t in t0_data]\n",
    "    t0_median = t0_data.median()\n",
    "    t0_q1     = t0_data.quantile(0.25)\n",
    "    t0_q3     = t0_data.quantile(0.75)\n",
    "    \n",
    "    t1_data   = df_all[f'{unit} last burst end (normalized)'].dropna()\n",
    "    t1_data[:] = [unnormalize_time(normalization_fixed_times, t) for t in t1_data]\n",
    "    t1_median = t1_data.median()\n",
    "    t1_q1     = t1_data.quantile(0.25)\n",
    "    t1_q3     = t1_data.quantile(0.75)\n",
    "    \n",
    "    # plot boxes using medians\n",
    "    height = 0.8\n",
    "    lw = 1\n",
    "    rect = patches.Rectangle((t0_median, i-height/2), t1_median-t0_median, height, facecolor=colors[unit], edgecolor='k', lw=lw, clip_on=False)\n",
    "    ax.add_patch(rect)\n",
    "    \n",
    "    # plot quartiles (25% and 75% quantiles)\n",
    "    ax.add_line(mlines.Line2D([t0_q1, t0_q1], [i-0.2, i+0.2], color='k', lw=lw, clip_on=False))\n",
    "    ax.add_line(mlines.Line2D([t0_q3, t0_q3], [i-0.2, i+0.2], color='k', lw=lw, clip_on=False))\n",
    "    ax.add_line(mlines.Line2D([t1_q1, t1_q1], [i-0.2, i+0.2], color='k', lw=lw, clip_on=False))\n",
    "    ax.add_line(mlines.Line2D([t1_q3, t1_q3], [i-0.2, i+0.2], color='k', lw=lw, clip_on=False))\n",
    "    ax.add_line(mlines.Line2D([t0_q1, t0_q3], [i, i], color='k', lw=lw, clip_on=False))\n",
    "    ax.add_line(mlines.Line2D([t1_q1, t1_q3], [i, i], color='k', lw=lw, clip_on=False))\n",
    "    \n",
    "    if unit == 'I2':\n",
    "        # plot I2 again shifted one cycle (5 phases)\n",
    "        shift = 5\n",
    "        t0_data   = df_all[f'{unit} first burst start (normalized)'].dropna()\n",
    "        t0_data[:] = [unnormalize_time(normalization_fixed_times, t+shift) for t in t0_data]\n",
    "        t0_median = t0_data.median()\n",
    "        t0_q1     = t0_data.quantile(0.25)\n",
    "        t0_q3     = t0_data.quantile(0.75)\n",
    "        t1_data   = df_all[f'{unit} last burst end (normalized)'].dropna()\n",
    "        t1_data[:] = [unnormalize_time(normalization_fixed_times, t+shift) for t in t1_data]\n",
    "        t1_median = t1_data.median()\n",
    "        t1_q1     = t1_data.quantile(0.25)\n",
    "        t1_q3     = t1_data.quantile(0.75)\n",
    "        rect = patches.Rectangle((t0_median, i-height/2), t1_median-t0_median, height, facecolor=colors[unit], edgecolor='k', lw=lw, clip_on=False)\n",
    "        ax.add_patch(rect)\n",
    "        ax.add_line(mlines.Line2D([t0_q1, t0_q1], [i-0.2, i+0.2], color='k', lw=lw, clip_on=False))\n",
    "        ax.add_line(mlines.Line2D([t0_q3, t0_q3], [i-0.2, i+0.2], color='k', lw=lw, clip_on=False))\n",
    "        ax.add_line(mlines.Line2D([t1_q1, t1_q1], [i-0.2, i+0.2], color='k', lw=lw, clip_on=False))\n",
    "        ax.add_line(mlines.Line2D([t1_q3, t1_q3], [i-0.2, i+0.2], color='k', lw=lw, clip_on=False))\n",
    "        ax.add_line(mlines.Line2D([t0_q1, t0_q3], [i, i], color='k', lw=lw, clip_on=False))\n",
    "        ax.add_line(mlines.Line2D([t1_q1, t1_q3], [i, i], color='k', lw=lw, clip_on=False))\n",
    "\n",
    "###\n",
    "### LABELS AND ANNOTATIONS\n",
    "###\n",
    "\n",
    "plt.title('WITHOUT MUSCLE DELAY')\n",
    "\n",
    "for x in normalization_fixed_times:\n",
    "    plt.axvline(x=x, ls=':', c='gray', zorder=-1, clip_on=False)\n",
    "\n",
    "# plt.xlabel('Normalized time')\n",
    "# plt.ylabel('Unit')\n",
    "plt.xlabel(None)\n",
    "plt.ylabel(None)\n",
    "\n",
    "sns.despine(bottom=True, left=True)\n",
    "plt.tick_params(bottom=False, left=False) # disable tick marks\n",
    "plt.xticks(normalization_fixed_times[:-1]+np.diff(normalization_fixed_times)/2, normalization_phases)\n",
    "plt.yticks(range(len(units)), units)\n",
    "\n",
    "plt.xlim(normalization_fixed_times[0], normalization_fixed_times[-1])\n",
    "plt.ylim(4.9, -0.5)\n",
    "for i in range(len(normalization_fixed_times)-1):\n",
    "    plt.annotate('0%',   (normalization_fixed_times[i],   4.9), textcoords=\"offset points\", xytext=( 6, 4), ha='left',  size=10)\n",
    "    plt.annotate('100%', (normalization_fixed_times[i+1], 4.9), textcoords=\"offset points\", xytext=(-6, 4), ha='right', size=10)\n",
    "\n",
    "plt.tight_layout()\n",
    "\n",
    "plt.gcf().savefig(os.path.join(export_dir, 'figure-unnormalized-times-animals-combined-no-delay.png'), dpi=300)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plt.figure(figsize=(9, 5))\n",
    "# ax = plt.gca()\n",
    "\n",
    "# # use times from an exemplary force record\n",
    "# normalization_fixed_times = df_exemplary_swallow.loc[0, 'Normalization fixed times (s)'].copy()\n",
    "# normalization_fixed_times -= normalization_fixed_times[3]\n",
    "# normalization_fixed_times\n",
    "\n",
    "# normalization_phases = [\n",
    "#     'Previous major\\nforce drop',\n",
    "# #     'Previous partial\\nforce maintenance\\nand final drop',\n",
    "#     'Previous\\npartial force\\nmaintenance',\n",
    "#     'Previous final\\nforce drop',\n",
    "#     'Force rise',\n",
    "#     'Force\\nmaintenance',\n",
    "#     'Major\\nforce drop',\n",
    "#     'Partial force\\nmaintenance',\n",
    "#     'Final\\nforce drop',\n",
    "# ]\n",
    "\n",
    "# units = ['I2', 'B8a/b', 'B6/B9', 'B3', 'B38']\n",
    "# colors = unit_colors\n",
    "# colors['I2'] = colors['I2 spikes']\n",
    "# colors['Next I2'] = colors['I2 spikes']\n",
    "\n",
    "\n",
    "# for i, unit in enumerate(units):\n",
    "#     t0_data   = df_all[f'{unit} first burst start (delayed normalized)'].dropna()\n",
    "# #     if unit == 'B8a/b':\n",
    "# #         # because of the way the muscle delay is estimated, B8 start time for the first\n",
    "# #         # swallow in each bout is equal to the force rise time by definition, so we\n",
    "# #         # remove those data points so they don't affect the distibution\n",
    "# #         t0_data = t0_data.drop(level='Behavior_index', index=0)\n",
    "#     t0_data[:] = [unnormalize_time(normalization_fixed_times, t) for t in t0_data]\n",
    "#     t0_median = t0_data.median()\n",
    "#     t0_q1     = t0_data.quantile(0.25)\n",
    "#     t0_q3     = t0_data.quantile(0.75)\n",
    "    \n",
    "#     t1_data   = df_all[f'{unit} last burst end (delayed normalized)'].dropna()\n",
    "#     if unit == 'I2':\n",
    "#         # because of the way the muscle delay is estimated, I2 end time for the first\n",
    "#         # swallow in each bout is equal to the force rise time by definition, so we\n",
    "#         # remove those data points so they don't affect the distibution\n",
    "#         t1_data = t1_data.drop(level='Behavior_index', index=0)\n",
    "#     t1_data[:] = [unnormalize_time(normalization_fixed_times, t) for t in t1_data]\n",
    "#     t1_median = t1_data.median()\n",
    "#     t1_q1     = t1_data.quantile(0.25)\n",
    "#     t1_q3     = t1_data.quantile(0.75)\n",
    "    \n",
    "#     # plot boxes using medians\n",
    "#     height = 0.8\n",
    "#     lw = 1\n",
    "#     rect = patches.Rectangle((t0_median, i-height/2), t1_median-t0_median, height, facecolor=colors[unit], edgecolor='k', lw=lw, clip_on=False)\n",
    "#     ax.add_patch(rect)\n",
    "    \n",
    "#     # plot quartiles (25% and 75% quantiles)\n",
    "#     ax.add_line(mlines.Line2D([t0_q1, t0_q1], [i-0.2, i+0.2], color='k', lw=lw, clip_on=False))\n",
    "#     ax.add_line(mlines.Line2D([t0_q3, t0_q3], [i-0.2, i+0.2], color='k', lw=lw, clip_on=False))\n",
    "#     ax.add_line(mlines.Line2D([t1_q1, t1_q1], [i-0.2, i+0.2], color='k', lw=lw, clip_on=False))\n",
    "#     ax.add_line(mlines.Line2D([t1_q3, t1_q3], [i-0.2, i+0.2], color='k', lw=lw, clip_on=False))\n",
    "#     ax.add_line(mlines.Line2D([t0_q1, t0_q3], [i, i], color='k', lw=lw, clip_on=False))\n",
    "#     ax.add_line(mlines.Line2D([t1_q1, t1_q3], [i, i], color='k', lw=lw, clip_on=False))\n",
    "    \n",
    "#     if unit == 'I2':\n",
    "#         # plot I2 again shifted one cycle (5 phases)\n",
    "#         shift = 5\n",
    "#         t0_data   = df_all[f'{unit} first burst start (delayed normalized)'].dropna()\n",
    "#         t0_data   = pd.Series([unnormalize_time(normalization_fixed_times, t+shift) for t in t0_data])\n",
    "#         t0_median = t0_data.median()\n",
    "#         t0_q1     = t0_data.quantile(0.25)\n",
    "#         t0_q3     = t0_data.quantile(0.75)\n",
    "#         t1_data   = df_all[f'{unit} last burst end (delayed normalized)'].dropna()\n",
    "#         t1_data   = pd.Series([unnormalize_time(normalization_fixed_times, t+shift) for t in t1_data])\n",
    "#         t1_median = t1_data.median()\n",
    "#         t1_q1     = t1_data.quantile(0.25)\n",
    "#         t1_q3     = t1_data.quantile(0.75)\n",
    "#         rect = patches.Rectangle((t0_median, i-height/2), t1_median-t0_median, height, facecolor=colors[unit], edgecolor='k', lw=lw, clip_on=False)\n",
    "#         ax.add_patch(rect)\n",
    "#         ax.add_line(mlines.Line2D([t0_q1, t0_q1], [i-0.2, i+0.2], color='k', lw=lw, clip_on=False))\n",
    "#         ax.add_line(mlines.Line2D([t0_q3, t0_q3], [i-0.2, i+0.2], color='k', lw=lw, clip_on=False))\n",
    "#         ax.add_line(mlines.Line2D([t1_q1, t1_q1], [i-0.2, i+0.2], color='k', lw=lw, clip_on=False))\n",
    "#         ax.add_line(mlines.Line2D([t1_q3, t1_q3], [i-0.2, i+0.2], color='k', lw=lw, clip_on=False))\n",
    "#         ax.add_line(mlines.Line2D([t0_q1, t0_q3], [i, i], color='k', lw=lw, clip_on=False))\n",
    "#         ax.add_line(mlines.Line2D([t1_q1, t1_q3], [i, i], color='k', lw=lw, clip_on=False))\n",
    "\n",
    "# ###\n",
    "# ### LABELS AND ANNOTATIONS\n",
    "# ###\n",
    "\n",
    "# plt.title('WITH MUSCLE DELAY (I2 END TO FORCE RISE START)')\n",
    "# # plt.title('WITH MUSCLE DELAY (B8 START TO FORCE RISE START)')\n",
    "\n",
    "# for x in normalization_fixed_times:\n",
    "#     plt.axvline(x=x, ls=':', c='gray', zorder=-1, clip_on=False)\n",
    "\n",
    "# # plt.xlabel('Normalized time')\n",
    "# # plt.ylabel('Unit')\n",
    "# plt.xlabel(None)\n",
    "# plt.ylabel(None)\n",
    "\n",
    "# sns.despine(bottom=True, left=True)\n",
    "# plt.tick_params(bottom=False, left=False) # disable tick marks\n",
    "# plt.xticks(normalization_fixed_times[:-1]+np.diff(normalization_fixed_times)/2, normalization_phases)\n",
    "# plt.yticks(range(len(units)), units)\n",
    "\n",
    "# plt.xlim(normalization_fixed_times[0], normalization_fixed_times[-1])\n",
    "# plt.ylim(4.9, -0.5)\n",
    "# for i in range(len(normalization_fixed_times)-1):\n",
    "#     plt.annotate('0%',   (normalization_fixed_times[i],   4.9), textcoords=\"offset points\", xytext=( 6, 4), ha='left',  size=10)\n",
    "#     plt.annotate('100%', (normalization_fixed_times[i+1], 4.9), textcoords=\"offset points\", xytext=(-6, 4), ha='right', size=10)\n",
    "\n",
    "# plt.tight_layout()\n",
    "\n",
    "# plt.gcf().savefig(os.path.join(export_dir, 'figure-unnormalized-times-animals-combined-i2-delay.png'), dpi=300)\n",
    "# # plt.gcf().savefig(os.path.join(export_dir, 'figure-unnormalized-times-animals-combined-b8-delay.png'), dpi=300)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## [FIGURE ??] Exemplary swallow bout"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "start = datetime.datetime.now()\n",
    "\n",
    "df = df_exemplary_bout\n",
    "(data_set_name, channel_names, time_window, epoch_types_to_keep, burst_thresholds) = feeding_bouts[exemplary_bout]\n",
    "\n",
    "t_start, t_stop = time_window*pq.s\n",
    "# plots = [\n",
    "#     {'channel': 'I2',       'units': 'uV', 'ylim': [ -60,  60], 'scalebar': 50}, #, 'decimation_factor': 100},\n",
    "#     {'channel': 'RN',       'units': 'uV', 'ylim': [ -25,  25], 'scalebar': 25}, #, 'decimation_factor': 100},\n",
    "#     {'channel': 'BN2',      'units': 'uV', 'ylim': [ -45,  45], 'scalebar': 50}, #, 'decimation_factor': 100},\n",
    "#     {'channel': 'BN3-DIST', 'units': 'uV', 'ylim': [ -60,  60], 'scalebar': 50, 'ylabel': 'BN3'}, #, 'decimation_factor': 100},\n",
    "#     {'channel': 'Force',    'units': 'mN', 'ylim': [ -50, 450], 'scalebar': 300, 'decimation_factor': 100},\n",
    "# ]\n",
    "plots = [\n",
    "    {'channel': 'I2',       'units': 'uV', 'ylim': [ -60,  60], 'scalebar': 50, 'decimation_factor': 100},\n",
    "    {'channel': 'RN',       'units': 'uV', 'ylim': [ -25,  25], 'scalebar': 25, 'decimation_factor': 100},\n",
    "    {'channel': 'BN2',      'units': 'uV', 'ylim': [ -45,  45], 'scalebar': 50, 'decimation_factor': 100},\n",
    "    {'channel': 'BN3-DIST', 'units': 'uV', 'ylim': [ -60,  60], 'scalebar': 50, 'ylabel': 'BN3', 'decimation_factor': 100},\n",
    "    {'channel': 'Force',    'units': 'mN', 'ylim': [ -50, 450], 'scalebar': 300, 'decimation_factor': 100},\n",
    "]\n",
    "channel_names = [p['channel'] for p in plots]\n",
    "channel_units = [p['units'] for p in plots]\n",
    "\n",
    "kwargs = dict(\n",
    "    figsize = (12, 6),\n",
    "    linewidth = 0.5,\n",
    "    x_scalebar = 10*pq.s,\n",
    ")\n",
    "\n",
    "# load the data\n",
    "metadata = neurotic.MetadataSelector('../../data/metadata.yml')\n",
    "metadata.select(data_set_name)\n",
    "blk = neurotic.load_dataset(metadata) # not lazy so that I2 filter is applied\n",
    "\n",
    "# plot the signal\n",
    "fig, axes = prettyplot_with_scalebars(blk, t_start, t_stop, plots, **kwargs)\n",
    "\n",
    "units = [\n",
    "    'I2 spikes',\n",
    "    'B8a/b',\n",
    "    'B6/B9',\n",
    "    'B3',\n",
    "    'B38',\n",
    "]\n",
    "unit_burst_boxes = {\n",
    "    'I2 spikes': [-35, 30],\n",
    "    'B8a/b':     [-20, 12],\n",
    "    'B6/B9':     [-15, 12],\n",
    "    'B3':        [-45, 35],\n",
    "    'B38':       [-12, 12],\n",
    "}\n",
    "\n",
    "# plot a zero baseline for force\n",
    "ax = axes[channel_names.index('Force')]\n",
    "force_zero = -11.5 # mN, average before animal began swallowing, not zero because of DC offset\n",
    "ax.axhline(force_zero, color='0.75', lw=1, ls='--')\n",
    "\n",
    "for j, i in enumerate(df.index):\n",
    "    for k, unit in enumerate(units):\n",
    "        st = df.loc[i, unit+' spike train']\n",
    "        if st is not None and st.size > 0:\n",
    "                \n",
    "            # get the neural channel\n",
    "            channel = st.annotations['channels'][0]\n",
    "            sig = get_sig(blk, channel)\n",
    "\n",
    "            # get the signal for the entire bout\n",
    "            sig = sig.time_slice(t_start, t_stop)\n",
    "            sig = sig.rescale(channel_units[channel_names.index(channel)])\n",
    "\n",
    "            # plot spikes\n",
    "            ax = axes[channel_names.index(channel)]\n",
    "            spike_amplitudes = np.array([sig[sig.time_index(t)] for t in st]) * pq.Quantity(sig.units)\n",
    "            ax.scatter(st.times.rescale('s'), spike_amplitudes, marker='.', s=4, c=unit_colors[unit], zorder=3)\n",
    "\n",
    "            # plot burst windows\n",
    "            bursts = df.at[i, unit+' all bursts (s)']\n",
    "            bottom, top = unit_burst_boxes[unit]\n",
    "            height = top-bottom\n",
    "            for burst in bursts:\n",
    "                if is_good_burst(burst):\n",
    "                    left = burst['Start (s)']\n",
    "                    right = burst['End (s)']\n",
    "                    width = right-left\n",
    "                    rect = patches.Rectangle((left, bottom), width, height, linewidth=2, ls='-', edgecolor=unit_colors[unit], fill=False, zorder=3, clip_on=False)\n",
    "                    ax.add_patch(rect)\n",
    "\n",
    "fig.savefig(os.path.join(export_dir, 'figure-exemplary-bout-export.png'), dpi=600)\n",
    "\n",
    "end = datetime.datetime.now()\n",
    "print('render time:', end-start)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## [FIGURE 3A] Exemplary swallow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "start = datetime.datetime.now()\n",
    "\n",
    "df = df_exemplary_swallow\n",
    "(data_set_name, channel_names, time_window, epoch_types_to_keep, burst_thresholds) = feeding_bouts[exemplary_swallow]\n",
    "\n",
    "t_start = (df.loc[0, 'I2 spikes first burst start (s)'] - 0.4)*pq.s\n",
    "t_stop = (df.loc[0, 'Next force rise start (s)'] + 0.4)*pq.s\n",
    "plots = [\n",
    "    {'channel': 'I2',       'units': 'uV', 'ylim': [ -60,  60], 'scalebar': 50}, #, 'decimation_factor': 100},\n",
    "    {'channel': 'RN',       'units': 'uV', 'ylim': [ -25,  25], 'scalebar': 25}, #, 'decimation_factor': 100},\n",
    "    {'channel': 'BN2',      'units': 'uV', 'ylim': [ -45,  45], 'scalebar': 50}, #, 'decimation_factor': 100},\n",
    "    {'channel': 'BN3-DIST', 'units': 'uV', 'ylim': [ -60,  60], 'scalebar': 50, 'ylabel': 'BN3'}, #, 'decimation_factor': 100},\n",
    "    {'channel': 'Force',    'units': 'mN', 'ylim': [ -50, 260], 'scalebar': 100, 'decimation_factor': 100},\n",
    "]\n",
    "# plots = [\n",
    "#     {'channel': 'I2',       'units': 'uV', 'ylim': [ -60,  60], 'scalebar': 50, 'decimation_factor': 100},\n",
    "#     {'channel': 'RN',       'units': 'uV', 'ylim': [ -25,  25], 'scalebar': 25, 'decimation_factor': 100},\n",
    "#     {'channel': 'BN2',      'units': 'uV', 'ylim': [ -45,  45], 'scalebar': 50, 'decimation_factor': 100},\n",
    "#     {'channel': 'BN3-DIST', 'units': 'uV', 'ylim': [ -60,  60], 'scalebar': 50, 'ylabel': 'BN3', 'decimation_factor': 100},\n",
    "#     {'channel': 'Force',    'units': 'mN', 'ylim': [ -50, 260], 'scalebar': 100, 'decimation_factor': 100},\n",
    "# ]\n",
    "channel_names = [p['channel'] for p in plots]\n",
    "channel_units = [p['units'] for p in plots]\n",
    "\n",
    "kwargs = dict(\n",
    "    figsize = (7, 8),\n",
    "    linewidth = 0.5,\n",
    "    x_scalebar = 1*pq.s,\n",
    ")\n",
    "\n",
    "# load the metadata\n",
    "metadata = neurotic.MetadataSelector('../../data/metadata.yml')\n",
    "metadata.select(data_set_name)\n",
    "\n",
    "# add/update the force filter\n",
    "new_force_filter = {'channel': 'Force', 'lowpass': 10}\n",
    "update_filter(metadata, new_force_filter)\n",
    "\n",
    "# load the data\n",
    "blk = neurotic.load_dataset(metadata) # not lazy so that I2 and force filters are applied\n",
    "\n",
    "# plot the signal\n",
    "fig, axes = prettyplot_with_scalebars(blk, t_start, t_stop, plots, **kwargs)\n",
    "\n",
    "units = [\n",
    "    'I2 spikes',\n",
    "    'B8a/b',\n",
    "    'B6/B9',\n",
    "    'B3',\n",
    "    'B38',\n",
    "]\n",
    "unit_burst_boxes = {\n",
    "    'I2 spikes': [-35, 45],\n",
    "    'B8a/b':     [-20, 12],\n",
    "    'B6/B9':     [-15, 12],\n",
    "    'B3':        [-45, 35],\n",
    "    'B38':       [-12, 12],\n",
    "}\n",
    "\n",
    "ax = axes[channel_names.index('Force')]\n",
    "\n",
    "# plot a zero baseline for force\n",
    "# force_zero = -11.5 # mN, average before animal began swallowing, not zero because of DC offset\n",
    "# ax.axhline(force_zero, color='0.75', lw=1, ls='--')\n",
    "\n",
    "# add roman numerals for force phases\n",
    "times = df.loc[0, 'Normalization fixed times (s)'][3:8]\n",
    "for t in times:\n",
    "    ax.axvline(x=t, lw=1, ls=':', c='gray', zorder=-1, clip_on=False)\n",
    "#     axes[-1].add_artist(patches.ConnectionPatch(\n",
    "#         xyA=(t, 0), xyB=(t, 1),\n",
    "#         coordsA=axes[-1].get_xaxis_transform(), coordsB=axes[0].get_xaxis_transform(),\n",
    "#         axesA=axes[-1], axesB=axes[0],\n",
    "#         color='gray', lw=1, ls=':', zorder=-1))\n",
    "\n",
    "# add roman numerals for force phases\n",
    "ax.annotate('I',   xy=(times[0],          5), xycoords=('data', 'axes points'), ha='right',  # min\n",
    "                                              xytext=(-5, 0), textcoords='offset points')\n",
    "ax.annotate('II',  xy=(times[0:2].mean(), 5), xycoords=('data', 'axes points'), ha='center') # rise\n",
    "ax.annotate('III', xy=(times[1:3].mean(), 5), xycoords=('data', 'axes points'), ha='center') # plateau\n",
    "ax.annotate('IV',  xy=(times[2:4].mean(), 5), xycoords=('data', 'axes points'), ha='center') # drop\n",
    "ax.annotate('V',   xy=(times[3:5].mean(), 5), xycoords=('data', 'axes points'), ha='center') # shoulder\n",
    "ax.annotate('VI',  xy=(times[4],          5), xycoords=('data', 'axes points'), ha='left',   # dip\n",
    "                                              xytext=( 5, 0), textcoords='offset points')\n",
    "\n",
    "for j, i in enumerate(df.index):\n",
    "    for k, unit in enumerate(units):\n",
    "        st = df.loc[i, unit+' spike train']\n",
    "        if st is not None and st.size > 0:\n",
    "\n",
    "            # get the neural channel\n",
    "            channel = st.annotations['channels'][0]\n",
    "            sig = get_sig(blk, channel)\n",
    "\n",
    "            # get the signal for the entire bout\n",
    "            sig = sig.time_slice(t_start, t_stop)\n",
    "            sig = sig.rescale(channel_units[channel_names.index(channel)])\n",
    "\n",
    "            # plot spikes\n",
    "            ax = axes[channel_names.index(channel)]\n",
    "            spike_amplitudes = np.array([sig[sig.time_index(t)] for t in st]) * pq.Quantity(sig.units)\n",
    "            ax.scatter(st.times.rescale('s'), spike_amplitudes, marker='.', s=20, c=unit_colors[unit], zorder=3)\n",
    "\n",
    "            # plot burst windows\n",
    "            bursts = df.at[i, unit+' all bursts (s)']\n",
    "            bottom, top = unit_burst_boxes[unit]\n",
    "            height = top-bottom\n",
    "            for burst in bursts:\n",
    "                if is_good_burst(burst):\n",
    "                    left = burst['Start (s)']\n",
    "                    right = burst['End (s)']\n",
    "                    width = right-left\n",
    "                    rect = patches.Rectangle((left, bottom), width, height, linewidth=2, ls='-', edgecolor=unit_colors[unit], fill=False, zorder=3, clip_on=False)\n",
    "                    ax.add_patch(rect)\n",
    "\n",
    "fig.savefig(os.path.join(export_dir, 'figure-exemplary-swallow-export.png'), dpi=600)\n",
    "\n",
    "end = datetime.datetime.now()\n",
    "print('render time:', end-start)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
