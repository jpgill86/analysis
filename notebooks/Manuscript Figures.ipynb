{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Import Packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import quantities as pq\n",
    "import elephant\n",
    "import pandas as pd\n",
    "import statsmodels.api as sm\n",
    "import neurotic\n",
    "from neurotic.datasets.data import _detect_spikes\n",
    "from utils import BehaviorsDataFrame\n",
    "\n",
    "pq.markup.config.use_unicode = True  # allow symbols like mu for micro in output\n",
    "pq.mN = pq.UnitQuantity('millinewton', pq.N/1e3, symbol = 'mN');  # define millinewton\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.patches as patches\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# IPython Magics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# make figures interactive and open in a separate window\n",
    "# %matplotlib qt\n",
    "\n",
    "# make figures interactive and inline\n",
    "%matplotlib notebook\n",
    "\n",
    "# make figures non-interactive and inline\n",
    "# %matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Plot Settings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# color map\n",
    "cm = plt.cm.cool\n",
    "# cm = plt.cm.brg\n",
    "# cm = plt.cm.RdBu\n",
    "\n",
    "sns.set(\n",
    "#     context = 'poster',\n",
    "    style = 'ticks',\n",
    "    font_scale = 1,\n",
    "    font = 'Palatino Linotype',\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "markers = ['.', '+', 'x', '1', '4', 'o', 'D']\n",
    "colors = ['C0', 'C1', 'C2', 'C3', 'C4', 'C5', 'C6']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "feeding_bouts = {\n",
    "    # (animal, food, bout_index): (\n",
    "    #     data_set_name,\n",
    "    #     channels_to_keep,\n",
    "    #     time_window,\n",
    "    #     epoch_types_to_keep)\n",
    "    \n",
    "    ('JG08', 'Tape nori', 0): (\n",
    "        'IN VIVO / JG08 / 2018-06-21 / 002',\n",
    "        ['I2', 'RN', 'BN2', 'BN3', 'Force'],\n",
    "        [148, 208], # 7 swallows, some bucket and head movement\n",
    "        ['Swallow (tape nori)']),\n",
    "\n",
    "    ('JG12', 'Tape nori', 0): (\n",
    "        'IN VIVO / JG12 / 2019-05-10 / 002',\n",
    "        ['I2', 'RN', 'BN2', 'BN3-DIST', 'Force'],\n",
    "        [437, 465], # 4 swallows\n",
    "        ['Swallow (tape nori)']),\n",
    "    \n",
    "    ('JG12', 'Tape nori', 1): (\n",
    "        'IN VIVO / JG12 / 2019-05-10 / 002',\n",
    "        ['I2', 'RN', 'BN2', 'BN3-DIST', 'Force'],\n",
    "        [2901, 2937], # 5 swallows\n",
    "        ['Swallow (tape nori)']),\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Import and Process the Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def query_union(queries):\n",
    "    return '|'.join([f'({q})' for q in queries if q is not None])\n",
    "\n",
    "def label2query(label):\n",
    "    animal, food = label[:4], label[5:]\n",
    "    query = f'(Animal == \"{animal}\") & (Food == \"{food}\")'\n",
    "    return query\n",
    "\n",
    "def contains(series, string):\n",
    "#     return np.array([string in x for x in series])\n",
    "    return series.map(lambda x: string in x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# use Neo RawIO lazy loading to load much faster and using less memory\n",
    "# - with lazy=True, filtering parameters specified in metadata are ignored\n",
    "# - with lazy=True, loading via time_slice requires neo>=0.8.0.dev\n",
    "lazy = True # IMPORTANT: force and I2 filters affect smoothness and possibly threshold crossings and spike detection\n",
    "\n",
    "# load the metadata containing file paths\n",
    "metadata = neurotic.MetadataSelector(file='../../data/metadata.yml')\n",
    "\n",
    "# filter epochs for each bout and perform calculations\n",
    "df_list = []\n",
    "last_data_set_name = None\n",
    "for (animal, food, bout_index), (data_set_name, channels_to_keep, time_window, epoch_types_to_keep) in feeding_bouts.items():\n",
    "    \n",
    "    ###\n",
    "    ### LOCATE BEHAVIOR EPOCHS AND SUBEPOCHS\n",
    "    ###\n",
    "    \n",
    "    metadata.select(data_set_name)\n",
    "    if data_set_name is last_data_set_name:\n",
    "        # skip reloading the data if it's already in memory\n",
    "        pass\n",
    "    else:\n",
    "        blk = neurotic.load_dataset(metadata, lazy=lazy)\n",
    "    last_data_set_name = data_set_name\n",
    "    \n",
    "    # construct a query for locating behaviors\n",
    "    behavior_query = f'(Type in {epoch_types_to_keep}) & ({time_window[0]} <= Start) & (End <= {time_window[1]})'\n",
    "    \n",
    "    # construct queries for locating epochs associated with each behavior\n",
    "    # - each query should match at most one epoch\n",
    "    # - dictionary keys are used as prefixes for the names of new columns\n",
    "    subepoch_queries = {}\n",
    "    \n",
    "    subepoch_queries['I2 protraction activity'] = f'(Type == \"I2 protraction activity\") & ' \\\n",
    "                                                  f'(@behavior_start-0.5 <= Start) & (End <= @behavior_end)' # must start no earlier than 0.5 seconds before behavior and end within it\n",
    "    \n",
    "    subepoch_queries['B8 activity']             = f'(Type == \"B8 activity\") & ' \\\n",
    "                                                  f'(@behavior_start <= Start) & (End <= @behavior_end)' # must be fully contained within behavior\n",
    "    \n",
    "    subepoch_queries['B3/6/9/10 activity']      = f'(Type == \"B3/6/9/10 activity\") & ' \\\n",
    "                                                  f'(@behavior_start <= Start) & (End <= @behavior_end)' # must be fully contained within behavior\n",
    "\n",
    "    subepoch_queries['B38 activity']            = f'(Type == \"B38 activity\") & ' \\\n",
    "                                                  f'(@behavior_end-2 <= Start) & (Start <= @behavior_end+2)' # must start within 2 seconds of behavior end\n",
    "\n",
    "    subepoch_queries['Force dip']               = f'(Type == \"Force dip\") & ' \\\n",
    "                                                  f'(@behavior_start <= Start) & (End <= @behavior_end)' # must be fully contained within behavior\n",
    "    \n",
    "    subepoch_queries['Force shoulder']          = f'(Type == \"Force shoulder\") & ' \\\n",
    "                                                  f'(@behavior_end-2 <= Start) & (Start <= @behavior_end+2)' # must start within 2 seconds of behavior end\n",
    "    \n",
    "    # construct a table in which each row is a behavior and subepoch data\n",
    "    # is added as columns, e.g. df['Force start (s)']\n",
    "    df = BehaviorsDataFrame(blk.segments[0].epochs, behavior_query, subepoch_queries)\n",
    "\n",
    "    ###\n",
    "    ### PERFORM CALCULATIONS\n",
    "    ###\n",
    "\n",
    "    # sanity check: plot all channels for entire time window\n",
    "    plt.figure(figsize=(8,10))\n",
    "    axes = []\n",
    "    channel_units = ['uV', 'uV', 'uV', 'uV', 'mN']\n",
    "    for i, channel in enumerate(channels_to_keep):\n",
    "        if i == 0:\n",
    "            ax = plt.subplot(len(channels_to_keep), 1, i+1)\n",
    "        else:\n",
    "            ax = plt.subplot(len(channels_to_keep), 1, i+1, sharex=axes[0])\n",
    "        axes += [ax]\n",
    "        sig = next((sig for sig in blk.segments[0].analogsignals if sig.name==channel), None)\n",
    "        if sig is None:\n",
    "            raise Exception(f'For data set \"{data_set_name}\", channel \"{channel}\" could not be found')\n",
    "        sig = sig.time_slice(time_window[0]*pq.s, time_window[1]*pq.s)\n",
    "        sig = sig.rescale(channel_units[i])\n",
    "        plt.plot(sig.times, sig.magnitude, c='0.8', lw=1, zorder=-1)\n",
    "        if i == 0:\n",
    "            plt.title(f'({animal}, {food}, {bout_index}): {data_set_name}')\n",
    "        plt.xlabel('Time (s)')\n",
    "        plt.ylabel(sig.name + ' (' + sig.units.dimensionality.string + ')')\n",
    "    \n",
    "    \n",
    "    \n",
    "    # quantify force in each behavior\n",
    "    channel = 'Force'\n",
    "    for i in df.index:\n",
    "        \n",
    "        behavior_start = df.loc[i, 'Start (s)']*pq.s\n",
    "        behavior_end = df.loc[i, 'End (s)']*pq.s\n",
    "        force_dip_start = df.loc[i, 'Force dip start (s)']*pq.s\n",
    "        force_rise_start = df.loc[i, 'Force rise start (s)'] = df.loc[i, 'Force dip end (s)']*pq.s\n",
    "\n",
    "        # get the force channel\n",
    "        sig = next((sig for sig in blk.segments[0].analogsignals if sig.name==channel), None)\n",
    "        if sig is None:\n",
    "            raise Exception(f'For data set \"{data_set_name}\", channel \"{channel}\" could not be found')\n",
    "\n",
    "        # get force from a little before start of dip to 3 seconds after behavior\n",
    "        sig = sig.time_slice(force_dip_start - 0.01*pq.s, behavior_end + 3*pq.s)\n",
    "        sig = sig.rescale('mN')\n",
    "\n",
    "        # find force peak, force baseline, and the force at 80% of peak height relative to baseline\n",
    "        force_peak_time = elephant.spike_train_generation.peak_detection(sig, 0*pq.mN)[0]\n",
    "        force_peak = df.loc[i, 'Force peak (mN)'] = sig[sig.time_index(force_peak_time)][0]\n",
    "        force_baseline = df.loc[i, 'Force baseline (mN)'] = sig[sig.time_index(force_rise_start)][0]\n",
    "        force_80percent = df.loc[i, 'Force 80%-height (mN)'] = force_baseline + 0.8*(force_peak-force_baseline)\n",
    "\n",
    "        # find time when force first rises above the 80%-height threshold\n",
    "        crossings = elephant.spike_train_generation.threshold_detection(sig, force_80percent, 'above')\n",
    "        force_high_start = df.loc[i, 'Force high start (s)'] = crossings[np.where(crossings > force_rise_start)[0][0]].rescale('s')\n",
    "        \n",
    "        # find time when force drops below the 80%-height threshold after peaking\n",
    "        crossings = elephant.spike_train_generation.threshold_detection(sig, force_80percent, 'below')\n",
    "        force_rise_end = df.loc[i, 'Force rise end (s)'] = crossings[np.where(crossings > force_peak_time)[0][0]].rescale('s')\n",
    "        \n",
    "        # find force rise duration and force plateau duration\n",
    "        force_rise_duration = df.loc[i, 'Force rise duration (s)'] = force_rise_end - force_rise_start\n",
    "        force_high_duration = df.loc[i, 'Force high duration (s)'] = force_rise_end - force_high_start\n",
    "        \n",
    "        # find average slope during initial rising phase\n",
    "        force_slope = df.loc[i, 'Force slope (mN/s)'] = ((force_80percent-force_baseline)/(force_high_start-force_rise_start)).rescale('mN/s')\n",
    "\n",
    "        # sanity check: plot 80%-height force threshold\n",
    "        plt.sca(axes[channels_to_keep.index(channel)])\n",
    "        plt.plot([force_rise_start, force_rise_end], [force_80percent, force_80percent], c='gray', lw=1, ls=':')\n",
    "        \n",
    "        # sanity check: plot force dip\n",
    "        sig3 = sig.time_slice(force_dip_start, force_rise_start)\n",
    "        plt.plot(sig3.times, sig3.magnitude, c='#6666ff', lw=2)\n",
    "        \n",
    "        # sanity check: plot force rise\n",
    "        sig2 = sig.time_slice(force_rise_start, force_rise_end)\n",
    "        plt.plot(sig2.times, sig2.magnitude, c='#dd5500', lw=2)\n",
    "        \n",
    "        # sanity check: plot force shoulder\n",
    "        force_shoulder_start = df.loc[i, 'Force shoulder start (s)']*pq.s\n",
    "        force_shoulder_end = df.loc[i, 'Force shoulder end (s)']*pq.s\n",
    "        if np.isfinite(force_shoulder_start):\n",
    "            sig4 = sig.time_slice(force_shoulder_start, force_shoulder_end)\n",
    "            plt.plot(sig4.times, sig4.magnitude, c='#00dd00', lw=2)\n",
    "\n",
    "        # sanity check: plot force baseline, peak, and threshold crossings\n",
    "        plt.plot([force_rise_start], [force_baseline],  marker=6, markersize=5, color='k')\n",
    "        plt.plot([force_peak_time],  [force_peak],      marker=7, markersize=5, color='k')\n",
    "        plt.plot([force_high_start], [force_80percent], marker=5, markersize=5, color='k')\n",
    "        plt.plot([force_rise_end],   [force_80percent], marker=4, markersize=5, color='k')\n",
    "\n",
    "        \n",
    "\n",
    "    # spike train columns must have type object, which\n",
    "    # can be accomplished by initializing with None\n",
    "    units = [\n",
    "        'I2 spikes',\n",
    "        'B8a/b',\n",
    "        'B3',\n",
    "        'B6/B9',\n",
    "        'B38',\n",
    "    ]\n",
    "    for unit in units:\n",
    "        df[unit+' spike train'] = None\n",
    "        df[unit+' inter-spike intervals'] = None\n",
    "        \n",
    "        \n",
    "    \n",
    "    # find spike trains in each behavior\n",
    "    for i in df.index:\n",
    "        behavior_start = df.loc[i, 'Start (s)']*pq.s\n",
    "        behavior_end = df.loc[i, 'End (s)']*pq.s\n",
    "        if lazy:\n",
    "            if metadata['amplitude_discriminators'] is not None:\n",
    "                for discriminator in metadata['amplitude_discriminators']:\n",
    "                    sig = next((sig for sig in blk.segments[0].analogsignals if sig.name == discriminator['channel']), None)\n",
    "                    if sig is not None:\n",
    "                        sig = sig.time_slice(behavior_start - 5*pq.s, behavior_end + 5*pq.s)\n",
    "                        st = _detect_spikes(sig, discriminator, blk.segments[0].epochs)\n",
    "                        st_epoch_start = df.loc[i, discriminator['epoch']+' start (s)']*pq.s\n",
    "                        st_epoch_end = df.loc[i, discriminator['epoch']+' end (s)']*pq.s\n",
    "                        st = st.time_slice(st_epoch_start, st_epoch_end)\n",
    "                        df.at[i, st.name+' spike train'] = st # 'at', not 'loc', is important for inserting list into cell\n",
    "        else:\n",
    "            for spiketrain in blk.segments[0].spiketrains:\n",
    "                discriminator = next((d for d in metadata['amplitude_discriminators'] if d['name'] == spiketrain.name), None)\n",
    "                if discriminator is None:\n",
    "                    raise Exception(f'For data set \"{data_set_name}\", discriminator \"{spiketrain.name}\" could not be found')\n",
    "                st_epoch_start = df.loc[i, discriminator['epoch']+' start (s)']*pq.s\n",
    "                st_epoch_end = df.loc[i, discriminator['epoch']+' end (s)']*pq.s\n",
    "                st = spiketrain.time_slice(st_epoch_start, st_epoch_end)\n",
    "                df.at[i, st.name+' spike train'] = st # 'at', not 'loc', is important for inserting list into cell\n",
    "    \n",
    "    \n",
    "            \n",
    "    # quantify spike trains in each behavior\n",
    "    for i in df.index:\n",
    "        behavior_start = df.loc[i, 'Start (s)']*pq.s\n",
    "        behavior_end = df.loc[i, 'End (s)']*pq.s\n",
    "        for unit in units:\n",
    "            st = df.loc[i, unit+' spike train']\n",
    "            if st is not None:\n",
    "                df.at[i, unit+' inter-spike intervals'] = elephant.statistics.isi(st) # 'at', not 'loc', is important for inserting list into cell\n",
    "                df.loc[i, unit+' spike count'] = len(st)\n",
    "                if len(st) >= 2:\n",
    "                    burst_duration = np.ptp(st)\n",
    "                    df.loc[i, unit+' burst start (s)'] = st.times[0]\n",
    "                    df.loc[i, unit+' burst end (s)'] = st.times[-1]\n",
    "                    df.loc[i, unit+' burst duration (s)'] = burst_duration\n",
    "                    df.loc[i, unit+' burst mean frequency (Hz)'] = ((len(st)-1)/burst_duration).rescale('Hz')\n",
    "                else:\n",
    "                    df.loc[i, unit+' burst duration (s)'] = 0\n",
    "                    df.loc[i, unit+' burst mean frequency (Hz)'] = 0\n",
    "\n",
    "                    \n",
    "                    \n",
    "    # sanity check: plot spikes\n",
    "    for j, i in enumerate(df.index):\n",
    "        behavior_start = df.loc[i, 'Start (s)']*pq.s\n",
    "        behavior_end = df.loc[i, 'End (s)']*pq.s\n",
    "        for k, unit in enumerate(units):\n",
    "            marker = ['.', 'x'][j%2] # alternate markers between behaviors\n",
    "            color = f'C{k%10}' # cycle through colors with units\n",
    "            \n",
    "            st = df.loc[i, unit+' spike train']\n",
    "            if st.size > 0:\n",
    "                channel = st.annotations['channels'][0]\n",
    "                plt.sca(axes[channels_to_keep.index(channel)])\n",
    "                sig = next((sig for sig in blk.segments[0].analogsignals if sig.name == channel), None)\n",
    "                if sig is None:\n",
    "                    raise Exception(f'For data set \"{data_set_name}\", channel \"{channel}\" could not be found')\n",
    "                sig = sig.time_slice(behavior_start - 5*pq.s, behavior_end + 5*pq.s)\n",
    "                sig = sig.rescale(channel_units[channels_to_keep.index(channel)])\n",
    "                spike_amplitudes = np.concatenate([sig[sig.time_index(t)] for t in st] + [[]]) * pq.Quantity(sig.units)\n",
    "                plt.scatter(st.times.rescale('s'), spike_amplitudes, marker=marker, c=color)\n",
    "\n",
    "                discriminator = next((d for d in metadata['amplitude_discriminators'] if d['name'] == st.name), None)\n",
    "                if discriminator is None:\n",
    "                    raise Exception(f'For data set \"{data_set_name}\", discriminator \"{st.name}\" could not be found')\n",
    "                left = df.loc[i, unit+' burst start (s)']*pq.s\n",
    "                right = df.loc[i, unit+' burst end (s)']*pq.s\n",
    "                width = right-left\n",
    "                bottom = pq.Quantity(discriminator['amplitude'][0], discriminator['units']).rescale(sig.units)\n",
    "                top = pq.Quantity(discriminator['amplitude'][1], discriminator['units']).rescale(sig.units)\n",
    "                height = top-bottom\n",
    "                rect = patches.Rectangle((left, bottom), width, height, edgecolor=color, fill=False)\n",
    "                plt.gca().add_patch(rect)\n",
    "\n",
    "            \n",
    "\n",
    "    # find RAUC and mean voltage for each burst in each behavior\n",
    "    unit_to_channel_mapping = {\n",
    "        'I2 protraction activity': channels_to_keep[0],\n",
    "        'B8 activity': channels_to_keep[1],\n",
    "        'B3/6/9/10 activity': channels_to_keep[2],\n",
    "        'B38 activity': channels_to_keep[2],\n",
    "    }\n",
    "    for i in df.index:\n",
    "        \n",
    "        behavior_start = df.loc[i, 'Start (s)']*pq.s\n",
    "        behavior_end = df.loc[i, 'End (s)']*pq.s\n",
    "        \n",
    "        for unit, channel in unit_to_channel_mapping.items():\n",
    "            burst_start = df.loc[i, unit+' start (s)']*pq.s\n",
    "            burst_end = df.loc[i, unit+' end (s)']*pq.s\n",
    "            burst_duration = df.loc[i, unit+' duration (s)']*pq.s\n",
    "            \n",
    "            # get the neural channel\n",
    "            sig = next((sig for sig in blk.segments[0].analogsignals if sig.name==channel), None)\n",
    "            if sig is None:\n",
    "                raise Exception(f'For data set \"{data_set_name}\", channel \"{channel}\" could not be found')\n",
    "        \n",
    "            # get the signal for the behavior with 5 seconds cushion before and after (for better baseline estimation)\n",
    "            sig = sig.time_slice(behavior_start - 5*pq.s, behavior_end + 5*pq.s)\n",
    "            sig = sig.rescale('uV')\n",
    "            \n",
    "            # find burst RAUC and mean voltage\n",
    "            rauc = df.loc[i, unit+' RAUC (μV·s)'] = elephant.signal_processing.rauc(sig, baseline='mean', t_start=burst_start, t_stop=burst_end).rescale('uV*s')\n",
    "            mean_rect_voltage = df.loc[i, unit+' mean rectified voltage (μV)'] = rauc/burst_duration\n",
    "\n",
    "\n",
    "\n",
    "    # find timing delays between neural and force events\n",
    "    for i in df.index:\n",
    "        i2_burst_start = df.loc[i, 'I2 protraction activity start (s)']*pq.s\n",
    "        i2_burst_end = df.loc[i, 'I2 protraction activity end (s)']*pq.s\n",
    "        b8_burst_start = df.loc[i, 'B8 activity start (s)']*pq.s\n",
    "        b8_burst_end = df.loc[i, 'B8 activity end (s)']*pq.s\n",
    "        bn2_burst_start = df.loc[i, 'B3/6/9/10 activity start (s)']*pq.s\n",
    "        bn2_burst_end = df.loc[i, 'B3/6/9/10 activity end (s)']*pq.s\n",
    "        b38_burst_start = df.loc[i, 'B38 activity start (s)']*pq.s\n",
    "        b38_burst_end = df.loc[i, 'B38 activity end (s)']*pq.s\n",
    "        force_dip_start = df.loc[i, 'Force dip start (s)']*pq.s\n",
    "        force_rise_start = df.loc[i, 'Force rise start (s)']*pq.s\n",
    "        force_rise_end = df.loc[i, 'Force rise end (s)']*pq.s\n",
    "        force_shoulder_start = df.loc[i, 'Force shoulder start (s)']*pq.s\n",
    "        force_shoulder_end = df.loc[i, 'Force shoulder end (s)']*pq.s\n",
    "        \n",
    "        i2_force_dip_delay = df.loc[i, 'Delay from I2 end to force dip (s)'] = force_dip_start - i2_burst_end\n",
    "        \n",
    "        b8_force_start_delay = df.loc[i, 'Delay from B8 start to force start (s)'] = force_rise_start - b8_burst_start\n",
    "        b8_force_end_delay = df.loc[i, 'Delay from B8 end to force end (s)'] = force_rise_end - b8_burst_end\n",
    "        \n",
    "        bn2_force_start_delay = df.loc[i, 'Delay from B3/6/9/10 start to force start (s)'] = force_rise_start - bn2_burst_start\n",
    "        bn2_force_end_delay = df.loc[i, 'Delay from B3/6/9/10 end to force end (s)'] = force_rise_end - bn2_burst_end\n",
    "        \n",
    "        b38_shoulder_start_delay = df.loc[i, 'Delay from B38 start to shoulder start (s)'] = force_shoulder_start - b38_burst_start\n",
    "        b38_shoulder_end_delay = df.loc[i, 'Delay from B38 end to shoulder end (s)'] = force_shoulder_end - b38_burst_end\n",
    "\n",
    "\n",
    "        \n",
    "    plt.tight_layout()\n",
    "    \n",
    "    \n",
    "\n",
    "    # renumber behaviors assuming all behaviors are from a single contiguous sequence\n",
    "    df = df.sort_values('Start (s)').reset_index(drop=True).rename_axis('Behavior_index')\n",
    "    \n",
    "    # index the table on 4 variables\n",
    "    df['Animal'] = animal\n",
    "    df['Food'] = food\n",
    "    df['Bout_index'] = bout_index\n",
    "    df = df.reset_index().set_index(['Animal', 'Food', 'Bout_index', 'Behavior_index'])\n",
    "    \n",
    "    df_list += [df]\n",
    "    \n",
    "df_all = pd.concat(df_list, sort=False).sort_index()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Plots"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def scatter2d(ax, data_subsets, xlabel, xlim, ylabel, ylim, trend=False, tooltips=False, padding=0.05):\n",
    "    \n",
    "    for j, (label, query) in enumerate(data_subsets.items()):\n",
    "        if query is not None:\n",
    "            df = df_all.query(query)\n",
    "            ax.scatter(df[xlabel], df[ylabel],\n",
    "                       label=label, marker=markers[j], c=colors[j], clip_on=False)\n",
    "            \n",
    "    all_points = df_all.query(query_union(data_subsets.values()))[[xlabel, ylabel]].dropna()\n",
    "    \n",
    "    if len(all_points) > 0:\n",
    "\n",
    "        xrange = np.ptp(all_points.iloc[:, 0])\n",
    "        xmin = min(all_points.iloc[:, 0]) - xrange * padding\n",
    "        xmax = max(all_points.iloc[:, 0]) + xrange * padding\n",
    "        if xlim is None:\n",
    "            xlim = [xmin, xmax]\n",
    "        if xlim[0] is None:\n",
    "            xlim[0] = xmin\n",
    "        if xlim[1] is None:\n",
    "            xlim[1] = xmax\n",
    "\n",
    "        yrange = np.ptp(all_points.iloc[:, 1])\n",
    "        ymin = min(all_points.iloc[:, 1]) - yrange * padding\n",
    "        ymax = max(all_points.iloc[:, 1]) + yrange * padding\n",
    "        if ylim is None:\n",
    "            ylim = [ymin, ymax]\n",
    "        if ylim[0] is None:\n",
    "            ylim[0] = ymin\n",
    "        if ylim[1] is None:\n",
    "            ylim[1] = ymax\n",
    "        \n",
    "    if trend:\n",
    "        model = sm.OLS(all_points.iloc[:,1], sm.add_constant(all_points.iloc[:,0])).fit()\n",
    "        model_stats = 'R$^2$ = {:.2f}, p = {:.3f}, n = {}'.format(model.rsquared, model.pvalues[1], len(all_points))\n",
    "        print(model_stats)\n",
    "        model_x = np.linspace(xlim[0], xlim[1], 100)\n",
    "        model_y = model.params[0] + model.params[1] * model_x\n",
    "        ax.plot(model_x, model_y, label=model_stats, color='gray')#colors[len(data_subsets)])\n",
    "    \n",
    "    if tooltips:\n",
    "        # create a transparent layer containing all points for detecting mouse events\n",
    "        sc = ax.scatter(all_points.iloc[:, 0], all_points.iloc[:, 1], label=None,\n",
    "                        alpha=0, # transparent points\n",
    "                        s=0.001, # small radius of tooltip activation\n",
    "                       )\n",
    "        \n",
    "        # initialize a hidden empty tooltip\n",
    "        annot = ax.annotate(\n",
    "            '', xy=(0, 0),                              # initialize empty at origin\n",
    "            xytext=(0, 15), textcoords='offset points', # position text above point\n",
    "            color='k', size=10, ha='center',            # small black centered text\n",
    "            bbox=dict(fc='w', lw=0, alpha=0.6),         # transparent white background\n",
    "            arrowprops=dict(shrink=0, headlength=7, headwidth=7, width=0, lw=0, color='k'), # small black arrow\n",
    "        )\n",
    "        annot.set_visible(False)\n",
    "        \n",
    "        # prepare tooltip contents\n",
    "        tooltip_text = [' '.join([str(x) for x in index]) for index in list(all_points.index)]\n",
    "        \n",
    "        # bind the animation of tooltips to a hover event\n",
    "        def hover(event):\n",
    "            if event.inaxes == ax:\n",
    "                cont, ind = sc.contains(event)\n",
    "                if cont:\n",
    "                    point_index = ind['ind'][0]\n",
    "                    pos = sc.get_offsets()[point_index]\n",
    "                    annot.xy = pos\n",
    "                    annot.set_text(tooltip_text[point_index])\n",
    "                    annot.set_visible(True)\n",
    "                    ax.figure.canvas.draw_idle()\n",
    "                else:\n",
    "                    if annot.get_visible():\n",
    "                        annot.set_visible(False)\n",
    "                        ax.figure.canvas.draw_idle()\n",
    "        ax.figure.canvas.mpl_connect('motion_notify_event', hover)\n",
    "        \n",
    "    ax.set_xlabel(xlabel)\n",
    "    ax.set_xlim(xlim)\n",
    "    ax.set_ylabel(ylabel)#.replace('rectified ',''))\n",
    "    ax.set_ylim(ylim)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Figure 3: B3/6/9/10 and the rise, or B8 and the rise"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__TODO:__\n",
    "\n",
    "* Plot mean voltage on BN2 during B3/6/9/10 acitivty vs slope or relative rise in force ?\n",
    "* Use firing frequency thresholds to crop neural activity window ?\n",
    "* Example panel illustating measurements, with example data point marked in scatter plot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(5, 5))\n",
    "ax = plt.gca()\n",
    "\n",
    "data_subsets = [\n",
    "    'JG08 Tape nori',\n",
    "    'JG12 Tape nori',\n",
    "]\n",
    "data_subsets = {label:label2query(label) for label in data_subsets}\n",
    "\n",
    "xlabel, xlim = 'B3/6/9/10 activity duration (s)', [0, 8]\n",
    "ylabel, ylim = 'Force rise duration (s)', [0, 8]\n",
    "\n",
    "scatter2d(ax, data_subsets, xlabel, xlim, ylabel, ylim, trend=False, tooltips=False)\n",
    "plt.plot([0, 999], [0, 999], ls=':', c='gray', zorder=0)\n",
    "ax.legend()\n",
    "sns.despine(ax=ax, offset=20, trim=True)\n",
    "plt.tight_layout()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(5, 5))\n",
    "ax = plt.gca()\n",
    "\n",
    "data_subsets = [\n",
    "    'JG08 Tape nori',\n",
    "    'JG12 Tape nori',\n",
    "]\n",
    "data_subsets = {label:label2query(label) for label in data_subsets}\n",
    "\n",
    "xlabel, xlim = 'B8 activity duration (s)', [0, 8]\n",
    "ylabel, ylim = 'Force rise duration (s)', [0, 8]\n",
    "\n",
    "scatter2d(ax, data_subsets, xlabel, xlim, ylabel, ylim, trend=False, tooltips=False)\n",
    "plt.plot([0, 999], [0, 999], ls=':', c='gray', zorder=0)\n",
    "ax.legend()\n",
    "sns.despine(ax=ax, offset=20, trim=True)\n",
    "plt.tight_layout()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(5, 5))\n",
    "ax = plt.gca()\n",
    "\n",
    "df = df_all.reset_index()\n",
    "df = df.rename(columns={\n",
    "    'Delay from B3/6/9/10 start to force start (s)': 'Start of burst',\n",
    "    'Delay from B3/6/9/10 end to force end (s)':     'End of burst'})\n",
    "df = pd.melt(df,\n",
    "             id_vars=['Animal', 'Food', 'Bout_index', 'Behavior_index'],\n",
    "             value_vars=['Start of burst', 'End of burst'],\n",
    "             var_name='When?',\n",
    "             value_name='Delay from B3/6/9/10 to force (s)')\n",
    "\n",
    "sns.violinplot(y='Animal', x='Delay from B3/6/9/10 to force (s)', hue='When?', data=df, inner='points')#, split=True)\n",
    "\n",
    "plt.axvline(x=0, ls=':', c='gray', zorder=-1)\n",
    "\n",
    "plt.tight_layout()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(5, 5))\n",
    "ax = plt.gca()\n",
    "\n",
    "df = df_all.reset_index()\n",
    "df = df.rename(columns={\n",
    "    'Delay from B8 start to force start (s)': 'Start of burst',\n",
    "    'Delay from B8 end to force end (s)':     'End of burst'})\n",
    "df = pd.melt(df,\n",
    "             id_vars=['Animal', 'Food', 'Bout_index', 'Behavior_index'],\n",
    "             value_vars=['Start of burst', 'End of burst'],\n",
    "             var_name='When?',\n",
    "             value_name='Delay from B8 to force (s)')\n",
    "\n",
    "sns.violinplot(y='Animal', x='Delay from B8 to force (s)', hue='When?', data=df, inner='points')#, split=True)\n",
    "\n",
    "plt.axvline(x=0, ls=':', c='gray', zorder=-1)\n",
    "\n",
    "plt.tight_layout()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__TODO__:\n",
    "\n",
    "* The section of BN2 that should be compared to force slope should be calculated backwards from threshold crossing, esp. to exclude neural activity responsible for plateau, after slope had leveled out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(5, 5))\n",
    "ax = plt.gca()\n",
    "\n",
    "data_subsets = [\n",
    "    'JG08 Tape nori',\n",
    "    'JG12 Tape nori',\n",
    "]\n",
    "data_subsets = {label:label2query(label) for label in data_subsets}\n",
    "\n",
    "xlabel, xlim = 'B3/6/9/10 activity mean rectified voltage (μV)', [0, None]\n",
    "ylabel, ylim = 'Force slope (mN/s)', [0, None]\n",
    "\n",
    "scatter2d(ax, data_subsets, xlabel, xlim, ylabel, ylim, trend=False, tooltips=True)\n",
    "ax.legend()\n",
    "sns.despine(ax=ax, offset=20, trim=True)\n",
    "plt.tight_layout()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(5, 5))\n",
    "ax = plt.gca()\n",
    "\n",
    "data_subsets = [\n",
    "    'JG08 Tape nori',\n",
    "    'JG12 Tape nori',\n",
    "]\n",
    "data_subsets = {label:label2query(label) for label in data_subsets}\n",
    "\n",
    "xlabel, xlim = 'B8 activity mean rectified voltage (μV)', [0, None]\n",
    "ylabel, ylim = 'Force slope (mN/s)', [0, None]\n",
    "\n",
    "scatter2d(ax, data_subsets, xlabel, xlim, ylabel, ylim, trend=False, tooltips=True)\n",
    "ax.legend()\n",
    "sns.despine(ax=ax, offset=20, trim=True)\n",
    "plt.tight_layout()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Figure 4: Peak protraction and the dip"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(5, 5))\n",
    "ax = plt.gca()\n",
    "\n",
    "df = df_all.reset_index()\n",
    "\n",
    "sns.violinplot(y='Animal', x='Delay from I2 end to force dip (s)', data=df, inner='points')\n",
    "\n",
    "plt.axvline(x=0, ls=':', c='gray', zorder=-1)\n",
    "\n",
    "plt.tight_layout()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Figure 6: B3 and the plateau"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(5, 5))\n",
    "ax = plt.gca()\n",
    "\n",
    "data_subsets = [\n",
    "    'JG08 Tape nori',\n",
    "    'JG12 Tape nori',\n",
    "]\n",
    "data_subsets = {label:label2query(label) for label in data_subsets}\n",
    "\n",
    "xlabel, xlim = 'B3 burst duration (s)', [0, 5]\n",
    "ylabel, ylim = 'Force high duration (s)', [0, 5]\n",
    "\n",
    "scatter2d(ax, data_subsets, xlabel, xlim, ylabel, ylim, trend=False, tooltips=False)\n",
    "plt.plot([0, 999], [0, 999], ls=':', c='gray', zorder=0)\n",
    "ax.legend()\n",
    "sns.despine(ax=ax, offset=20, trim=True)\n",
    "plt.tight_layout()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Figure 7: B38 and the shoulder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(5, 5))\n",
    "ax = plt.gca()\n",
    "\n",
    "data_subsets = [\n",
    "    'JG08 Tape nori',\n",
    "    'JG12 Tape nori',\n",
    "]\n",
    "data_subsets = {label:label2query(label) for label in data_subsets}\n",
    "\n",
    "xlabel, xlim = 'B38 activity duration (s)', [0, 6]\n",
    "ylabel, ylim = 'Force shoulder duration (s)', [0, 6]\n",
    "\n",
    "scatter2d(ax, data_subsets, xlabel, xlim, ylabel, ylim, trend=False, tooltips=False)\n",
    "plt.plot([0, 999], [0, 999], ls=':', c='gray', zorder=0)\n",
    "ax.legend()\n",
    "sns.despine(ax=ax, offset=20, trim=True)\n",
    "plt.tight_layout()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(5, 5))\n",
    "ax = plt.gca()\n",
    "\n",
    "df = df_all.reset_index()\n",
    "df = df.rename(columns={\n",
    "    'Delay from B38 start to shoulder start (s)': 'Start of burst',\n",
    "    'Delay from B38 end to shoulder end (s)':     'End of burst'})\n",
    "df = pd.melt(df,\n",
    "             id_vars=['Animal', 'Food', 'Bout_index', 'Behavior_index'],\n",
    "             value_vars=['Start of burst', 'End of burst'],\n",
    "             var_name='When?',\n",
    "             value_name='Delay from B38 to shoulder (s)')\n",
    "\n",
    "sns.violinplot(y='Animal', x='Delay from B38 to shoulder (s)', hue='When?', data=df, inner='points')#, split=True)\n",
    "\n",
    "plt.axvline(x=0, ls=':', c='gray', zorder=-1)\n",
    "\n",
    "plt.tight_layout()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
