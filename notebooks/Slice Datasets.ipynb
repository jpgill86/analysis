{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import quantities as pq\n",
    "import neo\n",
    "import neurotic\n",
    "import axographio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "export_dir = '../../data/data-for-paper'\n",
    "if not os.path.exists(export_dir):\n",
    "    os.mkdir(export_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "metadata_file = '../../data/metadata.yml'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "epoch_types_to_keep = [\n",
    "    'Swallow (regular 5-cm nori strip)',\n",
    "    'Swallow (tape nori)',\n",
    "    'B38 activity',\n",
    "    'I2 protraction activity',\n",
    "    'B8 activity',\n",
    "    'B3/6/9/10 activity',\n",
    "    'B4/B5 activity',\n",
    "    'Inward movement',\n",
    "    'Force shoulder end',\n",
    "    'Force rise start',\n",
    "    'Force plateau start',\n",
    "    'Force plateau end',\n",
    "    'Force drop end',\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "channel_names_by_animal = {\n",
    "    'Animal 1': ['I2-L', 'RN-L', 'BN2-L', 'BN3-L',    'Force'],\n",
    "    'Animal 2': ['I2',   'RN',   'BN2',   'BN3',      'Force'],\n",
    "    'Animal 3': ['I2',   'RN',   'BN2',   'BN3-PROX', 'Force'],\n",
    "    'Animal 4': ['I2',   'RN',   'BN2',   'BN3-DIST', 'Force'],\n",
    "    'Animal 5': ['I2',   'RN',   'BN2',   'BN3-PROX', 'Force'],\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "datasets = {\n",
    "    'Animal 1 Unloaded 1': ('IN VIVO / JG07 / 2018-05-20 / 002', [1169, 1191]), # 4 swallows\n",
    "    'Animal 1 Unloaded 2': ('IN VIVO / JG07 / 2018-05-20 / 002', [1495, 1518]), # 4 swallows\n",
    "    'Animal 1 Unloaded 3': ('IN VIVO / JG07 / 2018-05-20 / 002', [1581, 1615]), # 5 swallows\n",
    "    'Animal 1 Loaded 1':   ('IN VIVO / JG07 / 2018-05-20 / 002', [2716, 2755]), # 5 swallows\n",
    "    \n",
    "    'Animal 2 Unloaded 1': ('IN VIVO / JG08 / 2018-06-21 / 002', [ 256,  287]), # 4 swallows\n",
    "    'Animal 2 Unloaded 2': ('IN VIVO / JG08 / 2018-06-21 / 002', [ 454,  481]), # 4 swallows\n",
    "    'Animal 2 Loaded 1':   ('IN VIVO / JG08 / 2018-06-21 / 002', [ 141,  210]), # 7 swallows, some bucket and head movement\n",
    "    'Animal 2 Loaded 2':   ('IN VIVO / JG08 / 2018-06-21 / 002', [ 660,  701]), # 5 swallows, large bucket movement\n",
    "    'Animal 2 Loaded 3':   ('IN VIVO / JG08 / 2018-06-21 / 002', [1448, 1477]), # 3 swallows, some bucket movement\n",
    "    \n",
    "    'Animal 3 Unloaded 1': ('IN VIVO / JG11 / 2019-04-03 / 001', [1791, 1819]), # 5 swallows\n",
    "    'Animal 3 Unloaded 2': ('IN VIVO / JG11 / 2019-04-03 / 004', [ 551,  568]), # 3 swallows\n",
    "    'Animal 3 Loaded 1':   ('IN VIVO / JG11 / 2019-04-03 / 004', [1226, 1280]), # 5 swallows, inward food movements had very low amplitude\n",
    "    \n",
    "    'Animal 4 Unloaded 1': ('IN VIVO / JG12 / 2019-05-10 / 002', [ 147,  165]), # 3 swallows\n",
    "    'Animal 4 Unloaded 2': ('IN VIVO / JG12 / 2019-05-10 / 002', [ 228,  245]), # 3 swallows\n",
    "    'Animal 4 Unloaded 3': ('IN VIVO / JG12 / 2019-05-10 / 002', [ 277,  291]), # 3 swallows\n",
    "    'Animal 4 Loaded 1':   ('IN VIVO / JG12 / 2019-05-10 / 002', [ 434,  465]), # 4 swallows\n",
    "    'Animal 4 Loaded 2':   ('IN VIVO / JG12 / 2019-05-10 / 002', [2897, 2937]), # 5 swallows\n",
    "    \n",
    "    'Animal 4 Unloaded 2 Superset': ('IN VIVO / JG12 / 2019-05-10 / 002', [ 223.4,  261.4]), # Fig 2A\n",
    "    'Animal 4 Loaded 2 Superset':   ('IN VIVO / JG12 / 2019-05-10 / 002', [2875.3, 3039.3]), # Fig 2B & 1\n",
    "    \n",
    "    'Animal 5 Unloaded 1': ('IN VIVO / JG14 / 2019-07-30 / 001', [1834, 1865]), # 4 swallows\n",
    "    'Animal 5 Unloaded 2': ('IN VIVO / JG14 / 2019-07-30 / 001', [1909, 1943]), # 5 swallows\n",
    "    'Animal 5 Unloaded 3': ('IN VIVO / JG14 / 2019-07-30 / 001', [2049, 2084]), # 5 swallows\n",
    "    'Animal 5 Loaded 1':   ('IN VIVO / JG14 / 2019-07-29 / 004', [ 828,  870]), # 5 swallows\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "metadata = neurotic.MetadataSelector(metadata_file)\n",
    "\n",
    "for label, (data_set_name, time_window) in datasets.items():\n",
    "    metadata.select(data_set_name)\n",
    "    \n",
    "    if 'annotations_file' in metadata and metadata['annotations_file'] is not None:\n",
    "        # read the file\n",
    "        csv_file = metadata.abs_path('annotations_file')\n",
    "        df = pd.read_csv(csv_file)\n",
    "        \n",
    "        # filter rows by time\n",
    "        df = df[(df['Start (s)'] >= time_window[0]) & (df['End (s)'] <= time_window[1])]\n",
    "        \n",
    "        # filter rows by epoch type\n",
    "        df = df.query(f'Type in {epoch_types_to_keep}')\n",
    "        \n",
    "        # export the filtered annotations\n",
    "        export_file = os.path.join(export_dir, f'{label} Annotations.csv')\n",
    "        df.round(6).to_csv(export_file, index=False)\n",
    "\n",
    "    if 'epoch_encoder_file' in metadata and metadata['epoch_encoder_file'] is not None:\n",
    "        # read the file\n",
    "        csv_file = metadata.abs_path('epoch_encoder_file')\n",
    "        df = pd.read_csv(csv_file)\n",
    "        \n",
    "        # filter rows by time\n",
    "        df = df[(df['Start (s)'] >= time_window[0]) & (df['End (s)'] <= time_window[1])]\n",
    "        \n",
    "        # filter rows by epoch type\n",
    "        df = df.query(f'Type in {epoch_types_to_keep}')\n",
    "        \n",
    "        # export the filtered annotations\n",
    "        export_file = os.path.join(export_dir, f'{label} Epoch Encoder.csv')\n",
    "        df.round(6).to_csv(export_file, index=False)\n",
    "\n",
    "    if 'data_file' in metadata and metadata['data_file'] is not None:\n",
    "        # open the file\n",
    "        axo_file = metadata.abs_path('data_file')\n",
    "        r = neo.io.AxographIO(axo_file)\n",
    "        blk = r.read_block(lazy=True, signal_group_mode='split-all')\n",
    "        \n",
    "        # load signal slices\n",
    "        channels_to_keep = channel_names_by_animal[label[:8]]\n",
    "        sigs = []\n",
    "        for channel in channels_to_keep:\n",
    "            sig = next((sig for sig in blk.segments[0].analogsignals if sig.name == channel), None)\n",
    "            if sig is not None:\n",
    "                t_start = time_window[0]*pq.s - 0.01*pq.ms\n",
    "                t_stop = time_window[1]*pq.s + 0.01*pq.ms\n",
    "                sigs.append(sig.time_slice(t_start, t_stop))\n",
    "        \n",
    "        # write the signal slices to an AxoGraph file\n",
    "        export_file = os.path.join(export_dir, f'{label}.axgx')\n",
    "        times = axographio.linearsequence(\n",
    "            sigs[0].times.size,\n",
    "            sigs[0].t_start.rescale('s').magnitude,\n",
    "            sigs[0].sampling_period.rescale('s').magnitude\n",
    "        )\n",
    "        data = [times]\n",
    "        names = ['Time (s)']\n",
    "        for sig in sigs:\n",
    "            index = np.where(r.header['signal_channels']['name'] == sig.name)[0][0]\n",
    "            gain = r.header['signal_channels']['gain'][index]\n",
    "            offset = r.header['signal_channels']['offset'][index]\n",
    "            short_array = np.round((sig.as_array().flatten()-offset)/gain).astype(int)\n",
    "            data.append(axographio.scaledarray(short_array, gain, offset))\n",
    "            names.append(f'{sig.name} ({sig.dimensionality.string})')\n",
    "        f = axographio.file_contents(names, data)\n",
    "        f.write(export_file)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**IMPORTANT:** After writing the sliced AxoGraph files, each file should be opened in AxoGraph and re-saved to fix some missing metadata that is required for ``neo.rawio.AxographRawIO`` to read it. You may also want to execute the \"Separate Traces\" menu action so that the channels are not stacked."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
